Title,Abstract,Cleaned Abstract,DIM_1,DIM_2,Clusters,Cluster Keywords,Cluster Titles
Fundamental requirements of a machine learning operations platform for industrial metal additive manufacturing,"AbstractMetal-based Additive Manufacturing (AM) can realize fully dense metallic components and thus offers an opportunity to compete with conventional manufacturing based on the unique merits possible through layer-by-layer processing. Unsurprisingly, Machine Learning (ML) applications in AM technologies have been increasingly growing in the past several years. The trend is driven by the ability of data-driven techniques to support a range of AM concerns, including in-process monitoring and predictions. However, despite numerous ML applications being reported for different AM concerns, no framework exists to systematically manage these ML models for AM operations in the industry. Moreover, no guidance exists on fundamental requirements to realize such a cross-disciplinary platform. Working with experts in ML and AM, this work identifies the fundamental requirements to realize a Machine Learning Operations (MLOps) platform to support process-based ML models for industrial metal AM (MAM). Project-level activities are identified in terms of functional roles, processes, systems, operations, and interfaces. These components are discussed in detail and are linked with their respective requirements. In this regard, peer-reviewed references to identified requirements are made available. The requirements identified can help guide small and medium enterprises looking to implement ML solutions for AM in the industry. Challenges and opportunities for such a system are highlighted. The system can be expanded to include other lifecycle phases of metallic and non-metallic AM.Highlights •Connecting the status of ML-driven AM research and applications to the development of a platform for industrial deployment.•Identifying AM and ML requirements to develop an MLOps platform for industry.•Detailing functional roles, processes, systems, operations, and interfaces as fundamental components of the MLOps platform.•Bridging the knowledge gap and expertise between the domains of AM and ML to realize the cross-discipline platform.•Referencing peer-reviewed AM and ML research in support of the identified requirements.",abstractmetal based additive manufacturing  am  can realize fully dense metallic components and thus offers an opportunity to compete with conventional manufacturing based on the unique merits possible through layer by layer processing  unsurprisingly  machine learning  ml  applications in am technologies have been increasingly growing in the past several years  the trend is driven by the ability of data driven techniques to support a range of am concerns  including in process monitoring and predictions  however  despite numerous ml applications being reported for different am concerns  no framework exists to systematically manage these ml models for am operations in the industry  moreover  no guidance exists on fundamental requirements to realize such a cross disciplinary platform  working with experts in ml and am  this work identifies the fundamental requirements to realize a machine learning operations  mlops  platform to support process based ml models for industrial metal am  mam   project level activities are identified in terms of functional roles  processes  systems  operations  and interfaces  these components are discussed in detail and are linked with their respective requirements  in this regard  peer reviewed references to identified requirements are made available  the requirements identified can help guide small and medium enterprises looking to implement ml solutions for am in the industry  challenges and opportunities for such a system are highlighted  the system can be expanded to include other lifecycle phases of metallic and non metallic am highlights  connecting the status of ml driven am research and applications to the development of a platform for industrial deployment  identifying am and ml requirements to develop an mlops platform for industry  detailing functional roles  processes  systems  operations  and interfaces as fundamental components of the mlops platform  bridging the knowledge gap and expertise between the domains of am and ml to realize the cross discipline platform  referencing peer reviewed am and ml research in support of the identified requirements ,8.913391,4.7388005,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
LinkEdge: Open-sourced MLOps Integration with IoT Edge,"MLOps, or Machine Learning Operations, play a significant role in streamlining production deployment, monitoring, and management of machine learning models. Integrating MLOps with edge devices poses unique challenges that require customised deployment strategies and efficient model optimisation techniques. This paper introduces LinkEdge, a set of tools that enable the integration of MLOps practices with edge devices. LinkEdge consists of two sets of tools: one for setting up infrastructure within edge devices to be able to receive, monitor, and run inference on ML models and another for MLOps pipelines to package models to be compatible with the inference and monitoring components of the respective edge devices. The LinkEdge platform is evaluated by obtaining a public dataset for predicting the breakdown of Air Pressure Systems in trucks. Additionally, the platform is compared against a commercial tool that serves similar purposes. The overall performance of LinkEdge matches that of already existing tools and services while allowing end users setting up Edge-MLOps infrastructure the complete freedom to set up their system without entirely relying on third-party licensed software.",mlops  or machine learning operations  play a significant role in streamlining production deployment  monitoring  and management of machine learning models  integrating mlops with edge devices poses unique challenges that require customised deployment strategies and efficient model optimisation techniques  this paper introduces linkedge  a set of tools that enable the integration of mlops practices with edge devices  linkedge consists of two sets of tools  one for setting up infrastructure within edge devices to be able to receive  monitor  and run inference on ml models and another for mlops pipelines to package models to be compatible with the inference and monitoring components of the respective edge devices  the linkedge platform is evaluated by obtaining a public dataset for predicting the breakdown of air pressure systems in trucks  additionally  the platform is compared against a commercial tool that serves similar purposes  the overall performance of linkedge matches that of already existing tools and services while allowing end users setting up edge mlops infrastructure the complete freedom to set up their system without entirely relying on third party licensed software ,7.616082,6.693407,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
MLOps Automation – Developing a RESTful API for Text Based Emotion Detection,"Identifying the emotional state of a person or group of people by analyzing their written works often appears to be challenging but also important. In many situations, we see that emotions from textual expressions cannot be detected directly using emotional words alone but also results from the evaluation of the conceptual meaning and interactions which are expressed in a written article. A person's emotion may be revealed by their facial expression, speech, or text. In todays’ world we have seen that efforts have been made in identifying emotion from speech and facial expressions, but the aspect of text-based emotion detection is still lagging. The detection of human emotions from text is becoming progressively important from an applicative perspective. The paper proposed an algorithm for detecting emotions from text using logistic regression. The authors have developed a RESTful API to serve as a mediator between a client device and the trained model by adopting the principles of Machine Learning Operations (MLOps).",identifying the emotional state of a person or group of people by analyzing their written works often appears to be challenging but also important  in many situations  we see that emotions from textual expressions cannot be detected directly using emotional words alone but also results from the evaluation of the conceptual meaning and interactions which are expressed in a written article  a person s emotion may be revealed by their facial expression  speech  or text  in todays  world we have seen that efforts have been made in identifying emotion from speech and facial expressions  but the aspect of text based emotion detection is still lagging  the detection of human emotions from text is becoming progressively important from an applicative perspective  the paper proposed an algorithm for detecting emotions from text using logistic regression  the authors have developed a restful api to serve as a mediator between a client device and the trained model by adopting the principles of machine learning operations  mlops  ,7.215679,5.6643586,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
MLOps: five steps to guide its effective implementation,"DevOps practices have increasingly been applied to software development and engineering, as well as the machine learning lifecycle - in a process also known as MLOps. Today, many companies and professionals have been working and writing on this topic. However, in the academic and scientific literature, few results can be found on MLOps and how to implement it efficiently. This paper presents five essential steps to guide the understanding and practice of MLOps, which, based on the authors' research and experience, can assist in its effective implementation. The study aims to serve as a reference guide for all those who wish to learn more about the topic and intend to implement MLOps practices in the development of their systems.",devops practices have increasingly been applied to software development and engineering  as well as the machine learning lifecycle   in a process also known as mlops  today  many companies and professionals have been working and writing on this topic  however  in the academic and scientific literature  few results can be found on mlops and how to implement it efficiently  this paper presents five essential steps to guide the understanding and practice of mlops  which  based on the authors  research and experience  can assist in its effective implementation  the study aims to serve as a reference guide for all those who wish to learn more about the topic and intend to implement mlops practices in the development of their systems ,8.489512,5.164794,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
MLOps Challenges in Industry 4.0,"AbstractAn important part of the Industry 4.0 vision is the use of machine learning (ML) techniques to create novel capabilities and flexibility in industrial production processes. Currently, there is a strong emphasis on MLOps as an enabling collection of practices, techniques, and tools to integrate ML into industrial practice. However, while MLOps is often discussed in the context of pure software systems, Industry 4.0 systems received much less attention. So far, there is only little research focusing on MLOps for Industry 4.0. In this paper, we discuss whether MLOps in Industry 4.0 leads to significantly different challenges compared to typical Internet systems. We provide an initial analysis of MLOps approaches and identify both context-independent MLOps challenges (general challenges) as well as challenges particular to Industry 4.0 (specific challenges) and conclude that MLOps works very similarly in Industry 4.0 systems to pure software systems. This indicates that existing tools and approaches are also mostly suited for the Industry 4.0 context.",abstractan important part of the industry     vision is the use of machine learning  ml  techniques to create novel capabilities and flexibility in industrial production processes  currently  there is a strong emphasis on mlops as an enabling collection of practices  techniques  and tools to integrate ml into industrial practice  however  while mlops is often discussed in the context of pure software systems  industry     systems received much less attention  so far  there is only little research focusing on mlops for industry      in this paper  we discuss whether mlops in industry     leads to significantly different challenges compared to typical internet systems  we provide an initial analysis of mlops approaches and identify both context independent mlops challenges  general challenges  as well as challenges particular to industry      specific challenges  and conclude that mlops works very similarly in industry     systems to pure software systems  this indicates that existing tools and approaches are also mostly suited for the industry     context ,10.179603,4.168892,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
MLOps Pipeline Development: The OSSARA Use Case,"Software development based on MLOps practices is entering its early adoption stage. As for it, practitioners and researchers are starting to develop pipelines composed of tools capable of automating the whole software lifecycle. The development of the pipeline however is not as straightforward as it looks and some key points need to be addressed. In this work, we propose our vision for the development of the MLOps pipeline by showing what to keep into account when choosing the tools for each step of a pipeline. The proposition has been backed up by describing a developed use case scenario: the OSSARA use case. We believe that the presented use case, as well as the remarks presented for the process of tool selection for each MLOps phase, will help practitioners and researchers in the process of developing their own pipelines.",software development based on mlops practices is entering its early adoption stage  as for it  practitioners and researchers are starting to develop pipelines composed of tools capable of automating the whole software lifecycle  the development of the pipeline however is not as straightforward as it looks and some key points need to be addressed  in this work  we propose our vision for the development of the mlops pipeline by showing what to keep into account when choosing the tools for each step of a pipeline  the proposition has been backed up by describing a developed use case scenario  the ossara use case  we believe that the presented use case  as well as the remarks presented for the process of tool selection for each mlops phase  will help practitioners and researchers in the process of developing their own pipelines ,9.210491,5.589207,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
MLOps: a guide to its adoption in the context of responsible AI,"DevOps practices have increasingly been applied to software development as well as the machine learning lifecycle, in a process known as MLOps. Currently, many professionals have written about this topic, but still few results can be found in the academic and scientific literature on MLOps and how to to implement it effectively. Considering aspects of responsible AI, this number is even lower, opening up a field of research with many possibilities. This article presents five steps to guide the understanding and adoption of MLOps in the context of responsible AI. The study aims to serve as a reference guide for all those who wish to learn more about the topic and intend to implement MLOps practices to develop their systems, following responsible AI principles.",devops practices have increasingly been applied to software development as well as the machine learning lifecycle  in a process known as mlops  currently  many professionals have written about this topic  but still few results can be found in the academic and scientific literature on mlops and how to to implement it effectively  considering aspects of responsible ai  this number is even lower  opening up a field of research with many possibilities  this article presents five steps to guide the understanding and adoption of mlops in the context of responsible ai  the study aims to serve as a reference guide for all those who wish to learn more about the topic and intend to implement mlops practices to develop their systems  following responsible ai principles ,8.907647,5.139412,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
MLOps in freight rail operations,"AbstractRailways are essential for freight transport due to their operational reliability advantages, but maintaining this advantage requires optimised railway infrastructure. Previous research has developed models to predict freight rail disruptions/disturbances and their associated delay times, in order to better understand the impact of multiple factors on them. However, because these models are built on static datasets, extracting real value from a model in a production environment remains difficult.This paper presents a methodology that demonstrates the potential of MLOps in automating the entire workflow, from data extraction to model deployment for real-time delay predictions in freight rail operations, including good practices of Continuous-Integration, Continuous-Delivery, and Continuous-Training, as well as a tool list for each process.Our research advances the field of railway operations by developing an entire MLOps workflow using data from the freight rail operations of the Luxembourgish National Freight Railway Company over a seventeen-month period. Furthermore, we employed a LightGBM model that had previously performed well in another study. This workflow can be automatically triggered to develop the processes and thus maintain an ML model capable of predicting delay times for CFL Multimodal operations in real-time.Our findings demonstrate that MLOps have the potential to automate the entire process, opening up new avenues for future research in this field. Although the methodology presented is intended to optimise freight rail operations for a specific company, it can be easily transferable to other railway companies or other transportation industries, such as aviation, shipping, and trucking.",abstractrailways are essential for freight transport due to their operational reliability advantages  but maintaining this advantage requires optimised railway infrastructure  previous research has developed models to predict freight rail disruptions disturbances and their associated delay times  in order to better understand the impact of multiple factors on them  however  because these models are built on static datasets  extracting real value from a model in a production environment remains difficult this paper presents a methodology that demonstrates the potential of mlops in automating the entire workflow  from data extraction to model deployment for real time delay predictions in freight rail operations  including good practices of continuous integration  continuous delivery  and continuous training  as well as a tool list for each process our research advances the field of railway operations by developing an entire mlops workflow using data from the freight rail operations of the luxembourgish national freight railway company over a seventeen month period  furthermore  we employed a lightgbm model that had previously performed well in another study  this workflow can be automatically triggered to develop the processes and thus maintain an ml model capable of predicting delay times for cfl multimodal operations in real time our findings demonstrate that mlops have the potential to automate the entire process  opening up new avenues for future research in this field  although the methodology presented is intended to optimise freight rail operations for a specific company  it can be easily transferable to other railway companies or other transportation industries  such as aviation  shipping  and trucking ,10.258245,4.3427095,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Applications of MLOps in the Cognitive Cloud Continuum,"AbstractBackground. Since the rise of Machine Learning, the automation of software development has been a desired feature. MLOps is targeted to have the same impact on software development as DevOps had in the last decade.Objectives. The goal of the research is threefold: (RQ1) to analyze which MLOps tools and platforms can be used in the Cognitive Cloud Continuum, (RQ2) to investigate which combination of such tools and platforms is more beneficial, and (RQ3) to define how to distribute MLOps to nodes across the Cognitive Cloud Continuum.Methods. The work can be divided into three main blocks: analysis, proposal and identification, and application. The first part builds the foundations of the work, the second proposes a vision on the evolution of MLOps then identifies the key concepts while the third validates the previous steps through practical applications.Contribution. The thesis’s contribution is a set of MLOps pipelines that practitioners could adopt in different contexts and a practical implementation of an MLOps system in the Cognitive Cloud Continuum.",abstractbackground  since the rise of machine learning  the automation of software development has been a desired feature  mlops is targeted to have the same impact on software development as devops had in the last decade objectives  the goal of the research is threefold   rq   to analyze which mlops tools and platforms can be used in the cognitive cloud continuum   rq   to investigate which combination of such tools and platforms is more beneficial  and  rq   to define how to distribute mlops to nodes across the cognitive cloud continuum methods  the work can be divided into three main blocks  analysis  proposal and identification  and application  the first part builds the foundations of the work  the second proposes a vision on the evolution of mlops then identifies the key concepts while the third validates the previous steps through practical applications contribution  the thesis s contribution is a set of mlops pipelines that practitioners could adopt in different contexts and a practical implementation of an mlops system in the cognitive cloud continuum ,8.804704,4.825488,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
SensiX++: Bringing MLOps and Multi-tenant Model Serving to Sensory Edge Devices,"We present SensiX++, a multi-tenant runtime for adaptive model execution with integrated MLOps on edge devices, e.g., a camera, a microphone, or IoT sensors. SensiX++ operates on two fundamental principles: highly modular componentisation to externalise data operations with clear abstractions and document-centric manifestation for system-wide orchestration. First, a data coordinator manages the lifecycle of sensors and serves models with correct data through automated transformations. Next, a resource-aware model server executes multiple models in isolation through model abstraction, pipeline automation, and feature sharing. An adaptive scheduler then orchestrates the best-effort executions of multiple models across heterogeneous accelerators, balancing latency and throughput. Finally, microservices with REST APIs serve synthesised model predictions, system statistics, and continuous deployment. Collectively, these components enable SensiX++ to serve multiple models efficiently with fine-grained control on edge devices while minimising data operation redundancy, managing data and device heterogeneity, and reducing resource contention. We benchmark SensiX++ with 10 different vision and acoustics models across various multi-tenant configurations on different edge accelerators (Jetson AGX and Coral TPU) designed for sensory devices. We report on the overall throughput and quantified benefits of various automation components of SensiX++ and demonstrate its efficacy in significantly reducing operational complexity and lowering the effort to deploy, upgrade, reconfigure, and serve embedded models on edge devices.",we present sensix    a multi tenant runtime for adaptive model execution with integrated mlops on edge devices  e g   a camera  a microphone  or iot sensors  sensix   operates on two fundamental principles  highly modular componentisation to externalise data operations with clear abstractions and document centric manifestation for system wide orchestration  first  a data coordinator manages the lifecycle of sensors and serves models with correct data through automated transformations  next  a resource aware model server executes multiple models in isolation through model abstraction  pipeline automation  and feature sharing  an adaptive scheduler then orchestrates the best effort executions of multiple models across heterogeneous accelerators  balancing latency and throughput  finally  microservices with rest apis serve synthesised model predictions  system statistics  and continuous deployment  collectively  these components enable sensix   to serve multiple models efficiently with fine grained control on edge devices while minimising data operation redundancy  managing data and device heterogeneity  and reducing resource contention  we benchmark sensix   with    different vision and acoustics models across various multi tenant configurations on different edge accelerators  jetson agx and coral tpu  designed for sensory devices  we report on the overall throughput and quantified benefits of various automation components of sensix   and demonstrate its efficacy in significantly reducing operational complexity and lowering the effort to deploy  upgrade  reconfigure  and serve embedded models on edge devices ,7.6467457,7.0769014,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Quantitative Decomposition of Prediction Errors Revealing Multi-Cause Impacts: An Insightful Framework for MLOps,"As machine learning applications expand in various industries, MLOps, which enables continuous model operation and improvement, becomes increasingly significant. Identifying causes of prediction errors, such as low model performance or anomalous samples, and implementing appropriate countermeasures are essential for effective MLOps. Furthermore, quantitatively evaluating each cause's impact is necessary to determine the effectiveness of countermeasures. In this study, we propose a method to quantitatively decompose a single sample's prediction error into contributions from multiple causes. Our method involves four steps: calculating the prediction error, computing metrics related to error causes, using a regression model to learn the relationship between the error and metrics, and applying SHAP to interpret the model's predictions and calculate the contribution of each cause to the prediction error. Numerical experiments with open data show that our method offers valuable insights for model improvement, confirming the effectiveness of our approach.",as machine learning applications expand in various industries  mlops  which enables continuous model operation and improvement  becomes increasingly significant  identifying causes of prediction errors  such as low model performance or anomalous samples  and implementing appropriate countermeasures are essential for effective mlops  furthermore  quantitatively evaluating each cause s impact is necessary to determine the effectiveness of countermeasures  in this study  we propose a method to quantitatively decompose a single sample s prediction error into contributions from multiple causes  our method involves four steps  calculating the prediction error  computing metrics related to error causes  using a regression model to learn the relationship between the error and metrics  and applying shap to interpret the model s predictions and calculate the contribution of each cause to the prediction error  numerical experiments with open data show that our method offers valuable insights for model improvement  confirming the effectiveness of our approach ,5.635143,5.936427,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
"A Joint Study of the Challenges, Opportunities, and Roadmap of MLOps and AIOps: A Systematic Survey","Data science projects represent a greater challenge than software engineering for organizations pursuing their adoption. The diverse stakeholders involved emphasize the need for a collaborative culture in organizations. This article aims to offer joint insights into the role of MLOps and AIOps methodologies for raising the success of data science projects in various fields, ranging from pure research to more traditional industries. We analyze the open issues, opportunities, and future trends organizations face when implementing MLOps and AIOps. Then, the frameworks and architectures that promote these paradigms are presented, as are the different fields in which they are being utilized. This systematic review was conducted using an automated procedure that identified 44,903 records, which were filtered down to 93 studies. These articles are meant to better clarify the problem at hand and highlight the future areas in both research and industry in which MLOPs and AIOps are thriving. Our findings indicate that AIOps flourish in challenging circumstances like those presented by 5G and 6G technologies, whereas MLOps is more prevalent in traditional industrial environments. The use of AIOps in certain stages of the ML lifecycle, such as deployment, remains underrepresented in scientific literature.",data science projects represent a greater challenge than software engineering for organizations pursuing their adoption  the diverse stakeholders involved emphasize the need for a collaborative culture in organizations  this article aims to offer joint insights into the role of mlops and aiops methodologies for raising the success of data science projects in various fields  ranging from pure research to more traditional industries  we analyze the open issues  opportunities  and future trends organizations face when implementing mlops and aiops  then  the frameworks and architectures that promote these paradigms are presented  as are the different fields in which they are being utilized  this systematic review was conducted using an automated procedure that identified        records  which were filtered down to    studies  these articles are meant to better clarify the problem at hand and highlight the future areas in both research and industry in which mlops and aiops are thriving  our findings indicate that aiops flourish in challenging circumstances like those presented by  g and  g technologies  whereas mlops is more prevalent in traditional industrial environments  the use of aiops in certain stages of the ml lifecycle  such as deployment  remains underrepresented in scientific literature ,9.951305,4.401243,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Towards Regulatory-Compliant MLOps: Oravizio’s Journey from a Machine Learning Experiment to a Deployed Certified Medical Product,"AbstractAgile software development embraces change and manifests working software over comprehensive documentation and responding to change over following a plan. The ability to continuously release software has enabled a development approach where experimental features are put to use, and, if they stand the test of real use, they remain in production. Examples of such features include machine learning (ML) models, which are usually pre-trained, but can still evolve in production. However, many domains require more plan-driven approach to avoid hazard to environment and humans, and to mitigate risks in the process. In this paper, we start by presenting continuous software engineering practices in a regulated context, and then apply the results to the emerging practice of MLOps, or continuous delivery of ML features. Furthermore, as a practical contribution, we present a case study regarding Oravizio, first CE-certified medical software for assessing the risks of joint replacement surgeries. Towards the end of the paper, we also reflect the Oravizio experiences to MLOps in regulatory context.",abstractagile software development embraces change and manifests working software over comprehensive documentation and responding to change over following a plan  the ability to continuously release software has enabled a development approach where experimental features are put to use  and  if they stand the test of real use  they remain in production  examples of such features include machine learning  ml  models  which are usually pre trained  but can still evolve in production  however  many domains require more plan driven approach to avoid hazard to environment and humans  and to mitigate risks in the process  in this paper  we start by presenting continuous software engineering practices in a regulated context  and then apply the results to the emerging practice of mlops  or continuous delivery of ml features  furthermore  as a practical contribution  we present a case study regarding oravizio  first ce certified medical software for assessing the risks of joint replacement surgeries  towards the end of the paper  we also reflect the oravizio experiences to mlops in regulatory context ,9.351085,7.245574,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Development of MLOps Platform Based on Power Source Analysis for Considering Manufacturing Environment Changes in Real-Time Processes,"AbstractSmart factories have led to the introduction of automated facilities in manufacturing lines and the increase in productivity using semi-automatic equipment or work auxiliary tools that use power sources in parallel with the existing pure manual manufacturing method. The productivity and quality of manual manufacturing work heavily depend on the skill level of the operators. Therefore, changes in manufacturing input factors can be determined by analyzing the pattern change of power sources such as electricity and pneumatic energy consumed in work-aid tools or semi-automatic facilities used by skilled operators. The manual workflow can be optimized by modeling this pattern and the image information of the operator and analyzing it in real time. Machine learning operations (MLOps) technology is required to respond to rapid changes in production systems and facilities and work patterns that frequently occur in small-batch production methods. MLOps can selectively configure Kubeflow, the MLOps solution, and the data lake based on Kubernetes for the entire process, from collecting and analyzing data to learning and deploying ML models, enabling the provision of fast and differentiated services from model development to distribution by the scale and construction stage of the manufacturing site. In this study, the manual work patterns of operators, which are unstructured data, were formulated into power source consumption patterns and analyzed along with image information to develop a manufacturing management platform applicable to manual-based, multi-variety, small-volume production methods and eventually for operator training in connection with three-dimensional visualization technology.",abstractsmart factories have led to the introduction of automated facilities in manufacturing lines and the increase in productivity using semi automatic equipment or work auxiliary tools that use power sources in parallel with the existing pure manual manufacturing method  the productivity and quality of manual manufacturing work heavily depend on the skill level of the operators  therefore  changes in manufacturing input factors can be determined by analyzing the pattern change of power sources such as electricity and pneumatic energy consumed in work aid tools or semi automatic facilities used by skilled operators  the manual workflow can be optimized by modeling this pattern and the image information of the operator and analyzing it in real time  machine learning operations  mlops  technology is required to respond to rapid changes in production systems and facilities and work patterns that frequently occur in small batch production methods  mlops can selectively configure kubeflow  the mlops solution  and the data lake based on kubernetes for the entire process  from collecting and analyzing data to learning and deploying ml models  enabling the provision of fast and differentiated services from model development to distribution by the scale and construction stage of the manufacturing site  in this study  the manual work patterns of operators  which are unstructured data  were formulated into power source consumption patterns and analyzed along with image information to develop a manufacturing management platform applicable to manual based  multi variety  small volume production methods and eventually for operator training in connection with three dimensional visualization technology ,8.518273,4.1625867,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Teaching MLOps in Higher Education through Project-Based Learning,"Building and maintaining production-grade ML-enabled components is a complex endeavor that goes beyond the current approach of academic education, focused on the optimization of ML model performance in the lab. In this paper, we present a project-based learning approach to teaching MLOps, focused on the demonstration and experience with emerging practices and tools to automatize the construction of ML-enabled components. We examine the design of a course based on this approach, including laboratory sessions that cover the end-to-end ML component life cycle, from model building to production deployment. Moreover, we report on preliminary results from the first edition of the course. During the present year, an updated version of the same course is being delivered in two independent universities; the related learning outcomes will be evaluated to analyze the effectiveness of project-based learning for this specific subject.",building and maintaining production grade ml enabled components is a complex endeavor that goes beyond the current approach of academic education  focused on the optimization of ml model performance in the lab  in this paper  we present a project based learning approach to teaching mlops  focused on the demonstration and experience with emerging practices and tools to automatize the construction of ml enabled components  we examine the design of a course based on this approach  including laboratory sessions that cover the end to end ml component life cycle  from model building to production deployment  moreover  we report on preliminary results from the first edition of the course  during the present year  an updated version of the same course is being delivered in two independent universities  the related learning outcomes will be evaluated to analyze the effectiveness of project based learning for this specific subject ,8.421497,5.0538926,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
A Preliminary Investigation of MLOps Practices in GitHub,"Background. The rapid and growing popularity of machine learning (ML) applications has led to an increasing interest in MLOps, that is, the practice of continuous integration and deployment (CI/CD) of ML-enabled systems. Aims. Since changes may affect not only the code but also the ML model parameters and the data themselves, the automation of traditional CI/CD needs to be extended to manage model retraining in production. Method. In this paper, we present an initial investigation of the MLOps practices implemented in a set of ML-enabled systems retrieved from GitHub, focusing on GitHub Actions and CML, two solutions to automate the development workflow. Results. Our preliminary results suggest that the adoption of MLOps workflows in open-source GitHub projects is currently rather limited. Conclusions. Issues are also identified, which can guide future research work.",background  the rapid and growing popularity of machine learning  ml  applications has led to an increasing interest in mlops  that is  the practice of continuous integration and deployment  ci cd  of ml enabled systems  aims  since changes may affect not only the code but also the ml model parameters and the data themselves  the automation of traditional ci cd needs to be extended to manage model retraining in production  method  in this paper  we present an initial investigation of the mlops practices implemented in a set of ml enabled systems retrieved from github  focusing on github actions and cml  two solutions to automate the development workflow  results  our preliminary results suggest that the adoption of mlops workflows in open source github projects is currently rather limited  conclusions  issues are also identified  which can guide future research work ,9.386329,4.3580694,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Continuous Integration of Neural Networks in Autonomous Systems,"AbstractThe perception of the autonomous driving software of the FS223, a low-level sensor fusion of Lidar and Camera data requires the use of a neural network for image classification. To keep the neural network up to date with updates in the training data, we introduce a Continuous Integration (CI) pipeline to re-train the network. The network is then automatically validated and integrated into the code base of the autonomous system. The introduction of proper CI methods in these high-speed embedded software applications is an application of state-of-the-art MLOps techniques that aim to provide rapid generation of production-ready models. It further serves the purpose of professionalizing the otherwise script-based software production, which is re-done almost completely every year as the teams change from one year to the next.",abstractthe perception of the autonomous driving software of the fs     a low level sensor fusion of lidar and camera data requires the use of a neural network for image classification  to keep the neural network up to date with updates in the training data  we introduce a continuous integration  ci  pipeline to re train the network  the network is then automatically validated and integrated into the code base of the autonomous system  the introduction of proper ci methods in these high speed embedded software applications is an application of state of the art mlops techniques that aim to provide rapid generation of production ready models  it further serves the purpose of professionalizing the otherwise script based software production  which is re done almost completely every year as the teams change from one year to the next ,7.64099,7.2464066,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Enhancing Performance of Operationalized Machine Learning Models by Analyzing User Feedback,"Machine learning (ML) models that have been put into production must be actively monitored and maintained to ensure that the models continue to satisfy performance quality requirements. User feedback is often a very good indicator of whether the model is performing as per user expectations. We contend that monitoring ML models through user feedback, and promptly addressing the issues mentioned in the feedback will help to ensure long-term success of deployed ML models. However, the problem of incorporating user feedback for maintaining ML models has not been adequately studied. In this paper, we first motivate the importance of this problem by highlighting the benefits of incorporating user feedback. The paper discusses the challenges of effectively harnessing user feedback for enhancing performance of deployed ML models. Furthermore, we present a novel approach for analyzing user feedback to identify incompleteness of training datasets or differences between distributions of training datasets and actual workload. Our approach compares the user feedback and training data of deployed ML models to find the above mentioned deficiencies in the training dataset. And we determine a priority order to fix the issues. We also present experiments to demonstrate the effectiveness of the proposed approach.",machine learning  ml  models that have been put into production must be actively monitored and maintained to ensure that the models continue to satisfy performance quality requirements  user feedback is often a very good indicator of whether the model is performing as per user expectations  we contend that monitoring ml models through user feedback  and promptly addressing the issues mentioned in the feedback will help to ensure long term success of deployed ml models  however  the problem of incorporating user feedback for maintaining ml models has not been adequately studied  in this paper  we first motivate the importance of this problem by highlighting the benefits of incorporating user feedback  the paper discusses the challenges of effectively harnessing user feedback for enhancing performance of deployed ml models  furthermore  we present a novel approach for analyzing user feedback to identify incompleteness of training datasets or differences between distributions of training datasets and actual workload  our approach compares the user feedback and training data of deployed ml models to find the above mentioned deficiencies in the training dataset  and we determine a priority order to fix the issues  we also present experiments to demonstrate the effectiveness of the proposed approach ,9.990238,5.947347,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
AlerTiger: Deep Learning for AI Model Health Monitoring at LinkedIn,"Data-driven companies use AI models extensively to develop products and intelligent business solutions, making the health of these models crucial for business success. Model monitoring and alerting in industries pose unique challenges, including a lack of clear model health metrics definition, label sparsity, and fast model iterations that result in short-lived models and features. As a product, there are also requirements for scalability, generalizability, and explainability. To tackle these challenges, we propose AlerTiger, a deep-learning-based MLOps model monitoring system that helps AI teams across the company monitor their AI models' health by detecting anomalies in models' input features and output score over time. The system consists of four major steps: model statistics generation, deep-learning-based anomaly detection, anomaly post-processing, and user alerting. Our solution generates three categories of statistics to indicate AI model health, offers a two-stage deep anomaly detection solution to address label sparsity and attain the generalizability of monitoring new models, and provides holistic reports for actionable alerts. This approach has been deployed to most of LinkedIn's production AI models for over a year and has identified several model issues that later led to significant business metric gains after fixing.",data driven companies use ai models extensively to develop products and intelligent business solutions  making the health of these models crucial for business success  model monitoring and alerting in industries pose unique challenges  including a lack of clear model health metrics definition  label sparsity  and fast model iterations that result in short lived models and features  as a product  there are also requirements for scalability  generalizability  and explainability  to tackle these challenges  we propose alertiger  a deep learning based mlops model monitoring system that helps ai teams across the company monitor their ai models  health by detecting anomalies in models  input features and output score over time  the system consists of four major steps  model statistics generation  deep learning based anomaly detection  anomaly post processing  and user alerting  our solution generates three categories of statistics to indicate ai model health  offers a two stage deep anomaly detection solution to address label sparsity and attain the generalizability of monitoring new models  and provides holistic reports for actionable alerts  this approach has been deployed to most of linkedin s production ai models for over a year and has identified several model issues that later led to significant business metric gains after fixing ,7.3432493,5.953057,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Machine Learning on Insurance Premium Prediction,"The insurance field is going through a phase of great transformation due to the growth of new technologies and techniques that are causing a change in the way data is handled and analyzed. The main perpetrator of this phenomenon is the introduction of Machine Learning (ML) in financial decision-making due to their efficiency and productivity. However, there is a new intervenient in the room, which will automate and support all steps of ML system development. Machine Learning Operations (MLOPs) will reduce technical friction, so that the model may move from an idea into production, in the shortest amount of time, and subsequently to market with the least possible risk. In this paper, a detailed review of the impacts of ML on insurance premium forecasting and the influence that MLOPs can have on forecasting outcomes is provided. Furthermore, a comprehensive summary is presented of crucial principles in the insurance industry, which are essential for comprehending the role that MLOPs will play in tailoring and individualizing insurance policies and premiums.",the insurance field is going through a phase of great transformation due to the growth of new technologies and techniques that are causing a change in the way data is handled and analyzed  the main perpetrator of this phenomenon is the introduction of machine learning  ml  in financial decision making due to their efficiency and productivity  however  there is a new intervenient in the room  which will automate and support all steps of ml system development  machine learning operations  mlops  will reduce technical friction  so that the model may move from an idea into production  in the shortest amount of time  and subsequently to market with the least possible risk  in this paper  a detailed review of the impacts of ml on insurance premium forecasting and the influence that mlops can have on forecasting outcomes is provided  furthermore  a comprehensive summary is presented of crucial principles in the insurance industry  which are essential for comprehending the role that mlops will play in tailoring and individualizing insurance policies and premiums ,8.124538,4.6222625,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
A Report on the First Workshop on Changing Phases of Software Engineering with the Generations,"With the industry moving towards Cloud, Software Engineering becomes center play in everything with an infusion of hybrid cloud, AI and Machine learning. The workshop focuses on Software engineering transformation driven by Cloud, AI and Machine learning journey. The workshop brings in both industry and academic views in building Software to meet the needs of the growing cloud market.",with the industry moving towards cloud  software engineering becomes center play in everything with an infusion of hybrid cloud  ai and machine learning  the workshop focuses on software engineering transformation driven by cloud  ai and machine learning journey  the workshop brings in both industry and academic views in building software to meet the needs of the growing cloud market ,10.384694,5.421403,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Teaching Advanced AI Development Techniques with a New Master’s Program in Artificial Intelligence Engineering,"AbstractThe paper presents a new Master’s program Artificial Intelligence Engineering at Ural Federal University created in cooperation with IT companies and partner universities. The aim of the program is to teach engineers who are able to develop complex large-scale software solutions that use artificial intelligence and put the solutions into production. The students study in detail not only the theoretical foundations and practical applications of artificial intelligence for various areas (natural language processing, computer vision, time series analysis, information security) but also contemporary methods and software engineering tools for machine learning operations (MLOps). The students acquire soft skills through project-based learning by solving research or real-world problems provided by partner companies, universities labs and Institutes of Russian Academy of Science. In addition to Ural Federal University, the program was implemented at six partner universities.",abstractthe paper presents a new master s program artificial intelligence engineering at ural federal university created in cooperation with it companies and partner universities  the aim of the program is to teach engineers who are able to develop complex large scale software solutions that use artificial intelligence and put the solutions into production  the students study in detail not only the theoretical foundations and practical applications of artificial intelligence for various areas  natural language processing  computer vision  time series analysis  information security  but also contemporary methods and software engineering tools for machine learning operations  mlops   the students acquire soft skills through project based learning by solving research or real world problems provided by partner companies  universities labs and institutes of russian academy of science  in addition to ural federal university  the program was implemented at six partner universities ,9.134227,5.438753,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Responsible AI Tutorial,"There is rapid technical progress and widespread adoption of Artificial Intelligence (AI) based products and workflows influencing many aspects of human and business activities like banking, healthcare, advertising and many more. Although accuracy of AI models is undoubtedly the most important factor considered while deploying AI based products, there is urgent need to understand how AI can be designed to operate responsibly. Responsible AI is a framework that each software developing organization needs to adapt to build customer trust in the transparency, accountability, fairness, and security of deployed AI solutions. At the same time a key aspect to making AI responsible is to have a development pipeline that can promote reproducibility of results and manage the lineage of data and ML models. This tutorial will throw light on these aspects of Responsible AI with a working example demonstrating the concept. The intent of the tutorial will be to equip the audience with enough knowledge of the concepts along with code to gain appreciation for the importance of building Responsible AI.",there is rapid technical progress and widespread adoption of artificial intelligence  ai  based products and workflows influencing many aspects of human and business activities like banking  healthcare  advertising and many more  although accuracy of ai models is undoubtedly the most important factor considered while deploying ai based products  there is urgent need to understand how ai can be designed to operate responsibly  responsible ai is a framework that each software developing organization needs to adapt to build customer trust in the transparency  accountability  fairness  and security of deployed ai solutions  at the same time a key aspect to making ai responsible is to have a development pipeline that can promote reproducibility of results and manage the lineage of data and ml models  this tutorial will throw light on these aspects of responsible ai with a working example demonstrating the concept  the intent of the tutorial will be to equip the audience with enough knowledge of the concepts along with code to gain appreciation for the importance of building responsible ai ,11.900346,6.944547,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
The pipeline for the continuous development of artificial intelligence models—Current state of research and practice,"AbstractCompanies struggle to continuously develop and deploy Artificial Intelligence (AI) models to complex production systems due to AI characteristics while assuring quality. To ease the development process, continuous pipelines for AI have become an active research area where consolidated and in-depth analysis regarding the terminology, triggers, tasks, and challenges is required.This paper includes a Multivocal Literature Review (MLR) where we consolidated 151 relevant formal and informal sources. In addition, nine-semi structured interviews with participants from academia and industry verified and extended the obtained information. Based on these sources, this paper provides and compares terminologies for Development and Operations (DevOps) and Continuous Integration (CI)/Continuous Delivery (CD) for AI, Machine Learning Operations (MLOps), (end-to-end) lifecycle management, and Continuous Delivery for Machine Learning (CD4ML). Furthermore, the paper provides an aggregated list of potential triggers for reiterating the pipeline, such as alert systems or schedules. In addition, this work uses a taxonomy creation strategy to present a consolidated pipeline comprising tasks regarding the continuous development of AI. This pipeline consists of four stages: Data Handling, Model Learning, Software Development and System Operations. Moreover, we map challenges regarding pipeline implementation, adaption, and usage for the continuous development of AI to these four stages.Highlights •Terms for AI and DevOps, CI/CD, MLOps, continuous development lifecycle, CD4ML.•Trigger types for executing the continuous development of AI.•AI pipeline: data handling, model learning, software development, system operations.•Pipeline-specific challenges for continuous AI development.",abstractcompanies struggle to continuously develop and deploy artificial intelligence  ai  models to complex production systems due to ai characteristics while assuring quality  to ease the development process  continuous pipelines for ai have become an active research area where consolidated and in depth analysis regarding the terminology  triggers  tasks  and challenges is required this paper includes a multivocal literature review  mlr  where we consolidated     relevant formal and informal sources  in addition  nine semi structured interviews with participants from academia and industry verified and extended the obtained information  based on these sources  this paper provides and compares terminologies for development and operations  devops  and continuous integration  ci  continuous delivery  cd  for ai  machine learning operations  mlops    end to end  lifecycle management  and continuous delivery for machine learning  cd ml   furthermore  the paper provides an aggregated list of potential triggers for reiterating the pipeline  such as alert systems or schedules  in addition  this work uses a taxonomy creation strategy to present a consolidated pipeline comprising tasks regarding the continuous development of ai  this pipeline consists of four stages  data handling  model learning  software development and system operations  moreover  we map challenges regarding pipeline implementation  adaption  and usage for the continuous development of ai to these four stages highlights  terms for ai and devops  ci cd  mlops  continuous development lifecycle  cd ml  trigger types for executing the continuous development of ai  ai pipeline  data handling  model learning  software development  system operations  pipeline specific challenges for continuous ai development ,9.759292,5.3814507,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Scaling Enterprise Recommender Systems for Decentralization,"Within decentralized organizations, the local demand for recommender systems to support business processes grows. The diversity in data sources and infrastructure challenges central engineering teams. Achieving a high delivery velocity without technical debt requires a scalable approach in the development and operations of recommender systems. At the HEINEKEN Company, we execute a machine learning operations method with five best practices: pipeline automation, data availability, exchangeable artifacts, observability, and policy-based security. Creating a culture of self-service, automation, and collaboration to scale recommender systems for decentralization. We demonstrate a practical use case of a self-service ML workspace deployment and a recommender system, that scale faster to subsidiaries and with less technical debt. This enables HEINEKEN to globally support applications that generate insights with local business impact.",within decentralized organizations  the local demand for recommender systems to support business processes grows  the diversity in data sources and infrastructure challenges central engineering teams  achieving a high delivery velocity without technical debt requires a scalable approach in the development and operations of recommender systems  at the heineken company  we execute a machine learning operations method with five best practices  pipeline automation  data availability  exchangeable artifacts  observability  and policy based security  creating a culture of self service  automation  and collaboration to scale recommender systems for decentralization  we demonstrate a practical use case of a self service ml workspace deployment and a recommender system  that scale faster to subsidiaries and with less technical debt  this enables heineken to globally support applications that generate insights with local business impact ,7.600272,5.462854,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Scarecrow - Intelligent Annotation platform for Engine Health Management,"Engine Health Management (EHM) in the context of applications such as gas turbines, power packs is dependent on massive amount of data captured by onboard sensors. The data streams are then processed to extract key points and trends capturing events related to failures and deterioration, which subsequently need to be enhanced by insights and judgements from Subject Matter Experts (SME). Data volumes and extremely demanding requirements, commercial and regulatory, cause human efforts to quickly emerge as bottleneck in EHM service delivery. We have developed an intelligent data annotation platform called Scarecrow which records SME inputs, generates machine learning models in near real-time which are then deployed into analytic pipelines for EHM diagnostics. Scarecrow enables seamless ML ops strategy through human assisted feature learning, model building and deployment",engine health management  ehm  in the context of applications such as gas turbines  power packs is dependent on massive amount of data captured by onboard sensors  the data streams are then processed to extract key points and trends capturing events related to failures and deterioration  which subsequently need to be enhanced by insights and judgements from subject matter experts  sme   data volumes and extremely demanding requirements  commercial and regulatory  cause human efforts to quickly emerge as bottleneck in ehm service delivery  we have developed an intelligent data annotation platform called scarecrow which records sme inputs  generates machine learning models in near real time which are then deployed into analytic pipelines for ehm diagnostics  scarecrow enables seamless ml ops strategy through human assisted feature learning  model building and deployment,10.086817,7.570458,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
From ML models to intelligent applications: the rise of MLOps,"The last 5+ years in ML have focused on building the best models, hyperparameter optimization, parallel training, massive neural networks, etc. Now that the building of models has become easy, models are being integrated into every piece of software and device - from smart kitchens to radiology to detecting performance of turbines. This shift from training ML models to building intelligent, ML-driven applications has highlighted a variety of problems going from ""a model"" to a whole application or business process running on ML. These challenges range from operational challenges (how to package and deploy different types of models using existing SDLC tools and practices), rethinking what existing abstractions mean for ML (e.g., testing, monitoring, warehouses for ML), and collaboration challenges arising from disparate skill sets involved in ML product development (DS vs. SWE), and brand-new problems unique to ML (e.g., explainability, fairness, retraining, etc.) In this talk, I will discuss the slew of challenges that still exist in operationalizing ML to build intelligent applications, some solutions that the community has adopted, and highlight various open problems that would benefit from the research community's contributions.",the last    years in ml have focused on building the best models  hyperparameter optimization  parallel training  massive neural networks  etc  now that the building of models has become easy  models are being integrated into every piece of software and device   from smart kitchens to radiology to detecting performance of turbines  this shift from training ml models to building intelligent  ml driven applications has highlighted a variety of problems going from  a model  to a whole application or business process running on ml  these challenges range from operational challenges  how to package and deploy different types of models using existing sdlc tools and practices   rethinking what existing abstractions mean for ml  e g   testing  monitoring  warehouses for ml   and collaboration challenges arising from disparate skill sets involved in ml product development  ds vs  swe   and brand new problems unique to ml  e g   explainability  fairness  retraining  etc   in this talk  i will discuss the slew of challenges that still exist in operationalizing ml to build intelligent applications  some solutions that the community has adopted  and highlight various open problems that would benefit from the research community s contributions ,9.618767,5.2575183,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Fine-grained provenance for linear algebra operators,"Provenance is well-understood for relational query operators. Increasingly, however, data analytics is incorporating operations expressed through linear algebra: machine learning operations, network centrality measures, and so on. In this paper, we study provenance information for matrix data and linear algebra operations. Our core technique builds upon provenance for aggregate queries and constructs a K--semialgebra. This approach tracks provenance by annotating matrix data and propagating these annotations through linear algebra operations. We investigate applications in matrix inversion and graph analysis.",provenance is well understood for relational query operators  increasingly  however  data analytics is incorporating operations expressed through linear algebra  machine learning operations  network centrality measures  and so on  in this paper  we study provenance information for matrix data and linear algebra operations  our core technique builds upon provenance for aggregate queries and constructs a k  semialgebra  this approach tracks provenance by annotating matrix data and propagating these annotations through linear algebra operations  we investigate applications in matrix inversion and graph analysis ,6.5193105,6.6748285,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
StreamAI: Dealing with Challenges of Continual Learning Systems for Serving AI in Production,"How to build, deploy, update & maintain dynamic models which continuously learn from streaming data? This paper covers the industrialization aspects of these questions in production systems. In today's fast-changing environments, organizations are faced with the crucial challenge of predictive analytics in online fashion from big data and deploying Artificial Intelligence models at scale. Applications include cyber-security, cloud infrastructure, social networks and financial markets. Online learning models that learn continuously and adapt to the potentially evolving data distributions have demonstrated efficiency for big data stream learning. However, the challenges of deploying and maintaining such models in production (serving) have stalled their adoption. In this paper, we first categorize key challenges faced by the R&D, MLOps and governance teams for deploying automated and self-training AI models in production. Next, we highlight the challenges related to stream-based online machine-learning systems. Finally, we propose StreamAI, a technology-agnostic architecture to deal with the MLOps journey (learning, serving, maintenance) of online models in production. We conclude with open research questions for AI, MLOps and software engineering to bridge the gaps between industry needs and research-oriented development.",how to build  deploy  update   maintain dynamic models which continuously learn from streaming data  this paper covers the industrialization aspects of these questions in production systems  in today s fast changing environments  organizations are faced with the crucial challenge of predictive analytics in online fashion from big data and deploying artificial intelligence models at scale  applications include cyber security  cloud infrastructure  social networks and financial markets  online learning models that learn continuously and adapt to the potentially evolving data distributions have demonstrated efficiency for big data stream learning  however  the challenges of deploying and maintaining such models in production  serving  have stalled their adoption  in this paper  we first categorize key challenges faced by the r d  mlops and governance teams for deploying automated and self training ai models in production  next  we highlight the challenges related to stream based online machine learning systems  finally  we propose streamai  a technology agnostic architecture to deal with the mlops journey  learning  serving  maintenance  of online models in production  we conclude with open research questions for ai  mlops and software engineering to bridge the gaps between industry needs and research oriented development ,7.472901,6.9189153,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Development of a virtual metrology system for smart manufacturing: A case study of spandex fiber production,"AbstractVirtual metrology (VM) is one of the most important enabling technologies in smart manufacturing. Although there is an abundance of literature on VM applications, the context of continuous production has received less attention. Fundamental challenges involved in the application of VM to a continuous process have been overlooked in comparison with intermittent (or batch) processes. Here, we described a real-world VM system for the manufacturing of spandex fiber, focusing on how practical challenges associated with a continuous process, including time synchronization, recirculation process, and autocorrelated features, can be addressed using data analytics. A model refresh strategy is discussed for the deployed VM system to ensure continuous usability and high-quality predictions. The virtual-physical connection established by the VM system creates a virtuous cycle in which constantly updated data render the system realistic, and valuable insights generated by the system can be applied to the physical production environment.Highlights •A real-world development case of a virtual metrology system for smart manufacturing is presented.•The role and aim of expert systems for spandex fiber production are discussed.•Practical challenges associated with continuous production process are addressed.•A model refresh strategy to ensure continuous usability with high-quality prediction is established.•A virtual-physical connection enabled by the deployed system has been demonstrated",abstractvirtual metrology  vm  is one of the most important enabling technologies in smart manufacturing  although there is an abundance of literature on vm applications  the context of continuous production has received less attention  fundamental challenges involved in the application of vm to a continuous process have been overlooked in comparison with intermittent  or batch  processes  here  we described a real world vm system for the manufacturing of spandex fiber  focusing on how practical challenges associated with a continuous process  including time synchronization  recirculation process  and autocorrelated features  can be addressed using data analytics  a model refresh strategy is discussed for the deployed vm system to ensure continuous usability and high quality predictions  the virtual physical connection established by the vm system creates a virtuous cycle in which constantly updated data render the system realistic  and valuable insights generated by the system can be applied to the physical production environment highlights  a real world development case of a virtual metrology system for smart manufacturing is presented  the role and aim of expert systems for spandex fiber production are discussed  practical challenges associated with continuous production process are addressed  a model refresh strategy to ensure continuous usability with high quality prediction is established  a virtual physical connection enabled by the deployed system has been demonstrated,8.468397,4.0833583,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Enabling adaptive analytics at the edge with the Bi-Rex Big Data platform,"AbstractZero Defect Manufacturing (ZDM) is an emergent and disruptive paradigm that aims to optimize industrial process efficiency and sustainability by leveraging innovative and sophisticated data-driven approaches. It is a technology intensive concept that has the ambition of achieving and maintaining “first-time-right” quality goals in spite of varying processes and input material. As a result, developing ZDM applications might become overwhelming for small enterprises due to the multitude of diverse platform, the lack of know-how, and the need to adapt general purpose solutions to meet their needs. The Big Data Innovation and Research Excellence (Bi-Rex) is an Italian consortium that aims to accelerate the industrial innovation process of small enterprises. Within this consortium we developed a Big Data platform that enables adaptive analytics at the IT/OT boundary by leveraging innovative solutions for the safe and automatic deployment of data-driven apps, using MLOps and DevOps techniques and technologies, and evaluated it in real use cases provided by the world leading industrial partners involved in the project.Highlights •Zero Defect Manufacturing presents challenges at the adaptive data analytics level.•Innovative solutions based on MLOps and DevOps can address the ZDM requirements.•We designed the Bi-Rex Big Data platform to empower next generation ZDM solutions.",abstractzero defect manufacturing  zdm  is an emergent and disruptive paradigm that aims to optimize industrial process efficiency and sustainability by leveraging innovative and sophisticated data driven approaches  it is a technology intensive concept that has the ambition of achieving and maintaining  first time right  quality goals in spite of varying processes and input material  as a result  developing zdm applications might become overwhelming for small enterprises due to the multitude of diverse platform  the lack of know how  and the need to adapt general purpose solutions to meet their needs  the big data innovation and research excellence  bi rex  is an italian consortium that aims to accelerate the industrial innovation process of small enterprises  within this consortium we developed a big data platform that enables adaptive analytics at the it ot boundary by leveraging innovative solutions for the safe and automatic deployment of data driven apps  using mlops and devops techniques and technologies  and evaluated it in real use cases provided by the world leading industrial partners involved in the project highlights  zero defect manufacturing presents challenges at the adaptive data analytics level  innovative solutions based on mlops and devops can address the zdm requirements  we designed the bi rex big data platform to empower next generation zdm solutions ,11.116142,6.778933,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Auto-Validate by-History: Auto-Program Data Quality Constraints to Validate Recurring Data Pipelines,"Data pipelines are widely employed in modern enterprises to power a variety of Machine-Learning (ML) and Business-Intelligence (BI) applications. Crucially, these pipelines are recurring (e.g., daily or hourly) in production settings to keep data updated so that ML models can be re-trained regularly, and BI dashboards refreshed frequently. However, data quality (DQ) issues can often creep into recurring pipelines because of upstream schema and data drift over time. As modern enterprises operate thousands of recurring pipelines, today data engineers have to spend substantial efforts to manually monitor and resolve DQ issues, as part of their DataOps and MLOps practices. Given the high human cost of managing large-scale pipeline operations, it is imperative that we can automate as much as possible. In this work, we propose Auto-Validate-by-History (AVH) that can automatically detect DQ issues in recurring pipelines, leveraging rich statistics from historical executions. We formalize this as an optimization problem, and develop constant-factor approximation algorithms with provable precision guarantees. Extensive evaluations using 2000 production data pipelines at Microsoft demonstrate the effectiveness and efficiency of AVH.",data pipelines are widely employed in modern enterprises to power a variety of machine learning  ml  and business intelligence  bi  applications  crucially  these pipelines are recurring  e g   daily or hourly  in production settings to keep data updated so that ml models can be re trained regularly  and bi dashboards refreshed frequently  however  data quality  dq  issues can often creep into recurring pipelines because of upstream schema and data drift over time  as modern enterprises operate thousands of recurring pipelines  today data engineers have to spend substantial efforts to manually monitor and resolve dq issues  as part of their dataops and mlops practices  given the high human cost of managing large scale pipeline operations  it is imperative that we can automate as much as possible  in this work  we propose auto validate by history  avh  that can automatically detect dq issues in recurring pipelines  leveraging rich statistics from historical executions  we formalize this as an optimization problem  and develop constant factor approximation algorithms with provable precision guarantees  extensive evaluations using      production data pipelines at microsoft demonstrate the effectiveness and efficiency of avh ,8.6831,6.3417077,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Testing of machine learning models with limited samples: an industrial vacuum pumping application,"There is often a scarcity of training data for machine learning (ML) classification and regression models in industrial production, especially for time-consuming or sparsely run manufacturing processes. Traditionally, a majority of the limited ground-truth data is used for training, while a handful of samples are left for testing. In that case, the number of test samples is inadequate to properly evaluate the robustness of the ML models under test (i.e., the system under test) for classification and regression. Furthermore, the output of these ML models may be inaccurate or even fail if the input data differ from the expected. This is the case for ML models used in the Electroslag Remelting (ESR) process in the refined steel industry to predict the pressure in a vacuum chamber. A vacuum pumping event that occurs once a workday generates a few hundred samples in a year of pumping for training and testing. In the absence of adequate training and test samples, this paper first presents a method to generate a fresh set of augmented samples based on vacuum pumping principles. Based on the generated augmented samples, three test scenarios and one test oracle are presented to assess the robustness of an ML model used for production on an industrial scale. Experiments are conducted with real industrial production data obtained from Uddeholms AB steel company. The evaluations indicate that Ensemble and Neural Network are the most robust when trained on augmented data using the proposed testing strategy. The evaluation also demonstrates the proposed method's effectiveness in checking and improving ML algorithms' robustness in such situations. The work improves software testing's state-of-the-art robustness testing in similar settings. Finally, the paper presents an MLOps implementation of the proposed approach for real-time ML model prediction and action on the edge node and automated continuous delivery of ML software from the cloud.",there is often a scarcity of training data for machine learning  ml  classification and regression models in industrial production  especially for time consuming or sparsely run manufacturing processes  traditionally  a majority of the limited ground truth data is used for training  while a handful of samples are left for testing  in that case  the number of test samples is inadequate to properly evaluate the robustness of the ml models under test  i e   the system under test  for classification and regression  furthermore  the output of these ml models may be inaccurate or even fail if the input data differ from the expected  this is the case for ml models used in the electroslag remelting  esr  process in the refined steel industry to predict the pressure in a vacuum chamber  a vacuum pumping event that occurs once a workday generates a few hundred samples in a year of pumping for training and testing  in the absence of adequate training and test samples  this paper first presents a method to generate a fresh set of augmented samples based on vacuum pumping principles  based on the generated augmented samples  three test scenarios and one test oracle are presented to assess the robustness of an ml model used for production on an industrial scale  experiments are conducted with real industrial production data obtained from uddeholms ab steel company  the evaluations indicate that ensemble and neural network are the most robust when trained on augmented data using the proposed testing strategy  the evaluation also demonstrates the proposed method s effectiveness in checking and improving ml algorithms  robustness in such situations  the work improves software testing s state of the art robustness testing in similar settings  finally  the paper presents an mlops implementation of the proposed approach for real time ml model prediction and action on the edge node and automated continuous delivery of ml software from the cloud ,5.5096855,6.231632,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
HexRIC: Building a Better near-Real Time Network Controller for the Open RAN Ecosystem,"The Open Radio Access Network (O-RAN) architecture has served as a key enabler for the programmable control of cellular networks through its introduction of the RAN Intelligent Controller (RIC). However, the RIC solutions available today are hobbled by scalability issues, inaccessibility, and a general lack of robustness, thereby serving as an impediment to the widespread adoption of O-RAN. To that end, this paper introduces HexRIC- a purpose-built next-generation network controller for the O-RAN ecosystem. Key highlights of HexRIC include a robust messaging infrastructure, a machine learning operations framework, and support for O-RAN's flagship use cases such as RAN slicing. Furthermore, the paper also includes a comprehensive system evaluation addressing the key themes of scalability, ML model lifecycle management, and finegrained network control. The results thus obtained showcase that not only is HexRIC the most feature-complete control platform to date, it also offers a significant performance advantage over the prior art.",the open radio access network  o ran  architecture has served as a key enabler for the programmable control of cellular networks through its introduction of the ran intelligent controller  ric   however  the ric solutions available today are hobbled by scalability issues  inaccessibility  and a general lack of robustness  thereby serving as an impediment to the widespread adoption of o ran  to that end  this paper introduces hexric  a purpose built next generation network controller for the o ran ecosystem  key highlights of hexric include a robust messaging infrastructure  a machine learning operations framework  and support for o ran s flagship use cases such as ran slicing  furthermore  the paper also includes a comprehensive system evaluation addressing the key themes of scalability  ml model lifecycle management  and finegrained network control  the results thus obtained showcase that not only is hexric the most feature complete control platform to date  it also offers a significant performance advantage over the prior art ,7.8239546,5.5233245,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Unified data analytics: state-of-the-art and open problems,"There is an urgent need for unifying data analytics as more and more application tasks become more complex: Nowadays, it is normal to see tasks performing data preparation, analytical processing, and machine learning operations in a single pipeline. Despite this need, achieving this is still a dreadful process where developers have to get familiar with many data processing platforms and write ad hoc scripts for integrating them. This tutorial is motivated by this need from both academia and industry. We will discuss the importance of unifying data processing as well as the current efforts to achieve it. In particular, we will introduce a classification of the different cases where an application needs or benefits from data analytics unification and discuss the challenges in each case. Along with this classification, we will also present current efforts known up to date that aim at unifying data processing, such as Apache Beam and Apache Wayang, and emphasize their differences. We will conclude with open problems and their challenges.",there is an urgent need for unifying data analytics as more and more application tasks become more complex  nowadays  it is normal to see tasks performing data preparation  analytical processing  and machine learning operations in a single pipeline  despite this need  achieving this is still a dreadful process where developers have to get familiar with many data processing platforms and write ad hoc scripts for integrating them  this tutorial is motivated by this need from both academia and industry  we will discuss the importance of unifying data processing as well as the current efforts to achieve it  in particular  we will introduce a classification of the different cases where an application needs or benefits from data analytics unification and discuss the challenges in each case  along with this classification  we will also present current efforts known up to date that aim at unifying data processing  such as apache beam and apache wayang  and emphasize their differences  we will conclude with open problems and their challenges ,9.033695,5.8680024,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Harris Hawk Optimization: A Survey onVariants and Applications,"In this review, we intend to present a complete literature survey on the conception and variants of the recent successful optimization algorithm, Harris Hawk optimizer (HHO), along with an updated set of applications in well-established works. For this purpose, we first present an overview of HHO, including its logic of equations and mathematical model. Next, we focus on reviewing different variants of HHO from the available well-established literature. To provide readers a deep vision and foster the application of the HHO, we review the state-of-the-art improvements of HHO, focusing mainly on fuzzy HHO and a new intuitionistic fuzzy HHO algorithm. We also review the applications of HHO in enhancing machine learning operations and in tackling engineering optimization problems. This survey can cover different aspects of HHO and its future applications to provide a basis for future research in the development of swarm intelligence paths and the use of HHO for real-world problems.",in this review  we intend to present a complete literature survey on the conception and variants of the recent successful optimization algorithm  harris hawk optimizer  hho   along with an updated set of applications in well established works  for this purpose  we first present an overview of hho  including its logic of equations and mathematical model  next  we focus on reviewing different variants of hho from the available well established literature  to provide readers a deep vision and foster the application of the hho  we review the state of the art improvements of hho  focusing mainly on fuzzy hho and a new intuitionistic fuzzy hho algorithm  we also review the applications of hho in enhancing machine learning operations and in tackling engineering optimization problems  this survey can cover different aspects of hho and its future applications to provide a basis for future research in the development of swarm intelligence paths and the use of hho for real world problems ,2.5405295,7.5008388,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Testing Challenges of Mobile Augmented Reality Systems,"Abstract
Augmented reality systems are ones which insert virtual content into a user's view of the real world, in response to environmental conditions and the user's behavior within that environment. This virtual content can take the form of visual elements such as 2D labels or 3D models, auditory cues, or even haptics; content is generated and updated based on user behavior and environmental conditions, such as the user's location, movement patterns, and the results of computer vision or machine learning operations. AR systems are used to solve problems in a range of domains, from tourism and retail, education and healthcare, to industry and entertainment. For example, apps from Lowe's [82] and Houzz [81] support retail transactions by scanning a user's environment and placing product models into the space, thus allowing the user to preview what the product might look like in her home. AR systems have also proven helpful in such areas as aiding industrial assembly tasks [155, 175], helping users overcome phobias [35], and reviving interest in cultural heritage sites [163].Mobile AR systems are ones which run on portable handheld or wearable devices, such that the user is free to move around their environment without restric- tion. Examples of such devices include smartphones, tablets, and head-mounted dis- plays. This freedom of movement and usage, in combination with the application's reliance on computer vision and machine learning logic to provide core function- ality, make mobile AR applications very difficult to test. In addition, as demand and prevalence of machine learning logic increases, the availability and power of commercially available third-party vision libraries introduces new and easy ways for developers to violate usability and end-user privacy.The goal of this dissertation, therefore, is to understand and mitigate the challenges involved in testing mobile AR systems, given the capabilities of today's commercially available vision and machine learning libraries. We consider three related challenge areas: application behavior during unconstrained usage conditions, general usability, and end-user privacy. To address these challenge areas, we present three research efforts. The first presents a framework for collecting application performance and usability data in the wild. The second explores how commercial vision libraries can be exploited to conduct machine learning operations without user knowledge. The third presents a framework for leveraging the environment itself to enforce privacy and access control policies for mobile AR applications.",abstract augmented reality systems are ones which insert virtual content into a user s view of the real world  in response to environmental conditions and the user s behavior within that environment  this virtual content can take the form of visual elements such as  d labels or  d models  auditory cues  or even haptics  content is generated and updated based on user behavior and environmental conditions  such as the user s location  movement patterns  and the results of computer vision or machine learning operations  ar systems are used to solve problems in a range of domains  from tourism and retail  education and healthcare  to industry and entertainment  for example  apps from lowe s      and houzz      support retail transactions by scanning a user s environment and placing product models into the space  thus allowing the user to preview what the product might look like in her home  ar systems have also proven helpful in such areas as aiding industrial assembly tasks             helping users overcome phobias       and reviving interest in cultural heritage sites       mobile ar systems are ones which run on portable handheld or wearable devices  such that the user is free to move around their environment without restric  tion  examples of such devices include smartphones  tablets  and head mounted dis  plays  this freedom of movement and usage  in combination with the application s reliance on computer vision and machine learning logic to provide core function  ality  make mobile ar applications very difficult to test  in addition  as demand and prevalence of machine learning logic increases  the availability and power of commercially available third party vision libraries introduces new and easy ways for developers to violate usability and end user privacy the goal of this dissertation  therefore  is to understand and mitigate the challenges involved in testing mobile ar systems  given the capabilities of today s commercially available vision and machine learning libraries  we consider three related challenge areas  application behavior during unconstrained usage conditions  general usability  and end user privacy  to address these challenge areas  we present three research efforts  the first presents a framework for collecting application performance and usability data in the wild  the second explores how commercial vision libraries can be exploited to conduct machine learning operations without user knowledge  the third presents a framework for leveraging the environment itself to enforce privacy and access control policies for mobile ar applications ,7.756518,6.680441,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
"From Selecting Best Algorithm to Explaining Why It is: A General Review, Formal Problem Statement and Guidelines Towards to an Empirical Generalization","AbstractIt has been observed on solution algorithms for problems as sorting, forecasting, classification, clustering, constraint satisfaction, decision, optimization from several disciplines (computational complexity theory, data mining, artificial intelligence, machine learning, operations research) that algorithm performance is better in certain problem instances than other. This paper describes how has been the way for trying to reach the empirical generalization for this phenomenon existing in the experimental relation problem – algorithm. For each understanding level, research questions, problem description were formulated, using the same Rice’s nomenclature and supplementing it; as well as, influence indexes and analysis approaches were described. A diagram about this long trajectory and a reflection is performed, highlighting contributions and scope. It shows that up to now the problem of explaining formally why an algorithm is the best for solving an instance set had remained open. A formal problem statement for describing this phenomenon and a general framework were proposed as a guide for working in adequate way toward generation of theories; which could contribute to build generalized indexes and self-adaptive algorithms to give the best solution to problems.",abstractit has been observed on solution algorithms for problems as sorting  forecasting  classification  clustering  constraint satisfaction  decision  optimization from several disciplines  computational complexity theory  data mining  artificial intelligence  machine learning  operations research  that algorithm performance is better in certain problem instances than other  this paper describes how has been the way for trying to reach the empirical generalization for this phenomenon existing in the experimental relation problem   algorithm  for each understanding level  research questions  problem description were formulated  using the same rice s nomenclature and supplementing it  as well as  influence indexes and analysis approaches were described  a diagram about this long trajectory and a reflection is performed  highlighting contributions and scope  it shows that up to now the problem of explaining formally why an algorithm is the best for solving an instance set had remained open  a formal problem statement for describing this phenomenon and a general framework were proposed as a guide for working in adequate way toward generation of theories  which could contribute to build generalized indexes and self adaptive algorithms to give the best solution to problems ,2.5526462,7.7091784,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
A lightweight MapReduce framework for secure processing with SGX,"MapReduce is a programming model used extensively for parallel data processing in distributed environments. A wide range of algorithms were implemented using MapReduce, from simple tasks like sorting and searching up to complex clustering and machine learning operations. Many of these implementations are part of services externalized to cloud infrastructures. Over the past years, however, many concerns have been raised regarding the security guarantees offered in such environments. Some solutions relying on cryptography were proposed for countering threats but these typically imply a high computational overhead. Intel, the largest manufacturer of commodity CPUs, recently introduced SGX (software guard extensions), a set of hardware instructions that support execution of code in an isolated secure environment. In this paper, we explore the use of Intel SGX for providing privacy guarantees for MapReduce operations, and based on our evaluation we conclude that it represents a viable alternative to a cryptographic mechanism. We present results based on the widely used k-means clustering algorithm, but our implementation can be generalized to other applications that can be expressed using MapReduce model.",mapreduce is a programming model used extensively for parallel data processing in distributed environments  a wide range of algorithms were implemented using mapreduce  from simple tasks like sorting and searching up to complex clustering and machine learning operations  many of these implementations are part of services externalized to cloud infrastructures  over the past years  however  many concerns have been raised regarding the security guarantees offered in such environments  some solutions relying on cryptography were proposed for countering threats but these typically imply a high computational overhead  intel  the largest manufacturer of commodity cpus  recently introduced sgx  software guard extensions   a set of hardware instructions that support execution of code in an isolated secure environment  in this paper  we explore the use of intel sgx for providing privacy guarantees for mapreduce operations  and based on our evaluation we conclude that it represents a viable alternative to a cryptographic mechanism  we present results based on the widely used k means clustering algorithm  but our implementation can be generalized to other applications that can be expressed using mapreduce model ,3.2978568,8.105979,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
You Do Not Need a Bigger Boat: Recommendations at Reasonable Scale in a (Mostly) Serverless and Open Stack,"We argue that immature data pipelines are preventing a large portion of industry practitioners from leveraging the latest research on recommender systems. We propose our template data stack for machine learning at “reasonable scale”, and show how many challenges are solved by embracing a serverless paradigm. Leveraging our experience, we detail how modern open source tools can provide a pipeline processing terabytes of data with minimal infrastructure work.",we argue that immature data pipelines are preventing a large portion of industry practitioners from leveraging the latest research on recommender systems  we propose our template data stack for machine learning at  reasonable scale   and show how many challenges are solved by embracing a serverless paradigm  leveraging our experience  we detail how modern open source tools can provide a pipeline processing terabytes of data with minimal infrastructure work ,8.754868,7.1212173,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Supporting the Design of Machine Learning Workflows with a Recommendation System,"Machine learning and data analytics tasks in practice require several consecutive processing steps. RapidMiner is a widely used software tool for the development and execution of such analytics workflows. Unlike many other algorithm toolkits, it comprises a visual editor that allows the user to design processes on a conceptual level. This conceptual and visual approach helps the user to abstract from the technical details during the development phase and to retain a focus on the core modeling task. The large set of preimplemented data analysis and machine learning operations available in the tool, as well as their logical dependencies, can, however, be overwhelming in particular for novice users.In this work, we present an add-on to the RapidMiner framework that supports the user during the modeling phase by recommending additional operations to insert into the currently developed machine learning workflow. First, we propose different recommendation techniques and evaluate them in an offline setting using a pool of several thousand existing workflows. Second, we present the results of a laboratory study, which show that our tool helps users to significantly increase the efficiency of the modeling process. Finally, we report on analyses using data that were collected during the real-world deployment of the plug-in component and compare the results of the live deployment of the tool with the results obtained through an offline analysis and a replay simulation.",machine learning and data analytics tasks in practice require several consecutive processing steps  rapidminer is a widely used software tool for the development and execution of such analytics workflows  unlike many other algorithm toolkits  it comprises a visual editor that allows the user to design processes on a conceptual level  this conceptual and visual approach helps the user to abstract from the technical details during the development phase and to retain a focus on the core modeling task  the large set of preimplemented data analysis and machine learning operations available in the tool  as well as their logical dependencies  can  however  be overwhelming in particular for novice users in this work  we present an add on to the rapidminer framework that supports the user during the modeling phase by recommending additional operations to insert into the currently developed machine learning workflow  first  we propose different recommendation techniques and evaluate them in an offline setting using a pool of several thousand existing workflows  second  we present the results of a laboratory study  which show that our tool helps users to significantly increase the efficiency of the modeling process  finally  we report on analyses using data that were collected during the real world deployment of the plug in component and compare the results of the live deployment of the tool with the results obtained through an offline analysis and a replay simulation ,6.137806,4.755122,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Error-Correcting Neural Networks for Two-Dimensional Curvature Computation in the Level-set Method,"AbstractWe present an error-neural-modeling-based strategy for approximating two-dimensional curvature in the level-set method. Our main contribution is a redesigned hybrid solver [Larios-Cárdenas and Gibou, J. Comput. Phys. (May 2022), 10.1016/j.jcp.2022.111291] that relies on numerical schemes to enable machine-learning operations on demand. In particular, our routine features double predicting to harness curvature symmetry invariance in favor of precision and stability. The core of this solver is a multilayer perceptron trained on circular- and sinusoidal-interface samples. Its role is to quantify the error in numerical curvature approximations and emit corrected estimates for select grid vertices along the free boundary. These corrections arise in response to preprocessed context level-set, curvature, and gradient data. To promote neural capacity, we have adopted sample negative-curvature normalization, reorientation, and reflection-based augmentation. In the same manner, our system incorporates dimensionality reduction, well-balancedness, and regularization to minimize outlying effects. Our training approach is likewise scalable across mesh sizes. For this purpose, we have introduced dimensionless parametrization and probabilistic subsampling during data production. Together, all these elements have improved the accuracy and efficiency of curvature calculations around under-resolved regions. In most experiments, our strategy has outperformed the numerical baseline at twice the number of redistancing steps while requiring only a fraction of the cost.",abstractwe present an error neural modeling based strategy for approximating two dimensional curvature in the level set method  our main contribution is a redesigned hybrid solver  larios c rdenas and gibou  j  comput  phys   may                j jcp              that relies on numerical schemes to enable machine learning operations on demand  in particular  our routine features double predicting to harness curvature symmetry invariance in favor of precision and stability  the core of this solver is a multilayer perceptron trained on circular  and sinusoidal interface samples  its role is to quantify the error in numerical curvature approximations and emit corrected estimates for select grid vertices along the free boundary  these corrections arise in response to preprocessed context level set  curvature  and gradient data  to promote neural capacity  we have adopted sample negative curvature normalization  reorientation  and reflection based augmentation  in the same manner  our system incorporates dimensionality reduction  well balancedness  and regularization to minimize outlying effects  our training approach is likewise scalable across mesh sizes  for this purpose  we have introduced dimensionless parametrization and probabilistic subsampling during data production  together  all these elements have improved the accuracy and efficiency of curvature calculations around under resolved regions  in most experiments  our strategy has outperformed the numerical baseline at twice the number of redistancing steps while requiring only a fraction of the cost ,4.318441,6.633879,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
An automatic model management system and its implementation for AIOps on microservice platforms,"AbstractWith the gradual expansion of microservice architecture-based applications, the complexity of system operation and maintenance is also growing significantly. With the advent of AIOps, it is now possible to automatically detect the state of the system, allocate resources, warn, and detect anomalies using machine learning models. Given the dynamic nature of online workloads, the running state of a microservice system in production is constantly in flux. Therefore, it is necessary to continuously train, encapsulate, and deploy models based on the current system status for the AIOps model to dynamically adapt to the system environment. This paper proposes a model update and management pipeline framework for AIOps models in microservices systems in order to accomplish the aforementioned objectives and simplify the process. In addition, a prototype system based on Kubernetes and Gitlab is designed to provide preliminary framework implementation and validation. The system consists of three components: model training, model packaging, and model deploying. Parallelization and parameter search are incorporated into the model training procedure in order to facilitate rapid training of multiple models and automated model hyperparameter tuning. We automate the packaging and deployment process using technology for continuous integration. Experiments are conducted to validate the prototype system, and the results demonstrate the feasibility of the proposed framework. This work serves as a useful resource for constructing an integrated and streamlined AIOps model management system.",abstractwith the gradual expansion of microservice architecture based applications  the complexity of system operation and maintenance is also growing significantly  with the advent of aiops  it is now possible to automatically detect the state of the system  allocate resources  warn  and detect anomalies using machine learning models  given the dynamic nature of online workloads  the running state of a microservice system in production is constantly in flux  therefore  it is necessary to continuously train  encapsulate  and deploy models based on the current system status for the aiops model to dynamically adapt to the system environment  this paper proposes a model update and management pipeline framework for aiops models in microservices systems in order to accomplish the aforementioned objectives and simplify the process  in addition  a prototype system based on kubernetes and gitlab is designed to provide preliminary framework implementation and validation  the system consists of three components  model training  model packaging  and model deploying  parallelization and parameter search are incorporated into the model training procedure in order to facilitate rapid training of multiple models and automated model hyperparameter tuning  we automate the packaging and deployment process using technology for continuous integration  experiments are conducted to validate the prototype system  and the results demonstrate the feasibility of the proposed framework  this work serves as a useful resource for constructing an integrated and streamlined aiops model management system ,8.112777,4.1604123,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
A hybrid quantum feature selection algorithm using a quantum inspired graph theoretic approach,"AbstractQuantum machine learning bridges the gap between abstract developments in quantum computing and the applied research on machine learning. It generally exposes the synthesis of important machine learning algorithms in a quantum framework. Dimensionality reduction of a dataset with a suitable feature selection strategy is one of the most important tasks in knowledge discovery and data mining. The efficient feature selection strategy helps to improve the overall accuracy of a large dataset in terms of machine learning operations. In this paper, a quantum feature selection algorithm using a graph-theoretic approach has been proposed. The proposed algorithm has used the concept of correlation coefficient based graph-theoretic classical approach initially and then applied the quantum Oracle with CNOT operation to verify whether the dataset is suitable for dimensionality reduction or not. If it is suitable, then our algorithm can efficiently estimate their high correlation values by using quantum parallel amplitude estimation and amplitude amplification techniques. This paper also shows that our proposed algorithm substantially outperforms than some popular classical feature selection algorithms for supervised classification in terms of query complexity of O(kNc(k)Nf(k)𝜖), where N is the size of the feature vectors whose values are ⩾ THmin(minimum threshold), k is the number of iterations and where 𝜖 is the error for estimating those feature vectors. Compared with the classical counterpart, i.e. the performance of our quantum algorithm quadratically improves than others.",abstractquantum machine learning bridges the gap between abstract developments in quantum computing and the applied research on machine learning  it generally exposes the synthesis of important machine learning algorithms in a quantum framework  dimensionality reduction of a dataset with a suitable feature selection strategy is one of the most important tasks in knowledge discovery and data mining  the efficient feature selection strategy helps to improve the overall accuracy of a large dataset in terms of machine learning operations  in this paper  a quantum feature selection algorithm using a graph theoretic approach has been proposed  the proposed algorithm has used the concept of correlation coefficient based graph theoretic classical approach initially and then applied the quantum oracle with cnot operation to verify whether the dataset is suitable for dimensionality reduction or not  if it is suitable  then our algorithm can efficiently estimate their high correlation values by using quantum parallel amplitude estimation and amplitude amplification techniques  this paper also shows that our proposed algorithm substantially outperforms than some popular classical feature selection algorithms for supervised classification in terms of query complexity of o knc k nf k     where n is the size of the feature vectors whose values are   thmin minimum threshold   k is the number of iterations and where   is the error for estimating those feature vectors  compared with the classical counterpart  i e  the performance of our quantum algorithm quadratically improves than others ,4.4897356,7.161837,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Looper: An End-to-End ML Platform for Product Decisions,"Modern software systems and products increasingly rely on machine learning models to make data-driven decisions based on interactions with users, infrastructure and other systems. For broader adoption, this practice must (i) accommodate product engineers without ML backgrounds, (ii) support finegrain product-metric evaluation and (iii) optimize for product goals. To address shortcomings of prior platforms, we introduce general principles for and the architecture of an ML platform, Looper, with simple APIs for decision-making and feedback collection. Looper covers the end-to-end ML lifecycle from collecting training data and model training to deployment and inference, and extends support to personalization, causal evaluation with heterogenous treatment effects, and Bayesian tuning for product goals. During the 2021 production deployment, Looper simultaneously hosted 440-1,000 ML models that made 4-6 million real-time decisions per second. We sum up experiences of platform adopters and describe their learning curve.",modern software systems and products increasingly rely on machine learning models to make data driven decisions based on interactions with users  infrastructure and other systems  for broader adoption  this practice must  i  accommodate product engineers without ml backgrounds   ii  support finegrain product metric evaluation and  iii  optimize for product goals  to address shortcomings of prior platforms  we introduce general principles for and the architecture of an ml platform  looper  with simple apis for decision making and feedback collection  looper covers the end to end ml lifecycle from collecting training data and model training to deployment and inference  and extends support to personalization  causal evaluation with heterogenous treatment effects  and bayesian tuning for product goals  during the      production deployment  looper simultaneously hosted           ml models that made     million real time decisions per second  we sum up experiences of platform adopters and describe their learning curve ,8.222699,7.2997217,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
A Software Ecosystem for Deploying Deep Learning in Gravitational Wave Physics,"The recent application of neural network algorithms to problems in gravitational-wave physics invites the study of how best to build production-ready applications on top of them. By viewing neural networks not as standalone models, but as components or functions in larger data processing pipelines, we can apply lessons learned from both traditional software development practices as well as successful deep learning applications from the private sector. This paper highlights challenges presented by straightforward but naïve deployment strategies for deep learning models, and identifies solutions to them gleaned from these sources. It then presents HERMES, a library of tools for implementing these solutions, and describes how HERMES is being used to develop a particular deep learning application which will be deployed during the next data collection run of the International Gravitational-Wave Observatories.",the recent application of neural network algorithms to problems in gravitational wave physics invites the study of how best to build production ready applications on top of them  by viewing neural networks not as standalone models  but as components or functions in larger data processing pipelines  we can apply lessons learned from both traditional software development practices as well as successful deep learning applications from the private sector  this paper highlights challenges presented by straightforward but na ve deployment strategies for deep learning models  and identifies solutions to them gleaned from these sources  it then presents hermes  a library of tools for implementing these solutions  and describes how hermes is being used to develop a particular deep learning application which will be deployed during the next data collection run of the international gravitational wave observatories ,9.632651,7.6966157,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
OTIF: Efficient Tracker Pre-processing over Large Video Datasets,"Performing analytics tasks over large-scale video datasets is increasingly common in a wide range of applications, from traffic planning to sports analytics. These tasks generally involve object detection and tracking operations that require pre-processing the video through expensive machine learning models. To address this cost, several video query optimizers have recently been proposed. Broadly, these methods trade large reductions in pre-processing cost for increases in query execution cost: during query execution, they apply query-specific machine learning operations over portions of the video dataset. Although video query optimizers reduce the overall cost of executing a single query over large video datasets compared to naive object tracking methods, executing several queries over the same video remains cost-prohibitive; moreover, the high per-query latency makes these systems unsuitable for exploratory analytics where fast response times are crucial. In this paper, we present OTIF, a video pre-processor that efficiently extracts all object tracks from large-scale video datasets. By integrating several optimizations under a joint parameter tuning framework, OTIF is able to extract all object tracks from video as fast as existing video query optimizers can execute just one single query. In contrast to the outputs of video query optimizers, OTIF's outputs are general-purpose object tracks that can be used to execute many queries with sub-second latencies. We compare OTIF against three recent video query optimizers, as well as several general-purpose object detection and tracking techniques, and find that, across multiple datasets, OTIF provides a 6x to 25x average reduction in the overall cost to execute five queries over the same video.",performing analytics tasks over large scale video datasets is increasingly common in a wide range of applications  from traffic planning to sports analytics  these tasks generally involve object detection and tracking operations that require pre processing the video through expensive machine learning models  to address this cost  several video query optimizers have recently been proposed  broadly  these methods trade large reductions in pre processing cost for increases in query execution cost  during query execution  they apply query specific machine learning operations over portions of the video dataset  although video query optimizers reduce the overall cost of executing a single query over large video datasets compared to naive object tracking methods  executing several queries over the same video remains cost prohibitive  moreover  the high per query latency makes these systems unsuitable for exploratory analytics where fast response times are crucial  in this paper  we present otif  a video pre processor that efficiently extracts all object tracks from large scale video datasets  by integrating several optimizations under a joint parameter tuning framework  otif is able to extract all object tracks from video as fast as existing video query optimizers can execute just one single query  in contrast to the outputs of video query optimizers  otif s outputs are general purpose object tracks that can be used to execute many queries with sub second latencies  we compare otif against three recent video query optimizers  as well as several general purpose object detection and tracking techniques  and find that  across multiple datasets  otif provides a  x to   x average reduction in the overall cost to execute five queries over the same video ,4.691184,6.973467,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Orfeon: An AIOps framework for the goal-driven operationalization of distributed analytical pipelines,"AbstractThe use of Artificial Intelligence solutions keeps raising in the business domain. However, this adoption has not brought the expected results to companies so far. There are several reasons that make Artificial Intelligence solutions particularly complicated to adopt by businesses, such as the knowledge gap between the data science and operations teams. In this paper, we tackle the operationalization of distributed analytical pipelines in heterogeneous production environments, which span across different computational layers. In particular, we present a system called Orfeon, which can leverage different objectives and yields an optimized deployment for these pipelines. In addition, we offer the mathematical formulation of the problem alongside the objectives in hand (i.e. resilience, performance, and cost). Next, we propose a scenario utilizing cloud and edge infrastructural devices, in which we demonstrate how the system can optimize these objectives, without incurring scalability issues in terms of time nor memory. Finally, we compare the usefulness of Orfeon with a variety of tools in the field of machine learning operationalization and conclude that it is able to outperform these tools under the analyzed criteria, making it an appropriate system for the operationalization of machine learning pipelines.Highlights •Orfeon is envisioned to raise the success of ML projects in production environments.•The metric shipper can gather performance ML metrics in distributed environments.•The system optimizes the benefits of the devices in different computational layers.•The mathematical formulation enables the goal-driven deployment of ML projects.•Existing technologies are seamlessly integrated into the operationalization workflow.",abstractthe use of artificial intelligence solutions keeps raising in the business domain  however  this adoption has not brought the expected results to companies so far  there are several reasons that make artificial intelligence solutions particularly complicated to adopt by businesses  such as the knowledge gap between the data science and operations teams  in this paper  we tackle the operationalization of distributed analytical pipelines in heterogeneous production environments  which span across different computational layers  in particular  we present a system called orfeon  which can leverage different objectives and yields an optimized deployment for these pipelines  in addition  we offer the mathematical formulation of the problem alongside the objectives in hand  i e  resilience  performance  and cost   next  we propose a scenario utilizing cloud and edge infrastructural devices  in which we demonstrate how the system can optimize these objectives  without incurring scalability issues in terms of time nor memory  finally  we compare the usefulness of orfeon with a variety of tools in the field of machine learning operationalization and conclude that it is able to outperform these tools under the analyzed criteria  making it an appropriate system for the operationalization of machine learning pipelines highlights  orfeon is envisioned to raise the success of ml projects in production environments  the metric shipper can gather performance ml metrics in distributed environments  the system optimizes the benefits of the devices in different computational layers  the mathematical formulation enables the goal driven deployment of ml projects  existing technologies are seamlessly integrated into the operationalization workflow ,7.227371,6.9443045,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Towards a roadmap on software engineering for responsible AI,"Although AI is transforming the world, there are serious concerns about its ability to behave and make decisions responsibly. Many ethical regulations, principles, and frameworks for responsible AI have been issued recently. However, they are high level and difficult to put into practice. On the other hand, most AI researchers focus on algorithmic solutions, while the responsible AI challenges actually crosscut the entire engineering lifecycle and components of AI systems. To close the gap in operationalizing responsible AI, this paper aims to develop a roadmap on software engineering for responsible AI. The roadmap focuses on (i) establishing multi-level governance for responsible AI systems, (ii) setting up the development processes incorporating process-oriented practices for responsible AI systems, and (iii) building responsible-AI-by-design into AI systems through system-level architectural style, patterns and techniques.",although ai is transforming the world  there are serious concerns about its ability to behave and make decisions responsibly  many ethical regulations  principles  and frameworks for responsible ai have been issued recently  however  they are high level and difficult to put into practice  on the other hand  most ai researchers focus on algorithmic solutions  while the responsible ai challenges actually crosscut the entire engineering lifecycle and components of ai systems  to close the gap in operationalizing responsible ai  this paper aims to develop a roadmap on software engineering for responsible ai  the roadmap focuses on  i  establishing multi level governance for responsible ai systems   ii  setting up the development processes incorporating process oriented practices for responsible ai systems  and  iii  building responsible ai by design into ai systems through system level architectural style  patterns and techniques ,12.178673,6.270808,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
A Robust Backward Compatibility Metric for Model Retraining,"Model retraining and updating are essential processes in AI applications. However, during updates, there is a potential for performance degradation, in which the overall performance improves, but local performance deteriorates. This study proposes a backward compatibility metric that focuses on the compatibility of local predictive performance. The score of the proposed metric increases if the accuracy over the conditional distribution for each input is higher than before. Furthermore, we propose a model retraining method based on the proposed metric. Due to the use of the conditional distribution, our metric and retraining method are robust against label noises, while existing sample-based backward compatibility metrics are often affected by noise. We perform a theoretical analysis of our method and derive an upper bound for the generalization error. Numerical experiments demonstrate that our retraining method enhances compatibility while achieving equal or better trade-offs in overall performance compared to existing methods.",model retraining and updating are essential processes in ai applications  however  during updates  there is a potential for performance degradation  in which the overall performance improves  but local performance deteriorates  this study proposes a backward compatibility metric that focuses on the compatibility of local predictive performance  the score of the proposed metric increases if the accuracy over the conditional distribution for each input is higher than before  furthermore  we propose a model retraining method based on the proposed metric  due to the use of the conditional distribution  our metric and retraining method are robust against label noises  while existing sample based backward compatibility metrics are often affected by noise  we perform a theoretical analysis of our method and derive an upper bound for the generalization error  numerical experiments demonstrate that our retraining method enhances compatibility while achieving equal or better trade offs in overall performance compared to existing methods ,3.9892085,7.255103,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Operationalizing machine learning models: a systematic literature review,"Deploying machine learning (ML) models to production with the same level of rigor and automation as traditional software systems has shown itself to be a non-trivial task, requiring extra care and infrastructure to deal with the additional challenges. Although many studies focus on adapting ML software engineering (SE) approaches and techniques, few studies have summarized the status and challenges of operationalizing ML models. Model operationalization encompasses all steps after model training and evaluation, including packaging the model in a format appropriate for deployment, publishing to a model registry or storage, integrating the model into a broader software system, serving, and monitoring. This study is the first systematic literature review investigating the techniques, tools, and infrastructures to operationalize ML models. After reviewing 24 primary studies, the results show that there are a number of tools for most use cases to operationalize ML models and cloud deployment in particular. The review also revealed several research opportunities, such as dynamic model-switching, continuous model-monitoring, and efficient edge ML deployments.",deploying machine learning  ml  models to production with the same level of rigor and automation as traditional software systems has shown itself to be a non trivial task  requiring extra care and infrastructure to deal with the additional challenges  although many studies focus on adapting ml software engineering  se  approaches and techniques  few studies have summarized the status and challenges of operationalizing ml models  model operationalization encompasses all steps after model training and evaluation  including packaging the model in a format appropriate for deployment  publishing to a model registry or storage  integrating the model into a broader software system  serving  and monitoring  this study is the first systematic literature review investigating the techniques  tools  and infrastructures to operationalize ml models  after reviewing    primary studies  the results show that there are a number of tools for most use cases to operationalize ml models and cloud deployment in particular  the review also revealed several research opportunities  such as dynamic model switching  continuous model monitoring  and efficient edge ml deployments ,7.860011,6.499669,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Profiling Deep Learning Workloads at Scale using Amazon SageMaker,"With the rise of deep learning (DL), machine learning (ML) has become compute and data intensive, typically requiring multi-node multi-GPU clusters. As state-of-the-art models grow in size in the order of trillions of parameters, their computational complexity and cost also increase rapidly. Since 2012, the cost of deep learning doubled roughly every quarter, and this trend is likely to continue. ML practitioners have to cope with common challenges of efficient resource utilization when training such large models. In this paper, we propose a new profiling tool that cross-correlates relevant system utilization metrics and framework operations. The tool supports profiling DL models at scale, identifies performance bottlenecks, and provides insights with recommendations. We deployed the profiling functionality as an add-on to Amazon SageMaker Debugger, a fully-managed service that leverages an on-the-fly analysis system (called rules) to automatically identify complex issues in DL training jobs. By presenting deployment results and customer case studies, we show that it enables users to identify and fix issues caused by inefficient hardware resource usage, thereby reducing training time and cost.",with the rise of deep learning  dl   machine learning  ml  has become compute and data intensive  typically requiring multi node multi gpu clusters  as state of the art models grow in size in the order of trillions of parameters  their computational complexity and cost also increase rapidly  since       the cost of deep learning doubled roughly every quarter  and this trend is likely to continue  ml practitioners have to cope with common challenges of efficient resource utilization when training such large models  in this paper  we propose a new profiling tool that cross correlates relevant system utilization metrics and framework operations  the tool supports profiling dl models at scale  identifies performance bottlenecks  and provides insights with recommendations  we deployed the profiling functionality as an add on to amazon sagemaker debugger  a fully managed service that leverages an on the fly analysis system  called rules  to automatically identify complex issues in dl training jobs  by presenting deployment results and customer case studies  we show that it enables users to identify and fix issues caused by inefficient hardware resource usage  thereby reducing training time and cost ,6.367293,7.2731676,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Vigil: Effective End-to-end Monitoring for Large-scale Recommender Systems at Glance,"The success of large-scale recommender systems hinges upon their ability to deliver accurate and timely recommendations to a diverse user base. At Glance, we deliver snackable personalized content to the lock screens of 200M smartphones. In this context, continuous monitoring is paramount as it safeguards data integrity, detects drifts, addresses evolving user preferences, optimizes system downtime, and ultimately augments the system's effectiveness and user satisfaction. In this talk, we delve into Vigil, a set of monitoring practices developed to provide comprehensive end-to-end monitoring of recommender systems at Glance. These practices revolve around three key pillars: mitigating developer fatigue, ensuring precise predictions, and establishing a centralized monitoring framework. By adopting these practices, we have observed a 30% reduction in compute cost, a 26% drop in downtime, and a surge in developer productivity demonstrated by a 45% decrease in turnaround time.",the success of large scale recommender systems hinges upon their ability to deliver accurate and timely recommendations to a diverse user base  at glance  we deliver snackable personalized content to the lock screens of    m smartphones  in this context  continuous monitoring is paramount as it safeguards data integrity  detects drifts  addresses evolving user preferences  optimizes system downtime  and ultimately augments the system s effectiveness and user satisfaction  in this talk  we delve into vigil  a set of monitoring practices developed to provide comprehensive end to end monitoring of recommender systems at glance  these practices revolve around three key pillars  mitigating developer fatigue  ensuring precise predictions  and establishing a centralized monitoring framework  by adopting these practices  we have observed a     reduction in compute cost  a     drop in downtime  and a surge in developer productivity demonstrated by a     decrease in turnaround time ,9.544835,6.535817,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
On the Challenges of Migrating to Machine Learning Life Cycle Management Platforms,"Given the lack of targeted services for Machine Learning software by traditional Version Control systems (VCS), many platforms for Machine Learning Life Cycle Management (MLLCM) and config­uration have emerged. These tools leverage software engineering and DevOps practices to improve the way developers build, operate and maintain Machine Learning applications. This study aims to identify the main challenges that developers face when adopting and/or migrating existing projects to these platforms. Through an experimental and statistical analysis, we explore a generic mi­gration methodology and record the different challenges faced at each stage of the migration. Based on our own experience, we also recommend potential solutions to overcome these challenges and propose some steps that developers can take when building ML projects in order to ease any future migration to MLLCM platforms.",given the lack of targeted services for machine learning software by traditional version control systems  vcs   many platforms for machine learning life cycle management  mllcm  and config uration have emerged  these tools leverage software engineering and devops practices to improve the way developers build  operate and maintain machine learning applications  this study aims to identify the main challenges that developers face when adopting and or migrating existing projects to these platforms  through an experimental and statistical analysis  we explore a generic mi gration methodology and record the different challenges faced at each stage of the migration  based on our own experience  we also recommend potential solutions to overcome these challenges and propose some steps that developers can take when building ml projects in order to ease any future migration to mllcm platforms ,8.561118,5.4018097,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
A Computer Vision-Based Water Level Monitoring System for Touchless and Sustainable Water Dispensing,"AbstractIn recent years, the need for contactless and sustainable systems has become increasingly relevant. The traditional water dispensers, which require contact with the dispenser and often involve single-use plastic cups or bottles, are not only unhygienic but also contribute to environmental pollution. This paper presents a touchless water dispenser system that uses artificial intelligence (AI) to control the dispensing of water or any liquid beverage. The system is designed to fill a container under the nozzle, dispense water when the container is aligned with the flow, and stop dispensing when the container is full, all without requiring any physical contact. This approach ensures compliance with hygiene regulations and promotes environmental sustainability by eliminating the need for plastic bottles or cups, making it a “plastic-free” and “zero waste” system. The prototype is based on a computer vision approach that employs an RGB camera and a Raspberry Pi board, which allows for real-time image processing and machine learning operations. The system uses image processing techniques to detect the presence of a container under the nozzle and then utilizes AI algorithms to control the flow of liquid. The system is trained using machine learning models and optimized to ensure accuracy and efficiency. We discuss the development and implementation of the touchless water dispenser system, including the hardware and software components used, the algorithms employed, and the testing and evaluation of the system. The results of our experiments show that the touchless water dispenser system is highly accurate and efficient, and it offers a safe and sustainable alternative to traditional water dispensers. The system has the potential to be used in a variety of settings, including public spaces, hospitals, schools, and offices, where hygiene and sustainability are of utmost importance.",abstractin recent years  the need for contactless and sustainable systems has become increasingly relevant  the traditional water dispensers  which require contact with the dispenser and often involve single use plastic cups or bottles  are not only unhygienic but also contribute to environmental pollution  this paper presents a touchless water dispenser system that uses artificial intelligence  ai  to control the dispensing of water or any liquid beverage  the system is designed to fill a container under the nozzle  dispense water when the container is aligned with the flow  and stop dispensing when the container is full  all without requiring any physical contact  this approach ensures compliance with hygiene regulations and promotes environmental sustainability by eliminating the need for plastic bottles or cups  making it a  plastic free  and  zero waste  system  the prototype is based on a computer vision approach that employs an rgb camera and a raspberry pi board  which allows for real time image processing and machine learning operations  the system uses image processing techniques to detect the presence of a container under the nozzle and then utilizes ai algorithms to control the flow of liquid  the system is trained using machine learning models and optimized to ensure accuracy and efficiency  we discuss the development and implementation of the touchless water dispenser system  including the hardware and software components used  the algorithms employed  and the testing and evaluation of the system  the results of our experiments show that the touchless water dispenser system is highly accurate and efficient  and it offers a safe and sustainable alternative to traditional water dispensers  the system has the potential to be used in a variety of settings  including public spaces  hospitals  schools  and offices  where hygiene and sustainability are of utmost importance ,4.930099,4.914483,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Demonstration of Geyser: Provenance Extraction and Applications over Data Science Scripts,"As enterprises have started developing and deploying complicated data science workloads at scale, the need for mechanisms that enable enterprise-grade data science (e.g., compliance or auditing) has become more pronounced. In this paper, we present Geyser, an extensible provenance system for data science workloads that can be used as a foundation for enterprise-grade data science. Our system supports both static and dynamic provenance, over a wide range of data science scripts, driven by a knowledge base of data science APIs. We demonstrate the wide applicability of the system using various industrial applications: provenance extraction, model compliance, model linting, model versioning, and poisoning detection. A video of the demonstration is available at https://aka.ms/geyserdemo.",as enterprises have started developing and deploying complicated data science workloads at scale  the need for mechanisms that enable enterprise grade data science  e g   compliance or auditing  has become more pronounced  in this paper  we present geyser  an extensible provenance system for data science workloads that can be used as a foundation for enterprise grade data science  our system supports both static and dynamic provenance  over a wide range of data science scripts  driven by a knowledge base of data science apis  we demonstrate the wide applicability of the system using various industrial applications  provenance extraction  model compliance  model linting  model versioning  and poisoning detection  a video of the demonstration is available at https   aka ms geyserdemo ,10.078233,6.081625,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
End-to-end Machine Learning using Kubeflow,"Usually data scientists are adept in deriving valuable insights from data by applying appropriate machine learning algorithms. However, data scientists are usually not skilled in developing or operating production level software which is the domain of ML Operators. In order to move from initial experiments to production grade systems, the code needs to run at scale on large, realistic data sets, and be able to run on both on-premise equipment as well as on public clouds. Additionally, the entire process needs to be part of some Software Development Lifecycle (SDLC), accounting for some flavour of continuous integration/continuous development (CICD).  In this tutorial, attendees will learn about the components of an end-to-end ML system, and will get hands-on experience on model training, hyperparameter tuning, and model deployment. The tutorial will be based on Kubeflow, a widely used open-source (Apache License 2.0) machine learning toolkit for Kubernetes. The related code and examples can be accessed from a public github repository.",usually data scientists are adept in deriving valuable insights from data by applying appropriate machine learning algorithms  however  data scientists are usually not skilled in developing or operating production level software which is the domain of ml operators  in order to move from initial experiments to production grade systems  the code needs to run at scale on large  realistic data sets  and be able to run on both on premise equipment as well as on public clouds  additionally  the entire process needs to be part of some software development lifecycle  sdlc   accounting for some flavour of continuous integration continuous development  cicd    in this tutorial  attendees will learn about the components of an end to end ml system  and will get hands on experience on model training  hyperparameter tuning  and model deployment  the tutorial will be based on kubeflow  a widely used open source  apache license      machine learning toolkit for kubernetes  the related code and examples can be accessed from a public github repository ,7.913593,7.120631,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Deepchecks: a library for testing and validating machine learning models and data,"This paper presents Deepchecks, a Python library for comprehensively validating machine learning models and data. Our goal is to provide an easy-to-use library comprising many checks related to various issues, such as model predictive performance, data integrity, data distribution mismatches, and more. The package is distributed under the GNU Affero General Public License (AGPL) and relies on core libraries from the scientific Python ecosystem: scikit-learn, PyTorch, NumPy, pandas, and SciPy. Source code, documentation, examples, and an extensive user guide can be found at https://github.com/deepchecks/deepchecks",this paper presents deepchecks  a python library for comprehensively validating machine learning models and data  our goal is to provide an easy to use library comprising many checks related to various issues  such as model predictive performance  data integrity  data distribution mismatches  and more  the package is distributed under the gnu affero general public license  agpl  and relies on core libraries from the scientific python ecosystem  scikit learn  pytorch  numpy  pandas  and scipy  source code  documentation  examples  and an extensive user guide can be found at https   github com deepchecks deepchecks,8.57471,7.1430893,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Parallelizing Automatic Model Management System for AIOps on Microservice Platforms,"AbstractWith the gradual increase in the scale of applications based on microservice architecture, the complexity of system operation and maintenance is also significantly increasing. The emergence of AIOps makes it possible to automatically detect the state, allocate the resources, warn and detect the anomaly of the system through some machine learning models. Given dynamic online workloads, the running state of a production microservice system is constantly in flux. Therefore, it is necessary to continuously train, encapsulate and deploy models based on the current system status, so that the AIOps model can dynamically adapt to the system environment. To address this problem, this paper proposes a model management pipeline framework for AIOps on microservice platforms, and implements a prototype system based on Kubernetes to verify the framework. The system consists of three components: model training, model packaging and model deploying. Parallelization and parameter search are introduced in the model training process to support rapid training of multiple models and automated model hyperparameter tuning. Rapid deployment of models is supported by the model packaging and deploying components. Experiments were performed to verify the prototype system, and the experimental results illustrate the feasibility of the proposed framework. This work provides a valuable reference for the construction of an integrated and streamlined AIOps model management system.",abstractwith the gradual increase in the scale of applications based on microservice architecture  the complexity of system operation and maintenance is also significantly increasing  the emergence of aiops makes it possible to automatically detect the state  allocate the resources  warn and detect the anomaly of the system through some machine learning models  given dynamic online workloads  the running state of a production microservice system is constantly in flux  therefore  it is necessary to continuously train  encapsulate and deploy models based on the current system status  so that the aiops model can dynamically adapt to the system environment  to address this problem  this paper proposes a model management pipeline framework for aiops on microservice platforms  and implements a prototype system based on kubernetes to verify the framework  the system consists of three components  model training  model packaging and model deploying  parallelization and parameter search are introduced in the model training process to support rapid training of multiple models and automated model hyperparameter tuning  rapid deployment of models is supported by the model packaging and deploying components  experiments were performed to verify the prototype system  and the experimental results illustrate the feasibility of the proposed framework  this work provides a valuable reference for the construction of an integrated and streamlined aiops model management system ,8.300992,4.1012697,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
JIZHI: A Fast and Cost-Effective Model-As-A-Service System for Web-Scale Online Inference at Baidu,"In modern internet industries, deep learning based recommender systems have became an indispensable building block for a wide spectrum of applications, such as search engine, news feed, and short video clips. However, it remains challenging to carry the well-trained deep models for online real-time inference serving, with respect to the time-varying web-scale traffics from billions of users, in a cost-effective manner. In this work, we present JIZHI - a Model-as-a-Service system - that per second handles hundreds of millions of online inference requests to huge deep models with more than trillions of sparse parameters, for over twenty real-time recommendation services at Baidu, Inc. In JIZHI, the inference workflow of every recommendation request is transformed to a Staged Event-Driven Pipeline (SEDP), where each node in the pipeline refers to a staged computation or I/O intensive task processor. With traffics of real-time inference requests arrived, each modularized processor can be run in a fully asynchronized way and managed separately. Besides, JIZHI introduces the heterogeneous and hierarchical storage to further accelerate the online inference process by reducing unnecessary computations and potential data access latency induced by ultra-sparse model parameters. Moreover, an intelligent resource manager has been deployed to maximize the throughput of JIZHI over the shared infrastructure by searching the optimal resource allocation plan from historical logs and fine-tuning the load shedding policies over intermediate system feedback. Extensive experiments have been done to demonstrate the advantages of JIZHI from the perspectives of end-to-end service latency, system-wide throughput, and resource consumption. Since launched in July 2019, JIZHI has helped Baidu saved more than ten million US dollars in hardware and utility costs per year while handling 200% more traffics without sacrificing the inference efficiency.",in modern internet industries  deep learning based recommender systems have became an indispensable building block for a wide spectrum of applications  such as search engine  news feed  and short video clips  however  it remains challenging to carry the well trained deep models for online real time inference serving  with respect to the time varying web scale traffics from billions of users  in a cost effective manner  in this work  we present jizhi   a model as a service system   that per second handles hundreds of millions of online inference requests to huge deep models with more than trillions of sparse parameters  for over twenty real time recommendation services at baidu  inc  in jizhi  the inference workflow of every recommendation request is transformed to a staged event driven pipeline  sedp   where each node in the pipeline refers to a staged computation or i o intensive task processor  with traffics of real time inference requests arrived  each modularized processor can be run in a fully asynchronized way and managed separately  besides  jizhi introduces the heterogeneous and hierarchical storage to further accelerate the online inference process by reducing unnecessary computations and potential data access latency induced by ultra sparse model parameters  moreover  an intelligent resource manager has been deployed to maximize the throughput of jizhi over the shared infrastructure by searching the optimal resource allocation plan from historical logs and fine tuning the load shedding policies over intermediate system feedback  extensive experiments have been done to demonstrate the advantages of jizhi from the perspectives of end to end service latency  system wide throughput  and resource consumption  since launched in july       jizhi has helped baidu saved more than ten million us dollars in hardware and utility costs per year while handling      more traffics without sacrificing the inference efficiency ,4.984557,6.3396645,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
"The Good, The Bad, and The Average: Benchmarking of Reconstruction Based Multivariate Time Series Anomaly Detection","AbstractReconstruction-based algorithms offer state-of-the-art performance in multivariate time series anomaly detection. But as always: there is no single best algorithm. To find the optimal solution, one has to compare different methods and tune their hyperparameters. This paper introduces a lightweight modular benchmarking framework for data scientists and researchers in the field. The framework can be easily set up and automatically create a visual summary of the relevant performance indicators and automatically selected examples to give insight into the behavior of the model and aid during the development.",abstractreconstruction based algorithms offer state of the art performance in multivariate time series anomaly detection  but as always  there is no single best algorithm  to find the optimal solution  one has to compare different methods and tune their hyperparameters  this paper introduces a lightweight modular benchmarking framework for data scientists and researchers in the field  the framework can be easily set up and automatically create a visual summary of the relevant performance indicators and automatically selected examples to give insight into the behavior of the model and aid during the development ,6.286489,4.715487,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Responsible AI Pattern Catalogue: A Collection of Best Practices for AI Governance and Engineering,"Responsible AI is widely considered as one of the greatest scientific challenges of our time and is key to increase the adoption of AI. Recently, a number of AI ethics principles frameworks have been published. However, without further guidance on best practices, practitioners are left with nothing much beyond truisms. Also, significant efforts have been placed at algorithm-level rather than system-level, mainly focusing on a subset of mathematics-amenable ethical principles, such as fairness. Nevertheless, ethical issues can arise at any step of the development lifecycle, cutting across many AI and non-AI components of systems beyond AI algorithms and models. To operationalize responsible AI from a system perspective, in this paper, we present a Responsible AI Pattern Catalogue based on the results of a Multivocal Literature Review (MLR). Rather than staying at the principle or algorithm level, we focus on patterns that AI system stakeholders can undertake in practice to ensure that the developed AI systems are responsible throughout the entire governance and engineering lifecycle. The Responsible AI Pattern Catalogue classifies the patterns into three groups: multi-level governance patterns, trustworthy process patterns, and responsible-AI-by-design product patterns. These patterns provide systematic and actionable guidance for stakeholders to implement responsible AI.",responsible ai is widely considered as one of the greatest scientific challenges of our time and is key to increase the adoption of ai  recently  a number of ai ethics principles frameworks have been published  however  without further guidance on best practices  practitioners are left with nothing much beyond truisms  also  significant efforts have been placed at algorithm level rather than system level  mainly focusing on a subset of mathematics amenable ethical principles  such as fairness  nevertheless  ethical issues can arise at any step of the development lifecycle  cutting across many ai and non ai components of systems beyond ai algorithms and models  to operationalize responsible ai from a system perspective  in this paper  we present a responsible ai pattern catalogue based on the results of a multivocal literature review  mlr   rather than staying at the principle or algorithm level  we focus on patterns that ai system stakeholders can undertake in practice to ensure that the developed ai systems are responsible throughout the entire governance and engineering lifecycle  the responsible ai pattern catalogue classifies the patterns into three groups  multi level governance patterns  trustworthy process patterns  and responsible ai by design product patterns  these patterns provide systematic and actionable guidance for stakeholders to implement responsible ai ,12.233573,6.1426396,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Amazon SageMaker Model Monitor: A System for Real-Time Insights into Deployed Machine Learning Models,"With the increasing adoption of machine learning (ML) models and systems in high-stakes settings across different industries, guaranteeing a model's performance after deployment has become crucial. Monitoring models in production is a critical aspect of ensuring their continued performance and reliability. We present Amazon SageMaker Model Monitor, a fully managed service that continuously monitors the quality of machine learning models hosted on Amazon SageMaker. Our system automatically detects data, concept, bias, and feature attribution drift in models in real-time and provides alerts so that model owners can take corrective actions and thereby maintain high quality models. We describe the key requirements obtained from customers, system design and architecture, and methodology for detecting different types of drift. Further, we provide quantitative evaluations followed by use cases, insights, and lessons learned from more than two years of production deployment.",with the increasing adoption of machine learning  ml  models and systems in high stakes settings across different industries  guaranteeing a model s performance after deployment has become crucial  monitoring models in production is a critical aspect of ensuring their continued performance and reliability  we present amazon sagemaker model monitor  a fully managed service that continuously monitors the quality of machine learning models hosted on amazon sagemaker  our system automatically detects data  concept  bias  and feature attribution drift in models in real time and provides alerts so that model owners can take corrective actions and thereby maintain high quality models  we describe the key requirements obtained from customers  system design and architecture  and methodology for detecting different types of drift  further  we provide quantitative evaluations followed by use cases  insights  and lessons learned from more than two years of production deployment ,7.0161176,5.971633,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Continuous design control for machine learning in certified medical systems,"AbstractContinuous software engineering has become commonplace in numerous fields. However, in regulating intensive sectors, where additional concerns need to be taken into account, it is often considered difficult to apply continuous development approaches, such as devops. In this paper, we present an approach for using pull requests as design controls, and apply this approach to machine learning in certified medical systems leveraging model cards, a novel technique developed to add explainability to machine learning systems, as a regulatory audit trail. The approach is demonstrated with an industrial system that we have used previously to show how medical systems can be developed in a continuous fashion.",abstractcontinuous software engineering has become commonplace in numerous fields  however  in regulating intensive sectors  where additional concerns need to be taken into account  it is often considered difficult to apply continuous development approaches  such as devops  in this paper  we present an approach for using pull requests as design controls  and apply this approach to machine learning in certified medical systems leveraging model cards  a novel technique developed to add explainability to machine learning systems  as a regulatory audit trail  the approach is demonstrated with an industrial system that we have used previously to show how medical systems can be developed in a continuous fashion ,7.339411,4.6054273,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Predicting Opioid Use Outcomes in Minoritized Communities,"Within the healthcare space, machine learning algorithms can sometimes exacerbate racial, ethnic, and gender disparities, among others. Many machine learning algorithms are trained on data from majority populations, thereby generating less accurate or reliable results for minoritized groups [3]. For example, in a widely used algorithm, at a given risk score, the technique falsely concludes that Black individuals are healthier than equally sick White individuals [6]. Thus, such large-scale algorithms can often perpetuate biases. There has been limited work at exploring potential biases in algorithms deployed within minoritized communities. In particular, minimal research has detailed how biases may manifest in algorithms developed by insurance companies to predict opioid use outcomes, or opioid overdoses among people who use opioids in urban areas. An algorithm trained on data from white individuals may provide incorrect estimates for Hispanic/Latino individuals, perhaps resulting in adverse health outcomes.
Since predicting opioid use outcomes is important to improving health in populations often neglected by larger health systems [4], our goal is to examine how machine learning algorithms perform at determining opioid use outcomes within minoritized communities. As a case study, we used data from a sample of 539 young adults who engaged in nonmedical use of prescription opioids and/or heroin [5]. The prevalence and incidence of opioid use has increased rapidly in the US in the past two decades, which is related to concomitant increases in opioid dependence, accidental overdose and death. We addressed the indicated issues through the following contributions: 1) Using machine learning techniques, we predicted opioid use outcomes for participants in our dataset; 2) We assessed if an algorithm trained on a majority sub-sample e.g., Non-Hispanic/Latino, male, could accurately predict opioid use outcomes for a minoritized subsample e.g., Latino, female. Our analysis was conducted to replicate possible real-world scenarios, and provide insight on how to improve broad health outcomes via predictive modeling. For example, if an insurance company primarily caters to Non-Hispanic/Latino individuals, models trained on data from Non-Hispanic/Latino individuals may not predict life insurance costing accurately for Hispanic individuals seeking treatment, and our analysis can provide understanding into such scenarios.
Results indicated that models were able to predict recent injection drug use and participation in drug treatment. The presence of peers who also engaged in opioid use appeared to play a role in predicting drug treatment and injection drug use. However, the available data lacked comprehensive information on other facets of opioid use, such as harm reduction. We noted a decrease in precision when we trained our models on only data from a majority sub-sample, and tested these models on a minoritized sub-sample. Overall, machine learning approaches are only as precise and useful as the data they are trained on, and to make valid and accurate predictions they must be trained on data from people who are similar in terms of key sociodemographic characteristics as the populations about whom predictions will be made. Key to mitigating biases in models to predict health outcomes within minoritized communities, is the inclusion of stakeholders at every stage of the machine learning operations (MLOps) pipeline. For example, methadone patients need to be involved in the development of models to predict methadone dropout risk [1, 2]. Similarly, a committee of ethnic minority individuals can be involved in auditing algorithms used to detect cardiovascular risk. Insurance companies and other stakeholders who use machine learning to predict opioid use outcomes need to be aware that models can exacerbate biases, and seek to improve their predictive modelling capabilities. Insurance companies that have primarily white individuals in their datasets should seek to augment their datasets with individuals from minoritized backgrounds. Such practices can aid providers in making accurate predictions if their client demographics shift, or if nonwhite individuals seek treatment. There increasingly exist independent corporations that audit large scale machine learning models, and such corporations need to ensure that minoritized communities are adequately represented within the audit committee.",within the healthcare space  machine learning algorithms can sometimes exacerbate racial  ethnic  and gender disparities  among others  many machine learning algorithms are trained on data from majority populations  thereby generating less accurate or reliable results for minoritized groups      for example  in a widely used algorithm  at a given risk score  the technique falsely concludes that black individuals are healthier than equally sick white individuals      thus  such large scale algorithms can often perpetuate biases  there has been limited work at exploring potential biases in algorithms deployed within minoritized communities  in particular  minimal research has detailed how biases may manifest in algorithms developed by insurance companies to predict opioid use outcomes  or opioid overdoses among people who use opioids in urban areas  an algorithm trained on data from white individuals may provide incorrect estimates for hispanic latino individuals  perhaps resulting in adverse health outcomes  since predicting opioid use outcomes is important to improving health in populations often neglected by larger health systems      our goal is to examine how machine learning algorithms perform at determining opioid use outcomes within minoritized communities  as a case study  we used data from a sample of     young adults who engaged in nonmedical use of prescription opioids and or heroin      the prevalence and incidence of opioid use has increased rapidly in the us in the past two decades  which is related to concomitant increases in opioid dependence  accidental overdose and death  we addressed the indicated issues through the following contributions     using machine learning techniques  we predicted opioid use outcomes for participants in our dataset     we assessed if an algorithm trained on a majority sub sample e g   non hispanic latino  male  could accurately predict opioid use outcomes for a minoritized subsample e g   latino  female  our analysis was conducted to replicate possible real world scenarios  and provide insight on how to improve broad health outcomes via predictive modeling  for example  if an insurance company primarily caters to non hispanic latino individuals  models trained on data from non hispanic latino individuals may not predict life insurance costing accurately for hispanic individuals seeking treatment  and our analysis can provide understanding into such scenarios  results indicated that models were able to predict recent injection drug use and participation in drug treatment  the presence of peers who also engaged in opioid use appeared to play a role in predicting drug treatment and injection drug use  however  the available data lacked comprehensive information on other facets of opioid use  such as harm reduction  we noted a decrease in precision when we trained our models on only data from a majority sub sample  and tested these models on a minoritized sub sample  overall  machine learning approaches are only as precise and useful as the data they are trained on  and to make valid and accurate predictions they must be trained on data from people who are similar in terms of key sociodemographic characteristics as the populations about whom predictions will be made  key to mitigating biases in models to predict health outcomes within minoritized communities  is the inclusion of stakeholders at every stage of the machine learning operations  mlops  pipeline  for example  methadone patients need to be involved in the development of models to predict methadone dropout risk         similarly  a committee of ethnic minority individuals can be involved in auditing algorithms used to detect cardiovascular risk  insurance companies and other stakeholders who use machine learning to predict opioid use outcomes need to be aware that models can exacerbate biases  and seek to improve their predictive modelling capabilities  insurance companies that have primarily white individuals in their datasets should seek to augment their datasets with individuals from minoritized backgrounds  such practices can aid providers in making accurate predictions if their client demographics shift  or if nonwhite individuals seek treatment  there increasingly exist independent corporations that audit large scale machine learning models  and such corporations need to ensure that minoritized communities are adequately represented within the audit committee ,5.2008467,5.3143554,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
AI governance in the system development life cycle: insights on responsible machine learning engineering,"In this study we explore the incorporation of artificial intelligence (AI) governance to system development life cycle (SDLC) models. We conducted expert interviews among AI and SDLC professionals and analyzed the interview data using qualitative coding and clustering to extract AI governance concepts. Subsequently, we mapped these concepts onto three stages in the machine learning (ML) system development process: (1) design, (2) development, and (3) operation. We discovered 20 governance concepts, some of which are relevant to more than one of the three stages. Our analysis highlights AI governance as a complex process that involves multiple activities and stakeholders. As development projects are unique, the governance requirements and processes also vary. This study is a step towards understanding how AI governance is conceptually connected to ML systems' management processes through the project life cycle.",in this study we explore the incorporation of artificial intelligence  ai  governance to system development life cycle  sdlc  models  we conducted expert interviews among ai and sdlc professionals and analyzed the interview data using qualitative coding and clustering to extract ai governance concepts  subsequently  we mapped these concepts onto three stages in the machine learning  ml  system development process      design      development  and     operation  we discovered    governance concepts  some of which are relevant to more than one of the three stages  our analysis highlights ai governance as a complex process that involves multiple activities and stakeholders  as development projects are unique  the governance requirements and processes also vary  this study is a step towards understanding how ai governance is conceptually connected to ml systems  management processes through the project life cycle ,11.740376,5.6230435,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Federated learning for 5G base station traffic forecasting,"AbstractCellular traffic prediction is of great importance on the path of enabling 5G mobile networks to perform intelligent and efficient infrastructure planning and management. However, available data are limited to base station logging information. Hence, training methods for generating high-quality predictions that can generalize to new observations across diverse parties are in demand. Traditional approaches require collecting measurements from multiple base stations, transmitting them to a central entity and conducting machine learning operations using the acquire data. The dissemination of local observations raises concerns regarding confidentiality and performance, which impede the applicability of machine learning techniques. Although various distributed learning methods have been proposed to address this issue, their application to traffic prediction remains highly unexplored. In this work, we investigate the efficacy of federated learning applied to raw base station LTE data for time-series forecasting. We evaluate one-step predictions using five different neural network architectures trained with a federated setting on non-identically distributed data. Our results show that the learning architectures adapted to the federated setting yield equivalent prediction error to the centralized setting. In addition, preprocessing techniques on base stations enhance forecasting accuracy, while advanced federated aggregators do not surpass simpler approaches. Simulations considering the environmental impact suggest that federated learning holds the potential for reducing carbon emissions and energy consumption. Finally, we consider a large-scale scenario with synthetic data and demonstrate that federated learning reduces the computational and communication costs compared to centralized settings.Highlights •Providing insights on the application of federated learning for a real-world time-series forecasting task.•Identifying the challenges of training federated time-series forecasting models with mixed types of non-iid data.•Discussing the influence of pre-processing on the final prediction accuracy.•Evaluating the applicability and effectiveness of various learning architectures.•Simulating the environmental impact of federated learning compared to traditional centralized learning.•Investigating the effects of different aggregation algorithms on model predictive accuracy.",abstractcellular traffic prediction is of great importance on the path of enabling  g mobile networks to perform intelligent and efficient infrastructure planning and management  however  available data are limited to base station logging information  hence  training methods for generating high quality predictions that can generalize to new observations across diverse parties are in demand  traditional approaches require collecting measurements from multiple base stations  transmitting them to a central entity and conducting machine learning operations using the acquire data  the dissemination of local observations raises concerns regarding confidentiality and performance  which impede the applicability of machine learning techniques  although various distributed learning methods have been proposed to address this issue  their application to traffic prediction remains highly unexplored  in this work  we investigate the efficacy of federated learning applied to raw base station lte data for time series forecasting  we evaluate one step predictions using five different neural network architectures trained with a federated setting on non identically distributed data  our results show that the learning architectures adapted to the federated setting yield equivalent prediction error to the centralized setting  in addition  preprocessing techniques on base stations enhance forecasting accuracy  while advanced federated aggregators do not surpass simpler approaches  simulations considering the environmental impact suggest that federated learning holds the potential for reducing carbon emissions and energy consumption  finally  we consider a large scale scenario with synthetic data and demonstrate that federated learning reduces the computational and communication costs compared to centralized settings highlights  providing insights on the application of federated learning for a real world time series forecasting task  identifying the challenges of training federated time series forecasting models with mixed types of non iid data  discussing the influence of pre processing on the final prediction accuracy  evaluating the applicability and effectiveness of various learning architectures  simulating the environmental impact of federated learning compared to traditional centralized learning  investigating the effects of different aggregation algorithms on model predictive accuracy ,5.9986734,7.8499665,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Digital Twin for Continual Learning in Location Based Services,"AbstractDecoupling the physical world and providing standardized service interfaces is still challenging when developing Location Based Services (LBS). This lack also hinders the possibility of developing Intelligent services on top of LBS architectures. In this paper, we propose a multi-layer Digital Twin-based architecture that aims to enable the development of machine learning-based Intelligent LBS (I-LBS) that are able to adapt, evolve, and perform Continual Learning (CL). The platform uses Digital Twins to ensure physical abstraction and provide cyber–physical knowledge to the I-LBSs, which is defined as an execution graph of operation modules. Finally, we simulated a use-case for this platform in the complex scenario of Healthcare organization and management where the I-LBS classifies allowed/not allowed trajectories of users inside a real-existing hospital scenario depending on their role in the organization. The use case is implemented as a Deep Learning-based reconstruction task of high-resolution trajectories processed by the DT architecture that also deploys the I-LBS. The platform is evaluated in terms of physical complexity and computational time on the DT side and on both a traditional machine learning setting and a replay-based CL one for the intelligence side to demonstrate the flexibility and adaptability features introduced by the components for dynamic or unseen scenarios.",abstractdecoupling the physical world and providing standardized service interfaces is still challenging when developing location based services  lbs   this lack also hinders the possibility of developing intelligent services on top of lbs architectures  in this paper  we propose a multi layer digital twin based architecture that aims to enable the development of machine learning based intelligent lbs  i lbs  that are able to adapt  evolve  and perform continual learning  cl   the platform uses digital twins to ensure physical abstraction and provide cyber physical knowledge to the i lbss  which is defined as an execution graph of operation modules  finally  we simulated a use case for this platform in the complex scenario of healthcare organization and management where the i lbs classifies allowed not allowed trajectories of users inside a real existing hospital scenario depending on their role in the organization  the use case is implemented as a deep learning based reconstruction task of high resolution trajectories processed by the dt architecture that also deploys the i lbs  the platform is evaluated in terms of physical complexity and computational time on the dt side and on both a traditional machine learning setting and a replay based cl one for the intelligence side to demonstrate the flexibility and adaptability features introduced by the components for dynamic or unseen scenarios ,9.069376,7.0961328,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
TinyMLOps for real-time ultra-low power MCUs applied to frame-based event classification,"TinyML applications such as speech recognition, motion detection, or anomaly detection are attracting many industries and researchers thanks to their innovative and cost-effective potential. Since tinyMLOps is at an even earlier stage than MLOps, the best practices and tools of tinyML are yet to be found to deliver seamless production-ready applications. TinyMLOps has common challenges with MLOps, but it differs from it because of its hard footprint constraints. In this work, we analyze the steps of successful tinyMLOps with a highlight on challenges and solutions in the case of real-time frame-based event classification on low-power devices. We also report a comparative result of our tinyMLOps solution against tf.lite and NNoM.",tinyml applications such as speech recognition  motion detection  or anomaly detection are attracting many industries and researchers thanks to their innovative and cost effective potential  since tinymlops is at an even earlier stage than mlops  the best practices and tools of tinyml are yet to be found to deliver seamless production ready applications  tinymlops has common challenges with mlops  but it differs from it because of its hard footprint constraints  in this work  we analyze the steps of successful tinymlops with a highlight on challenges and solutions in the case of real time frame based event classification on low power devices  we also report a comparative result of our tinymlops solution against tf lite and nnom ,7.853775,3.5846927,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Joint optimal resource allocation schemes for downlink cooperative cellular networks over orthogonal frequency division multiplexing carriers,"This study concentrates on the study of a downlink cooperative cellular (DCC) network in which an access point is located in the centre of each cell and two relay stations are installed in the border between both sectors of a cell to obtain higher cell‐edge throughput. To optimise the network efficiency, a joint optimal subcarrier and power allocation scheme is proposed which initially derives the highest achievable rate for a single‐legacy user (LU), then, through further evaluation and analysis, this is generalised to the case of a multiple‐LU environment. Next, to maximise the overall throughput and ensure fairness, a multi‐objective lexicographical optimisation problem (MLOP) is formulated to maximise the minimum LUs rate while improving the overall throughput. As the proposed MLOP is a mixed‐integer non‐linear problem, finding optimal solutions is impractical and in general, there is no standard method for optimally obtaining a solution. Hence, two efficient algorithms are introduced in this study. Simulation results confirm that the proposed algorithms achieve a fair and near‐optimal performance for the multi‐LU DCC network based on two relay channels, which makes them desirable in practice compared to some of the sub‐optimal well‐known algorithms investigated in this study.",this study concentrates on the study of a downlink cooperative cellular  dcc  network in which an access point is located in the centre of each cell and two relay stations are installed in the border between both sectors of a cell to obtain higher cell edge throughput  to optimise the network efficiency  a joint optimal subcarrier and power allocation scheme is proposed which initially derives the highest achievable rate for a single legacy user  lu   then  through further evaluation and analysis  this is generalised to the case of a multiple lu environment  next  to maximise the overall throughput and ensure fairness  a multi objective lexicographical optimisation problem  mlop  is formulated to maximise the minimum lus rate while improving the overall throughput  as the proposed mlop is a mixed integer non linear problem  finding optimal solutions is impractical and in general  there is no standard method for optimally obtaining a solution  hence  two efficient algorithms are introduced in this study  simulation results confirm that the proposed algorithms achieve a fair and near optimal performance for the multi lu dcc network based on two relay channels  which makes them desirable in practice compared to some of the sub optimal well known algorithms investigated in this study ,4.262292,7.71502,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Quality assurance of generative dialog models in an evolving conversational agent used for Swedish language practice,"Due to the migration megatrend, efficient and effective second-language acquisition is vital. One proposed solution involves AI-enabled conversational agents for person-centered interactive language practice. We present results from ongoing action research targeting quality assurance of proprietary generative dialog models trained for virtual job interviews. The action team elicited a set of 38 requirements for which we designed corresponding automated test cases for 15 of particular interest to the evolving solution. Our results show that six of the test case designs can detect meaningful differences between candidate models. While quality assurance of natural language processing applications is complex, we provide initial steps toward an automated framework for machine learning model selection in the context of an evolving conversational agent. Future work will focus on model selection in an MLOps setting.",due to the migration megatrend  efficient and effective second language acquisition is vital  one proposed solution involves ai enabled conversational agents for person centered interactive language practice  we present results from ongoing action research targeting quality assurance of proprietary generative dialog models trained for virtual job interviews  the action team elicited a set of    requirements for which we designed corresponding automated test cases for    of particular interest to the evolving solution  our results show that six of the test case designs can detect meaningful differences between candidate models  while quality assurance of natural language processing applications is complex  we provide initial steps toward an automated framework for machine learning model selection in the context of an evolving conversational agent  future work will focus on model selection in an mlops setting ,6.98426,5.0774345,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Towards fluid software architectures: bidirectional human-AI interaction,"The research on engineering software applications that employ artificial intelligence (AI) and machine learning (ML) is at an all-time peak. However, most of the research in this area is focused on the interactions between humans and AI which, in turn, is predominantly concerned with either building immersive interfaces and user experiences that allow for increased telemetry or on handling AI and ML applications in production (MLOps). Nonetheless, the research on fundamental architectural differences between AI-powered applications and traditional ones did not receive its fair share of attention. To that end, we believe that a new take on the fundamental architecture of building software applications is needed. With the ever increasing prominence of content-driven AI-powered applications, it is our conviction that 1) content could be served by servers without clients requesting, 2) servers could (should) request data from clients without waiting for their requests, and 3) interfaces should dynamically adapt to updates that happen to the intelligence driving the application. Hence, in this paper, we propose the fluid architecture that facilitates the bidirectional interaction between clients and servers as well as accommodates the co-dependent evolution of interfaces and back-end intelligence in AI-powered systems.",the research on engineering software applications that employ artificial intelligence  ai  and machine learning  ml  is at an all time peak  however  most of the research in this area is focused on the interactions between humans and ai which  in turn  is predominantly concerned with either building immersive interfaces and user experiences that allow for increased telemetry or on handling ai and ml applications in production  mlops   nonetheless  the research on fundamental architectural differences between ai powered applications and traditional ones did not receive its fair share of attention  to that end  we believe that a new take on the fundamental architecture of building software applications is needed  with the ever increasing prominence of content driven ai powered applications  it is our conviction that    content could be served by servers without clients requesting     servers could  should  request data from clients without waiting for their requests  and    interfaces should dynamically adapt to updates that happen to the intelligence driving the application  hence  in this paper  we propose the fluid architecture that facilitates the bidirectional interaction between clients and servers as well as accommodates the co dependent evolution of interfaces and back end intelligence in ai powered systems ,10.54069,5.640865,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
dalex: responsible machine learning with interactive explainability and fairness in Python,"In modern machine learning, we observe the phenomenon of opaqueness debt, which manifests itself by an increased risk of discrimination, lack of reproducibility, and deated performance due to data drift. An increasing amount of available data and computing power results in the growing complexity of black-box predictive models. To manage these issues, good MLOps practice asks for better validation of model performance and fairness, higher explainability, and continuous monitoring. The necessity for deeper model transparency comes from both scientific and social domains and is also caused by emerging laws and regulations on artificial intelligence. To facilitate the responsible development of machine learning models, we introduce dalex, a Python package which implements a model-agnostic interface for interactive explainability and fairness. It adopts the design crafted through the development of various tools for explainable machine learning; thus, it aims at the unification of existing solutions. This library's source code and documentation are available under open license at https://python.drwhy.ai.",in modern machine learning  we observe the phenomenon of opaqueness debt  which manifests itself by an increased risk of discrimination  lack of reproducibility  and deated performance due to data drift  an increasing amount of available data and computing power results in the growing complexity of black box predictive models  to manage these issues  good mlops practice asks for better validation of model performance and fairness  higher explainability  and continuous monitoring  the necessity for deeper model transparency comes from both scientific and social domains and is also caused by emerging laws and regulations on artificial intelligence  to facilitate the responsible development of machine learning models  we introduce dalex  a python package which implements a model agnostic interface for interactive explainability and fairness  it adopts the design crafted through the development of various tools for explainable machine learning  thus  it aims at the unification of existing solutions  this library s source code and documentation are available under open license at https   python drwhy ai ,10.745212,6.709679,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Iterative Assessment and Improvement of DNN Operational Accuracy,"Deep Neural Networks (DNN) are nowadays largely adopted in many application domains thanks to their human-like, or even superhuman, performance in specific tasks. However, due to unpredictable/unconsidered operating conditions, unexpected failures show up on field, making the performance of a DNN in operation very different from the one estimated prior to release.
In the life cycle of DNN systems, the assessment of accuracy is typically addressed in two ways: offline, via sampling of operational inputs, or online, via pseudo-oracles. The former is considered more expensive due to the need for manual labeling of the sampled inputs. The latter is automatic but less accurate.
We believe that emerging iterative industrial-strength life cycle models for Machine Learning systems, like MLOps, offer the possibility to leverage inputs observed in operation not only to provide faithful estimates of a DNN accuracy, but also to improve it through remodeling/retraining actions.
We propose DAIC (DNN Assessment and Improvement Cycle), an approach which combines ""low-cost"" online pseudo-oracles and ""high-cost"" offline sampling techniques to estimate and improve the operational accuracy of a DNN in the iterations of its life cycle. Preliminary results show the benefits of combining the two approaches and integrating them in the DNN life cycle.",deep neural networks  dnn  are nowadays largely adopted in many application domains thanks to their human like  or even superhuman  performance in specific tasks  however  due to unpredictable unconsidered operating conditions  unexpected failures show up on field  making the performance of a dnn in operation very different from the one estimated prior to release  in the life cycle of dnn systems  the assessment of accuracy is typically addressed in two ways  offline  via sampling of operational inputs  or online  via pseudo oracles  the former is considered more expensive due to the need for manual labeling of the sampled inputs  the latter is automatic but less accurate  we believe that emerging iterative industrial strength life cycle models for machine learning systems  like mlops  offer the possibility to leverage inputs observed in operation not only to provide faithful estimates of a dnn accuracy  but also to improve it through remodeling retraining actions  we propose daic  dnn assessment and improvement cycle   an approach which combines  low cost  online pseudo oracles and  high cost  offline sampling techniques to estimate and improve the operational accuracy of a dnn in the iterations of its life cycle  preliminary results show the benefits of combining the two approaches and integrating them in the dnn life cycle ,3.9053996,7.628134,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Socio-Technical Anti-Patterns in Building ML-Enabled Software: Insights from Leaders on the Forefront,"Although machine learning (ML)-enabled software systems seem to be a success story considering their rise in economic power, there are consistent reports from companies and practitioners struggling to bring ML models into production. Many papers have focused on specific, and purely technical aspects, such as testing and pipelines, but only few on socio-technical aspects.Driven by numerous anecdotes and reports from practitioners, our goal is to collect and analyze socio-technical challenges of productionizing ML models centered around and within teams. To this end, we conducted the largest qualitative empirical study in this area, involving the manual analysis of 66 hours of talks that have been recorded by the MLOps community.By analyzing talks from practitioners for practitioners of a community with over 11,000 members in their Slack workspace, we found 17 anti-patterns, often rooted in organizational or management problems. We further list recommendations to overcome these problems, ranging from technical solutions over guidelines to organizational restructuring. Finally, we contextualize our findings with previous research, confirming existing results, validating our own, and highlighting new insights.",although machine learning  ml  enabled software systems seem to be a success story considering their rise in economic power  there are consistent reports from companies and practitioners struggling to bring ml models into production  many papers have focused on specific  and purely technical aspects  such as testing and pipelines  but only few on socio technical aspects driven by numerous anecdotes and reports from practitioners  our goal is to collect and analyze socio technical challenges of productionizing ml models centered around and within teams  to this end  we conducted the largest qualitative empirical study in this area  involving the manual analysis of    hours of talks that have been recorded by the mlops community by analyzing talks from practitioners for practitioners of a community with over        members in their slack workspace  we found    anti patterns  often rooted in organizational or management problems  we further list recommendations to overcome these problems  ranging from technical solutions over guidelines to organizational restructuring  finally  we contextualize our findings with previous research  confirming existing results  validating our own  and highlighting new insights ,10.181685,4.280096,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
MDE for machine learning-enabled software systems: a case study and comparison of MontiAnna & ML-Quadrat,"In this paper, we propose to adopt the MDE paradigm for the development of Machine Learning (ML)-enabled software systems with a focus on the Internet of Things (IoT) domain. We illustrate how two state-of-the-art open-source modeling tools, namely MontiAnna and ML-Quadrat can be used for this purpose as demonstrated through a case study. The case study illustrates using ML, in particular deep Artificial Neural Networks (ANNs), for automated image recognition of handwritten digits using the MNIST reference dataset, and integrating the machine learning components into an IoT-system. Subsequently, we conduct a functional comparison of the two frameworks, setting out an analysis base to include a broad range of design considerations, such as the problem domain, methods for the ML integration into larger systems, and supported ML methods, as well as topics of recent intense interest to the ML community, such as AutoML and MLOps. Accordingly, this paper is focused on elucidating the potential of the MDE approach in the ML domain. This supports the ML-engineer in developing the (ML/software) model rather than implementing the code, and additionally enforces reusability and modularity of the design through enabling the out-of-the-box integration of ML functionality as a component of the IoT or cyber-physical systems.",in this paper  we propose to adopt the mde paradigm for the development of machine learning  ml  enabled software systems with a focus on the internet of things  iot  domain  we illustrate how two state of the art open source modeling tools  namely montianna and ml quadrat can be used for this purpose as demonstrated through a case study  the case study illustrates using ml  in particular deep artificial neural networks  anns   for automated image recognition of handwritten digits using the mnist reference dataset  and integrating the machine learning components into an iot system  subsequently  we conduct a functional comparison of the two frameworks  setting out an analysis base to include a broad range of design considerations  such as the problem domain  methods for the ml integration into larger systems  and supported ml methods  as well as topics of recent intense interest to the ml community  such as automl and mlops  accordingly  this paper is focused on elucidating the potential of the mde approach in the ml domain  this supports the ml engineer in developing the  ml software  model rather than implementing the code  and additionally enforces reusability and modularity of the design through enabling the out of the box integration of ml functionality as a component of the iot or cyber physical systems ,7.43195,4.409268,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Multi Datasource LTV User Representation (MDLUR),"In this paper, we propose a novel user representation methodology called Multi Datasource LTV User Representation (MDLUR). Our model aims to establish a universal user embedding for downstream tasks, specifically lifetime value (LTV) prediction on specific days after installation. MDLUR uses a combination of various data sources, including user information, portrait, and behavior data from the first n days after installation of the social casino game ""Club Vegas Slots"" developed by Bagelcode. This model overcomes the limitation of conventional approaches that struggle with effectively utilizing various data sources or accurately capturing interactions in sparse datasets. MDLUR adopts unique model architectures tailored to each data source. Coupled with robust dimensionality reduction techniques, this model succeeds in the effective integration of insights from various data sources. Comprehensive experiments on real-world industrial data demonstrate the superiority of the proposed methods compared to SOTA baselines including Two-Stage XGBoost, WhalesDector, MSDMT, and BST. Not only did it outperform these models, but it has also been efficiently deployed and tested in a live environment using MLOps demonstrating its maintainability. The representation may potentially be applied to a wide range of downstream tasks, including conversion, churn, and retention prediction, as well as user segmentation and item recommendation.",in this paper  we propose a novel user representation methodology called multi datasource ltv user representation  mdlur   our model aims to establish a universal user embedding for downstream tasks  specifically lifetime value  ltv  prediction on specific days after installation  mdlur uses a combination of various data sources  including user information  portrait  and behavior data from the first n days after installation of the social casino game  club vegas slots  developed by bagelcode  this model overcomes the limitation of conventional approaches that struggle with effectively utilizing various data sources or accurately capturing interactions in sparse datasets  mdlur adopts unique model architectures tailored to each data source  coupled with robust dimensionality reduction techniques  this model succeeds in the effective integration of insights from various data sources  comprehensive experiments on real world industrial data demonstrate the superiority of the proposed methods compared to sota baselines including two stage xgboost  whalesdector  msdmt  and bst  not only did it outperform these models  but it has also been efficiently deployed and tested in a live environment using mlops demonstrating its maintainability  the representation may potentially be applied to a wide range of downstream tasks  including conversion  churn  and retention prediction  as well as user segmentation and item recommendation ,5.6704016,6.370729,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Multi-metric Approach for Decomposition of Microservice-Based Data Science Workflows,"AbstractTo support fast development cycles in data science, microservice architectures are becoming increasingly important. However, while the design and identification of microservices in transaction-oriented applications are already widely studied, software architects lack support for data science workflows. The identification of microservices for data science workflows differs due to high volume and velocity characteristics.With this work, we aim to present a multi-metric approach for decomposition of microservice-based data science workflows. First, we select different metrics and evaluate their impact on workflow execution under different workload and data conditions. Within the approach, we provide a software architecture that enables microservice architectures to be deployed concurrently in cloud environments considering microservice design patterns such as orchestration of choreography. This architecture can be used to run real-world experiments, aggregate logs and analyze them in an automated way with respect to our chosen metrics. We evaluated our approach using a real-world data science workflow for automated startup assessments.Our work has both practical, theoretical and economic implications. Practically, it can support software architects and data scientists in architecting microservices. In this context, it also has implications for MLOps, as microservices can be used to train and deploy ML models. Theoretically, our software architecture can be used for other research comparing microservice architectures. Economically, we also achieve business impact by looking at the cost of microservice architectures based on service activation time.",abstractto support fast development cycles in data science  microservice architectures are becoming increasingly important  however  while the design and identification of microservices in transaction oriented applications are already widely studied  software architects lack support for data science workflows  the identification of microservices for data science workflows differs due to high volume and velocity characteristics with this work  we aim to present a multi metric approach for decomposition of microservice based data science workflows  first  we select different metrics and evaluate their impact on workflow execution under different workload and data conditions  within the approach  we provide a software architecture that enables microservice architectures to be deployed concurrently in cloud environments considering microservice design patterns such as orchestration of choreography  this architecture can be used to run real world experiments  aggregate logs and analyze them in an automated way with respect to our chosen metrics  we evaluated our approach using a real world data science workflow for automated startup assessments our work has both practical  theoretical and economic implications  practically  it can support software architects and data scientists in architecting microservices  in this context  it also has implications for mlops  as microservices can be used to train and deploy ml models  theoretically  our software architecture can be used for other research comparing microservice architectures  economically  we also achieve business impact by looking at the cost of microservice architectures based on service activation time ,9.445345,3.5887182,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Studying the Practices of Deploying Machine Learning Projects on Docker,"Docker is a containerization service that allows for convenient deployment of websites, databases, applications’ APIs, and machine learning (ML) models with a few lines of code. Studies have recently explored the use of Docker for deploying general software projects with no specific focus on how Docker is used to deploy ML-based projects. In this study, we conducted an exploratory study to understand how Docker is being used to deploy ML-based projects. As the initial step, we examined the categories of ML-based projects that use Docker. We then examined why and how these projects use Docker, and the characteristics of the resulting Docker images. Our results indicate that six categories of ML-based projects use Docker for deployment, including ML Applications, MLOps/ AIOps, Toolkits, DL Frameworks, Models, and Documentation. We derived the taxonomy of 21 major categories representing the purposes of using Docker, including those specific to models such as model management tasks (e.g., testing, training). We then showed that ML engineers use Docker images mostly to help with the platform portability, such as transferring the software across the operating systems, runtimes such as GPU, and language constraints. However, we also found that more resources may be required to run the Docker images for building ML-based software projects due to the large number of files contained in the image layers with deeply nested directories. We hope to shed light on the emerging practices of deploying ML software projects using containers and highlight aspects that should be improved.",docker is a containerization service that allows for convenient deployment of websites  databases  applications  apis  and machine learning  ml  models with a few lines of code  studies have recently explored the use of docker for deploying general software projects with no specific focus on how docker is used to deploy ml based projects  in this study  we conducted an exploratory study to understand how docker is being used to deploy ml based projects  as the initial step  we examined the categories of ml based projects that use docker  we then examined why and how these projects use docker  and the characteristics of the resulting docker images  our results indicate that six categories of ml based projects use docker for deployment  including ml applications  mlops  aiops  toolkits  dl frameworks  models  and documentation  we derived the taxonomy of    major categories representing the purposes of using docker  including those specific to models such as model management tasks  e g   testing  training   we then showed that ml engineers use docker images mostly to help with the platform portability  such as transferring the software across the operating systems  runtimes such as gpu  and language constraints  however  we also found that more resources may be required to run the docker images for building ml based software projects due to the large number of files contained in the image layers with deeply nested directories  we hope to shed light on the emerging practices of deploying ml software projects using containers and highlight aspects that should be improved ,7.423319,6.808197,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Dynamic data management for continuous retraining,"Managing dynamic datasets intended to serve as training data for a Machine Learning (ML) model often emerges as very challenging, especially when data is often altered iteratively and already existing ML models should pertain to the data. For example, this applies when new data versions arise from either a generated or aggregated extension of an existing dataset a model has already been trained on. In this work, it is investigated on how a model-based approach for these training data concerns can be provided as well as how the complete process, including the resulting training and retraining process of the ML model, can therein be integrated. Hence, model-based concepts and the implementation are devised to cope with the complexity of iterative data management as an enabler for the integration of continuous retraining routines. With Deep Learning techniques becoming technically feasible and massively being developed further over the last decade, MLOps, aiming to establish DevOps tailored to ML projects, gained crucial relevance. Unfortunately, data-management concepts for iteratively growing datasets with retraining capabilities embedded in a model-driven ML development methodology are unexplored to the best of our knowledge. To fill in this gap, this contribution provides such agile data management concepts and integrates them and continuous retraining into the model-driven ML Framework MontiAnna [18]. The new functionality is evaluated in the context of a research project where ML is exploited for the optimal design of lattice structures for crash applications.",managing dynamic datasets intended to serve as training data for a machine learning  ml  model often emerges as very challenging  especially when data is often altered iteratively and already existing ml models should pertain to the data  for example  this applies when new data versions arise from either a generated or aggregated extension of an existing dataset a model has already been trained on  in this work  it is investigated on how a model based approach for these training data concerns can be provided as well as how the complete process  including the resulting training and retraining process of the ml model  can therein be integrated  hence  model based concepts and the implementation are devised to cope with the complexity of iterative data management as an enabler for the integration of continuous retraining routines  with deep learning techniques becoming technically feasible and massively being developed further over the last decade  mlops  aiming to establish devops tailored to ml projects  gained crucial relevance  unfortunately  data management concepts for iteratively growing datasets with retraining capabilities embedded in a model driven ml development methodology are unexplored to the best of our knowledge  to fill in this gap  this contribution provides such agile data management concepts and integrates them and continuous retraining into the model driven ml framework montianna       the new functionality is evaluated in the context of a research project where ml is exploited for the optimal design of lattice structures for crash applications ,10.629709,5.543742,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Research and Development of a Smart Solution for Runtime Web Application Self-Protection,"In contemporary times, ensuring web application security is a critical concern for organizations due to the prevalence of numerous types of attacks that serve diverse purposes. While traditional security measures such as web application firewalls (WAF) and intrusion detection systems (IDS) can help mitigate attacks, there is still a possibility of them being circumvented or compromised. A more efficacious approach is to adopt runtime application self-protection (RASP) solutions integrated within the web application. This solution has demonstrated its effectiveness by aiding in early attack detection and rapid attack mitigation. In this research, we propose a smart solution for runtime web application self-protection (RASP) to protect against vulnerabilities, attacks, and common weaknesses that have been rated among the top ten web security risks in 2021 by the Open Web Application Security Project (OWASP). The proposed solution leverages convolutional neural network (CNN) and a family of recurrent neural network (RNN) techniques. It builds a deep learning model with deep neural network architectures that scrutinizes user requests, thereby detecting potential SQL injection (SQLi), Cross-Site scripting (XSS), command injection (CMDi), and other types of attacks. The solution is designed to dynamically adapt to the application’s behavior and traffic, with the goal of minimizing false positives and preventing the blocking of legitimate traffic. Furthermore, the proposed solution, based on a microservices architecture, enhances the flexibility of the prediction module during upgrades and automated deployment. It is integrated with MLOps and DevSecOps and is also designed to be compatible with RESTful API servers. Our results have validated the efficacy of this solution in providing real-time application protection.",in contemporary times  ensuring web application security is a critical concern for organizations due to the prevalence of numerous types of attacks that serve diverse purposes  while traditional security measures such as web application firewalls  waf  and intrusion detection systems  ids  can help mitigate attacks  there is still a possibility of them being circumvented or compromised  a more efficacious approach is to adopt runtime application self protection  rasp  solutions integrated within the web application  this solution has demonstrated its effectiveness by aiding in early attack detection and rapid attack mitigation  in this research  we propose a smart solution for runtime web application self protection  rasp  to protect against vulnerabilities  attacks  and common weaknesses that have been rated among the top ten web security risks in      by the open web application security project  owasp   the proposed solution leverages convolutional neural network  cnn  and a family of recurrent neural network  rnn  techniques  it builds a deep learning model with deep neural network architectures that scrutinizes user requests  thereby detecting potential sql injection  sqli   cross site scripting  xss   command injection  cmdi   and other types of attacks  the solution is designed to dynamically adapt to the application s behavior and traffic  with the goal of minimizing false positives and preventing the blocking of legitimate traffic  furthermore  the proposed solution  based on a microservices architecture  enhances the flexibility of the prediction module during upgrades and automated deployment  it is integrated with mlops and devsecops and is also designed to be compatible with restful api servers  our results have validated the efficacy of this solution in providing real time application protection ,3.1430476,5.5282345,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Local extreme complete trio pattern for multimedia image retrieval system,"This paper presents a new feature descriptor, namely local extreme complete trio pattern (LECTP) for image retrieval application. The LECTP extracts complete extreme to minimal edge information in all possible directions using trio values. The LECTP integrates the local extreme sign trio patterns (LESTP) with magnitude local operator (MLOP) for image retrieval. The performance of the LECTP is tested by conducting three experiments on Corel-5 000, Corel-10 000 and MIT-VisTex color databases, respectively. The results after investigation show a significant improvement in terms of average retrieval precision (ARP) and average retrieval rate (ARR) as compared to the other state-of-the art techniques in content based image retrieval (CBIR).",this paper presents a new feature descriptor  namely local extreme complete trio pattern  lectp  for image retrieval application  the lectp extracts complete extreme to minimal edge information in all possible directions using trio values  the lectp integrates the local extreme sign trio patterns  lestp  with magnitude local operator  mlop  for image retrieval  the performance of the lectp is tested by conducting three experiments on corel        corel        and mit vistex color databases  respectively  the results after investigation show a significant improvement in terms of average retrieval precision  arp  and average retrieval rate  arr  as compared to the other state of the art techniques in content based image retrieval  cbir  ,4.1222363,6.1207037,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Micro-Armed Bandit: Lightweight & Reusable Reinforcement Learning for Microarchitecture Decision-Making,"Online Reinforcement Learning (RL) has been adopted as an effective mechanism in various decision-making problems in microarchitecture. Its high adaptability and the ability to learn at runtime are attractive characteristics in microarchitecture settings. However, although hardware RL agents are effective, they suffer from two main problems. First, they have high complexity and storage overhead. This complexity stems from decomposing the environment into a large number of states and then, for each of these states, bookkeeping many action values. Second, many RL agents are engineered for a specific application and are not reusable.  In this work, we tackle both of these shortcomings by designing an RL agent that is both lightweight and reusable across different microarchitecture decision-making problems. We find that, in some of these problems, only a small fraction of the action space is useful in a given time window. We refer to this property as temporal homogeneity in the action space. Motivated by this property, we design an RL agent based on Multi-Armed Bandit algorithms, the simplest form of RL. We call our agent Micro-Armed Bandit.  We showcase our agent in two use cases: data prefetching and instruction fetch in simultaneous multithreaded (SMT) processors. For prefetching, our agent outperforms non-RL prefetchers Bingo and MLOP by 2.6% and 2.3% (geometric mean), respectively, and attains similar performance as the state-of-the-art RL prefetcher Pythia—with the dramatically lower storage requirement of only 100 bytes. For SMT instruction fetch, our agent outperforms the Hill Climbing method by 2.2% (geometric mean).",online reinforcement learning  rl  has been adopted as an effective mechanism in various decision making problems in microarchitecture  its high adaptability and the ability to learn at runtime are attractive characteristics in microarchitecture settings  however  although hardware rl agents are effective  they suffer from two main problems  first  they have high complexity and storage overhead  this complexity stems from decomposing the environment into a large number of states and then  for each of these states  bookkeeping many action values  second  many rl agents are engineered for a specific application and are not reusable   in this work  we tackle both of these shortcomings by designing an rl agent that is both lightweight and reusable across different microarchitecture decision making problems  we find that  in some of these problems  only a small fraction of the action space is useful in a given time window  we refer to this property as temporal homogeneity in the action space  motivated by this property  we design an rl agent based on multi armed bandit algorithms  the simplest form of rl  we call our agent micro armed bandit   we showcase our agent in two use cases  data prefetching and instruction fetch in simultaneous multithreaded  smt  processors  for prefetching  our agent outperforms non rl prefetchers bingo and mlop by      and       geometric mean   respectively  and attains similar performance as the state of the art rl prefetcher pythia with the dramatically lower storage requirement of only     bytes  for smt instruction fetch  our agent outperforms the hill climbing method by       geometric mean  ,4.2749176,8.2145405,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Pythia: A Customizable Hardware Prefetching Framework Using Online Reinforcement Learning,"Past research has proposed numerous hardware prefetching techniques, most of which rely on exploiting one specific type of program context information (e.g., program counter, cacheline address, or delta between cacheline addresses) to predict future memory accesses. These techniques either completely neglect a prefetcher’s undesirable effects (e.g., memory bandwidth usage) on the overall system, or incorporate system-level feedback as an afterthought to a system-unaware prefetch algorithm. We show that prior prefetchers often lose their performance benefit over a wide range of workloads and system configurations due to their inherent inability to take multiple different types of program context and system-level feedback information into account while prefetching. In this paper, we make a case for designing a holistic prefetch algorithm that learns to prefetch using multiple different types of program context and system-level feedback information inherent to its design. To this end, we propose Pythia, which formulates the prefetcher as a reinforcement learning agent. For every demand request, Pythia observes multiple different types of program context information to make a prefetch decision. For every prefetch decision, Pythia receives a numerical reward that evaluates prefetch quality under the current memory bandwidth usage. Pythia uses this reward to reinforce the correlation between program context information and prefetch decision to generate highly accurate, timely, and system-aware prefetch requests in the future. Our extensive evaluations using simulation and hardware synthesis show that Pythia outperforms two state-of-the-art prefetchers (MLOP and Bingo) by 3.4\% and 3.8\% in single-core, 7.7\% and 9.6\% in twelve-core, and 16.9\% and 20.2\% in bandwidth-constrained core configurations, while incurring only 1.03\% area overhead over a desktop-class processor and no software changes in workloads. The source code of Pythia can be freely downloaded from https://github.com/CMU-SAFARI/Pythia.",past research has proposed numerous hardware prefetching techniques  most of which rely on exploiting one specific type of program context information  e g   program counter  cacheline address  or delta between cacheline addresses  to predict future memory accesses  these techniques either completely neglect a prefetcher s undesirable effects  e g   memory bandwidth usage  on the overall system  or incorporate system level feedback as an afterthought to a system unaware prefetch algorithm  we show that prior prefetchers often lose their performance benefit over a wide range of workloads and system configurations due to their inherent inability to take multiple different types of program context and system level feedback information into account while prefetching  in this paper  we make a case for designing a holistic prefetch algorithm that learns to prefetch using multiple different types of program context and system level feedback information inherent to its design  to this end  we propose pythia  which formulates the prefetcher as a reinforcement learning agent  for every demand request  pythia observes multiple different types of program context information to make a prefetch decision  for every prefetch decision  pythia receives a numerical reward that evaluates prefetch quality under the current memory bandwidth usage  pythia uses this reward to reinforce the correlation between program context information and prefetch decision to generate highly accurate  timely  and system aware prefetch requests in the future  our extensive evaluations using simulation and hardware synthesis show that pythia outperforms two state of the art prefetchers  mlop and bingo  by       and       in single core        and       in twelve core  and        and        in bandwidth constrained core configurations  while incurring only        area overhead over a desktop class processor and no software changes in workloads  the source code of pythia can be freely downloaded from https   github com cmu safari pythia ,4.6521077,8.235613,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Berti: An Accurate Local-Delta Data Prefetcher,"Data prefetching is a technique that plays a crucial role in modern high-performance processors by hiding long latency memory accesses. Several state-of-the-art hardware prefetchers exploit the concept of deltas, defined as the difference between the cache line addresses of two demand accesses. Existing delta prefetchers, such as best offset prefetching (BOP) and multi-lookahead prefetching (MLOP), train and predict future accesses based on global deltas. We observed that the use of global deltas results in missed opportunities to anticipate memory accesses.
In this paper, we propose Berti, a first-level data cache prefetcher that selects the best local deltas, i.e., those that consider only demand accesses issued by the same instruction. Thanks to a high-confidence mechanism that precisely detects the timely local deltas with high coverage, Berti generates accurate prefetch requests. Then, it orchestrates the prefetch requests to the memory hierarchy, using the selected deltas.
Our empirical results using ChampSim and SPEC CPU2017 and GAP workloads show that, with a storage overhead of just 2.55 KB, Berti improves performance by 8.5% compared to a baseline IP-stride and 3.5% compared to IPCP, a state-of-the-art prefetcher. Our evaluation also shows that Berti reduces dynamic energy at the memory hierarchy by 33.6% compared to IPCP, thanks to its high prefetch accuracy.",data prefetching is a technique that plays a crucial role in modern high performance processors by hiding long latency memory accesses  several state of the art hardware prefetchers exploit the concept of deltas  defined as the difference between the cache line addresses of two demand accesses  existing delta prefetchers  such as best offset prefetching  bop  and multi lookahead prefetching  mlop   train and predict future accesses based on global deltas  we observed that the use of global deltas results in missed opportunities to anticipate memory accesses  in this paper  we propose berti  a first level data cache prefetcher that selects the best local deltas  i e   those that consider only demand accesses issued by the same instruction  thanks to a high confidence mechanism that precisely detects the timely local deltas with high coverage  berti generates accurate prefetch requests  then  it orchestrates the prefetch requests to the memory hierarchy  using the selected deltas  our empirical results using champsim and spec cpu     and gap workloads show that  with a storage overhead of just      kb  berti improves performance by      compared to a baseline ip stride and      compared to ipcp  a state of the art prefetcher  our evaluation also shows that berti reduces dynamic energy at the memory hierarchy by       compared to ipcp  thanks to its high prefetch accuracy ,4.6896143,8.197224,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
On Continuous Integration / Continuous Delivery for Automated Deployment of Machine Learning Models using MLOps,"In recent years, model deployment in machine learning is observed to be an interesting area of study. It can be seen as a process similar to the one established for traditional software development. Development and operations (DevOps) incorporating Continuous Integration and Continuous Delivery (CI/CD) have demonstrated to smooth out software advancement and speed up organizations. Nonetheless, employing CI/CD pipelines in an application that incorporates components of Machine Learning Operations (MLOps) has challenging issues, and pioneers in the field settle them with the utilization of exclusive tooling, frequently presented by cloud suppliers. This study gives a higher perspective on the machine learning lifecycle and the vital differences between DevOps and MLOps. We talk about tools and techniques to execute the CI/CD pipeline of machine learning frameworks in the MLOps approach. Subsequently, we deep dive into push and pull-based deployments in Github Operations (GitOps). Open exploration challenges are additionally distinguished and added that can direct future research.",in recent years  model deployment in machine learning is observed to be an interesting area of study  it can be seen as a process similar to the one established for traditional software development  development and operations  devops  incorporating continuous integration and continuous delivery  ci cd  have demonstrated to smooth out software advancement and speed up organizations  nonetheless  employing ci cd pipelines in an application that incorporates components of machine learning operations  mlops  has challenging issues  and pioneers in the field settle them with the utilization of exclusive tooling  frequently presented by cloud suppliers  this study gives a higher perspective on the machine learning lifecycle and the vital differences between devops and mlops  we talk about tools and techniques to execute the ci cd pipeline of machine learning frameworks in the mlops approach  subsequently  we deep dive into push and pull based deployments in github operations  gitops   open exploration challenges are additionally distinguished and added that can direct future research ,9.725027,4.4676943,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
IncWAD: An Incremental Learning Approach for Web Attack Detection using MLOps,"With the continuous growth of the internet and web applications, billions of websites built and available at our fingertips today lead more and more sophisticated and malicious attacks and pose requirements to build more precise and modern Web Attack Detection (WAD) system. Nowadays, many Machine Learning (ML)-based WAD approaches have been researched and yielded high efficiency. Additionally, to ensure optimal classification performance with data containing new classes, these models are regularly retrained. Nevertheless, the process of retraining models using both old and new data poses significant challenges in terms of computational requirements and storage capacity. On the other hand, when retraining the model with only new data, the model faces the problem of Catastrophic Forgetting (CF) which cannot adequately retain the previously learned amount of knowledge about the old data. To address these problems, in this work, we proposed an Deep Neural Network (DNN)-based WAD together with Incremental Learning (IL) technique, named IncWAD. Besides that, we also designed a Machine Learning Operations (MLOPs) cycle to deploy and manage the ML model conveniently. The evaluation results on the SR-BH 2020 multi-label dataset with various cases indicated that the IncWAD model could correctly classify different types of attacks and achieved an accuracy of more than 95%.",with the continuous growth of the internet and web applications  billions of websites built and available at our fingertips today lead more and more sophisticated and malicious attacks and pose requirements to build more precise and modern web attack detection  wad  system  nowadays  many machine learning  ml  based wad approaches have been researched and yielded high efficiency  additionally  to ensure optimal classification performance with data containing new classes  these models are regularly retrained  nevertheless  the process of retraining models using both old and new data poses significant challenges in terms of computational requirements and storage capacity  on the other hand  when retraining the model with only new data  the model faces the problem of catastrophic forgetting  cf  which cannot adequately retain the previously learned amount of knowledge about the old data  to address these problems  in this work  we proposed an deep neural network  dnn  based wad together with incremental learning  il  technique  named incwad  besides that  we also designed a machine learning operations  mlops  cycle to deploy and manage the ml model conveniently  the evaluation results on the sr bh      multi label dataset with various cases indicated that the incwad model could correctly classify different types of attacks and achieved an accuracy of more than     ,3.6729228,6.7080607,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
A Federated implementation for MLOps framework based on non-intrusive load monitoring,"Non-intrusive load monitoring (NILM) is used for smart meters with energy disaggregation. Deep learning methods are used for load forecasting with different devices for smart grids in advanced metering infrastructure (AMI). Scattered and large amounts of energy consumption data are used for information and communication technologies (ICT) using centralized model training. Therefore, federated learning (FL) shares weights without transmitting data. However, FL requires enough operation time to train multiple nodes. The proposed method in this study used a Machine Learning Operations (MLOps) framework which is lower-cost FL operations on the visual interface. With this method, developers can implement FL conveniently. The experimental results showed that only a small amount of code writing was required to obtain the training results. This greatly reduced the communication cost and computation complexity and improved the efficiency of retraining and code deployment. The productivity of operation, then, can be reduced significantly.",non intrusive load monitoring  nilm  is used for smart meters with energy disaggregation  deep learning methods are used for load forecasting with different devices for smart grids in advanced metering infrastructure  ami   scattered and large amounts of energy consumption data are used for information and communication technologies  ict  using centralized model training  therefore  federated learning  fl  shares weights without transmitting data  however  fl requires enough operation time to train multiple nodes  the proposed method in this study used a machine learning operations  mlops  framework which is lower cost fl operations on the visual interface  with this method  developers can implement fl conveniently  the experimental results showed that only a small amount of code writing was required to obtain the training results  this greatly reduced the communication cost and computation complexity and improved the efficiency of retraining and code deployment  the productivity of operation  then  can be reduced significantly ,5.914636,7.787988,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
"MLOps - Definitions, Tools and Challenges","This paper is an concentrated overview of the Machine Learning Operations (MLOps) area. Our aim is to define the operation and the components of such systems by highlighting the current problems and trends. In this context we present the different tools and their usefulness in order to provide the corresponding guidelines. Moreover, the connection between MLOps and AutoML (Automated Machine Learning) is identified and how this combination could work is proposed. The novelty of our approach relies on the combination of state-of-the-art topics such as AutoML, exlainability and sustain-ability in order to overcome the current challenges in MLOps identifying them not only as the answer for the incorporation of ML models in production but also as a possible tool for efficient, robust and accurate machine learning models.",this paper is an concentrated overview of the machine learning operations  mlops  area  our aim is to define the operation and the components of such systems by highlighting the current problems and trends  in this context we present the different tools and their usefulness in order to provide the corresponding guidelines  moreover  the connection between mlops and automl  automated machine learning  is identified and how this combination could work is proposed  the novelty of our approach relies on the combination of state of the art topics such as automl  exlainability and sustain ability in order to overcome the current challenges in mlops identifying them not only as the answer for the incorporation of ml models in production but also as a possible tool for efficient  robust and accurate machine learning models ,10.15446,3.8053133,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Cloud Computing Design Patterns for MLOps: Applications to Virtual Power Plants,"Virtual Power Plants (VPPs) are a key factor in smart grids, and they use cloud computing to integrate and manage Distributed Energy Resources (DERs). VPPs use Machine Learning (ML) methods to optimize various tasks. Machine Learning Operations (MLOps) methodology is a set of techniques that targets to develop, deploy and maintain ML applications smoothly on production. Cloud design patterns (CDPs) are general reusable solutions for common cloud problems that can improve the reliability, scalability, and quality of cloud applications. This paper discusses how CDPs can help in building complex ML applications on cloud with MLOps practices which can help VPPs to optimize their workloads. The paper also provides an example implementation on a public cloud provider.",virtual power plants  vpps  are a key factor in smart grids  and they use cloud computing to integrate and manage distributed energy resources  ders   vpps use machine learning  ml  methods to optimize various tasks  machine learning operations  mlops  methodology is a set of techniques that targets to develop  deploy and maintain ml applications smoothly on production  cloud design patterns  cdps  are general reusable solutions for common cloud problems that can improve the reliability  scalability  and quality of cloud applications  this paper discusses how cdps can help in building complex ml applications on cloud with mlops practices which can help vpps to optimize their workloads  the paper also provides an example implementation on a public cloud provider ,10.404582,5.4938188,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
MLOps in the Metaverse: Human-Centric Continuous Integration,"The metaverse is a virtual world that exists entirely in a computer-generated environment, and it offers a new frontier for machine learning. One of the major challenges for using machine learning in the metaverse is MLOps (Machine Learning Operations), an emerging field that focuses on deploying and managing machine learning models in production. It has been widely acknowledged that machine learning models require a large amount of data to learn and make accurate predictions, and such data is generated progressively in real-time as human users interact with the metaverse. Due to the human-centric nature of the metaverse, it goes without saying that, once deployed, models need to be able to adapt to the constantly changing interactive environment and still make accurate predictions. Borrowing a page from software engineering, in this paper, we explore the design space of human-centric continuous integration in metaverse environments, where labeled data samples accumulated with explicit human interactive behavior (e.g., using virtual reality or augmented reality headsets) are used for fine-tuning a deployed deep learning model over a sustained period of time. We propose SPIN, a new mechanism that efficiently utilizes data samples collected from a large number of participating human users over time to fine-tune a deployed model that is shared across all the users. In an extensive array of experimental results using image classification and state-of-the-art YOLOv8 object detection models as case studies, we show that SPIN outperforms FedBuff, a state-of-the-art asynchronous FL mechanism from conventional federated learning, by a substantial margin.",the metaverse is a virtual world that exists entirely in a computer generated environment  and it offers a new frontier for machine learning  one of the major challenges for using machine learning in the metaverse is mlops  machine learning operations   an emerging field that focuses on deploying and managing machine learning models in production  it has been widely acknowledged that machine learning models require a large amount of data to learn and make accurate predictions  and such data is generated progressively in real time as human users interact with the metaverse  due to the human centric nature of the metaverse  it goes without saying that  once deployed  models need to be able to adapt to the constantly changing interactive environment and still make accurate predictions  borrowing a page from software engineering  in this paper  we explore the design space of human centric continuous integration in metaverse environments  where labeled data samples accumulated with explicit human interactive behavior  e g   using virtual reality or augmented reality headsets  are used for fine tuning a deployed deep learning model over a sustained period of time  we propose spin  a new mechanism that efficiently utilizes data samples collected from a large number of participating human users over time to fine tune a deployed model that is shared across all the users  in an extensive array of experimental results using image classification and state of the art yolov  object detection models as case studies  we show that spin outperforms fedbuff  a state of the art asynchronous fl mechanism from conventional federated learning  by a substantial margin ,4.982559,5.392384,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
MLOps Engineering at Scale,"Dodge costly and time-consuming infrastructure tasks, and rapidly bring your machine learning models to production with MLOps and pre-built serverless tools!
 
 In MLOps Engineering at Scale you will learn:
 
 Extracting, transforming, and loading datasets
 Querying datasets with SQL
 Understanding automatic differentiation in PyTorch
 Deploying model training pipelines as a service endpoint
 Monitoring and managing your pipelineâ€™s life cycle
 Measuring performance improvements
 
 MLOps Engineering at Scale shows you how to put machine learning into production efficiently by using pre-built services from AWS and other cloud vendors. Youâ€™ll learn how to rapidly create flexible and scalable machine learning systems without laboring over time-consuming operational tasks or taking on the costly overhead of physical hardware. Following a real-world use case for calculating taxi fares, you will engineer an MLOps pipeline for a PyTorch model using AWS server-less capabilities.",dodge costly and time consuming infrastructure tasks  and rapidly bring your machine learning models to production with mlops and pre built serverless tools     in mlops engineering at scale you will learn     extracting  transforming  and loading datasets  querying datasets with sql  understanding automatic differentiation in pytorch  deploying model training pipelines as a service endpoint  monitoring and managing your pipeline   s life cycle  measuring performance improvements    mlops engineering at scale shows you how to put machine learning into production efficiently by using pre built services from aws and other cloud vendors  you   ll learn how to rapidly create flexible and scalable machine learning systems without laboring over time consuming operational tasks or taking on the costly overhead of physical hardware  following a real world use case for calculating taxi fares  you will engineer an mlops pipeline for a pytorch model using aws server less capabilities ,8.204552,7.8722377,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
An Approach to Experiment Reproducibility Through MLOps and Semantic Web Technologies,"This article addresses the challenge of reproducing machine learning (ML) experiments by integrating processes based on MLOps and semantic technologies. The inherent complexity of experimentation in scientific research hinders reproducibility through conventional methods, which has led to the need to automate processes. In this work, a solution has been developed allowing the execution of ML experiments of other researchers and their reproducibility. The use of semantic technologies allows the complete description of the experiment, including the data and resources necessary for its execution. The approach proposed in this work contributes to the automation of the experimentation phases based on MLOps, demonstrating how it can be used to reproduce experiments and offer a solution to the complexity of experimentation in scientific research. The effectiveness of the solution proposed in this work is evaluated by means of a survey-based analysis carried out among researchers who currently use manual processes to perform machine learning experiments. The results indicate that manual processing is prone to errors and not scalable regarding the size and complexity of most experiments. Moreover, the solution proposed in this work, which combines MLOps-based processes and semantic technologies, has been well received by researchers and considered to significantly improve the efficiency, reproducibility, and scalability of machine learning experimentation.",this article addresses the challenge of reproducing machine learning  ml  experiments by integrating processes based on mlops and semantic technologies  the inherent complexity of experimentation in scientific research hinders reproducibility through conventional methods  which has led to the need to automate processes  in this work  a solution has been developed allowing the execution of ml experiments of other researchers and their reproducibility  the use of semantic technologies allows the complete description of the experiment  including the data and resources necessary for its execution  the approach proposed in this work contributes to the automation of the experimentation phases based on mlops  demonstrating how it can be used to reproduce experiments and offer a solution to the complexity of experimentation in scientific research  the effectiveness of the solution proposed in this work is evaluated by means of a survey based analysis carried out among researchers who currently use manual processes to perform machine learning experiments  the results indicate that manual processing is prone to errors and not scalable regarding the size and complexity of most experiments  moreover  the solution proposed in this work  which combines mlops based processes and semantic technologies  has been well received by researchers and considered to significantly improve the efficiency  reproducibility  and scalability of machine learning experimentation ,8.652134,5.0275326,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Unlocking the Power of Data in Telecom: Building an Effective MLOps Infrastructure for Model Deployment,"The telecom industry is experiencing a data revolution, with vast amounts of data being generated from various sources such as customer interactions, network logs, and sensor data. To leverage the power of this data and gain a competitive edge, telecom companies are increasingly turning to machine learning models for various tasks. However, deploying and managing these models at scale is a complex and challenging task. This paper explores the construction of an effective MLOps infrastructure for model deployment in the telecom industry. It discusses the architecture, tools, and components involved in establishing a scalable and robust infrastructure. The paper also addresses industry-specific challenges such as real-time data processing and compliance requirements. The paper provides telecom professionals with a comprehensive guide to unlocking the potential of data through MLOps, enabling innovation and a competitive edge in the telecom sector.",the telecom industry is experiencing a data revolution  with vast amounts of data being generated from various sources such as customer interactions  network logs  and sensor data  to leverage the power of this data and gain a competitive edge  telecom companies are increasingly turning to machine learning models for various tasks  however  deploying and managing these models at scale is a complex and challenging task  this paper explores the construction of an effective mlops infrastructure for model deployment in the telecom industry  it discusses the architecture  tools  and components involved in establishing a scalable and robust infrastructure  the paper also addresses industry specific challenges such as real time data processing and compliance requirements  the paper provides telecom professionals with a comprehensive guide to unlocking the potential of data through mlops  enabling innovation and a competitive edge in the telecom sector ,9.725164,5.7898326,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Seamless Transition From Machine Learning on the Cloud to Industrial Edge Devices With Thinger.io,"Due to Industry 4.0, machines can be connected to their manufacturing processes with the ability to react faster and smarter to changing conditions in a factory. Previously, Internet of Things (IoT) devices could only collect and send data to the cloud for analysis. However, the increasing computing capacity of todayâ€™s devices allows them to perform complex computations on-device, resulting in edge computing. Edge devices are a fundamental component of modern, distributed real-world artificial intelligence (AI) systems in Industry 4.0 environments. As a result, edge computing extends cloud computing capabilities by bringing services near the edge of a network and thus supports a new variety of AI services and machine learning (ML) applications. However, there is a large difference between designing and training an ML model, potentially in the cloud, to create ML services that can be deployed and consumed on the edge. This article presents an ML workflow based on ML operations (MLOps) over the Thinger.io IoT platform to streamline the transition from model training to model deployment on edge devices. The proposed workflow is composed of different elements, such as the ML training pipeline, ML deployment pipeline, and ML workspace. Similarly, this article describes the ease of design and deployment of the proposed solution in a real environment, where an anomaly detection service is implemented for detecting outliers on temperature and humidity measurements. The performance tests performed over the ML pipeline steps and the ML service throughput on the edge indicate that this workflow adds minimum overhead to the process, providing a more reliable, reusable, and productive environment.",due to industry      machines can be connected to their manufacturing processes with the ability to react faster and smarter to changing conditions in a factory  previously  internet of things  iot  devices could only collect and send data to the cloud for analysis  however  the increasing computing capacity of today   s devices allows them to perform complex computations on device  resulting in edge computing  edge devices are a fundamental component of modern  distributed real world artificial intelligence  ai  systems in industry     environments  as a result  edge computing extends cloud computing capabilities by bringing services near the edge of a network and thus supports a new variety of ai services and machine learning  ml  applications  however  there is a large difference between designing and training an ml model  potentially in the cloud  to create ml services that can be deployed and consumed on the edge  this article presents an ml workflow based on ml operations  mlops  over the thinger io iot platform to streamline the transition from model training to model deployment on edge devices  the proposed workflow is composed of different elements  such as the ml training pipeline  ml deployment pipeline  and ml workspace  similarly  this article describes the ease of design and deployment of the proposed solution in a real environment  where an anomaly detection service is implemented for detecting outliers on temperature and humidity measurements  the performance tests performed over the ml pipeline steps and the ml service throughput on the edge indicate that this workflow adds minimum overhead to the process  providing a more reliable  reusable  and productive environment ,4.7014847,6.178075,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Frontiers of Data-Intensive Compute Algorithms: Sustainable MLOps and Beyond,"Summary form only given, as follows. The complete presentation was not made available for publication as part of the conference proceedings. The aggressive expansion of big data and data-intensive computing combined with the onset of Machine-Learning and AI-software as principal components to software systems has forced both practitioners and researchers to look for new ways to cater for increased demands in speed, heterogeneity, and scale of software as a construct and its computing in general. What is more, phenomena such as information explosion and half-life are often compounded by incidents such as COVID, which are becoming more frequent and impactful. It is clear that Data-Intensive compute algorithms-and the people around them-are undergoing massive and continuous changes, at an even higher rate than before and with unprecedented global scale. This talk will address the emerging frontiers of such novel data-intensive continuous computing in combination with emerging AI software demands, starting from an algorithmic perspective and delving into the approaches-both numeric and symbolic-that make such intelligent algorithms continuously evolving, smarter and smarter, as well as explainable and socially sustainable. I will conclude with research directions and novel frontiers which are still to be even fully incepted including take-home messages on such frontiers.",summary form only given  as follows  the complete presentation was not made available for publication as part of the conference proceedings  the aggressive expansion of big data and data intensive computing combined with the onset of machine learning and ai software as principal components to software systems has forced both practitioners and researchers to look for new ways to cater for increased demands in speed  heterogeneity  and scale of software as a construct and its computing in general  what is more  phenomena such as information explosion and half life are often compounded by incidents such as covid  which are becoming more frequent and impactful  it is clear that data intensive compute algorithms and the people around them are undergoing massive and continuous changes  at an even higher rate than before and with unprecedented global scale  this talk will address the emerging frontiers of such novel data intensive continuous computing in combination with emerging ai software demands  starting from an algorithmic perspective and delving into the approaches both numeric and symbolic that make such intelligent algorithms continuously evolving  smarter and smarter  as well as explainable and socially sustainable  i will conclude with research directions and novel frontiers which are still to be even fully incepted including take home messages on such frontiers ,10.402364,4.805783,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Tailoring MLOps Techniques for Industry 5.0 Needs,"It is a very popular era for machine learning (ML) applications, and Industry5.0 aims to have AI as one of its key technologies. Still, only a few ML initiatives make it to a production-grade implementation, mostly due to lacking proper Continuous Integration and Delivery framework and MLOps practices. This is especially true for industrial use cases, where the trust and reliability of ML applications are mission-critical. Most of these applications fail during the final stage of the development lifecycle, i.e. acceptance testing and validation of the ML application, while being integrated into Cyber-Physical System of Systems (CPSoS). This paper explores the key requirements for deploying ML applications in industrial scenarios, emphasizing the critical role of Digital Twins, edge AI, and responsible-explainable AI techniques in ensuring efficient and responsible operations. Building upon previous models, this paper suggests two process models: (i) the Olympics model for MLOps-coupled CPS engineering and (ii) the MLOps engineering toolchain for industrial applications.",it is a very popular era for machine learning  ml  applications  and industry    aims to have ai as one of its key technologies  still  only a few ml initiatives make it to a production grade implementation  mostly due to lacking proper continuous integration and delivery framework and mlops practices  this is especially true for industrial use cases  where the trust and reliability of ml applications are mission critical  most of these applications fail during the final stage of the development lifecycle  i e  acceptance testing and validation of the ml application  while being integrated into cyber physical system of systems  cpsos   this paper explores the key requirements for deploying ml applications in industrial scenarios  emphasizing the critical role of digital twins  edge ai  and responsible explainable ai techniques in ensuring efficient and responsible operations  building upon previous models  this paper suggests two process models   i  the olympics model for mlops coupled cps engineering and  ii  the mlops engineering toolchain for industrial applications ,12.095953,6.3302,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
An Integrated ML-Ops Framework for Automating AI-based Photovoltaic Forecasting,"Energy digitization holds significant importance for various energy applications, encompassing aspects like production, consumption, and distribution within power grids. The digital transformation of energy plays a pivotal role in enhancing the integration of Artificial Intelligence (AI) into energy management systems, leveraging extensive datasets. The development of AI systems and the utilization of Machine Learning (ML) techniques empower users with precise predictions related to renewable energy production, thereby expediting the shift towards clean energy. Nevertheless, the effective use of data demands a high level of expertise, thereby excluding energy stakeholders from the benefits modern technologies offer. In this paper, we introduce an AI forecasting system designed to bridge the knowledge gap in data processing methods and ML models for energy stakeholders. This system focuses on delivering a user-friendly interface for photovoltaic (PV) production forecasting by automating the entire ML operations pipeline. Consequently, users can obtain data-driven model results without the need to manually code all the requisite steps for model training and fine-tuning. To demonstrate the systemâ€™s capabilities, we provide an experimental application using real PV data from a Portuguese aggregator.",energy digitization holds significant importance for various energy applications  encompassing aspects like production  consumption  and distribution within power grids  the digital transformation of energy plays a pivotal role in enhancing the integration of artificial intelligence  ai  into energy management systems  leveraging extensive datasets  the development of ai systems and the utilization of machine learning  ml  techniques empower users with precise predictions related to renewable energy production  thereby expediting the shift towards clean energy  nevertheless  the effective use of data demands a high level of expertise  thereby excluding energy stakeholders from the benefits modern technologies offer  in this paper  we introduce an ai forecasting system designed to bridge the knowledge gap in data processing methods and ml models for energy stakeholders  this system focuses on delivering a user friendly interface for photovoltaic  pv  production forecasting by automating the entire ml operations pipeline  consequently  users can obtain data driven model results without the need to manually code all the requisite steps for model training and fine tuning  to demonstrate the system   s capabilities  we provide an experimental application using real pv data from a portuguese aggregator ,7.686844,5.896256,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
"Machine Learning Engineering on AWS: Build, scale, and secure machine learning systems and MLOps pipelines in production","Machine Learning Operations (MLOps), derived from DevOps, aims to unify the development, deployment, and maintenance of machine learning (ML) models. Continuous training (CT) automatically retrains ML models, and continuous deployment (CD) automatically deploys the retrained models to production. CT and CD are essential for maintaining ML model performance in dynamic production environments and, therefore, need to be considered when practicing MLOps. We present our CTCD-e MLOps pipeline, implemented mostly using existing open-source software, being able to autonomously adapt an ML system to changing production environments by enabling flexible model CT and CD. The pipeline can automatically trigger a model retraining round when the model performance degrades. Then it automatically conducts an A/B test for the retrained model and its predecessor in production to start serving the better one. The pipeline was evaluated by two experiments. In the pipeline, users can flexibly configure the model retraining, as well as the redeployment and production A/B test of the retrained models based on various requirements.",machine learning operations  mlops   derived from devops  aims to unify the development  deployment  and maintenance of machine learning  ml  models  continuous training  ct  automatically retrains ml models  and continuous deployment  cd  automatically deploys the retrained models to production  ct and cd are essential for maintaining ml model performance in dynamic production environments and  therefore  need to be considered when practicing mlops  we present our ctcd e mlops pipeline  implemented mostly using existing open source software  being able to autonomously adapt an ml system to changing production environments by enabling flexible model ct and cd  the pipeline can automatically trigger a model retraining round when the model performance degrades  then it automatically conducts an a b test for the retrained model and its predecessor in production to start serving the better one  the pipeline was evaluated by two experiments  in the pipeline  users can flexibly configure the model retraining  as well as the redeployment and production a b test of the retrained models based on various requirements ,5.868379,6.607408,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Test Automation with Grad-CAM Heatmaps - A Future Pipe Segment in MLOps for Vision AI?,"Machine Learning (ML) is a fundamental part of modern perception systems. In the last decade, the performance of computer vision using trained deep neural networks has outperformed previous approaches based on careful feature engineering. However, the opaqueness of large ML models is a substantial impediment for critical applications such as in the automotive context. As a remedy, Gradient-weighted Class Activation Mapping (Grad-CAM) has been proposed to provide visual explanations of model internals. In this paper, we demonstrate how Grad-CAM heatmaps can be used to increase the explainability of an image recognition model trained for a pedestrian underpass. We argue how the heatmaps support compliance to the EU's seven key requirements for Trustworthy AI. Finally, we propose adding automated heatmap analysis as a pipe segment in an MLOps pipeline. We believe that such a building block can be used to automatically detect if a trained ML-model is activated based on invalid pixels in test images, suggesting biased models.",machine learning  ml  is a fundamental part of modern perception systems  in the last decade  the performance of computer vision using trained deep neural networks has outperformed previous approaches based on careful feature engineering  however  the opaqueness of large ml models is a substantial impediment for critical applications such as in the automotive context  as a remedy  gradient weighted class activation mapping  grad cam  has been proposed to provide visual explanations of model internals  in this paper  we demonstrate how grad cam heatmaps can be used to increase the explainability of an image recognition model trained for a pedestrian underpass  we argue how the heatmaps support compliance to the eu s seven key requirements for trustworthy ai  finally  we propose adding automated heatmap analysis as a pipe segment in an mlops pipeline  we believe that such a building block can be used to automatically detect if a trained ml model is activated based on invalid pixels in test images  suggesting biased models ,7.5205374,4.6195583,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
FedOps: A Platform of Federated Learning Operations With Heterogeneity Management,"Federated learning (FL) is a decentralized machine learning (ML) method that enables model training while preserving privacy. FL is gaining attention because it avoids data transfer to the server, facilitating the decentralized learning of the traditional ML model. Despite its potential, FL project is significantly more challenging to develop than centralized ML methods owing to decentralized local data. We propose FedOps, federated learning operations for constructing systematic FL project by enhancing machine learning operations (MLOps) to be effectively applied to FL while preserving its core process. To address complexity of FL implementation, we developed FedOps platform, which involves FedOps-based projects to manage the whole lifecycle in FL context. We also investigated methods to identify performance degradation factors in FL and suggest an approach for improvement. FedOps Platform provides an analysis tool for client heterogeneity, called chunk-bench. This tool enables researchers and engineers to gain insights into systems heterogeneity by using only small chunk of the clients’ data to execute test in the shortest time possible while tracking the systems heterogeneity across the clients. By addressing systems heterogeneity, FedOps Platform achieved 13%–43% improvement in communication cost-to-accuracy and 20%–68% improvement in time-to-accuracy. We believe that FedOps Platform offers an optimal solution for end-to-end development of FL projects, with significantly improving both computational and communication efficiencies.",federated learning  fl  is a decentralized machine learning  ml  method that enables model training while preserving privacy  fl is gaining attention because it avoids data transfer to the server  facilitating the decentralized learning of the traditional ml model  despite its potential  fl project is significantly more challenging to develop than centralized ml methods owing to decentralized local data  we propose fedops  federated learning operations for constructing systematic fl project by enhancing machine learning operations  mlops  to be effectively applied to fl while preserving its core process  to address complexity of fl implementation  we developed fedops platform  which involves fedops based projects to manage the whole lifecycle in fl context  we also investigated methods to identify performance degradation factors in fl and suggest an approach for improvement  fedops platform provides an analysis tool for client heterogeneity  called chunk bench  this tool enables researchers and engineers to gain insights into systems heterogeneity by using only small chunk of the clients  data to execute test in the shortest time possible while tracking the systems heterogeneity across the clients  by addressing systems heterogeneity  fedops platform achieved         improvement in communication cost to accuracy and         improvement in time to accuracy  we believe that fedops platform offers an optimal solution for end to end development of fl projects  with significantly improving both computational and communication efficiencies ,6.009794,7.750842,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
"Federated Learning Operations (FLOps): Challenges, Lifecycle and Approaches","As machine learning workloads become computationally demanding, there is an increased focus on distributed machine learning to train and deploy models across multiple machines in a cloud-native cluster. However, optimizing a machine learning modelâ€™s lifecycle to facilitate efficient resource utilization is still an active area of research. The approach typically involves a manual effort to partition the models into distinct layers and decide how to store these distinct layers on a distributed computing framework. However, distributing distinct layers across nodes can induce a network latency bottleneck in the machine learning pipeline. Further, the above process becomes more inefficient as models become increasingly complex. In this paper, we present a heuristic-based approach to distributed model training. Further, we analyze the resource utilization metrics from a sample machine learning pipeline deployed on a KubeFlow MLOps framework testbed.",as machine learning workloads become computationally demanding  there is an increased focus on distributed machine learning to train and deploy models across multiple machines in a cloud native cluster  however  optimizing a machine learning model   s lifecycle to facilitate efficient resource utilization is still an active area of research  the approach typically involves a manual effort to partition the models into distinct layers and decide how to store these distinct layers on a distributed computing framework  however  distributing distinct layers across nodes can induce a network latency bottleneck in the machine learning pipeline  further  the above process becomes more inefficient as models become increasingly complex  in this paper  we present a heuristic based approach to distributed model training  further  we analyze the resource utilization metrics from a sample machine learning pipeline deployed on a kubeflow mlops framework testbed ,5.751535,7.1176467,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Heuristic-based Resource Allocation for Cloud-native Machine Learning Workloads,"Federated Learning has witnessed a rapid growth in research and industry applications as it offers the benefits of privacy preserving while contributing to the global model training. Cross-silo federated learning systems which are usually geographically distributed and cross-organizational are becoming a reality. Although DevOps and MLOps methodologies may help improving traditional machine learning systems' development efficiency and productivity, it is still challenging for them to develop cross-silo federated learning systems in a productive way. In this paper, we propose FLOps (Federated Learning Operations), a new methodology for developing cross-silo federated learning systems efficiently and continuously. By elaborating the challenges that FLOps is facing, we construct the lifecycle of FLOps, and propose approaches to FLOps. Finally, we highlight potential research directions of FLOps.",federated learning has witnessed a rapid growth in research and industry applications as it offers the benefits of privacy preserving while contributing to the global model training  cross silo federated learning systems which are usually geographically distributed and cross organizational are becoming a reality  although devops and mlops methodologies may help improving traditional machine learning systems  development efficiency and productivity  it is still challenging for them to develop cross silo federated learning systems in a productive way  in this paper  we propose flops  federated learning operations   a new methodology for developing cross silo federated learning systems efficiently and continuously  by elaborating the challenges that flops is facing  we construct the lifecycle of flops  and propose approaches to flops  finally  we highlight potential research directions of flops ,6.249508,7.5814614,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Machine Learning Engineering with Python: Manage the production life cycle of machine learning models using MLOps with practical examples,"Supercharge the value of your machine learning models by building scalable and robust solutions that can serve them in production environments Key Features Explore hyperparameter optimization and model management toolsLearn object-oriented programming and functional programming in Python to build your own ML libraries and packagesExplore key ML engineering patterns like microservices and the Extract Transform Machine Learn (ETML) pattern with use cases Book Description Machine learning engineering is a thriving discipline at the interface of software development and machine learning. This book will help developers working with machine learning and Python to put their knowledge to work and create high-quality machine learning products and services. Machine Learning Engineering with Python takes a hands-on approach to help you get to grips with essential technical concepts, implementation patterns, and development methodologies to have you up and running in no time. You'll begin by understanding key steps of the machine learning development life cycle before moving on to practical illustrations and getting to grips with building and deploying robust machine learning solutions. As you advance, you'll explore how to create your own toolsets for training and deployment across all your projects in a consistent way. The book will also help you get hands-on with deployment architectures and discover methods for scaling up your solutions while building a solid understanding of how to use cloud-based tools effectively. Finally, you'll work through examples to help you solve typical business problems. By the end of this book, you'll be able to build end-to-end machine learning services using a variety of techniques and design your own processes for consistently performant machine learning engineering. What you will learn Find out what an effective ML engineering process looks likeUncover options for automating training and deployment and learn how to use themDiscover how to bu...",supercharge the value of your machine learning models by building scalable and robust solutions that can serve them in production environments key features explore hyperparameter optimization and model management toolslearn object oriented programming and functional programming in python to build your own ml libraries and packagesexplore key ml engineering patterns like microservices and the extract transform machine learn  etml  pattern with use cases book description machine learning engineering is a thriving discipline at the interface of software development and machine learning  this book will help developers working with machine learning and python to put their knowledge to work and create high quality machine learning products and services  machine learning engineering with python takes a hands on approach to help you get to grips with essential technical concepts  implementation patterns  and development methodologies to have you up and running in no time  you ll begin by understanding key steps of the machine learning development life cycle before moving on to practical illustrations and getting to grips with building and deploying robust machine learning solutions  as you advance  you ll explore how to create your own toolsets for training and deployment across all your projects in a consistent way  the book will also help you get hands on with deployment architectures and discover methods for scaling up your solutions while building a solid understanding of how to use cloud based tools effectively  finally  you ll work through examples to help you solve typical business problems  by the end of this book  you ll be able to build end to end machine learning services using a variety of techniques and design your own processes for consistently performant machine learning engineering  what you will learn find out what an effective ml engineering process looks likeuncover options for automating training and deployment and learn how to use themdiscover how to bu   ,8.1132345,7.978176,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Desafios para AplicaÃ§Ã£o de MLOps na PrevisÃ£o do Consumo EnergÃ©tico [Not available in English],No English translation of this document was provided by the author or conference organizers.,no english translation of this document was provided by the author or conference organizers ,7.6081486,3.8021448,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
"MAP: Design, Development, Deployment, and Maintenance of Industrie 4.0 AI Applications","This paper presents a proven process and method to design, develop, deploy, and maintain Industrie 4.0 Big Data Artificial Intelligence (AI) scalable solutions at ABB called modular adaptive process (MAP). The method follows a hybrid DevOps-Agile-Waterfall approach that takes advantage of different elements of all three methodologies to bring to fruition Artificial Intelligence (AI) and Machine Learning (ML) solutions. The described methodology has three phases that include Definition, Development, and Deployment. An important and novel concept that will be discussed is the development of a Value-based Work Breakdown Structure (VWBS) that facilitates DevOps development. Another important discussion is related to the re-training of AI/ML models once the application is deployed.",this paper presents a proven process and method to design  develop  deploy  and maintain industrie     big data artificial intelligence  ai  scalable solutions at abb called modular adaptive process  map   the method follows a hybrid devops agile waterfall approach that takes advantage of different elements of all three methodologies to bring to fruition artificial intelligence  ai  and machine learning  ml  solutions  the described methodology has three phases that include definition  development  and deployment  an important and novel concept that will be discussed is the development of a value based work breakdown structure  vwbs  that facilitates devops development  another important discussion is related to the re training of ai ml models once the application is deployed ,9.833918,4.1084366,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Approaches for the Prediction of Lead Times in an Engineer to Order Environmentâ€”A Systematic Review,"The interest of manufacturing companies in a sufficient prediction of lead times is continuously increasing - especially in engineer to order environments with typically a large number of individual parts and complex production processes. A multitude of approaches have been proposed in the literature for predicting lead times considering different data and methods or algorithms from operations research (OR) and machine learning (ML). In order to provide guidance at setting up prediction models and developing new approaches, a systematic review of the available approaches for predicting lead times is presented in this paper. Forty-two publications were analyzed and synthetized: Based on a developed framework considering the used data class (e.g. product data or system status), the data origin (master data or real data) and the used method and algorithm from OR and ML, the publications are classified. Based on the classification, a descriptive analysis is performed to identify common approaches in the existing literature as well as implications for further research. One result is, that mostly order data and the status of the production system are used for predicting lead times whereas material data are used seldom. Additionally, ML approaches primarily use artificial neural networks and regression models for predicting lead times, while OR approaches use mainly combinatorial optimization or heuristics. Furthermore, with increasing model complexity the use of real data decreased. Thus, we identified as an implication for further research to set up a complex data model considering material data, which uses real data as data origin.",the interest of manufacturing companies in a sufficient prediction of lead times is continuously increasing   especially in engineer to order environments with typically a large number of individual parts and complex production processes  a multitude of approaches have been proposed in the literature for predicting lead times considering different data and methods or algorithms from operations research  or  and machine learning  ml   in order to provide guidance at setting up prediction models and developing new approaches  a systematic review of the available approaches for predicting lead times is presented in this paper  forty two publications were analyzed and synthetized  based on a developed framework considering the used data class  e g  product data or system status   the data origin  master data or real data  and the used method and algorithm from or and ml  the publications are classified  based on the classification  a descriptive analysis is performed to identify common approaches in the existing literature as well as implications for further research  one result is  that mostly order data and the status of the production system are used for predicting lead times whereas material data are used seldom  additionally  ml approaches primarily use artificial neural networks and regression models for predicting lead times  while or approaches use mainly combinatorial optimization or heuristics  furthermore  with increasing model complexity the use of real data decreased  thus  we identified as an implication for further research to set up a complex data model considering material data  which uses real data as data origin ,5.7600164,5.7612247,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
MSR4ML: Reconstructing Artifact Traceability in Machine Learning Repositories,"The increasing popularity of Machine Learning (ML) is generating challenges also for developers. The multitude of programming languages, libraries and available resources allow them to easily build their own models or algorithms. However, ML models are tightly connected to their data implying a different development process from other types of software. Software projects often rely on version control platforms, such as GitHub, but these platforms have not yet been extended to support ML projects. There is poor support for data versioning and no link between ML and software artifacts. Thus, traceability and model evolution can become challenging for developers. While some specific ML platforms exist, they still require considerable manual specification of ML artifacts and links between them. In this work, we propose a framework for automatic identification and traceability of links between data, code and ML model through Mining Software Repositories (MSR) techniques. Our tool combines static code analysis and mining commit data to identify ML, code and data artifacts, reconstruct links between them and retrieve commits that affect each end of the link. The objective is to increase productivity and the developers' awareness of their project through the recovered traceability.",the increasing popularity of machine learning  ml  is generating challenges also for developers  the multitude of programming languages  libraries and available resources allow them to easily build their own models or algorithms  however  ml models are tightly connected to their data implying a different development process from other types of software  software projects often rely on version control platforms  such as github  but these platforms have not yet been extended to support ml projects  there is poor support for data versioning and no link between ml and software artifacts  thus  traceability and model evolution can become challenging for developers  while some specific ml platforms exist  they still require considerable manual specification of ml artifacts and links between them  in this work  we propose a framework for automatic identification and traceability of links between data  code and ml model through mining software repositories  msr  techniques  our tool combines static code analysis and mining commit data to identify ml  code and data artifacts  reconstruct links between them and retrieve commits that affect each end of the link  the objective is to increase productivity and the developers  awareness of their project through the recovered traceability ,8.251993,4.79851,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Optimization of emergency response using higher order learning and clustering of 911 text messages,"In real-time emergency response an accurate picture of the situation is needed quickly. Often during large-scale disasters, cell towers become overloaded, and the only way of communication is through text messages. It becomes important to gather information from text messages sent to emergency numbers in order to respond quickly and efficiently with life-saving efforts. In addition, responders are unable to manually handle the large volume of incoming texts. To add to this difficult problem, these data sources tend to be microtext. This research developed a methodology to summarize text messages sent during an emergency, including analysis of locations. The real-time disaster needs were then input into a mixed integer programming resource allocation model for distribution of resources for disaster aid. Prior research included resource allocation and text modeling, but the combination of the two is a novel application not only in this arena, but more broadly across domains.",in real time emergency response an accurate picture of the situation is needed quickly  often during large scale disasters  cell towers become overloaded  and the only way of communication is through text messages  it becomes important to gather information from text messages sent to emergency numbers in order to respond quickly and efficiently with life saving efforts  in addition  responders are unable to manually handle the large volume of incoming texts  to add to this difficult problem  these data sources tend to be microtext  this research developed a methodology to summarize text messages sent during an emergency  including analysis of locations  the real time disaster needs were then input into a mixed integer programming resource allocation model for distribution of resources for disaster aid  prior research included resource allocation and text modeling  but the combination of the two is a novel application not only in this arena  but more broadly across domains ,3.7392616,1.8369328,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Learning Linear Programs from Data,"Linear Programming lies at the core of mathematical modelling and optimization. Designing linear programs (LPs) is a difficult and expensive process, as it requires both mathematical programming and domain expertise, and it involves both designing an objective function and feasibility constraints. To support this design process, we propose INCALP, an algorithm for inducing linear programs from examples. Since the objective can often be learned with standard techniques (e.g. regression), INCALP learns the hard constraints only. It does so by encoding constraint learning as a mixed integer linear program. INCALP achieves significant efficiency gains by considering gradually larger subsets of examples, and terminating as soon as a suitable program is found. In addition, INCALP encourages both compactness and sparsity of the learned program. Our empirical analysis on synthetic data and textbook problems highlights the promise of the approach.",linear programming lies at the core of mathematical modelling and optimization  designing linear programs  lps  is a difficult and expensive process  as it requires both mathematical programming and domain expertise  and it involves both designing an objective function and feasibility constraints  to support this design process  we propose incalp  an algorithm for inducing linear programs from examples  since the objective can often be learned with standard techniques  e g  regression   incalp learns the hard constraints only  it does so by encoding constraint learning as a mixed integer linear program  incalp achieves significant efficiency gains by considering gradually larger subsets of examples  and terminating as soon as a suitable program is found  in addition  incalp encourages both compactness and sparsity of the learned program  our empirical analysis on synthetic data and textbook problems highlights the promise of the approach ,3.089303,8.139384,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Machine Learning application lifecycle augmented with explanation and security,"We have developed a Distributed Denial of Service (DDoS) intrusion detection framework that employs ML ensembles of both supervised and unsupervised classifiers that are complementary in reaching a corroborated classification decision. Our work has been limited to DDoS attack detection techniques. We propose to extend our framework to general ML system development, based on our review of current ML system development life cycles. We also propose to augment the general life cycle model to include security features to enable building security-in as the development progresses and bolt security-on as flaws are discovered after deployment. Most ML systems today operate in a black-box mode, providing users with only the predictions without associated reasoning as to how the predictions are brought about. There is heavy emphasis now to build mechanisms that help the user develop higher confidence in accepting the predictions of ML systems. Such explainability feature of ML model predictions is a must for critical systems. We also propose to augment our lifecycle model with explainability features. Thus, our ultimate goal is to develop a generic ML lifecycle process augmented with security and explainability features. Such an ML lifecycle process will be of immense use in ML systems development for all domains.",we have developed a distributed denial of service  ddos  intrusion detection framework that employs ml ensembles of both supervised and unsupervised classifiers that are complementary in reaching a corroborated classification decision  our work has been limited to ddos attack detection techniques  we propose to extend our framework to general ml system development  based on our review of current ml system development life cycles  we also propose to augment the general life cycle model to include security features to enable building security in as the development progresses and bolt security on as flaws are discovered after deployment  most ml systems today operate in a black box mode  providing users with only the predictions without associated reasoning as to how the predictions are brought about  there is heavy emphasis now to build mechanisms that help the user develop higher confidence in accepting the predictions of ml systems  such explainability feature of ml model predictions is a must for critical systems  we also propose to augment our lifecycle model with explainability features  thus  our ultimate goal is to develop a generic ml lifecycle process augmented with security and explainability features  such an ml lifecycle process will be of immense use in ml systems development for all domains ,11.863633,6.5864086,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Towards Integrated Model-Based Machine Learning Experimentation Framework,"We examine the paradigm of data-centric artificial intelligence (DCAI) as a solution to the obstacles that small and medium-sized enterprises (SMEs) face in adopting AI. While the prevalent model-centric approach emphasizes collecting large amounts of data, SMEs often suffer from small datasets, data drift, and sparse ML knowledge, which hinders them from implementing AI. DCAI, on the other hand, emphasizes to systematically engineer the data used to build an AI system. Our contribution is to provide a concrete, transferable implementation of a DCAI development process geared towards industrial application, specffically in machining and manufacturing, and demonstrate how it enhances data quality by fostering collaboration between domain experts and ML engineers. This added value can place AI at the disposal of more SMEs. We provide the necessary background for practitioners to follow the rationale behind DCAI and successfully deploy the provided process template.",we examine the paradigm of data centric artificial intelligence  dcai  as a solution to the obstacles that small and medium sized enterprises  smes  face in adopting ai  while the prevalent model centric approach emphasizes collecting large amounts of data  smes often suffer from small datasets  data drift  and sparse ml knowledge  which hinders them from implementing ai  dcai  on the other hand  emphasizes to systematically engineer the data used to build an ai system  our contribution is to provide a concrete  transferable implementation of a dcai development process geared towards industrial application  specffically in machining and manufacturing  and demonstrate how it enhances data quality by fostering collaboration between domain experts and ml engineers  this added value can place ai at the disposal of more smes  we provide the necessary background for practitioners to follow the rationale behind dcai and successfully deploy the provided process template ,11.635013,6.599658,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
From Models to Microservices: Easily Operationalizing Machine Learning models,"ML systems in critical applications, such as autonomous driving, require high-quality assurance and the ability to handle concept drift and performance drop. To address these challenges, we propose an integrated system between the Multi-view Modeling tool to the automated pipeline for the ML Model Training and DNN Repair. Our preliminary integration and experiment has shown promising result.",ml systems in critical applications  such as autonomous driving  require high quality assurance and the ability to handle concept drift and performance drop  to address these challenges  we propose an integrated system between the multi view modeling tool to the automated pipeline for the ml model training and dnn repair  our preliminary integration and experiment has shown promising result ,7.796547,4.541501,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Automation and Development Effort in Continuous AI Development: A Practitionersâ€™ Survey,"The widespread adoption of AI-enabled systems and their required continuous development and deployment (MLOps) sparks research interest due to the added intricacy of automatically handling data, code, and the model itself. A better understanding of the stages for the continuous development of AI, namely Data Handling, Model Learning, Software Development, and System Operations, and the respective tasks can help to optimize and improve their effectiveness.Thus, this paper explores the degree of automation, development effort, importance, utilization of computing resources, and factors contributing to automation throughout these stages and tasks. We conducted a questionnaire-based global survey to explore these topics by analyzing 150 responses from experienced AI, data, and MLOps engineers.The results determined that the stage System Operations is mainly automated. Whereas several tasks from the other three stages (e.g., data cleaning, data quality assurance, model design, model improvement, and system level quality assurance) are more often partially automated than automated, and documentation-related tasks are mostly not automated or developed. Participants required the highest development effort for the stage Data Handling. Furthermore, the study reveals a negative correlation between automation and the perceived development effort, whereas the importance of the tasks does not seem to affect automation. 93% of participants consider the availability of computing resources, with model training, data transformation, and data cleaning ranked as the most resource-intensive tasks.",the widespread adoption of ai enabled systems and their required continuous development and deployment  mlops  sparks research interest due to the added intricacy of automatically handling data  code  and the model itself  a better understanding of the stages for the continuous development of ai  namely data handling  model learning  software development  and system operations  and the respective tasks can help to optimize and improve their effectiveness thus  this paper explores the degree of automation  development effort  importance  utilization of computing resources  and factors contributing to automation throughout these stages and tasks  we conducted a questionnaire based global survey to explore these topics by analyzing     responses from experienced ai  data  and mlops engineers the results determined that the stage system operations is mainly automated  whereas several tasks from the other three stages  e g   data cleaning  data quality assurance  model design  model improvement  and system level quality assurance  are more often partially automated than automated  and documentation related tasks are mostly not automated or developed  participants required the highest development effort for the stage data handling  furthermore  the study reveals a negative correlation between automation and the perceived development effort  whereas the importance of the tasks does not seem to affect automation      of participants consider the availability of computing resources  with model training  data transformation  and data cleaning ranked as the most resource intensive tasks ,9.759621,5.0527983,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Cost Effective Generic Machine Learning Operation: A Case Study,"In this research, we have proposed a mechanism to implement a typical Mops pipeline for small scale organization who cannot afford the operational expenditures to bring the pipeline at Cloudera, Horton works platform or cloud premises like AWS, GCP or Azure. This paper gives a very detailed understanding of operationalization of a typical ML pipelines to adhere all the elements and artifacts without even using any Docker, Kubernetes or even any API generating platforms like Flask or FastAPI. Using the combination of a simple Python/R along with SQL and Shell scripts we can manage the entire workflow at on premises with a very low-cost approach. From some angle this mechanism would not be comparable with the architectures like market ready MLOps platforms like Azure Devops, MLflow, Kubeflow, Apache Airflow, Databricks with Data factory or Sagemaker Studio workflow but from conceptual point of view, suffice almost 90% of the requirements with efficient manner. We have also done a latest review related to MLOps in recent past and also listed out the several research gaps that can be solved in future research.",in this research  we have proposed a mechanism to implement a typical mops pipeline for small scale organization who cannot afford the operational expenditures to bring the pipeline at cloudera  horton works platform or cloud premises like aws  gcp or azure  this paper gives a very detailed understanding of operationalization of a typical ml pipelines to adhere all the elements and artifacts without even using any docker  kubernetes or even any api generating platforms like flask or fastapi  using the combination of a simple python r along with sql and shell scripts we can manage the entire workflow at on premises with a very low cost approach  from some angle this mechanism would not be comparable with the architectures like market ready mlops platforms like azure devops  mlflow  kubeflow  apache airflow  databricks with data factory or sagemaker studio workflow but from conceptual point of view  suffice almost     of the requirements with efficient manner  we have also done a latest review related to mlops in recent past and also listed out the several research gaps that can be solved in future research ,8.151975,7.8344207,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
StreamMLOps: Operationalizing Online Learning for Big Data Streaming & Real-Time Applications,"Continuously learning and serving from evolving streaming data and serving in real-time is a challenging problem. Traditionally, data is partitioned and processed in batches to train machine learning (ML) models. In industrial applications, static modelsâ€™ performance drops over time (model degradation, concept drift), requiring new models to be trained with recent data and redeployed in production. The scientific community has been studying online and adaptive methods to address batch-learning limitations and continuously train AI tasks for industrial applications such as cyber-security, AIOps, anomaly scoring, and drift detection in stock markets. This paper deals with the MLOps aspects of deploying such online and dynamic models to address the requirements in the production systems for real-time applications. Our architectures - based on open-source tools such as Kafka and River - demonstrated how online learning methods could be scaled horizontally in production to meet the demands of a high-velocity streaming pipeline. We demonstrate an MLOps strategy to perform incremental learning from streaming data and continuously deploy the online learning model without pausing the inference pipeline. Indeed, the design satisfies requirements such as model versioning, monitoring, audibility and reproducibility of prediction in both a supervised and semi-supervised setting. Our experiments - for malicious URLs detection task - performed on high-dimensional and feature-evolving streaming data (more than 3 million features) establish the effectiveness and efficiency of online learning models compared to batch (static) machine learning regarding both time and space complexity. Finally, we provide some best practices on data engineering for deploying online models to process a real-time feature stream in production environments. Code is publicly available for reproducibility.",continuously learning and serving from evolving streaming data and serving in real time is a challenging problem  traditionally  data is partitioned and processed in batches to train machine learning  ml  models  in industrial applications  static models    performance drops over time  model degradation  concept drift   requiring new models to be trained with recent data and redeployed in production  the scientific community has been studying online and adaptive methods to address batch learning limitations and continuously train ai tasks for industrial applications such as cyber security  aiops  anomaly scoring  and drift detection in stock markets  this paper deals with the mlops aspects of deploying such online and dynamic models to address the requirements in the production systems for real time applications  our architectures   based on open source tools such as kafka and river   demonstrated how online learning methods could be scaled horizontally in production to meet the demands of a high velocity streaming pipeline  we demonstrate an mlops strategy to perform incremental learning from streaming data and continuously deploy the online learning model without pausing the inference pipeline  indeed  the design satisfies requirements such as model versioning  monitoring  audibility and reproducibility of prediction in both a supervised and semi supervised setting  our experiments   for malicious urls detection task   performed on high dimensional and feature evolving streaming data  more than   million features  establish the effectiveness and efficiency of online learning models compared to batch  static  machine learning regarding both time and space complexity  finally  we provide some best practices on data engineering for deploying online models to process a real time feature stream in production environments  code is publicly available for reproducibility ,7.4133625,6.763458,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Pressure Ulcer Categorization and Reporting in Domiciliary Settings Using Deep Learning and Mobile Devices: A Clinical Trial to Evaluate End-to-End Performance,"Pressure ulcers are a challenge for patients and healthcare professionals. In the UK, pressure ulcers affect 700,000 people each year. Treating them costs the National Health Service €3.8 million every day. Their etiology is complex and multifactorial. However, evidence has shown a strong link between old age, disease-related sedentary lifestyles, and unhealthy eating habits. Direct skin contact with a bed or chair without frequent position changes can cause pressure ulcers. Urinary and faecal incontinence, diabetes, and injuries that restrict body position and nutrition are also known risk factors. Guidelines and treatments exist but their implementation and success vary across different healthcare settings. This is primarily because healthcare practitioners have a) minimal experience in dealing with pressure ulcers, and b) a general lack of understanding of pressure ulcer treatments. Poorly managed, pressure ulcers can lead to severe pain, a poor quality of life, and significant healthcare costs. In this paper, we report the findings of a clinical trial conducted by Mersey Care NHS Foundation Trust that evaluated the performance of a faster region-based convolutional neural network and mobile platform that categorised and documented pressure ulcers automatically. The neural network classifies category I, II, III, and IV pressure ulcers, deep tissue injuries, and pressure ulcers that are unstageable. District nurses used their mobile phones to take pictures of pressure ulcers and transmit them over 4/5G communications to an inferencing server for classification. The approach uses existing deep learning technologies to provide a novel end-to-end pipeline for pressure ulcer categorisation that works in ad hoc domiciliary settings. The strength of the approach resides within MLOPS, model deployment at scale, and the platforms in-situ operation. While solutions exist in the NHS for analysing pressure ulcers none of them automatically classify and report pressure ulcers from a service users’ residential home automatically. We acknowledge that there is a great deal of work to do, but the approach offers a convincing solution to standardise pressure ulcer categorisation and reporting. The results from the study are encouraging and show that using 216 images, collected over an eight-month trial, it was possible to generate a mean average Precision=0.6796, Recall=0.6997, F1-Score=0.6786 with 45 false positives using an @.75 confidence score threshold.",pressure ulcers are a challenge for patients and healthcare professionals  in the uk  pressure ulcers affect         people each year  treating them costs the national health service      million every day  their etiology is complex and multifactorial  however  evidence has shown a strong link between old age  disease related sedentary lifestyles  and unhealthy eating habits  direct skin contact with a bed or chair without frequent position changes can cause pressure ulcers  urinary and faecal incontinence  diabetes  and injuries that restrict body position and nutrition are also known risk factors  guidelines and treatments exist but their implementation and success vary across different healthcare settings  this is primarily because healthcare practitioners have a  minimal experience in dealing with pressure ulcers  and b  a general lack of understanding of pressure ulcer treatments  poorly managed  pressure ulcers can lead to severe pain  a poor quality of life  and significant healthcare costs  in this paper  we report the findings of a clinical trial conducted by mersey care nhs foundation trust that evaluated the performance of a faster region based convolutional neural network and mobile platform that categorised and documented pressure ulcers automatically  the neural network classifies category i  ii  iii  and iv pressure ulcers  deep tissue injuries  and pressure ulcers that are unstageable  district nurses used their mobile phones to take pictures of pressure ulcers and transmit them over    g communications to an inferencing server for classification  the approach uses existing deep learning technologies to provide a novel end to end pipeline for pressure ulcer categorisation that works in ad hoc domiciliary settings  the strength of the approach resides within mlops  model deployment at scale  and the platforms in situ operation  while solutions exist in the nhs for analysing pressure ulcers none of them automatically classify and report pressure ulcers from a service users  residential home automatically  we acknowledge that there is a great deal of work to do  but the approach offers a convincing solution to standardise pressure ulcer categorisation and reporting  the results from the study are encouraging and show that using     images  collected over an eight month trial  it was possible to generate a mean average precision         recall         f  score        with    false positives using an      confidence score threshold ,4.6974616,3.3313594,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
A TinyML Soft-Sensor for the Internet of Intelligent Vehicles,"The increased number of sensors in modern cars offers the opportunity to develop algorithms that can monitor and diagnose vehicle performance more efficiently. We present the results of applying and deploying a TinyML model into a typical OBD-II automotive scanner to serve as a soft-sensor and estimate carbon dioxide emissions. A TinyML workflow based on TensorFlow, TensorFlow Lite, and Micro was designed to a 32-bit microcontroller target (Machhina A0 TM ) and considering different quantization methods and Multi-layer Perceptron Regressors (MLP). Train, test, and validation were conducted using real-world data fetched from several kinds of vehicles through an emission measurement system. The results suggest that the soft-sensor can estimate Carbon Dioxide emissions with a Mean Absolute Percentage Error (MAPE) of approximately 27% and processing time averages around 37 to 173 microseconds (depending on activation functions adopted) in the target hardware and using intake manifold absolute pressure, intake air temperature, and vehicle speed as independent variables. The results of this study also demonstrated quantization has a major impact on memory usage. On average, 10 to 17 times less memory is required to achieve the same result on MAPE.",the increased number of sensors in modern cars offers the opportunity to develop algorithms that can monitor and diagnose vehicle performance more efficiently  we present the results of applying and deploying a tinyml model into a typical obd ii automotive scanner to serve as a soft sensor and estimate carbon dioxide emissions  a tinyml workflow based on tensorflow  tensorflow lite  and micro was designed to a    bit microcontroller target  machhina a  tm   and considering different quantization methods and multi layer perceptron regressors  mlp   train  test  and validation were conducted using real world data fetched from several kinds of vehicles through an emission measurement system  the results suggest that the soft sensor can estimate carbon dioxide emissions with a mean absolute percentage error  mape  of approximately     and processing time averages around    to     microseconds  depending on activation functions adopted  in the target hardware and using intake manifold absolute pressure  intake air temperature  and vehicle speed as independent variables  the results of this study also demonstrated quantization has a major impact on memory usage  on average     to    times less memory is required to achieve the same result on mape ,4.8348885,8.403251,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Operationalizing Machine Learning Models - A Systematic Literature Review,"Deploying machine learning (ML) models to production with the same level of rigor and automation as traditional software systems has shown itself to be a non-trivial task, requiring extra care and infrastructure to deal with the additional challenges. Although many studies focus on adapting ML software engineering (SE) approaches and techniques, few studies have summarized the status and challenges of operationalizing ML models. Model operationalization encompasses all steps after model training and evaluation, including packaging the model in a format appropriate for deployment, publishing to a model registry or storage, integrating the model into a broader software system, serving, and monitoring. This study is the first systematic literature review investigating the techniques, tools, and infrastructures to operationalize ML models. After reviewing 24 primary studies, the results show that there are a number of tools for most use cases to operationalize ML models and cloud deployment in particular. The review also revealed several research opportunities, such as dynamic model-switching, continuous model-monitoring, and efficient edge ML deployments. CCS CONCEPTS â€¢ General and reference â†’ Surveys and overviews; â€¢ Computing methodologies â†’ Machine learning; â€¢ Software and its engineering â†’ Software development techniques.",deploying machine learning  ml  models to production with the same level of rigor and automation as traditional software systems has shown itself to be a non trivial task  requiring extra care and infrastructure to deal with the additional challenges  although many studies focus on adapting ml software engineering  se  approaches and techniques  few studies have summarized the status and challenges of operationalizing ml models  model operationalization encompasses all steps after model training and evaluation  including packaging the model in a format appropriate for deployment  publishing to a model registry or storage  integrating the model into a broader software system  serving  and monitoring  this study is the first systematic literature review investigating the techniques  tools  and infrastructures to operationalize ml models  after reviewing    primary studies  the results show that there are a number of tools for most use cases to operationalize ml models and cloud deployment in particular  the review also revealed several research opportunities  such as dynamic model switching  continuous model monitoring  and efficient edge ml deployments  ccs concepts     general and reference     surveys and overviews      computing methodologies     machine learning      software and its engineering     software development techniques ,8.009925,6.5641074,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
"Decentralized Machine Learning Governance: Overview, Opportunities, and Challenges","Researchers have started to recognize the necessity for a well-defined ML governance framework based on the principle of decentralization and comprehensively defining its scope of research and practice due to the growth of machine learning (ML) research and applications in the real world and the success of blockchain-based technology. In this paper, we study decentralized ML governance, which includes ML value chain management, decentralized identity for the ML community, decentralized ownership and rights management of ML assets, community-based decision-making for the ML process, decentralized ML finance, and risk management.",researchers have started to recognize the necessity for a well defined ml governance framework based on the principle of decentralization and comprehensively defining its scope of research and practice due to the growth of machine learning  ml  research and applications in the real world and the success of blockchain based technology  in this paper  we study decentralized ml governance  which includes ml value chain management  decentralized identity for the ml community  decentralized ownership and rights management of ml assets  community based decision making for the ml process  decentralized ml finance  and risk management ,11.6163225,5.4947495,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
A monitoring framework for deployed machine learning models with supply chain examples,"Actively monitoring machine learning models during production operations helps ensure prediction quality and detection and remediation of unexpected or undesired conditions. Monitoring models already deployed in big data environments brings the additional challenges of adding monitoring in parallel to the existing modelling workflow and controlling resource requirements. In this paper, we describe (1) a framework for monitoring machine learning models; and, (2) its implementation for a big data supply chain application. We use our implementation to study drift in model features, predictions, and performance on three real data sets. We compare hypothesis test and information theoretic approaches to drift detection in features and predictions using the Kolmogorov-Smirnov distance and Bhattacharyya coefficient. Results showed that model performance was stable over the evaluation period. Features and predictions showed statistically significant drifts; however, these drifts were not linked to changes in model performance during the time of our study.",actively monitoring machine learning models during production operations helps ensure prediction quality and detection and remediation of unexpected or undesired conditions  monitoring models already deployed in big data environments brings the additional challenges of adding monitoring in parallel to the existing modelling workflow and controlling resource requirements  in this paper  we describe     a framework for monitoring machine learning models  and      its implementation for a big data supply chain application  we use our implementation to study drift in model features  predictions  and performance on three real data sets  we compare hypothesis test and information theoretic approaches to drift detection in features and predictions using the kolmogorov smirnov distance and bhattacharyya coefficient  results showed that model performance was stable over the evaluation period  features and predictions showed statistically significant drifts  however  these drifts were not linked to changes in model performance during the time of our study ,7.3043337,6.351333,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Scanflow-K8s: Agent-based Framework for Autonomic Management and Supervision of ML Workflows in Kubernetes Clusters,"Machine Learning (ML) projects are currently heavily based on workflows composed of some reproducible steps and executed as containerized pipelines to build or deploy ML models efficiently because of the flexibility, portability, and fast delivery they provide to the ML life-cycle. However, deployed models need to be watched and constantly managed, supervised, and debugged to guarantee their availability, validity, and robustness in unexpected situations. Therefore, containerized ML workflows would benefit from leveraging flexible and diverse autonomic capabilities. This work presents an architecture for autonomic ML workflows with abilities for multi-layered control, based on an agent-based approach that enables autonomic management and supervision of ML workflows at the application layer and the infrastructure layer (by collaborating with the orchestrator). We redesign the Scanflow ML framework to support such multi-agent approach by using triggers, primitives, and strategies. We also implement a practical platform, so-called Scanflow-K8s, that enables autonomic ML workflows on Kubernetes clusters based on the Scanflow agents. MNIST image classification and MLPerf ImageNet classification benchmarks are used as case studies to show the capabilities of Scanflow-K8s under different scenarios. The experimental results demonstrate the feasibility and effectiveness of our proposed agent approach and the Scanflow-K8s platform for the autonomic management of ML workflows in Kubernetes clusters at multiple layers.",machine learning  ml  projects are currently heavily based on workflows composed of some reproducible steps and executed as containerized pipelines to build or deploy ml models efficiently because of the flexibility  portability  and fast delivery they provide to the ml life cycle  however  deployed models need to be watched and constantly managed  supervised  and debugged to guarantee their availability  validity  and robustness in unexpected situations  therefore  containerized ml workflows would benefit from leveraging flexible and diverse autonomic capabilities  this work presents an architecture for autonomic ml workflows with abilities for multi layered control  based on an agent based approach that enables autonomic management and supervision of ml workflows at the application layer and the infrastructure layer  by collaborating with the orchestrator   we redesign the scanflow ml framework to support such multi agent approach by using triggers  primitives  and strategies  we also implement a practical platform  so called scanflow k s  that enables autonomic ml workflows on kubernetes clusters based on the scanflow agents  mnist image classification and mlperf imagenet classification benchmarks are used as case studies to show the capabilities of scanflow k s under different scenarios  the experimental results demonstrate the feasibility and effectiveness of our proposed agent approach and the scanflow k s platform for the autonomic management of ml workflows in kubernetes clusters at multiple layers ,9.436775,3.553851,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Drift Lens: Real-time unsupervised Concept Drift detection by evaluating per-label embedding distributions,"Despite the significant improvements made by deep learning models, their adoption in real-world dynamic applications is still limited. Concept drift is among the open issues preventing the widespread exploitation of deep learning models in real-life settings. The dynamic world changes very quickly, and the collected data drifts accordingly. Prediction models, usually trained on static historical data, should be promptly re-trained in case of new real-time drifted data distributions. Although some drift detection methodologies have been proposed over the years, different issues are still open since state-of-the-art solutions show limited effectiveness and efficiency.This paper proposes Drift Lens, a novel real-time unsupervised per-label drift detection methodology based on embedding distribution distances in deep learning models. The preliminary experiments performed on a transformer-based model fine-tuned for topic text classification show promising results in drift detection accuracy, drift characterization, and efficient execution time to support real-time concept drift detection.",despite the significant improvements made by deep learning models  their adoption in real world dynamic applications is still limited  concept drift is among the open issues preventing the widespread exploitation of deep learning models in real life settings  the dynamic world changes very quickly  and the collected data drifts accordingly  prediction models  usually trained on static historical data  should be promptly re trained in case of new real time drifted data distributions  although some drift detection methodologies have been proposed over the years  different issues are still open since state of the art solutions show limited effectiveness and efficiency this paper proposes drift lens  a novel real time unsupervised per label drift detection methodology based on embedding distribution distances in deep learning models  the preliminary experiments performed on a transformer based model fine tuned for topic text classification show promising results in drift detection accuracy  drift characterization  and efficient execution time to support real time concept drift detection ,6.719117,5.758563,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Comparative Evaluation of Machine Learning Development Lifecycle Tools,"The ML development lifecycle is the SDLC equivalent of Machine Learning. While the ML code is at the core of a real-world ML production system, it frequently represents only 5% or less of the system's entire code. This study examines and contrasts the technologies utilised in the machine learning development lifecycle and focuses largely on the distinction between ML programming and ML development. According to Forrester Research, AI adoption is ramping up. 63% of business technology decision makers are implementing, have implemented, or are expanding use of AI. The main motivation behind this research is that the majority of the organizations do not have ML/AI solutions that have gone beyond the PoC / PoV stage, ML code in Jupyter notebooks cannot be distributed, and AI/ML solution deployment at scale is a challenge. Machine learning services are evolving at a dizzying rate, opening up a variety of opportunities for on-field applications, especially for brands and businesses with the infrastructure and resources required to integrate ML into their operational structures as a decision-making fulcrum. Nearly 65% of stock market swings may be predicted by Azure Machine Learning. By incorporating ML into its operational framework, Amazon has successfully decreased the “click-to-ship” time by 225%. Breast cancer can be identified with 89% accuracy using Google's Deep Learning. Thus, these commercial tools for ML life cycle support have been compared and a conclusion about which tool is most suitable is drawn.",the ml development lifecycle is the sdlc equivalent of machine learning  while the ml code is at the core of a real world ml production system  it frequently represents only    or less of the system s entire code  this study examines and contrasts the technologies utilised in the machine learning development lifecycle and focuses largely on the distinction between ml programming and ml development  according to forrester research  ai adoption is ramping up      of business technology decision makers are implementing  have implemented  or are expanding use of ai  the main motivation behind this research is that the majority of the organizations do not have ml ai solutions that have gone beyond the poc   pov stage  ml code in jupyter notebooks cannot be distributed  and ai ml solution deployment at scale is a challenge  machine learning services are evolving at a dizzying rate  opening up a variety of opportunities for on field applications  especially for brands and businesses with the infrastructure and resources required to integrate ml into their operational structures as a decision making fulcrum  nearly     of stock market swings may be predicted by azure machine learning  by incorporating ml into its operational framework  amazon has successfully decreased the  click to ship  time by       breast cancer can be identified with     accuracy using google s deep learning  thus  these commercial tools for ml life cycle support have been compared and a conclusion about which tool is most suitable is drawn ,8.5150585,7.8051505,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Federated machine learning through edge ready architectures with privacy preservation as a service,"This paper presents the details of a novel approach, based on edge and advanced privacy preserving solutions, that tries to accelerate the adoption of personal data federation for the benefit of the evolution of valuable advanced AI models. The approach focuses on the establishment of high degree of trust between data owner and data management infrastructure so that consent in data processing is given by means of functional and enforceable options applicable at all levels of workloads and processes. The overall set of solutions will be delivered as an open-source set of implementations in the context of the PAROMA-MED project.",this paper presents the details of a novel approach  based on edge and advanced privacy preserving solutions  that tries to accelerate the adoption of personal data federation for the benefit of the evolution of valuable advanced ai models  the approach focuses on the establishment of high degree of trust between data owner and data management infrastructure so that consent in data processing is given by means of functional and enforceable options applicable at all levels of workloads and processes  the overall set of solutions will be delivered as an open source set of implementations in the context of the paroma med project ,10.983472,7.366274,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
A Domain-Specific Language for Monitoring ML Model Performance,"As machine learning (ML) starts to offer competitive advantages for an increasing number of application domains, many organisations invest in developing ML-enabled products. The development of these products poses unique challenges compared to traditional software engineering projects and requires the collaboration of people from different disciplines. This work focuses on alleviating some of these challenges related to implementing monitoring systems for deployed ML models. To this end, a domain-specific language (DSL) is developed that data scientists can use to declaratively define monitoring workflows. Complementary to the DSL, a runtime component is developed that implements the specified behaviour. This component is designed to be easily integrated with the rest of an organisation's ML platform and extended by software engineers that do not necessarily have experience with model-driven engineering. An evaluation of the proposed system that supports the validity of the approach is also presented.",as machine learning  ml  starts to offer competitive advantages for an increasing number of application domains  many organisations invest in developing ml enabled products  the development of these products poses unique challenges compared to traditional software engineering projects and requires the collaboration of people from different disciplines  this work focuses on alleviating some of these challenges related to implementing monitoring systems for deployed ml models  to this end  a domain specific language  dsl  is developed that data scientists can use to declaratively define monitoring workflows  complementary to the dsl  a runtime component is developed that implements the specified behaviour  this component is designed to be easily integrated with the rest of an organisation s ml platform and extended by software engineers that do not necessarily have experience with model driven engineering  an evaluation of the proposed system that supports the validity of the approach is also presented ,8.614475,5.69041,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Automated Machine Learning in Critical Energy Infrastructure for Net Zero Carbon Emissions,"Increasing energy consumption and diversified energy generation have led to the proliferation of energy management (EM) systems for optimized grid operations and net zero carbon emissions. Artificial Intelligence (AI) is centric to EM systems to process large volumes of high velocity data for anomalies, predictions, optimization and other actionable insights that unravel the complexities of grid operations. Managing Energy AI capabilities itself is becoming an increasingly complex task that requires extensive resourcing and expertise. In this paper, we aim to address this gap by formalizing the role of Automated Machine Learning (AutoML) by proposing a novel framework for its key functionalities in critical energy infrastructure. This framework provides a generic and cohesive abstraction to assist with integrating and managing the complexities of AI capabilities. The framework is empirically evaluated in the microgrid setting of a multi-campus, multi-functional tertiary education institution. Results from these experiments confirm the performance contributions of the proposed framework in addressing the complexities of AI capabilities of EM systems as they transition towards microgrid energy optimisation and net zero carbon emissions.",increasing energy consumption and diversified energy generation have led to the proliferation of energy management  em  systems for optimized grid operations and net zero carbon emissions  artificial intelligence  ai  is centric to em systems to process large volumes of high velocity data for anomalies  predictions  optimization and other actionable insights that unravel the complexities of grid operations  managing energy ai capabilities itself is becoming an increasingly complex task that requires extensive resourcing and expertise  in this paper  we aim to address this gap by formalizing the role of automated machine learning  automl  by proposing a novel framework for its key functionalities in critical energy infrastructure  this framework provides a generic and cohesive abstraction to assist with integrating and managing the complexities of ai capabilities  the framework is empirically evaluated in the microgrid setting of a multi campus  multi functional tertiary education institution  results from these experiments confirm the performance contributions of the proposed framework in addressing the complexities of ai capabilities of em systems as they transition towards microgrid energy optimisation and net zero carbon emissions ,7.548955,5.9835668,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Pushing ML Predictions Into DBMSs,"In the past decade, many approaches have been suggested to execute ML workloads on a DBMS. However, most of them have looked at in-DBMS ML from a training perspective, whereas ML inference has been largely overlooked. We think that this is an important gap to fill for two main reasons: (1) in the near future, every application will be infused with some sort of ML capability; (2) behind every web page, application, and enterprise there is a DBMS, whereby in-DBMS inference is an appealing solution both for efficiency (e.g., less data movement), performance (e.g., cross-optimizations between relational operators and ML) and governance. In this article, we study whether DBMSs are a good fit for prediction serving. We introduce a technique for translating trained ML pipelines containing both featurizers (e.g., one-hot encoding) and models (e.g., linear and tree-based models) into SQL queries, and we compare in-DBMS performance against popular ML frameworks such as Sklearn and ml.net . Our experiments show that, when pushed inside a DBMS, trained ML pipelines can have performance comparable to ML frameworks in several scenarios, while they perform quite poorly on text featurization and over (even simple) neural networks.",in the past decade  many approaches have been suggested to execute ml workloads on a dbms  however  most of them have looked at in dbms ml from a training perspective  whereas ml inference has been largely overlooked  we think that this is an important gap to fill for two main reasons      in the near future  every application will be infused with some sort of ml capability      behind every web page  application  and enterprise there is a dbms  whereby in dbms inference is an appealing solution both for efficiency  e g   less data movement   performance  e g   cross optimizations between relational operators and ml  and governance  in this article  we study whether dbmss are a good fit for prediction serving  we introduce a technique for translating trained ml pipelines containing both featurizers  e g   one hot encoding  and models  e g   linear and tree based models  into sql queries  and we compare in dbms performance against popular ml frameworks such as sklearn and ml net   our experiments show that  when pushed inside a dbms  trained ml pipelines can have performance comparable to ml frameworks in several scenarios  while they perform quite poorly on text featurization and over  even simple  neural networks ,6.770712,6.8051243,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
On the Democratization of Machine Learning Pipelines,"With the increase of Machine Learning (ML) adoption throughout many industries, the need for efficient methods to continuously design, develop, and deploy ML models has also grown. To address this issue, several ML pipelines have emerged with the goal of creating development environments which facilitate the deployment, evaluation and maintenance. In this paper, we advocate that most existing pipelines are not well suited for the initial stages of ML development, due to their high setup and maintenance overheads. As such, we propose a lightweight Quick Machine Learning framework, QML, which is capable of reducing the setup overhead and operating in the low infrastructure environments that are most common-place in experimental ML projects. To demonstrate QML's usefulness, we present a case-study where a lightweight ML pipeline was developed, and subsequently validated on a standard ML classification problem. Lastly, we assess the differences between our pipeline and an alternative lightweight workflow, based on DAGsHub. With this comparison, we conclude that our approach increases ML task automation as well as feature support, while falling short only in the Experiment Tracking category. To enable the broader community to experiment and assess QML, as well as the Lightweight Pipeline, this project has been made publicly available 1 1 https://github.com/WALEX2000/qml1 https://github.com/WALEX2000/qml1 https://github.com/WALEX2000/qml1 https://github.com/WALEX2000/qml",with the increase of machine learning  ml  adoption throughout many industries  the need for efficient methods to continuously design  develop  and deploy ml models has also grown  to address this issue  several ml pipelines have emerged with the goal of creating development environments which facilitate the deployment  evaluation and maintenance  in this paper  we advocate that most existing pipelines are not well suited for the initial stages of ml development  due to their high setup and maintenance overheads  as such  we propose a lightweight quick machine learning framework  qml  which is capable of reducing the setup overhead and operating in the low infrastructure environments that are most common place in experimental ml projects  to demonstrate qml s usefulness  we present a case study where a lightweight ml pipeline was developed  and subsequently validated on a standard ml classification problem  lastly  we assess the differences between our pipeline and an alternative lightweight workflow  based on dagshub  with this comparison  we conclude that our approach increases ml task automation as well as feature support  while falling short only in the experiment tracking category  to enable the broader community to experiment and assess qml  as well as the lightweight pipeline  this project has been made publicly available     https   github com walex     qml  https   github com walex     qml  https   github com walex     qml  https   github com walex     qml,6.0415807,7.6516666,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Technical Debt Management in Industrial ML - State of Practice and Management Model Proposal,"With the increasing application of artificial intelligence (AI) and machine learning (ML), the topic of technical debt management for machine learning systems is gaining more attention. Additionally, industrial systems including manufacturing or logistics processes are also supposed to benefit from AI and ML, which is reported in many publications related to ML application models. However, fewer studies on “how is technical debt managed in context of ML systems” are being published. This contribution fills this gap by reporting findings from 15 semi-structured and in-depth interviews conducted with industrial practitioners. Based on the interview results, suggestions for an initial technical debt management process and two document artifacts that facilitate the process are addressed.",with the increasing application of artificial intelligence  ai  and machine learning  ml   the topic of technical debt management for machine learning systems is gaining more attention  additionally  industrial systems including manufacturing or logistics processes are also supposed to benefit from ai and ml  which is reported in many publications related to ml application models  however  fewer studies on  how is technical debt managed in context of ml systems  are being published  this contribution fills this gap by reporting findings from    semi structured and in depth interviews conducted with industrial practitioners  based on the interview results  suggestions for an initial technical debt management process and two document artifacts that facilitate the process are addressed ,8.826227,4.740187,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Machine Learning on Kubernetes: A practical handbook for building and using a complete open source machine learning platform on Kubernetes,"Build a Kubernetes-based self-serving, agile data science and machine learning ecosystem for your organization using reliable and secure open source technologies",build a kubernetes based self serving  agile data science and machine learning ecosystem for your organization using reliable and secure open source technologies,10.095147,6.5196056,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Performance Evaluation of Machine Learning Models on Apache Spark: An Empirical Study,"Artificial intelligence (AI) and machine learning significantly improve many sectors, such as education, healthcare, and industry. Machine learning techniques mainly depend on the volume and diversity of training data. With the digital transformation we live in, an abundant amount of data can be collected from different sources. However, the problem that needs to be addressed is how this amount of data can be processed and where it can be stored. Cloud services and distributed file systems (DFSs) help address this issue. Many DFSs such as Hadoop, Quantcast, and Apache Spark differ in many aspects, including scheduling algorithms, data management protocol, throughput, and runtime. Some DFSs may be better for working with specific applications than others. Apache Spark is capable of handling iterative operations like machine learning operations as well as it provides an integrated library of different machine learning algorithms called MLlib. In this paper, we evaluated the use of Spark using two machine learning algorithms, namely Logistic Regression (LR) and Random Forests (RF). We investigated the effect of varying the memory allocation configuration and the use of GPU. We concluded that the use of Spark greatly improves the runtime and memory consumption. However, its use has to be justifiable and needed for the size of the data due to different factors that affect the machine learning model's accuracy. The memory allocation should be kept to the minimum needed, and GPU should only be used when the machine learning algorithm used supports parallelization.",artificial intelligence  ai  and machine learning significantly improve many sectors  such as education  healthcare  and industry  machine learning techniques mainly depend on the volume and diversity of training data  with the digital transformation we live in  an abundant amount of data can be collected from different sources  however  the problem that needs to be addressed is how this amount of data can be processed and where it can be stored  cloud services and distributed file systems  dfss  help address this issue  many dfss such as hadoop  quantcast  and apache spark differ in many aspects  including scheduling algorithms  data management protocol  throughput  and runtime  some dfss may be better for working with specific applications than others  apache spark is capable of handling iterative operations like machine learning operations as well as it provides an integrated library of different machine learning algorithms called mllib  in this paper  we evaluated the use of spark using two machine learning algorithms  namely logistic regression  lr  and random forests  rf   we investigated the effect of varying the memory allocation configuration and the use of gpu  we concluded that the use of spark greatly improves the runtime and memory consumption  however  its use has to be justifiable and needed for the size of the data due to different factors that affect the machine learning model s accuracy  the memory allocation should be kept to the minimum needed  and gpu should only be used when the machine learning algorithm used supports parallelization ,4.7287555,7.3526626,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
DDoS Attack Detection Combining Time Series-based Multi-dimensional Sketch and Machine Learning,"Machine learning-based DDoS attack detection methods are mostly implemented at the packet level with expensive computational time costs, and the space cost of those sketch-based detection methods is uncertain. This paper proposes a two-stage DDoS attack detection algorithm combining time series-based multi-dimensional sketch and machine learning technologies. Besides packet numbers, total lengths, and protocols, we construct the time series-based multi-dimensional sketch with limited space cost by storing elephant flow information with the Boyer-Moore voting algorithm and hash index. For the first stage of detection, we adopt CNN to generate sketch-level DDoS attack detection results from the time series-based multi-dimensional sketch. For the sketch with potential DDoS attacks, we use RNN with flow information extracted from the sketch to implement flow-level DDoS attack detection in the second stage. Experimental results show that not only is the detection accuracy of our proposed method much close to that of packet-level DDoS attack detection methods based on machine learning, but also the computational time cost of our method is much smaller with regard to the number of machine learning operations.",machine learning based ddos attack detection methods are mostly implemented at the packet level with expensive computational time costs  and the space cost of those sketch based detection methods is uncertain  this paper proposes a two stage ddos attack detection algorithm combining time series based multi dimensional sketch and machine learning technologies  besides packet numbers  total lengths  and protocols  we construct the time series based multi dimensional sketch with limited space cost by storing elephant flow information with the boyer moore voting algorithm and hash index  for the first stage of detection  we adopt cnn to generate sketch level ddos attack detection results from the time series based multi dimensional sketch  for the sketch with potential ddos attacks  we use rnn with flow information extracted from the sketch to implement flow level ddos attack detection in the second stage  experimental results show that not only is the detection accuracy of our proposed method much close to that of packet level ddos attack detection methods based on machine learning  but also the computational time cost of our method is much smaller with regard to the number of machine learning operations ,3.5150793,6.1007514,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Computerized Data-Preprocessing To Improve Data Quality,"Machine Learning (ML) has seen a sudden exponential rise in past decades. Numerous resources and documentation allow people to become ML practitioners. Companies make huge profits out of the analysis and predictions they make. ML Engineers are highly paid for their knowledge in this domain. It has become prevalent and much more comprehensible. One best out of the important stages in ML is Data preprocessing, and feature extraction. In Data Preprocessing itself, there are various tasks one needs to perform accurately to make the data provided. From handling missing values to encoding and normalization, each step has its importance and hence a professional must be adept with each of these steps. Data Preprocessing steps depend upon the type of data provided i.e. categorical data, continuous data, an array of images' pixels or even images themselves. With the requirement to deal with all the cleaning steps, it becomes quite strenuous to learn and become an expert. Moreover, it is time-consuming and does not guarantee expected results. Hence, there is a need to handle this issue. We aim to automate this complete process to ease the work of Machine Learning Engineers and make it more productive. Any user will only have to provide the dataset and does not have to manually select the processing techniques as provided by the latest Data Mining tools. The application will observe the dataset and apply the suitable techniques on its own. Since all the steps will be automated and the user will only have to provide the dataset, even the people who are not familiar with concepts of Machine Learning can pre-process the dataset. This allows the opening of opportunities for people from various domains who desire to perform Machine Learning operations.",machine learning  ml  has seen a sudden exponential rise in past decades  numerous resources and documentation allow people to become ml practitioners  companies make huge profits out of the analysis and predictions they make  ml engineers are highly paid for their knowledge in this domain  it has become prevalent and much more comprehensible  one best out of the important stages in ml is data preprocessing  and feature extraction  in data preprocessing itself  there are various tasks one needs to perform accurately to make the data provided  from handling missing values to encoding and normalization  each step has its importance and hence a professional must be adept with each of these steps  data preprocessing steps depend upon the type of data provided i e  categorical data  continuous data  an array of images  pixels or even images themselves  with the requirement to deal with all the cleaning steps  it becomes quite strenuous to learn and become an expert  moreover  it is time consuming and does not guarantee expected results  hence  there is a need to handle this issue  we aim to automate this complete process to ease the work of machine learning engineers and make it more productive  any user will only have to provide the dataset and does not have to manually select the processing techniques as provided by the latest data mining tools  the application will observe the dataset and apply the suitable techniques on its own  since all the steps will be automated and the user will only have to provide the dataset  even the people who are not familiar with concepts of machine learning can pre process the dataset  this allows the opening of opportunities for people from various domains who desire to perform machine learning operations ,8.80376,7.0691476,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Mastering Azure Machine Learning: Execute large-scale end-to-end machine learning with Azure,"Supercharge and automate your deployments to Azure Machine Learning clusters and Azure Kubernetes Service using Azure Machine Learning services Key Features Implement end-to-end machine learning pipelines on AzureTrain deep learning models using Azure compute infrastructureDeploy machine learning models using MLOps Book Description Azure Machine Learning is a cloud service for accelerating and managing the machine learning (ML) project life cycle that ML professionals, data scientists, and engineers can use in their day-to-day workflows. This book covers the end-to-end ML process using Microsoft Azure Machine Learning, including data preparation, performing and logging ML training runs, designing training and deployment pipelines, and managing these pipelines via MLOps. The first section shows you how to set up an Azure Machine Learning workspace; ingest and version datasets; as well as preprocess, label, and enrich these datasets for training. In the next two sections, you'll discover how to enrich and train ML models for embedding, classification, and regression. You'll explore advanced NLP techniques, traditional ML models such as boosted trees, modern deep neural networks, recommendation systems, reinforcement learning, and complex distributed ML training techniques - all using Azure Machine Learning. The last section will teach you how to deploy the trained models as a batch pipeline or real-time scoring service using Docker, Azure Machine Learning clusters, Azure Kubernetes Services, and alternative deployment targets. By the end of this book, youâ€™ll be able to combine all the steps youâ€™ve learned by building an MLOps pipeline. What you will learn Understand the end-to-end ML pipelineGet to grips with the Azure Machine Learning workspaceIngest, analyze, and preprocess datasets for ML using the Azure cloudTrain traditional and modern ML techniques efficiently using Azure MLDeploy ML models for batch and real-time scoringUnderstand model interoperability with ON...",supercharge and automate your deployments to azure machine learning clusters and azure kubernetes service using azure machine learning services key features implement end to end machine learning pipelines on azuretrain deep learning models using azure compute infrastructuredeploy machine learning models using mlops book description azure machine learning is a cloud service for accelerating and managing the machine learning  ml  project life cycle that ml professionals  data scientists  and engineers can use in their day to day workflows  this book covers the end to end ml process using microsoft azure machine learning  including data preparation  performing and logging ml training runs  designing training and deployment pipelines  and managing these pipelines via mlops  the first section shows you how to set up an azure machine learning workspace  ingest and version datasets  as well as preprocess  label  and enrich these datasets for training  in the next two sections  you ll discover how to enrich and train ml models for embedding  classification  and regression  you ll explore advanced nlp techniques  traditional ml models such as boosted trees  modern deep neural networks  recommendation systems  reinforcement learning  and complex distributed ml training techniques   all using azure machine learning  the last section will teach you how to deploy the trained models as a batch pipeline or real time scoring service using docker  azure machine learning clusters  azure kubernetes services  and alternative deployment targets  by the end of this book  you   ll be able to combine all the steps you   ve learned by building an mlops pipeline  what you will learn understand the end to end ml pipelineget to grips with the azure machine learning workspaceingest  analyze  and preprocess datasets for ml using the azure cloudtrain traditional and modern ml techniques efficiently using azure mldeploy ml models for batch and real time scoringunderstand model interoperability with on   ,8.018431,8.045121,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
"Agile Machine Learning with DataRobot: Automate each step of the machine learning life cycle, from understanding problems to delivering value","Leverage DataRobot's enterprise AI platform and automated decision intelligence to extract business value from data Key Features Get well-versed with DataRobot features using real-world examplesUse this all-in-one platform to build, monitor, and deploy ML models for handling the entire production life cycleMake use of advanced DataRobot capabilities to programmatically build and deploy a large number of ML models Book Description DataRobot enables data science teams to become more efficient and productive. This book helps you to address machine learning (ML) challenges with DataRobot's enterprise platform, enabling you to extract business value from data and rapidly create commercial impact for your organization. You'll begin by learning how to use DataRobot's features to perform data prep and cleansing tasks automatically. The book then covers best practices for building and deploying ML models, along with challenges faced while scaling them to handle complex business problems. Moving on, you'll perform exploratory data analysis (EDA) tasks to prepare your data to build ML models and ways to interpret results. You'll also discover how to analyze the model's predictions and turn them into actionable insights for business users. Next, you'll create model documentation for internal as well as compliance purposes and learn how the model gets deployed as an API. In addition, you'll find out how to operationalize and monitor the model's performance. Finally, you'll work with examples on time series forecasting, NLP, image processing, MLOps, and more using advanced DataRobot capabilities. By the end of this book, you'll have learned to use DataRobot's AutoML and MLOps features to scale ML model building by avoiding repetitive tasks and common errors. What you will learn Understand and solve business problems using DataRobotUse DataRobot to prepare your data and perform various data analysis tasks to start building modelsDevelop robust ML models and assess their results co...",leverage datarobot s enterprise ai platform and automated decision intelligence to extract business value from data key features get well versed with datarobot features using real world examplesuse this all in one platform to build  monitor  and deploy ml models for handling the entire production life cyclemake use of advanced datarobot capabilities to programmatically build and deploy a large number of ml models book description datarobot enables data science teams to become more efficient and productive  this book helps you to address machine learning  ml  challenges with datarobot s enterprise platform  enabling you to extract business value from data and rapidly create commercial impact for your organization  you ll begin by learning how to use datarobot s features to perform data prep and cleansing tasks automatically  the book then covers best practices for building and deploying ml models  along with challenges faced while scaling them to handle complex business problems  moving on  you ll perform exploratory data analysis  eda  tasks to prepare your data to build ml models and ways to interpret results  you ll also discover how to analyze the model s predictions and turn them into actionable insights for business users  next  you ll create model documentation for internal as well as compliance purposes and learn how the model gets deployed as an api  in addition  you ll find out how to operationalize and monitor the model s performance  finally  you ll work with examples on time series forecasting  nlp  image processing  mlops  and more using advanced datarobot capabilities  by the end of this book  you ll have learned to use datarobot s automl and mlops features to scale ml model building by avoiding repetitive tasks and common errors  what you will learn understand and solve business problems using datarobotuse datarobot to prepare your data and perform various data analysis tasks to start building modelsdevelop robust ml models and assess their results co   ,8.084786,8.063901,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
A maximum feasible subset algorithm with application to radiation therapy,"Consider a set of linear one sided or two sided inequality constraints on a real vector X. The problem of interest is selection of X so as to maximize the number of constraints that are simultaneously satisfied, or equivalently, combinatorial selection of a maximum cardinality subset of feasible inequalities. Special classes of this problem are of interest in a variety of areas such as pattern recognition, machine learning, operations research, and medical treatment planning. This problem is generally solvable in exponential time. A heuristic polynomial time algorithm is presented in this paper. The algorithm relies on an iterative constraint removal procedure where constraints are eliminated from a set proposed by solutions to minmax linear programs. The method is illustrated by a simulated example of a linear system with double sided bounds and a case from the area of radiation therapy.",consider a set of linear one sided or two sided inequality constraints on a real vector x  the problem of interest is selection of x so as to maximize the number of constraints that are simultaneously satisfied  or equivalently  combinatorial selection of a maximum cardinality subset of feasible inequalities  special classes of this problem are of interest in a variety of areas such as pattern recognition  machine learning  operations research  and medical treatment planning  this problem is generally solvable in exponential time  a heuristic polynomial time algorithm is presented in this paper  the algorithm relies on an iterative constraint removal procedure where constraints are eliminated from a set proposed by solutions to minmax linear programs  the method is illustrated by a simulated example of a linear system with double sided bounds and a case from the area of radiation therapy ,3.1914406,7.8952127,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Distributed Dual Coordinate Ascent in General Tree Networks and Communication Network Effect on Synchronous Machine Learning,"Due to the big size of data and limited data storage volume of a single computer or a single server, data are often stored in a distributed manner. Thus, performing large-scale machine learning operations with the distributed datasets through communication networks is often required. In this paper, we study the convergence rate of the distributed dual coordinate ascent for distributed machine learning problems in a general tree-structured network. Since a tree network model can be understood as the generalization of a star network, our algorithm can be thought of as the generalization of the distributed dual coordinate ascent in a star network. We provide the convergence rate of the distributed dual coordinate ascent over a general tree network in a recursive manner and analyze the network effect on the convergence rate. Secondly, by considering network communication delays, we optimize the distributed dual coordinate ascent algorithm to maximize its convergence speed. From our analytical result, we can choose the optimal number of local iterations depending on the communication delay severity to achieve the fastest convergence speed. In numerical experiments, we consider machine learning scenarios over communication networks, where local workers cannot directly reach to a central node due to constraints in communication, and demonstrate that the usability of our distributed dual coordinate ascent algorithm in tree networks.",due to the big size of data and limited data storage volume of a single computer or a single server  data are often stored in a distributed manner  thus  performing large scale machine learning operations with the distributed datasets through communication networks is often required  in this paper  we study the convergence rate of the distributed dual coordinate ascent for distributed machine learning problems in a general tree structured network  since a tree network model can be understood as the generalization of a star network  our algorithm can be thought of as the generalization of the distributed dual coordinate ascent in a star network  we provide the convergence rate of the distributed dual coordinate ascent over a general tree network in a recursive manner and analyze the network effect on the convergence rate  secondly  by considering network communication delays  we optimize the distributed dual coordinate ascent algorithm to maximize its convergence speed  from our analytical result  we can choose the optimal number of local iterations depending on the communication delay severity to achieve the fastest convergence speed  in numerical experiments  we consider machine learning scenarios over communication networks  where local workers cannot directly reach to a central node due to constraints in communication  and demonstrate that the usability of our distributed dual coordinate ascent algorithm in tree networks ,3.8120213,7.8502345,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Hardware Acceleration for DBMS Machine Learning Scoring: Is It Worth the Overheads?,"Query processing for data analytics with machine learning scoring involves executing heterogeneous operations in a pipelined fashion. Hardware acceleration is one approach to improve the pipeline performance and free up processor resources by offloading computations to the accelerators. However, the performance benefits of accelerators can be limited by the compute and data offloading overheads. Although prior works have studied acceleration opportunities, including with accelerators for machine learning operations, an end-to-end application performance analysis has not been well studied, particularly for data analytics and model scoring pipelines. In this paper, we study speedups and overheads of using PCIe-based hardware accelerators in such pipelines. In particular, we analyze the effectiveness of using GPUs and FPGAs to accelerate scoring for random forest, a popular machine learning model, on tabular input data obtained from Microsoft SQL Server. We observe that the offloading decision as well as the choice of the optimal hardware backend should depend at least on the model complexity (e.g., number of features and tree depth), the scoring data size, and the overheads associated with data movement and invocation of the pipeline stages. We also highlight potential future research explorations based on our findings.",query processing for data analytics with machine learning scoring involves executing heterogeneous operations in a pipelined fashion  hardware acceleration is one approach to improve the pipeline performance and free up processor resources by offloading computations to the accelerators  however  the performance benefits of accelerators can be limited by the compute and data offloading overheads  although prior works have studied acceleration opportunities  including with accelerators for machine learning operations  an end to end application performance analysis has not been well studied  particularly for data analytics and model scoring pipelines  in this paper  we study speedups and overheads of using pcie based hardware accelerators in such pipelines  in particular  we analyze the effectiveness of using gpus and fpgas to accelerate scoring for random forest  a popular machine learning model  on tabular input data obtained from microsoft sql server  we observe that the offloading decision as well as the choice of the optimal hardware backend should depend at least on the model complexity  e g   number of features and tree depth   the scoring data size  and the overheads associated with data movement and invocation of the pipeline stages  we also highlight potential future research explorations based on our findings ,5.0987887,7.74825,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
SliceTeller: A Data Slice-Driven Approach for Machine Learning Model Validation,"Real-world machine learning applications need to be thoroughly evaluated to meet critical product requirements for model release, to ensure fairness for different groups or individuals, and to achieve a consistent performance in various scenarios. For example, in autonomous driving, an object classification model should achieve high detection rates under different conditions of weather, distance, etc. Similarly, in the financial setting, credit-scoring models must not discriminate against minority groups. These conditions or groups are called as â€œ Data Slices â€. In product MLOps cycles, product developers must identify such critical data slices and adapt models to mitigate data slice problems. Discovering where models fail, understanding why they fail, and mitigating these problems, are therefore essential tasks in the MLOps life-cycle. In this paper, we present SliceTeller , a novel tool that allows users to debug, compare and improve machine learning models driven by critical data slices. SliceTeller automatically discovers problematic slices in the data, helps the user understand why models fail. More importantly, we present an efficient algorithm, SliceBoosting , to estimate trade-offs when prioritizing the optimization over certain slices. Furthermore, our system empowers model developers to compare and analyze different model versions during model iterations, allowing them to choose the model version best suitable for their applications. We evaluate our system with three use cases, including two real-world use cases of product development , to demonstrate the power of SliceTeller in the debugging and improvement of product-quality ML models.",real world machine learning applications need to be thoroughly evaluated to meet critical product requirements for model release  to ensure fairness for different groups or individuals  and to achieve a consistent performance in various scenarios  for example  in autonomous driving  an object classification model should achieve high detection rates under different conditions of weather  distance  etc  similarly  in the financial setting  credit scoring models must not discriminate against minority groups  these conditions or groups are called as     data slices      in product mlops cycles  product developers must identify such critical data slices and adapt models to mitigate data slice problems  discovering where models fail  understanding why they fail  and mitigating these problems  are therefore essential tasks in the mlops life cycle  in this paper  we present sliceteller   a novel tool that allows users to debug  compare and improve machine learning models driven by critical data slices  sliceteller automatically discovers problematic slices in the data  helps the user understand why models fail  more importantly  we present an efficient algorithm  sliceboosting   to estimate trade offs when prioritizing the optimization over certain slices  furthermore  our system empowers model developers to compare and analyze different model versions during model iterations  allowing them to choose the model version best suitable for their applications  we evaluate our system with three use cases  including two real world use cases of product development   to demonstrate the power of sliceteller in the debugging and improvement of product quality ml models ,5.3035564,6.6278267,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
GELAB – The Cutting Edge of Grammatical Evolution,"The advent of cloud-based super-computing platforms has given rise to a Data Science (DS) boom. Many types of technological problems that were once considered prohibitively expensive to tackle are now candidates for exploration. Machine Learning (ML) tools that were valued only in academic environments are quickly being embraced by industrial giants and tiny startups alike. Coupled with modern-day computing power, ML tools can be looked at as hammers that can deal with even the most stubborn nails. ML tools have become so ubiquitous that the current industrial expectation is that they should not only deliver accurate and intelligent solutions but also do so rapidly. In order to keep pace with these requirements, a new enterprise, referred to as MLOps has blossomed in recent years. MLOps combines the process of ML and DS with an agile software engineering technique to develop and deliver solutions in a fast and iterative way. One of the key challenges to this is that ML and DS tools should be efficient and have better usability characteristics than were traditionally offered. In this paper, we present a novel software for Grammatical Evolution (GE) that meets both of these expectations. Our tool, GELAB, is a toolbox for GE in Matlab which has numerous features that distinguish it from existing contemporary GE software. Firstly, it is user-friendly and its development was aimed for use by non-specialists. Secondly, it is capable of hybrid optimization, in which standard numerical optimization techniques can be added to GE. We have shown experimentally that when hybridized with meta-heuristics GELAB has an overall better performance as compared with standard GE.",the advent of cloud based super computing platforms has given rise to a data science  ds  boom  many types of technological problems that were once considered prohibitively expensive to tackle are now candidates for exploration  machine learning  ml  tools that were valued only in academic environments are quickly being embraced by industrial giants and tiny startups alike  coupled with modern day computing power  ml tools can be looked at as hammers that can deal with even the most stubborn nails  ml tools have become so ubiquitous that the current industrial expectation is that they should not only deliver accurate and intelligent solutions but also do so rapidly  in order to keep pace with these requirements  a new enterprise  referred to as mlops has blossomed in recent years  mlops combines the process of ml and ds with an agile software engineering technique to develop and deliver solutions in a fast and iterative way  one of the key challenges to this is that ml and ds tools should be efficient and have better usability characteristics than were traditionally offered  in this paper  we present a novel software for grammatical evolution  ge  that meets both of these expectations  our tool  gelab  is a toolbox for ge in matlab which has numerous features that distinguish it from existing contemporary ge software  firstly  it is user friendly and its development was aimed for use by non specialists  secondly  it is capable of hybrid optimization  in which standard numerical optimization techniques can be added to ge  we have shown experimentally that when hybridized with meta heuristics gelab has an overall better performance as compared with standard ge ,2.863245,7.263925,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Privacy-Preserving Ridge Regression on Hundreds of Millions of Records,"Ridge regression is an algorithm that takes as input a large number of data points and finds the best-fit linear curve through these points. The algorithm is a building block for many machine-learning operations. We present a system for privacy-preserving ridge regression. The system outputs the best-fit curve in the clear, but exposes no other information about the input data. Our approach combines both homomorphic encryption and Yao garbled circuits, where each is used in a different part of the algorithm to obtain the best performance. We implement the complete system and experiment with it on real data-sets, and show that it significantly outperforms pure implementations based only on homomorphic encryption or Yao circuits.",ridge regression is an algorithm that takes as input a large number of data points and finds the best fit linear curve through these points  the algorithm is a building block for many machine learning operations  we present a system for privacy preserving ridge regression  the system outputs the best fit curve in the clear  but exposes no other information about the input data  our approach combines both homomorphic encryption and yao garbled circuits  where each is used in a different part of the algorithm to obtain the best performance  we implement the complete system and experiment with it on real data sets  and show that it significantly outperforms pure implementations based only on homomorphic encryption or yao circuits ,2.9811296,8.186169,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Evolutionary computation: practical issues,"Evolutionary computation techniques, which are based on a powerful principle of evolution: survival of the fittest, constitute an interesting category of heuristic search. These stochastic algorithms whose search methods model some natural phenomena: genetic inheritance and Darwinian strife for survival, have been applied to a large number of hard, real-world problems from a variety of domains: social systems, machine learning, operations research, ecology, engineering, immune systems, economics, management, etc. Any evolutionary algorithm applied to a particular problem must address the issue of genetic representation of solutions to the problem and genetic operators that would alter the genetic composition of offspring during the reproduction process. Additional heuristics should be incorporated in the algorithm as well; some of these heuristic rules provide guidelines for initializing the population of potential solutions, for setting various parameters of the system (e.g., population size, probabilities of operators, etc.) and for evaluating individuals in the population. This paper discusses some practical issues connected with applications of evolutionary techniques.",evolutionary computation techniques  which are based on a powerful principle of evolution  survival of the fittest  constitute an interesting category of heuristic search  these stochastic algorithms whose search methods model some natural phenomena  genetic inheritance and darwinian strife for survival  have been applied to a large number of hard  real world problems from a variety of domains  social systems  machine learning  operations research  ecology  engineering  immune systems  economics  management  etc  any evolutionary algorithm applied to a particular problem must address the issue of genetic representation of solutions to the problem and genetic operators that would alter the genetic composition of offspring during the reproduction process  additional heuristics should be incorporated in the algorithm as well  some of these heuristic rules provide guidelines for initializing the population of potential solutions  for setting various parameters of the system  e g   population size  probabilities of operators  etc   and for evaluating individuals in the population  this paper discusses some practical issues connected with applications of evolutionary techniques ,2.894313,7.9629116,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Smart-ML: A System for Machine Learning Model Exploration using Pipeline Graph,"In this paper, we describe an overarching ML system with a simple programming interface that leverages existing AI and ML frameworks to make the task of model exploration easier. The proposed system introduces a new programming construct namely pipeline graph (a directed acyclic graph) consisting of multiple machine learning operations provided by different ML repositories. End user uses the pipeline graph as a common interface for modeling different ML tasks such as classification, regression, and timeseries prediction, while enabling efficient execution on different environments (Spark, Celery and Cloud). We further annotated the pipeline graph with a hyper-parameter grid and an option to try-out a wide range of optimization strategies (i.e., Random, Bayesian, Bandit, AutoLearn, etc). Given a large pre-defined pipeline graph along with its hyper-parameters, we provided a general-purpose, scalable and efficient pipeline-graph exploration technique to provide the automated solutions to a variety of ML tasks. We compare our automated approach to several state-of-the-art automated AI systems and find that we achieve performance comparable to the best results, while often producing simpler pipelines using off the shelf components. Our evaluation suite consists of experiments on 60+ classifications and regressions datasets.",in this paper  we describe an overarching ml system with a simple programming interface that leverages existing ai and ml frameworks to make the task of model exploration easier  the proposed system introduces a new programming construct namely pipeline graph  a directed acyclic graph  consisting of multiple machine learning operations provided by different ml repositories  end user uses the pipeline graph as a common interface for modeling different ml tasks such as classification  regression  and timeseries prediction  while enabling efficient execution on different environments  spark  celery and cloud   we further annotated the pipeline graph with a hyper parameter grid and an option to try out a wide range of optimization strategies  i e   random  bayesian  bandit  autolearn  etc   given a large pre defined pipeline graph along with its hyper parameters  we provided a general purpose  scalable and efficient pipeline graph exploration technique to provide the automated solutions to a variety of ml tasks  we compare our automated approach to several state of the art automated ai systems and find that we achieve performance comparable to the best results  while often producing simpler pipelines using off the shelf components  our evaluation suite consists of experiments on     classifications and regressions datasets ,7.5304384,5.8719673,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Interpretable Medical Recommendations Based on SHAPs,"In the past few years, chronic diseases of the elderly have gradually become the killer of the elderly, seriously affecting their physical health of the elderly. Doctors can extract relevant information from the data to make patient treatment recommendations. This study proposed a smart recommendation system for doctors by using deep learning traditional methods. Proposed method firstly use six traditional deep learning methods such as naive Bayes, logistic regression, decision tree etc for recommendation purpose. Next step to get the better understanding of the recommendation we apply an interpretable recommendation system based on SHapley Additive exPlanations. (SHAP). Last time is provide recommendations based on better and weak recommenations by graphical way. The proposed methods were applied to two chronic diseases of old age, including heart disease and diabetes. After the data is preprocessed, naive Bayes, decision tree, and other machine learning operations are carried out on the data. SHAP was used to calculate the importance of each feature for randomly selected patients. Finally, the contribution coefficient of the feature to the result is presented, which impacts the output. By analyzing the influence of different features of users on recommendation results, the proposed system explains why such results are recommended to users to improve users' trust in the recommendation results, which is of great significance for medical recommendation.",in the past few years  chronic diseases of the elderly have gradually become the killer of the elderly  seriously affecting their physical health of the elderly  doctors can extract relevant information from the data to make patient treatment recommendations  this study proposed a smart recommendation system for doctors by using deep learning traditional methods  proposed method firstly use six traditional deep learning methods such as naive bayes  logistic regression  decision tree etc for recommendation purpose  next step to get the better understanding of the recommendation we apply an interpretable recommendation system based on shapley additive explanations   shap   last time is provide recommendations based on better and weak recommenations by graphical way  the proposed methods were applied to two chronic diseases of old age  including heart disease and diabetes  after the data is preprocessed  naive bayes  decision tree  and other machine learning operations are carried out on the data  shap was used to calculate the importance of each feature for randomly selected patients  finally  the contribution coefficient of the feature to the result is presented  which impacts the output  by analyzing the influence of different features of users on recommendation results  the proposed system explains why such results are recommended to users to improve users  trust in the recommendation results  which is of great significance for medical recommendation ,4.893755,4.4469986,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Getting Started with Amazon SageMaker Studio: Learn to build end-to-end machine learning projects in the SageMaker machine learning IDE,"Build production-grade machine learning models with Amazon SageMaker Studio, the first integrated development environment in the cloud, using real-life machine learning examples and code Key Features Understand the ML lifecycle in the cloud and its development on Amazon SageMaker StudioLearn to apply SageMaker features in SageMaker Studio for ML use casesScale and operationalize the ML lifecycle effectively using SageMaker Studio Book Description Amazon SageMaker Studio is the first integrated development environment (IDE) for machine learning (ML) and is designed to integrate ML workflows: data preparation, feature engineering, statistical bias detection, automated machine learning (AutoML), training, hosting, ML explainability, monitoring, and MLOps in one environment. In this book, you'll start by exploring the features available in Amazon SageMaker Studio to analyze data, develop ML models, and productionize models to meet your goals. As you progress, you will learn how these features work together to address common challenges when building ML models in production. After that, you'll understand how to effectively scale and operationalize the ML life cycle using SageMaker Studio. By the end of this book, you'll have learned ML best practices regarding Amazon SageMaker Studio, as well as being able to improve productivity in the ML development life cycle and build and deploy models easily for your ML use cases. What you will learn Explore the ML development life cycle in the cloudUnderstand SageMaker Studio features and the user interfaceBuild a dataset with clicks and host a feature store for MLTrain ML models with ease and scaleCreate ML models and solutions with little codeHost ML models in the cloud with optimal cloud resourcesEnsure optimal model performance with model monitoringApply governance and operational excellence to ML projects Who this book is for This book is for data scientists and machine learning engineers who are looking to become well-versed w...",build production grade machine learning models with amazon sagemaker studio  the first integrated development environment in the cloud  using real life machine learning examples and code key features understand the ml lifecycle in the cloud and its development on amazon sagemaker studiolearn to apply sagemaker features in sagemaker studio for ml use casesscale and operationalize the ml lifecycle effectively using sagemaker studio book description amazon sagemaker studio is the first integrated development environment  ide  for machine learning  ml  and is designed to integrate ml workflows  data preparation  feature engineering  statistical bias detection  automated machine learning  automl   training  hosting  ml explainability  monitoring  and mlops in one environment  in this book  you ll start by exploring the features available in amazon sagemaker studio to analyze data  develop ml models  and productionize models to meet your goals  as you progress  you will learn how these features work together to address common challenges when building ml models in production  after that  you ll understand how to effectively scale and operationalize the ml life cycle using sagemaker studio  by the end of this book  you ll have learned ml best practices regarding amazon sagemaker studio  as well as being able to improve productivity in the ml development life cycle and build and deploy models easily for your ml use cases  what you will learn explore the ml development life cycle in the cloudunderstand sagemaker studio features and the user interfacebuild a dataset with clicks and host a feature store for mltrain ml models with ease and scalecreate ml models and solutions with little codehost ml models in the cloud with optimal cloud resourcesensure optimal model performance with model monitoringapply governance and operational excellence to ml projects who this book is for this book is for data scientists and machine learning engineers who are looking to become well versed w   ,7.9016867,8.081369,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
"Azure Machine Learning Engineering: Deploy, fine-tune, and optimize ML models using Microsoft Azure","Fully build and productionize end-to-end machine learning solutions using Azure Machine Learning Service Key Features Automate complete machine learning solutions using Microsoft AzureUnderstand how to productionize machine learning modelsGet to grips with monitoring, MLOps, deep learning, distributed training, and reinforcement learning Book Description Data scientists working on productionizing machine learning (ML) workloads face a breadth of challenges at every step owing to the countless factors involved in getting ML models deployed and running. This book offers solutions to common issues, detailed explanations of essential concepts, and step-by-step instructions to productionize ML workloads using the Azure Machine Learning service. Youâ€™ll see how data scientists and ML engineers working with Microsoft Azure can train and deploy ML models at scale by putting their knowledge to work with this practical guide. Throughout the book, youâ€™ll learn how to train, register, and productionize ML models by making use of the power of the Azure Machine Learning service. Youâ€™ll get to grips with scoring models in real time and batch, explaining models to earn business trust, mitigating model bias, and developing solutions using an MLOps framework. By the end of this Azure Machine Learning book, youâ€™ll be ready to build and deploy end-to-end ML solutions into a production system using the Azure Machine Learning service for real-time scenarios. What you will learn Train ML models in the Azure Machine Learning serviceBuild end-to-end ML pipelinesHost ML models on real-time scoring endpointsMitigate bias in ML modelsGet the hang of using an MLOps framework to productionize modelsSimplify ML model explainability using the Azure Machine Learning service and Azure Interpret Who this book is for Machine learning engineers and data scientists who want to move to ML engineering roles will find this AMLS book useful. Familiarity with the Azure ecosystem will assist with understanding...",fully build and productionize end to end machine learning solutions using azure machine learning service key features automate complete machine learning solutions using microsoft azureunderstand how to productionize machine learning modelsget to grips with monitoring  mlops  deep learning  distributed training  and reinforcement learning book description data scientists working on productionizing machine learning  ml  workloads face a breadth of challenges at every step owing to the countless factors involved in getting ml models deployed and running  this book offers solutions to common issues  detailed explanations of essential concepts  and step by step instructions to productionize ml workloads using the azure machine learning service  you   ll see how data scientists and ml engineers working with microsoft azure can train and deploy ml models at scale by putting their knowledge to work with this practical guide  throughout the book  you   ll learn how to train  register  and productionize ml models by making use of the power of the azure machine learning service  you   ll get to grips with scoring models in real time and batch  explaining models to earn business trust  mitigating model bias  and developing solutions using an mlops framework  by the end of this azure machine learning book  you   ll be ready to build and deploy end to end ml solutions into a production system using the azure machine learning service for real time scenarios  what you will learn train ml models in the azure machine learning servicebuild end to end ml pipelineshost ml models on real time scoring endpointsmitigate bias in ml modelsget the hang of using an mlops framework to productionize modelssimplify ml model explainability using the azure machine learning service and azure interpret who this book is for machine learning engineers and data scientists who want to move to ml engineering roles will find this amls book useful  familiarity with the azure ecosystem will assist with understanding   ,7.852656,8.298206,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Amazon SageMaker Best Practices: Proven tips and tricks to build successful machine learning solutions on Amazon SageMaker,"Overcome advanced challenges in building end-to-end ML solutions by leveraging the capabilities of Amazon SageMaker for developing and integrating ML models into production Key Features Learn best practices for all phases of building machine learning solutions - from data preparation to monitoring models in productionAutomate end-to-end machine learning workflows with Amazon SageMaker and related AWSDesign, architect, and operate machine learning workloads in the AWS Cloud Book Description Amazon SageMaker is a fully managed AWS service that provides the ability to build, train, deploy, and monitor machine learning models. The book begins with a high-level overview of Amazon SageMaker capabilities that map to the various phases of the machine learning process to help set the right foundation. You'll learn efficient tactics to address data science challenges such as processing data at scale, data preparation, connecting to big data pipelines, identifying data bias, running A/B tests, and model explainability using Amazon SageMaker. As you advance, you'll understand how you can tackle the challenge of training at scale, including how to use large data sets while saving costs, monitoring training resources to identify bottlenecks, speeding up long training jobs, and tracking multiple models trained for a common goal. Moving ahead, you'll find out how you can integrate Amazon SageMaker with other AWS to build reliable, cost-optimized, and automated machine learning applications. In addition to this, you'll build ML pipelines integrated with MLOps principles and apply best practices to build secure and performant solutions. By the end of the book, you'll confidently be able to apply Amazon SageMaker's wide range of capabilities to the full spectrum of machine learning workflows. What you will learn Perform data bias detection with AWS Data Wrangler and SageMaker ClarifySpeed up data processing with SageMaker Feature StoreOvercome labeling bias with SageMaker Ground Truth...",overcome advanced challenges in building end to end ml solutions by leveraging the capabilities of amazon sagemaker for developing and integrating ml models into production key features learn best practices for all phases of building machine learning solutions   from data preparation to monitoring models in productionautomate end to end machine learning workflows with amazon sagemaker and related awsdesign  architect  and operate machine learning workloads in the aws cloud book description amazon sagemaker is a fully managed aws service that provides the ability to build  train  deploy  and monitor machine learning models  the book begins with a high level overview of amazon sagemaker capabilities that map to the various phases of the machine learning process to help set the right foundation  you ll learn efficient tactics to address data science challenges such as processing data at scale  data preparation  connecting to big data pipelines  identifying data bias  running a b tests  and model explainability using amazon sagemaker  as you advance  you ll understand how you can tackle the challenge of training at scale  including how to use large data sets while saving costs  monitoring training resources to identify bottlenecks  speeding up long training jobs  and tracking multiple models trained for a common goal  moving ahead  you ll find out how you can integrate amazon sagemaker with other aws to build reliable  cost optimized  and automated machine learning applications  in addition to this  you ll build ml pipelines integrated with mlops principles and apply best practices to build secure and performant solutions  by the end of the book  you ll confidently be able to apply amazon sagemaker s wide range of capabilities to the full spectrum of machine learning workflows  what you will learn perform data bias detection with aws data wrangler and sagemaker clarifyspeed up data processing with sagemaker feature storeovercome labeling bias with sagemaker ground truth   ,7.843026,7.950634,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Considering various aspects of modelsâ€™ quality in the ML pipeline - application in the logistics sector,"The industrial machine learning applications today involve developing and deploying MLOps pipelines to ensure the versatile quality of forecasting models over an extended period, simultaneously assuring the modelâ€™s accuracy, stability, short training time, and resilience. In this study, we present the ML pipeline conforming to all the abovementioned aspects of modelsâ€™ quality formulated as a constrained multi-objective optimization problem. We also provide the reference implementation on state-of-the-art methods for data preprocessing, feature extraction, dimensionality reduction, feature and instance selection, model fitting, and ensemble blending. The experimental study on the real data set from the logistics industry confirmed the qualities of the proposed approach, as the successful participation in an international data competition did.",the industrial machine learning applications today involve developing and deploying mlops pipelines to ensure the versatile quality of forecasting models over an extended period  simultaneously assuring the model   s accuracy  stability  short training time  and resilience  in this study  we present the ml pipeline conforming to all the abovementioned aspects of models    quality formulated as a constrained multi objective optimization problem  we also provide the reference implementation on state of the art methods for data preprocessing  feature extraction  dimensionality reduction  feature and instance selection  model fitting  and ensemble blending  the experimental study on the real data set from the logistics industry confirmed the qualities of the proposed approach  as the successful participation in an international data competition did ,5.4308133,6.508348,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Automated visual inspection of manufactured parts using deep convolutional neural networks and transfer learning,"Most manufacturing processes involve some form of visual quality control of the produced parts. Automated solutions can reduce the required manual work significantly while increasing reliability. However, common obstacles to the construction of smart visual inspection systems are the complexity of the inspected parts, varying types of defects, and small datasets. In this study, we apply state-of-the-art convolutional neural networks to classify infrared images of thermal conductive components manufactured in a real factory setting. Typically, training deep neural architectures requires very large datasets, but this effect is mitigated by using transfer learning. The dataset consists of 6,000 images with 4,200 defect samples and 1,800 intact samples, including different types of flaws and component models. We present a concept for implementing the automated visual inspection system, including dataset preparation, model training, and the inline application. The goal is to establish a Human-in-the-Loop approach, that maximizes accuracy and safety while keeping the required human work at a minimum. A key finding of our research is that dataset preparation and cleaning had a greater impact on the classification accuracy than the optimal choice of the model or training parameters.",most manufacturing processes involve some form of visual quality control of the produced parts  automated solutions can reduce the required manual work significantly while increasing reliability  however  common obstacles to the construction of smart visual inspection systems are the complexity of the inspected parts  varying types of defects  and small datasets  in this study  we apply state of the art convolutional neural networks to classify infrared images of thermal conductive components manufactured in a real factory setting  typically  training deep neural architectures requires very large datasets  but this effect is mitigated by using transfer learning  the dataset consists of       images with       defect samples and       intact samples  including different types of flaws and component models  we present a concept for implementing the automated visual inspection system  including dataset preparation  model training  and the inline application  the goal is to establish a human in the loop approach  that maximizes accuracy and safety while keeping the required human work at a minimum  a key finding of our research is that dataset preparation and cleaning had a greater impact on the classification accuracy than the optimal choice of the model or training parameters ,4.2171354,5.384097,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
A reference architecture for the operationalization of machine learning models in manufacturing,"Inherent characteristics of machine learning algorithms such as their probabilistic nature, their reliance on large datasets as well as their need for constant retraining pose major challenges to the operationalization of machine learning models (MLOps) in the manufacturing domain. As such systems are known to quickly accumulate technical debt due to system-level interdependencies of code, data, and models, clear abstractions boundaries are mandatory. Therefore, this publication derives a systematic functional decomposition of an MLOps system tailored to the manufacturing industry into specific domains and contexts. Moreover, a concrete deployment view is provided, and possible future research directions are discussed.",inherent characteristics of machine learning algorithms such as their probabilistic nature  their reliance on large datasets as well as their need for constant retraining pose major challenges to the operationalization of machine learning models  mlops  in the manufacturing domain  as such systems are known to quickly accumulate technical debt due to system level interdependencies of code  data  and models  clear abstractions boundaries are mandatory  therefore  this publication derives a systematic functional decomposition of an mlops system tailored to the manufacturing industry into specific domains and contexts  moreover  a concrete deployment view is provided  and possible future research directions are discussed ,9.015498,8.356956,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Chapter Five: State-of-the-art data prefetchers,"We introduced several styles of data prefetching in the past three chapters. The introduced data prefetchers were known for a long time, sometimes for decades. In this chapter, we introduce several state-of-the-art data prefetchers, which have been introduced in the past few years. In particular, we introduce Domino, Bingo, MLOP, and Runahead Metadata.",we introduced several styles of data prefetching in the past three chapters  the introduced data prefetchers were known for a long time  sometimes for decades  in this chapter  we introduce several state of the art data prefetchers  which have been introduced in the past few years  in particular  we introduce domino  bingo  mlop  and runahead metadata ,9.382228,6.961529,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
"ML-driven risk estimation for memory failure in a data center environment with convolutional neural networks, self-supervised data labeling and distribution-based model drift determination","With the trend towards multi-socket server systems, the demand for random access memory (RAM) per server increased. The consequence are more DIMM sockets per server. Since every dual in-line memory module (DIMM), which comprises a series of dynamic random-access memory integrated circuits, has a probability of failure, RAM issues became a dominant failure pattern for servers. The concept introduced in this work contributes to improving the reliability of data centers by avoiding RAM failures and mitigating their impact. For this purpose, an ML-driven framework is provided to estimate the probability of memory failure for each RAM module. The ML framework is based on structural information between correctable (CE) and uncorrectable errors (UE). In a common memory scenario, a corrupted bit within a module can be restored by redundancy using an error correction code (ECC), resulting in a CE. However, if there is more than one corrupted bit within a group of bits covered by the ECC, the information cannot be restored, resulting in a UE.

Consequently, the related task requesting the memory content, and the corresponding service may crash. There is evidence that UEs have a CE history and structural relation between the CEs. However, for the case of UEs without a CE history or of a false decision of the ML framework, we extend the total framework by engineering measures to mitigate the impact of a UE by avoiding kernel panic and using backups. The engineering measures use a mapping between physical and logical memory addresses.",with the trend towards multi socket server systems  the demand for random access memory  ram  per server increased  the consequence are more dimm sockets per server  since every dual in line memory module  dimm   which comprises a series of dynamic random access memory integrated circuits  has a probability of failure  ram issues became a dominant failure pattern for servers  the concept introduced in this work contributes to improving the reliability of data centers by avoiding ram failures and mitigating their impact  for this purpose  an ml driven framework is provided to estimate the probability of memory failure for each ram module  the ml framework is based on structural information between correctable  ce  and uncorrectable errors  ue   in a common memory scenario  a corrupted bit within a module can be restored by redundancy using an error correction code  ecc   resulting in a ce  however  if there is more than one corrupted bit within a group of bits covered by the ecc  the information cannot be restored  resulting in a ue   consequently  the related task requesting the memory content  and the corresponding service may crash  there is evidence that ues have a ce history and structural relation between the ces  however  for the case of ues without a ce history or of a false decision of the ml framework  we extend the total framework by engineering measures to mitigate the impact of a ue by avoiding kernel panic and using backups  the engineering measures use a mapping between physical and logical memory addresses ,4.73574,8.134474,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
"Leaching disturbed the altitudinal distribution of soil organic phosphorus in subalpine coniferous forests on Mt. Gongga, SW China","Little information is available about the leaching effects on the altitudinal distribution of soil organic phosphorus (OP), even though this process commonly occurs in most humid montane. Our aims were to decipher spatial variations in OP fractions and to clarify the effects of leaching on these variations along the altitudinal gradient (2628, 2781, 3044 and 3210?m?a.s.l.) on Mt. Gongga, southwest China. The results showed that the stocks of total OP (TOP) and moderately resistant OP (MROP) increased roughly upslope, with their minimums (824.69 and 410.56?kg?ha?1, respectively) at 2781?m. The concentrations and stocks of labile OP (LOP) markedly increased with altitude. The stocks of moderately labile OP (MLOP) and highly resistant OP (HROP) did not vary significantly among the four sites. The TOP distribution was likely related to the decrease of mineralization rate caused by the decreasing temperature upslope, and also disturbed by the leaching process. In addition, distributions of other P fractions were also regulated by this process. A larger loss of bioavailable P (Bio-P) occurred at the lower altitudes (2628 and 2781?m) due to more intensive leaching. This larger loss was compensated by microbial processes, as sharp decline in microbial biomass P and intensive mineralization of LOP via higher enzyme activities were observed. The MLOP and MROP were the main OP fractions that were downward migrated with fulvic acids, amorphous Fe and Al. The results highlight the role of leaching in regulating distributions of OP and Bio-P along altitudinal gradients in montane ecosystems.",little information is available about the leaching effects on the altitudinal distribution of soil organic phosphorus  op   even though this process commonly occurs in most humid montane  our aims were to decipher spatial variations in op fractions and to clarify the effects of leaching on these variations along the altitudinal gradient                   and      m a s l   on mt  gongga  southwest china  the results showed that the stocks of total op  top  and moderately resistant op  mrop  increased roughly upslope  with their minimums         and        kg ha    respectively  at      m  the concentrations and stocks of labile op  lop  markedly increased with altitude  the stocks of moderately labile op  mlop  and highly resistant op  hrop  did not vary significantly among the four sites  the top distribution was likely related to the decrease of mineralization rate caused by the decreasing temperature upslope  and also disturbed by the leaching process  in addition  distributions of other p fractions were also regulated by this process  a larger loss of bioavailable p  bio p  occurred at the lower altitudes       and      m  due to more intensive leaching  this larger loss was compensated by microbial processes  as sharp decline in microbial biomass p and intensive mineralization of lop via higher enzyme activities were observed  the mlop and mrop were the main op fractions that were downward migrated with fulvic acids  amorphous fe and al  the results highlight the role of leaching in regulating distributions of op and bio p along altitudinal gradients in montane ecosystems ,4.2072654,2.0944493,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Nutritional composition and consumer acceptability of Moringa oleifera leaf powder (MOLP)-supplemented mahewu,"Adequate nutrition is fundamental for optimal human well-being and productivity. Mahewu, a non-alcoholic cereal grain beverage, is prepared in many rural settings in southern Africa by fermenting maize meal porridge. People of all age groups, including infants, consume mahewu. However, the drink is deficient in essential amino acids and some micronutrients. This study investigated the effects of adding Moringa oleifera leaf powder (MOLP) on the nutritional composition and consumer acceptability of mahewu. Moringa oleifera leaf powder-supplemented mahewu was prepared by substituting a portion of the maize meal used in a traditional recipe with MOLP at 2, 4 and 6% (w/w) levels. The MOLP was boiled and added to the fermented porridge (mahewu) prior to consumption. The nutritional composition of the resulting mahewu samples and standard traditional mahewu were analyzed using AOAC methods. Sensory evaluation was conducted using (n?=?52) untrained panelists who rated the samples on a 5-point hedonic scale. Adding MOLP resulted in a significant (p?<?.05) increase in the total mineral content (ash), selected mineral elements, fat and fiber content of the beverage. The Calcium content increased by 350, 700 and 950% in mahewu samples supplemented with 2, 4 and 6% MOLP, respectively. The Iron content increased by 106, 214 and 287% in the same order of MOLP substitution levels. However, consumer acceptability decreased as the percentage of MOLP increased in the beverage. The color and aroma of mahewu were the sensory attributes most affected by MOLP supplementation. These results indicate that blanched MOLP could be used to enhance the nutritional profile of maize meal-based staple foods.",adequate nutrition is fundamental for optimal human well being and productivity  mahewu  a non alcoholic cereal grain beverage  is prepared in many rural settings in southern africa by fermenting maize meal porridge  people of all age groups  including infants  consume mahewu  however  the drink is deficient in essential amino acids and some micronutrients  this study investigated the effects of adding moringa oleifera leaf powder  molp  on the nutritional composition and consumer acceptability of mahewu  moringa oleifera leaf powder supplemented mahewu was prepared by substituting a portion of the maize meal used in a traditional recipe with molp at      and     w w  levels  the molp was boiled and added to the fermented porridge  mahewu  prior to consumption  the nutritional composition of the resulting mahewu samples and standard traditional mahewu were analyzed using aoac methods  sensory evaluation was conducted using  n       untrained panelists who rated the samples on a   point hedonic scale  adding molp resulted in a significant  p        increase in the total mineral content  ash   selected mineral elements  fat and fiber content of the beverage  the calcium content increased by          and      in mahewu samples supplemented with      and    molp  respectively  the iron content increased by          and      in the same order of molp substitution levels  however  consumer acceptability decreased as the percentage of molp increased in the beverage  the color and aroma of mahewu were the sensory attributes most affected by molp supplementation  these results indicate that blanched molp could be used to enhance the nutritional profile of maize meal based staple foods ,3.954494,2.1265912,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Accuracy of Potfit-based potential representations and its impact on the performance of (ML-)MCTDH,"Quantum molecular dynamics simulations with MCTDH or ML-MCTDH perform best if the potential energy surface (PES) has a sum-of-products (SOP) or multi-layer operator (MLOp) structure. Here we investigate four different POTFIT-based methods for representing a general PES as such a structure, among them the novel random-sampling multi-layer Potfit (RS-MLPF). We study how the format and accuracy of the PES representation influences the runtime of a benchmark (ML-)MCTDH calculation, namely the computation of the ground state of the H3O2? ion. Our results show that compared to the SOP format, the MLOp format leads to a much more favorable scaling of the (ML-)MCTDH runtime with the PES accuracy. At reasonably high PES accuracy, ML-MCTDH calculations thus become up to 20 times faster, and taken to the extreme, the RS-MLPF method yields extremely accurate PES representations (global root-mean-square error of ?0.1?cm?1) which still lead to only moderate computational demands for ML-MCTDH.",quantum molecular dynamics simulations with mctdh or ml mctdh perform best if the potential energy surface  pes  has a sum of products  sop  or multi layer operator  mlop  structure  here we investigate four different potfit based methods for representing a general pes as such a structure  among them the novel random sampling multi layer potfit  rs mlpf   we study how the format and accuracy of the pes representation influences the runtime of a benchmark  ml  mctdh calculation  namely the computation of the ground state of the h o   ion  our results show that compared to the sop format  the mlop format leads to a much more favorable scaling of the  ml  mctdh runtime with the pes accuracy  at reasonably high pes accuracy  ml mctdh calculations thus become up to    times faster  and taken to the extreme  the rs mlpf method yields extremely accurate pes representations  global root mean square error of      cm    which still lead to only moderate computational demands for ml mctdh ,4.5187616,8.123977,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Secure and privacy-preserving automated machine learning operations into end-to-end integrated IoT-edge-artificial intelligence-blockchain monitoring system for diabetes mellitus prediction,"Diabetes Mellitus, one of the leading causes of death worldwide, has no cure to date and can lead to severe health complications, such as retinopathy, limb amputation, cardiovascular diseases, and neuronal disease, if left untreated. Consequently, it becomes crucial to be able to monitor and predict the incidence of diabetes. Machine learning approaches have been proposed and evaluated in the literature for diabetes prediction. This paper proposes an IoT-edge-Artificial Intelligence (AI)-blockchain system for diabetes prediction based on risk factors. The proposed system is underpinned by blockchain to obtain a cohesive view of the risk factors data from patients across different hospitals and ensure security and privacy of the user's data. We provide a comparative analysis of different medical sensors, devices, and methods to measure and collect the risk factors values in the system. Numerical experiments and comparative analysis were carried out within our proposed system, using the most accurate random forest (RF) model, and the two most used state-of-the-art machine learning approaches, Logistic Regression (LR) and Support Vector Machine (SVM), using three real-life diabetes datasets. The results show that the proposed system predicts diabetes using RF with 4.57% more accuracy on average in comparison with the other models LR and SVM, with 2.87 times more execution time. Data balancing without feature selection does not show significant improvement. When using feature selection, the performance is improved by 1.14% for PIMA Indian and 0.02% for Sylhet datasets, while it is reduced by 0.89% for MIMIC III.",diabetes mellitus  one of the leading causes of death worldwide  has no cure to date and can lead to severe health complications  such as retinopathy  limb amputation  cardiovascular diseases  and neuronal disease  if left untreated  consequently  it becomes crucial to be able to monitor and predict the incidence of diabetes  machine learning approaches have been proposed and evaluated in the literature for diabetes prediction  this paper proposes an iot edge artificial intelligence  ai  blockchain system for diabetes prediction based on risk factors  the proposed system is underpinned by blockchain to obtain a cohesive view of the risk factors data from patients across different hospitals and ensure security and privacy of the user s data  we provide a comparative analysis of different medical sensors  devices  and methods to measure and collect the risk factors values in the system  numerical experiments and comparative analysis were carried out within our proposed system  using the most accurate random forest  rf  model  and the two most used state of the art machine learning approaches  logistic regression  lr  and support vector machine  svm   using three real life diabetes datasets  the results show that the proposed system predicts diabetes using rf with       more accuracy on average in comparison with the other models lr and svm  with      times more execution time  data balancing without feature selection does not show significant improvement  when using feature selection  the performance is improved by       for pima indian and       for sylhet datasets  while it is reduced by       for mimic iii ,5.085873,4.199013,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Processes and their explanatory factors governing distribution of organic phosphorous pools in lake sediments,"The amount of organic phosphorus (OP) and its distribution among different pools in lake sediments depends on biotic and abiotic processes driving the OP fractionation. Key environmental factors governing these transformations processes between OP fractionations in sediments were studied on the basis of geochemical characteristics of OP pools in relation to environmental factors in the sediments. The results illustrate that the factors influencing the accumulation or depletion of different OP pools were intrinsically dependent on the composition of the deposited organic matter (OM). During the mineralization of the OM the microorganisms excrete the enzyme alkaline phosphatase, accelerating the OP hydrolysis, and thereby setting the grounds for the bacterially-mediated oxidation of OM. There are two main degradation products of the labile OP pool (LOP) and the moderately labile OP pool (MLOP): Either the OP is transformed to a dissolved organic or inorganic P form, and thereby released to water column, or OP is transformed to a non-labile OP pool and stored in the sediments. A comparative study showed that oxy-hydroxides of iron (Fe) and aluminum (Al) only played an important role in influencing OP fractionation in Lake Wuliangsuhai, while the complexation reactions of OP with calcium ions and sorption to its minerals are key factors governing the OP fractionation in the two alkaline lakes. It is worth noting that a significant correlation between the FeñP pool and the pools of LOP and MLOP indicates that the degradation of the rather labile OP pools are highly dependent on the iron redox reaction.",the amount of organic phosphorus  op  and its distribution among different pools in lake sediments depends on biotic and abiotic processes driving the op fractionation  key environmental factors governing these transformations processes between op fractionations in sediments were studied on the basis of geochemical characteristics of op pools in relation to environmental factors in the sediments  the results illustrate that the factors influencing the accumulation or depletion of different op pools were intrinsically dependent on the composition of the deposited organic matter  om   during the mineralization of the om the microorganisms excrete the enzyme alkaline phosphatase  accelerating the op hydrolysis  and thereby setting the grounds for the bacterially mediated oxidation of om  there are two main degradation products of the labile op pool  lop  and the moderately labile op pool  mlop   either the op is transformed to a dissolved organic or inorganic p form  and thereby released to water column  or op is transformed to a non labile op pool and stored in the sediments  a comparative study showed that oxy hydroxides of iron  fe  and aluminum  al  only played an important role in influencing op fractionation in lake wuliangsuhai  while the complexation reactions of op with calcium ions and sorption to its minerals are key factors governing the op fractionation in the two alkaline lakes  it is worth noting that a significant correlation between the fe p pool and the pools of lop and mlop indicates that the degradation of the rather labile op pools are highly dependent on the iron redox reaction ,3.9463482,2.0088232,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
AutoML: A systematic review on automated machine learning with neural architecture search,"AutoML (Automated Machine Learning) is an emerging field that aims to automate the process of building machine learning models. AutoML emerged to increase productivity and efficiency by automating as much as possible the inefficient work that occurs while repeating this process whenever machine learning is applied. In particular, research has been conducted for a long time on technologies that can effectively develop high-quality models by minimizing the intervention of model developers in the process from data preprocessing to algorithm selection and tuning. In this semantic review research, we summarize the data processing requirements for AutoML approaches and provide a detailed explanation. We place greater emphasis on neural architecture search (NAS) as it currently represents a highly popular sub-topic within the field of AutoML. NAS methods use machine learning algorithms to search through a large space of possible architectures and find the one that performs best on a given task. We provide a summary of the performance achieved by representative NAS algorithms on the CIFAR-10, CIFAR-100, ImageNet and well-known benchmark datasets. Additionally, we delve into several noteworthy research directions in NAS methods including one/two-stage NAS, one-shot NAS and joint hyperparameter with architecture optimization. We discussed how the search space size and complexity in NAS can vary depending on the specific problem being addressed. To conclude, we examine several open problems (SOTA problems) within current AutoML methods that assure further investigation in future research.",automl  automated machine learning  is an emerging field that aims to automate the process of building machine learning models  automl emerged to increase productivity and efficiency by automating as much as possible the inefficient work that occurs while repeating this process whenever machine learning is applied  in particular  research has been conducted for a long time on technologies that can effectively develop high quality models by minimizing the intervention of model developers in the process from data preprocessing to algorithm selection and tuning  in this semantic review research  we summarize the data processing requirements for automl approaches and provide a detailed explanation  we place greater emphasis on neural architecture search  nas  as it currently represents a highly popular sub topic within the field of automl  nas methods use machine learning algorithms to search through a large space of possible architectures and find the one that performs best on a given task  we provide a summary of the performance achieved by representative nas algorithms on the cifar     cifar      imagenet and well known benchmark datasets  additionally  we delve into several noteworthy research directions in nas methods including one two stage nas  one shot nas and joint hyperparameter with architecture optimization  we discussed how the search space size and complexity in nas can vary depending on the specific problem being addressed  to conclude  we examine several open problems  sota problems  within current automl methods that assure further investigation in future research ,3.3781657,7.100396,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
1D convolutional neural networks and applications: A survey,"During the last decade, Convolutional Neural Networks (CNNs) have become the de facto standard for various Computer Vision and Machine Learning operations. CNNs are feed-forward Artificial Neural Networks (ANNs) with alternating convolutional and subsampling layers. Deep 2D CNNs with many hidden layers and millions of parameters have the ability to learn complex objects and patterns providing that they can be trained on a massive size visual database with ground-truth labels. With a proper training, this unique ability makes them the primary tool for various engineering applications for 2D signals such as images and video frames. Yet, this may not be a viable option in numerous applications over 1D signals especially when the training data is scarce or application specific. To address this issue, 1D CNNs have recently been proposed and immediately achieved the state-of-the-art performance levels in several applications such as personalized biomedical data classification and early diagnosis, structural health monitoring, anomaly detection and identification in power electronics and electrical motor fault detection. Another major advantage is that a real-time and low-cost hardware implementation is feasible due to the simple and compact configuration of 1D CNNs that perform only 1D convolutions (scalar multiplications and additions). This paper presents a comprehensive review of the general architecture and principals of 1D CNNs along with their major engineering applications, especially focused on the recent progress in this field. Their state-of-the-art performance is highlighted concluding with their unique properties. The benchmark datasets and the principal 1D CNN software used in those applications are also publicly shared in a dedicated website. While there has not been a paper on the review of 1D CNNs and its applications in the literature, this paper fulfills this gap.",during the last decade  convolutional neural networks  cnns  have become the de facto standard for various computer vision and machine learning operations  cnns are feed forward artificial neural networks  anns  with alternating convolutional and subsampling layers  deep  d cnns with many hidden layers and millions of parameters have the ability to learn complex objects and patterns providing that they can be trained on a massive size visual database with ground truth labels  with a proper training  this unique ability makes them the primary tool for various engineering applications for  d signals such as images and video frames  yet  this may not be a viable option in numerous applications over  d signals especially when the training data is scarce or application specific  to address this issue   d cnns have recently been proposed and immediately achieved the state of the art performance levels in several applications such as personalized biomedical data classification and early diagnosis  structural health monitoring  anomaly detection and identification in power electronics and electrical motor fault detection  another major advantage is that a real time and low cost hardware implementation is feasible due to the simple and compact configuration of  d cnns that perform only  d convolutions  scalar multiplications and additions   this paper presents a comprehensive review of the general architecture and principals of  d cnns along with their major engineering applications  especially focused on the recent progress in this field  their state of the art performance is highlighted concluding with their unique properties  the benchmark datasets and the principal  d cnn software used in those applications are also publicly shared in a dedicated website  while there has not been a paper on the review of  d cnns and its applications in the literature  this paper fulfills this gap ,3.4575365,6.84904,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Integration and Deployment of Model Serving Framework at Production Scale,"With the help of machine learning systems, we can examine data, learn from that data, and make decisions. Nowadays machine learning models have become more relevant to various use cases, but to manage them, especially if numerous, is a challenging task. For this reason, several Machine Learning Operations (MLOps) tools have been developed. These tools are the main platforms, hosting the full machine learning process lifecycle, starting with data management, and ending with model versioning and deployment. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",with the help of machine learning systems  we can examine data  learn from that data  and make decisions  nowadays machine learning models have become more relevant to various use cases  but to manage them  especially if numerous  is a challenging task  for this reason  several machine learning operations  mlops  tools have been developed  these tools are the main platforms  hosting the full machine learning process lifecycle  starting with data management  and ending with model versioning and deployment          the author s   under exclusive license to springer nature switzerland ag ,8.724186,6.8834553,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
"Digital Strategy, Machine Learning, and Industry Survey of MLOps","As part of a digital strategy, machine learning (ML) has become a common toolset and capability across many businesses. However, the operational aspects of machine learning (MLOps) are often overlooked for ML projects until they are already installed and being executed in the business environment. This chapter provides a review of MLOps products and vendors to give data scientists the ability to set up the appropriate ML infrastructure in a proactive manner. © 2023 by World Scientific Publishing Co. Pte. Ltd.",as part of a digital strategy  machine learning  ml  has become a common toolset and capability across many businesses  however  the operational aspects of machine learning  mlops  are often overlooked for ml projects until they are already installed and being executed in the business environment  this chapter provides a review of mlops products and vendors to give data scientists the ability to set up the appropriate ml infrastructure in a proactive manner         by world scientific publishing co  pte  ltd ,11.202493,7.2818837,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
TOWARDS EXPLAINABLE MACHINE LEARNING OPERATIONS (MLOPS),"In the dynamically expanding AI applications, there is a need for an effective operational framework for managing ever increasing number of predictive models. A new field of Machine Learning Operations (MLOps) has recently emerged to address the issue of efficient operations and management of machine learning models. However, enterprises still struggle to develop effective MLOps systems due to lack of expertise and limited experience in AI operational needs. Attempts of an ad-hoc administration of ML algorithms have not been successful to deal with the challenges of fast proliferation of AI models. At the same time, existing concepts of MLOps frameworks don't adequately address an important question of accurate machine learning models diagnostics and explainability. In this reflection paper, we review commonly used MLOps approaches and explainability methods and suggest novel methods to address challenges of current model explainability methods. We discuss the need for university curriculum to address the issues facing management of AI models, their diagnostics and explainability. © ICT 2023.All rights reserved.",in the dynamically expanding ai applications  there is a need for an effective operational framework for managing ever increasing number of predictive models  a new field of machine learning operations  mlops  has recently emerged to address the issue of efficient operations and management of machine learning models  however  enterprises still struggle to develop effective mlops systems due to lack of expertise and limited experience in ai operational needs  attempts of an ad hoc administration of ml algorithms have not been successful to deal with the challenges of fast proliferation of ai models  at the same time  existing concepts of mlops frameworks don t adequately address an important question of accurate machine learning models diagnostics and explainability  in this reflection paper  we review commonly used mlops approaches and explainability methods and suggest novel methods to address challenges of current model explainability methods  we discuss the need for university curriculum to address the issues facing management of ai models  their diagnostics and explainability    ict      all rights reserved ,11.347173,6.576658,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
MLOps Approach for Automatic Segmentation of Biomedical Images,"When using artificial intelligence systems for processing medical images, a large amount of software libraries, data and cloud computing is required. Implementing deep learning elements in CAD is a complex process and applying DevOps can help speed up this process. The implementation of DevOps approaches in the field of machine learning differs from the operations with standard programs; therefore the development of MLOps approaches to the implementation of deep learning elements for the analysis of biomedical images is an actual task. The developed pipeline allows scientists and specialists to use the findings in this article to launch projects based on machine learning and focus on model development rather than the process of setting up the environment. This paper provides examples of improved MLOps pipelines that can be used for solving problems of automatic image segmentation and evaluating the quantitative characteristics of microobjects. © 2023 Copyright for this paper by its authors.",when using artificial intelligence systems for processing medical images  a large amount of software libraries  data and cloud computing is required  implementing deep learning elements in cad is a complex process and applying devops can help speed up this process  the implementation of devops approaches in the field of machine learning differs from the operations with standard programs  therefore the development of mlops approaches to the implementation of deep learning elements for the analysis of biomedical images is an actual task  the developed pipeline allows scientists and specialists to use the findings in this article to launch projects based on machine learning and focus on model development rather than the process of setting up the environment  this paper provides examples of improved mlops pipelines that can be used for solving problems of automatic image segmentation and evaluating the quantitative characteristics of microobjects         copyright for this paper by its authors ,9.768206,5.222363,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Smart and Fault-Tolerant Multisensor Fusion Model for UCM Methane Hazard Monitoring Based on Belief Divergence Backed DS Filter and Hybrid CNN-LSTM Classifier,"The underground coal mine (UCM) dynamic and complex environment impose various hazards that significantly affect the mining production and safety of the personnel. Flammable and poisonous gases significantly contribute to many fatal accidents. This study proposes a real-time-based reliable gas hazard monitoring system using multisensor data fusion. A hybrid of CNN-LSTM-based deep neural network (HCLM) is developed to serve the purpose. Due to the challenging environment of the UCM, sensor malfunctioning is inevitable and severely affects the performance of HCLM. A novel front-end filter (FEF) is developed based on Damper Shafer's (DS) theory and belief divergence-based weighted credibility metric to overcome the drawback of HCLM. In the laboratory trial, it is observed that the hazard classification accuracy of HCLM for the faulty node scenarios is 85%. In contrast, the accuracy of the HCLM integrated with FEF is maintained at 98%, even for multiple faulty node cases. Another novelty of this study is the tinyML implementation of the proposed model. Due to UCM's inherent complexities and challenges, traditional wireless communications face operational difficulties. Hence, a cloud-based machine learning operation is not a feasible option in UCM. Hence, using the concept of tinyML, the proposed model is directly deployed on a microcontroller near the data sources, thereby reducing network latency and security issues.  © 2014 IEEE.",the underground coal mine  ucm  dynamic and complex environment impose various hazards that significantly affect the mining production and safety of the personnel  flammable and poisonous gases significantly contribute to many fatal accidents  this study proposes a real time based reliable gas hazard monitoring system using multisensor data fusion  a hybrid of cnn lstm based deep neural network  hclm  is developed to serve the purpose  due to the challenging environment of the ucm  sensor malfunctioning is inevitable and severely affects the performance of hclm  a novel front end filter  fef  is developed based on damper shafer s  ds  theory and belief divergence based weighted credibility metric to overcome the drawback of hclm  in the laboratory trial  it is observed that the hazard classification accuracy of hclm for the faulty node scenarios is      in contrast  the accuracy of the hclm integrated with fef is maintained at      even for multiple faulty node cases  another novelty of this study is the tinyml implementation of the proposed model  due to ucm s inherent complexities and challenges  traditional wireless communications face operational difficulties  hence  a cloud based machine learning operation is not a feasible option in ucm  hence  using the concept of tinyml  the proposed model is directly deployed on a microcontroller near the data sources  thereby reducing network latency and security issues          ieee ,4.8808713,5.1493883,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Automated Data and ML Pipelines to Accelerate Subsurface Digitalization,"Understanding the subsurface is key to deliver reliable well construction and efficient production operations. Embracing digitalization in subsurface helps to improve accuracy, reduce risks, and accelerate cycle time. Crew change, availability of high-precision data sets and increased pressures on margins imply that human interpreters need to be supplemented by automation and machine learning (ML) driven insights through digital techniques. ML solutions can accelerate interpretation to modeling to reservoir engineering workflows by optimizing first break picking in seismic processing, improving fault detection, stratigraphic interpretation in seismic and reconstructing logs and detect outliers in wellbore. Scalable machine learning requires reliable data products, but operators are fraught with data wrangling challenges across sources without lineage or context. Domain users cannot collaborate well with data scientists further impeding ML models from moving from innovation to production. New wellbore and seismic data can be aggregated across vendors, data stores and contextualized to reliable data products by automated DataOps pipelines. Domain experts can understand these data products and collaboratively work with data scientists on an intuitive ML workbench democratizing the ML craft and providing first principal guard-rails. An MLOps pipeline can manage model versions and continuously deliver qualified ML models into elastic compute-clusters for reliable result prediction on new datasets. Such a digital system can account for ML models drift recalibration and regional localization ensuring the solution remains operational and reliable over time. Reliable data products through DataOps pipelines feeding contextualized information to ML models deployed and operationalized using MLOps in the cloud, result in efficient and intelligent solutions that optimize subsurface processing, interpretation, and modeling workflows. Copyright 2023, Latin America Unconventional Resources Technology Conference (LA URTeC).",understanding the subsurface is key to deliver reliable well construction and efficient production operations  embracing digitalization in subsurface helps to improve accuracy  reduce risks  and accelerate cycle time  crew change  availability of high precision data sets and increased pressures on margins imply that human interpreters need to be supplemented by automation and machine learning  ml  driven insights through digital techniques  ml solutions can accelerate interpretation to modeling to reservoir engineering workflows by optimizing first break picking in seismic processing  improving fault detection  stratigraphic interpretation in seismic and reconstructing logs and detect outliers in wellbore  scalable machine learning requires reliable data products  but operators are fraught with data wrangling challenges across sources without lineage or context  domain users cannot collaborate well with data scientists further impeding ml models from moving from innovation to production  new wellbore and seismic data can be aggregated across vendors  data stores and contextualized to reliable data products by automated dataops pipelines  domain experts can understand these data products and collaboratively work with data scientists on an intuitive ml workbench democratizing the ml craft and providing first principal guard rails  an mlops pipeline can manage model versions and continuously deliver qualified ml models into elastic compute clusters for reliable result prediction on new datasets  such a digital system can account for ml models drift recalibration and regional localization ensuring the solution remains operational and reliable over time  reliable data products through dataops pipelines feeding contextualized information to ml models deployed and operationalized using mlops in the cloud  result in efficient and intelligent solutions that optimize subsurface processing  interpretation  and modeling workflows  copyright       latin america unconventional resources technology conference  la urtec  ,10.062106,7.5574746,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Machine Learning Models Monitoring in MLOps Context: Metrics and Tools,"In many machine learning projects, the lack of an effective monitoring system is a worrying issue. This leads to a series of challenges and risks that compromise the quality, reliability and sustainability of models deployed in production. As Machine Learning gains importance in various fields, poorly implemented monitoring represents a major obstacle to realizing its full potential. This article presents a comprehensive guide of machine learning models monitoring metrics and tool used in the MLOps context. The monitoring of metrics is important to evaluate and validate the performance of a machine-learning model, not only throughout the development phase but also during its deployment in the production environment. It enables real-time data to be collected on various metrics. The purpose of monitoring in MLOps context is to identify potential issues and adjustments made accordingly, guaranteeing consistent model quality and reliability. This article provides a comprehensive guide that introduces and explains a wide range of metrics used for continuous monitoring of ML systems at various stages of the MLOps lifecycle. Additionally, it presents a comparative analysis of available monitoring tools, enabling organizations to optimize their performance and ensure the seamless deployment of their machine learning applications. In essence, it underscores the critical importance of continuous monitoring and tailored metrics for ensuring the success and reliability of machine learning systems. © 2023 by the authors of this article. Published under CC-BY.",in many machine learning projects  the lack of an effective monitoring system is a worrying issue  this leads to a series of challenges and risks that compromise the quality  reliability and sustainability of models deployed in production  as machine learning gains importance in various fields  poorly implemented monitoring represents a major obstacle to realizing its full potential  this article presents a comprehensive guide of machine learning models monitoring metrics and tool used in the mlops context  the monitoring of metrics is important to evaluate and validate the performance of a machine learning model  not only throughout the development phase but also during its deployment in the production environment  it enables real time data to be collected on various metrics  the purpose of monitoring in mlops context is to identify potential issues and adjustments made accordingly  guaranteeing consistent model quality and reliability  this article provides a comprehensive guide that introduces and explains a wide range of metrics used for continuous monitoring of ml systems at various stages of the mlops lifecycle  additionally  it presents a comparative analysis of available monitoring tools  enabling organizations to optimize their performance and ensure the seamless deployment of their machine learning applications  in essence  it underscores the critical importance of continuous monitoring and tailored metrics for ensuring the success and reliability of machine learning systems         by the authors of this article  published under cc by ,10.255529,6.3022556,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
A Novel Homomorphic Encryption and Consortium Blockchain-Based Hybrid Deep Learning Model for Industrial Internet of Medical Things,"Securing Electronic Medical Records (EMRs) is one of the most critical applications of cryptography over the Internet due to the value and importance of data contained in such EMRs. Although blockchain-based healthcare systems can provide security, privacy, and immutability to EMRs, several outstanding security and latency issues are associated with existing schemes. For example, some researchers have used the blockchain as a storage tool which increases delay and adversely affects the blockchain performance since it stores a copy of each transaction. A distributed ledger also requires appropriate space and computational power with increased data size. In addition, existing healthcare-based approaches usually rely on centralized servers connected to clouds, which are vulnerable to denial of service (DoS), distributed DoS (DDoS), and collusion attacks. This paper proposes a novel hybrid-deep learning-based homomorphic encryption (HE) model for the Industrial Internet of Medical Things (IIoMT) to cope with such challenges using a consortium blockchain. Integrating HE with the proposed IIoMT system is a vital contribution of this work. The use of HE while outsourcing to the cloud the storage provides a unique facility to perform any statistical and machine learning operation on the encrypted EMR data, hence providing resistance to collusion and phishing attacks. Our proposed model uses a pre-trained hybrid deep learning model in the cloud and deploys the trained model into blockchain-based edge devices in order to classify and train local models using EMRs. This is further conditioned on the private data of each edge and IoT device connected with the consortium blockchain. All local models obtained are aggregated to the cloud to update a global model, which is finally disseminated to the edge nodes. Our proposed approach provides more privacy and security than conventional models and can deliver high efficiency and low end-to-end latency for users. Comparative simulation analysis with state-of-the-art approaches is carried out using benchmark performance metrics, which show that our proposed model provides enhanced security, efficiency, and transparency. © 2013 IEEE.",securing electronic medical records  emrs  is one of the most critical applications of cryptography over the internet due to the value and importance of data contained in such emrs  although blockchain based healthcare systems can provide security  privacy  and immutability to emrs  several outstanding security and latency issues are associated with existing schemes  for example  some researchers have used the blockchain as a storage tool which increases delay and adversely affects the blockchain performance since it stores a copy of each transaction  a distributed ledger also requires appropriate space and computational power with increased data size  in addition  existing healthcare based approaches usually rely on centralized servers connected to clouds  which are vulnerable to denial of service  dos   distributed dos  ddos   and collusion attacks  this paper proposes a novel hybrid deep learning based homomorphic encryption  he  model for the industrial internet of medical things  iiomt  to cope with such challenges using a consortium blockchain  integrating he with the proposed iiomt system is a vital contribution of this work  the use of he while outsourcing to the cloud the storage provides a unique facility to perform any statistical and machine learning operation on the encrypted emr data  hence providing resistance to collusion and phishing attacks  our proposed model uses a pre trained hybrid deep learning model in the cloud and deploys the trained model into blockchain based edge devices in order to classify and train local models using emrs  this is further conditioned on the private data of each edge and iot device connected with the consortium blockchain  all local models obtained are aggregated to the cloud to update a global model  which is finally disseminated to the edge nodes  our proposed approach provides more privacy and security than conventional models and can deliver high efficiency and low end to end latency for users  comparative simulation analysis with state of the art approaches is carried out using benchmark performance metrics  which show that our proposed model provides enhanced security  efficiency  and transparency         ieee ,6.564563,7.2814693,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
An Adaptable and Unsupervised TinyML Anomaly Detection System for Extreme Industrial Environments †,"Industrial assets often feature multiple sensing devices to keep track of their status by monitoring certain physical parameters. These readings can be analyzed with machine learning (ML) tools to identify potential failures through anomaly detection, allowing operators to take appropriate corrective actions. Typically, these analyses are conducted on servers located in data centers or the cloud. However, this approach increases system complexity and is susceptible to failure in cases where connectivity is unavailable. Furthermore, this communication restriction limits the approach’s applicability in extreme industrial environments where operating conditions affect communication and access to the system. This paper proposes and evaluates an end-to-end adaptable and configurable anomaly detection system that uses the Internet of Things (IoT), edge computing, and Tiny-MLOps methodologies in an extreme industrial environment such as submersible pumps. The system runs on an IoT sensing Kit, based on an ESP32 microcontroller and MicroPython firmware, located near the data source. The processing pipeline on the sensing device collects data, trains an anomaly detection model, and alerts an external gateway in the event of an anomaly. The anomaly detection model uses the isolation forest algorithm, which can be trained on the microcontroller in just 1.2 to 6.4 s and detect an anomaly in less than 16 milliseconds with an ensemble of 50 trees and 80 KB of RAM. Additionally, the system employs blockchain technology to provide a transparent and irrefutable repository of anomalies. © 2023 by the authors.",industrial assets often feature multiple sensing devices to keep track of their status by monitoring certain physical parameters  these readings can be analyzed with machine learning  ml  tools to identify potential failures through anomaly detection  allowing operators to take appropriate corrective actions  typically  these analyses are conducted on servers located in data centers or the cloud  however  this approach increases system complexity and is susceptible to failure in cases where connectivity is unavailable  furthermore  this communication restriction limits the approach s applicability in extreme industrial environments where operating conditions affect communication and access to the system  this paper proposes and evaluates an end to end adaptable and configurable anomaly detection system that uses the internet of things  iot   edge computing  and tiny mlops methodologies in an extreme industrial environment such as submersible pumps  the system runs on an iot sensing kit  based on an esp   microcontroller and micropython firmware  located near the data source  the processing pipeline on the sensing device collects data  trains an anomaly detection model  and alerts an external gateway in the event of an anomaly  the anomaly detection model uses the isolation forest algorithm  which can be trained on the microcontroller in just     to     s and detect an anomaly in less than    milliseconds with an ensemble of    trees and    kb of ram  additionally  the system employs blockchain technology to provide a transparent and irrefutable repository of anomalies         by the authors ,3.6432805,5.9064846,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Simulated Annealing,"Simulated annealing (SA) is a well-known local search metaheuristic for finding high-quality solutions to both discrete and continuous optimization problems. The algorithm was first proposed and used in statistical mechanics by Metropolis et al. (J Chem Phys 21:1087-1092, 1953). Yet, not until Kirkpatrick et al. (Science 220:671-680, 1983) and Cerny (J Optim Theory Appl 45:41–52, 1985) was SA implemented as a heuristic for a notoriously hard combinatorial optimization problem – the traveling salesman problem. Since then, SA has been successfully applied across a broad range of application areas such as finance, machine learning, operations research, etc., where the associated optimization problems can be computationally intractable for large problem instances. In these situations, SA is a serious contender as a convenient, yet effective, optimization tool as it requires no knowledge of the problem structure. Indeed, the key advantage of SA is in its simplicity, which facilitates quick implementation for solving many real-life applications. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",simulated annealing  sa  is a well known local search metaheuristic for finding high quality solutions to both discrete and continuous optimization problems  the algorithm was first proposed and used in statistical mechanics by metropolis et al   j chem phys                      yet  not until kirkpatrick et al   science                    and cerny  j optim theory appl                 was sa implemented as a heuristic for a notoriously hard combinatorial optimization problem   the traveling salesman problem  since then  sa has been successfully applied across a broad range of application areas such as finance  machine learning  operations research  etc   where the associated optimization problems can be computationally intractable for large problem instances  in these situations  sa is a serious contender as a convenient  yet effective  optimization tool as it requires no knowledge of the problem structure  indeed  the key advantage of sa is in its simplicity  which facilitates quick implementation for solving many real life applications    the author s   under exclusive license to springer nature switzerland ag      ,2.5709856,7.7618284,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Integrated MLOps and EEG techniques for enhanced crime detection and prevention,"The use of machine learning and artificial intelligence in crime detection has gained significant attention in recent years. This research paper explores the potential of MLOps techniques in identifying criminal behavior through the analysis of vehicle plate numbers (Tripathi et al 2021), person detection, and object behavior detection. This paper presents a literature review of studies that have investigated the use of MLOps in crime detection and highlight the potential of these techniques to be used in criminal investigations. Specifically, the use of machine learning models for vehicle plate number recognition, person detection through image and video analysis, and object behavior detection through image and video analysis has been discussed. The paper presents a framework for integrating MLOps techniques into criminal investigations, which involves a combination of data acquisition, data preprocessing, model development, model training and testing, and deployment. Additionally, the discussion includes the ethical implications of using MLOps techniques in criminal investigations and highlights the need for transparency and fairness in model development and deployment. The detection and prevention of criminal behavior is a critical issue for society. In recent years, there has been growing interest in the use of electroencephalogram (EEG) techniques to detect and predict criminal behavior. This research paper explores the potential of EEG techniques as a means of detecting crime by analyzing brainwave activity. Specifically, this paper examines the use of alpha and beta waves in identifying deceptive or abnormal behavior (Xie et al 2022). The paper presents a literature review of studies that have investigated the relationship between EEG signals and criminal behavior and highlight the potential of these techniques to be used in criminal investigations (Xie et al 2022). Furthermore, a framework is proposed for integrating EEG techniques into criminal investigations, which involves a combination of data acquisition, analysis, and interpretation. Finally, the ethical implications of using EEG techniques in criminal investigations and the need for further research in this area have been discussed. © 2024 Multidiscip. Sci. J. All rights reserved.",the use of machine learning and artificial intelligence in crime detection has gained significant attention in recent years  this research paper explores the potential of mlops techniques in identifying criminal behavior through the analysis of vehicle plate numbers  tripathi et al        person detection  and object behavior detection  this paper presents a literature review of studies that have investigated the use of mlops in crime detection and highlight the potential of these techniques to be used in criminal investigations  specifically  the use of machine learning models for vehicle plate number recognition  person detection through image and video analysis  and object behavior detection through image and video analysis has been discussed  the paper presents a framework for integrating mlops techniques into criminal investigations  which involves a combination of data acquisition  data preprocessing  model development  model training and testing  and deployment  additionally  the discussion includes the ethical implications of using mlops techniques in criminal investigations and highlights the need for transparency and fairness in model development and deployment  the detection and prevention of criminal behavior is a critical issue for society  in recent years  there has been growing interest in the use of electroencephalogram  eeg  techniques to detect and predict criminal behavior  this research paper explores the potential of eeg techniques as a means of detecting crime by analyzing brainwave activity  specifically  this paper examines the use of alpha and beta waves in identifying deceptive or abnormal behavior  xie et al        the paper presents a literature review of studies that have investigated the relationship between eeg signals and criminal behavior and highlight the potential of these techniques to be used in criminal investigations  xie et al        furthermore  a framework is proposed for integrating eeg techniques into criminal investigations  which involves a combination of data acquisition  analysis  and interpretation  finally  the ethical implications of using eeg techniques in criminal investigations and the need for further research in this area have been discussed         multidiscip  sci  j  all rights reserved ,7.0061917,5.0837283,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
A Dataflow-Oriented Approach for Machine-Learning-Powered Internet of Things Applications,"The rise of the Internet of Things (IoT) has led to an exponential increase in data generated by connected devices. Machine Learning (ML) has emerged as a powerful tool to analyze these data and enable intelligent IoT applications. However, developing and managing ML applications in the decentralized Cloud-to-Things continuum is extremely complex. This paper proposes Zenoh-Flow, a dataflow programming framework that supports the implementation of End-to-End (E2E) ML pipelines in a fully decentralized manner and abstracted from communication aspects. Thus, it simplifies the development and upgrade process of the next-generation ML-powered applications in the IoT domain. The proposed framework was demonstrated using a real-world use case, and the results showcased a significant improvement in overall performance and network usage compared to the original implementation. Additionally, other of its inherent benefits are a significant step towards developing efficient and scalable ML applications in the decentralized IoT ecosystem. © 2023 by the authors.",the rise of the internet of things  iot  has led to an exponential increase in data generated by connected devices  machine learning  ml  has emerged as a powerful tool to analyze these data and enable intelligent iot applications  however  developing and managing ml applications in the decentralized cloud to things continuum is extremely complex  this paper proposes zenoh flow  a dataflow programming framework that supports the implementation of end to end  e e  ml pipelines in a fully decentralized manner and abstracted from communication aspects  thus  it simplifies the development and upgrade process of the next generation ml powered applications in the iot domain  the proposed framework was demonstrated using a real world use case  and the results showcased a significant improvement in overall performance and network usage compared to the original implementation  additionally  other of its inherent benefits are a significant step towards developing efficient and scalable ml applications in the decentralized iot ecosystem         by the authors ,7.7427773,5.816249,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Centrality of AI Quality in MLOPs Lifecycle and Its Impact on the Adoption of AI/ML Solutions,"Despite the challenges around incorporating Artificial Intelligence into business processes, AI is revolutionizing the way companies are doing business. The biggest business and social challenge in the adoption of AI solutions is achieving the end users’ trust in the models and scaling prototypes to production ready models in an enterprise environment. Scaling trustworthy AI in a more transparent, responsible, and governed manner could facilitate widespread adoption of AI solutions in an enterprise environment. After conducting an extensive literature review on different aspects of AI quality, we have developed an integrated AI Quality-MLOps framework which enables the development and deployment of AI solutions in an enterprise environment. AI Quality is the center of the proposed framework, and it guides businesses towards putting a complete set of quality metrics, tests, approaches, and algorithms together to ensure conformance with business objectives. This approach improves the delivery efficiency of the solution both during the design and production phase while conforming to the regulatory guidelines adopted by an organization. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",despite the challenges around incorporating artificial intelligence into business processes  ai is revolutionizing the way companies are doing business  the biggest business and social challenge in the adoption of ai solutions is achieving the end users  trust in the models and scaling prototypes to production ready models in an enterprise environment  scaling trustworthy ai in a more transparent  responsible  and governed manner could facilitate widespread adoption of ai solutions in an enterprise environment  after conducting an extensive literature review on different aspects of ai quality  we have developed an integrated ai quality mlops framework which enables the development and deployment of ai solutions in an enterprise environment  ai quality is the center of the proposed framework  and it guides businesses towards putting a complete set of quality metrics  tests  approaches  and algorithms together to ensure conformance with business objectives  this approach improves the delivery efficiency of the solution both during the design and production phase while conforming to the regulatory guidelines adopted by an organization          the author s   under exclusive license to springer nature switzerland ag ,11.460543,6.833431,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Three-dimensional evaluation of mandibular lingula: Comparisons of skeletal angle classifications and growth patterns,"Objectives: This study aimed to evaluate the position of the mandibular lingula (ML) in adult patients (aged between 18 and 35 years old) with different skeletal and growth patterns using cone-beam computed tomography (CBCT). Design: Cross-sectional. Setting: Dentistry department of University. Subjects: Subjects comprised CBCT images of 150 adult patients, including 300 rami. Methods and Materials: In total, 150 CBCT aged between 18 and 35 were selected and divided into three main groups of 50 samples based on their skeletal relationships (classes I, II and III). Patients were subdivided based on their growth pattern (vertical vs. horizontal), resulting in 25 samples per subgroup. Distances between the mandibular lingula and occlusal plane (ML-OP), sigmoid notch (ML-SN), external oblique ridge (ML-EOR), internal oblique ridge (ML-IOR), posterior border of the ramus (ML-PBR), inferior border of the ramus (ML-IBR), and horizontal and vertical distances to the mandibular foramen (ML-hMF and ML-vMF). One-way ANOVA variance analysis was employed to compare different angle classifications, and Bonferroni analysis was used for multiple comparisons. The Student's t-test was also used to compare growth patterns within each main group and genders within the subgroup. Results: The study revealed statistically significant differences in the position of the mandibular lingula between different angle classifications, growth patterns, and genders. Class II samples showed a more anterior position of the ML, whereas Class III samples displayed a more posterior position of the ML. Patients with horizontal growth patterns and Angle Class III had a more posteriorly positioned ML. Gender differences were observed, particularly in Class I and Class III classifications, suggesting that gender may influence the variability of ML position in these specific classifications. Conclusion: The position of the mandibular lingula showed high variability among individuals with different angle classifications, growth patterns and genders. © 2024 John Wiley & Sons A/S. Published by John Wiley & Sons Ltd.",objectives  this study aimed to evaluate the position of the mandibular lingula  ml  in adult patients  aged between    and    years old  with different skeletal and growth patterns using cone beam computed tomography  cbct   design  cross sectional  setting  dentistry department of university  subjects  subjects comprised cbct images of     adult patients  including     rami  methods and materials  in total      cbct aged between    and    were selected and divided into three main groups of    samples based on their skeletal relationships  classes i  ii and iii   patients were subdivided based on their growth pattern  vertical vs  horizontal   resulting in    samples per subgroup  distances between the mandibular lingula and occlusal plane  ml op   sigmoid notch  ml sn   external oblique ridge  ml eor   internal oblique ridge  ml ior   posterior border of the ramus  ml pbr   inferior border of the ramus  ml ibr   and horizontal and vertical distances to the mandibular foramen  ml hmf and ml vmf   one way anova variance analysis was employed to compare different angle classifications  and bonferroni analysis was used for multiple comparisons  the student s t test was also used to compare growth patterns within each main group and genders within the subgroup  results  the study revealed statistically significant differences in the position of the mandibular lingula between different angle classifications  growth patterns  and genders  class ii samples showed a more anterior position of the ml  whereas class iii samples displayed a more posterior position of the ml  patients with horizontal growth patterns and angle class iii had a more posteriorly positioned ml  gender differences were observed  particularly in class i and class iii classifications  suggesting that gender may influence the variability of ml position in these specific classifications  conclusion  the position of the mandibular lingula showed high variability among individuals with different angle classifications  growth patterns and genders         john wiley   sons a s  published by john wiley   sons ltd ,4.6221933,2.9705987,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Jet Energy Calibration with Deep Learning as a Kubeflow Pipeline,"Precise measurements of the energy of jets emerging from particle collisions at the LHC are essential for a vast majority of physics searches at the CMS experiment. In this study, we leverage well-established deep learning models for point clouds and CMS open data to improve the energy calibration of particle jets. To enable production-ready machine learning based jet energy calibration an end-to-end pipeline is built on the Kubeflow cloud platform. The pipeline allowed us to scale up our hyperparameter tuning experiments on cloud resources, and serve optimal models as REST endpoints. We present the results of the parameter tuning process and analyze the performance of the served models in terms of inference time and overhead, providing insights for future work in this direction. The study also demonstrates improvements in both flavor dependence and resolution of the energy response when compared to the standard jet energy corrections baseline. © 2023, The Author(s).",precise measurements of the energy of jets emerging from particle collisions at the lhc are essential for a vast majority of physics searches at the cms experiment  in this study  we leverage well established deep learning models for point clouds and cms open data to improve the energy calibration of particle jets  to enable production ready machine learning based jet energy calibration an end to end pipeline is built on the kubeflow cloud platform  the pipeline allowed us to scale up our hyperparameter tuning experiments on cloud resources  and serve optimal models as rest endpoints  we present the results of the parameter tuning process and analyze the performance of the served models in terms of inference time and overhead  providing insights for future work in this direction  the study also demonstrates improvements in both flavor dependence and resolution of the energy response when compared to the standard jet energy corrections baseline          the author s  ,5.459323,6.56413,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Empowering Machine Learning Development with Service-Oriented Computing Principles,"Despite software industries’ successful utilization of Service-Oriented Computing (SOC) to streamline software development, machine learning (ML) development has yet to fully integrate these practices. This disparity can be attributed to multiple factors, such as the unique challenges inherent to ML development and the absence of a unified framework for incorporating services into this process. In this paper, we shed light on the disparities between services-oriented computing and machine learning development. We propose “Everything as a Module” (XaaM), a framework designed to encapsulate every ML artifacts including models, code, data, and configurations as individual modules, to bridge this gap. We propose a set of additional steps that need to be taken to empower machine learning development using services-oriented computing via an architecture that facilitates efficient management and orchestration of complex ML systems. By leveraging the best practices of services-oriented computing, we believe that machine learning development can achieve a higher level of maturity, improve the efficiency of the development process, and ultimately, facilitate the more effective creation of machine learning applications. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.",despite software industries  successful utilization of service oriented computing  soc  to streamline software development  machine learning  ml  development has yet to fully integrate these practices  this disparity can be attributed to multiple factors  such as the unique challenges inherent to ml development and the absence of a unified framework for incorporating services into this process  in this paper  we shed light on the disparities between services oriented computing and machine learning development  we propose  everything as a module   xaam   a framework designed to encapsulate every ml artifacts including models  code  data  and configurations as individual modules  to bridge this gap  we propose a set of additional steps that need to be taken to empower machine learning development using services oriented computing via an architecture that facilitates efficient management and orchestration of complex ml systems  by leveraging the best practices of services oriented computing  we believe that machine learning development can achieve a higher level of maturity  improve the efficiency of the development process  and ultimately  facilitate the more effective creation of machine learning applications    the author s   under exclusive license to springer nature switzerland ag      ,7.8293896,7.121751,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Survey on Model Monitoring in NLP,"Model Monitoring is an operational stage which comes after model deployment in machine learning lifecycle. It includes monitoring ML models for changes like model performance degradation, resultant data drift, and concept drift, and ensuring that the developed model is maintaining an optimum level of performance. ML teams can use model performance metrics like accuracy, precision, recall to monitor the real time or live performance of production models. However, these metrics need ‘ground truth’ or labels for these real-time predictions. Although labels are always available in a training data set, they might not always be available in production for a given use case. In the absence of inputs or to complement the visibility of the performance metrics, monitoring live changes in production features and prediction distributions can be used as an indicator and troubleshooting tool for issues in performance. Proper model monitoring can help improve model performance, increase transparency, and ensure that models are deployed ethically and responsibly. We provide an overview of the importance of model monitoring in NLP and highlight some of the key techniques and tools used for this purpose. The main aim of this research will be to understand the capabilities of novel drift algorithms and how they can be used to automate the ML-OPS pipeline used in the industries. Monitoring NLP Models can save a lot of time and effort of data scientists. It will also help organizations in keeping their large language models to be more consumer friendly and ethical. © Grenze Scientific Society, 2023.",model monitoring is an operational stage which comes after model deployment in machine learning lifecycle  it includes monitoring ml models for changes like model performance degradation  resultant data drift  and concept drift  and ensuring that the developed model is maintaining an optimum level of performance  ml teams can use model performance metrics like accuracy  precision  recall to monitor the real time or live performance of production models  however  these metrics need  ground truth  or labels for these real time predictions  although labels are always available in a training data set  they might not always be available in production for a given use case  in the absence of inputs or to complement the visibility of the performance metrics  monitoring live changes in production features and prediction distributions can be used as an indicator and troubleshooting tool for issues in performance  proper model monitoring can help improve model performance  increase transparency  and ensure that models are deployed ethically and responsibly  we provide an overview of the importance of model monitoring in nlp and highlight some of the key techniques and tools used for this purpose  the main aim of this research will be to understand the capabilities of novel drift algorithms and how they can be used to automate the ml ops pipeline used in the industries  monitoring nlp models can save a lot of time and effort of data scientists  it will also help organizations in keeping their large language models to be more consumer friendly and ethical    grenze scientific society       ,9.975971,6.28219,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Toward Standardization and Automation of Data Science Projects: MLOps and Cloud Computing as Facilitators,"The significant increase in the amount of generated data provides potential for organizations to improve performance. Accordingly, Data Science (DS), which encompasses the methods to extract knowledge from data, has increased in popularity. Nevertheless, enterprises often fail to reap the benefits from data as they suffer from high failure rates in the conducted DS projects. Literature suggests that the main reason for the lack of success is shortcomings in the current pool of DS project management methodologies. Hence, new procedures for DS are required. Consequently, in this paper, the outline for a model for DS project standardization and automation is discussed. Following a summary of DS project challenges and success factors, the concept, which will incorporate MLOps and cloud technologies, and its individual components to address these issues are described on a high level. Therefore, the foundation for further research endeavors in this area is presented. Copyright © 2023 by SCITEPRESS - Science and Technology Publications, Lda.",the significant increase in the amount of generated data provides potential for organizations to improve performance  accordingly  data science  ds   which encompasses the methods to extract knowledge from data  has increased in popularity  nevertheless  enterprises often fail to reap the benefits from data as they suffer from high failure rates in the conducted ds projects  literature suggests that the main reason for the lack of success is shortcomings in the current pool of ds project management methodologies  hence  new procedures for ds are required  consequently  in this paper  the outline for a model for ds project standardization and automation is discussed  following a summary of ds project challenges and success factors  the concept  which will incorporate mlops and cloud technologies  and its individual components to address these issues are described on a high level  therefore  the foundation for further research endeavors in this area is presented  copyright        by scitepress   science and technology publications  lda ,11.075245,5.4271283,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
An Analysis of the Barriers Preventing the Implementation of MLOps,"The rapid improvements in machine learning (ML) and the increasing importance of ML models in numerous industries have resulted in the emergence of MLOps (Machine Learning Operations), a discipline focusing on efficiently managing and operationalising ML workflows. This exploratory study investigates the difficulties encountered when implementing MLOps within organisations and compares MLOps to DevOps. The study begins by conducting an SLR to identify the challenges mentioned in the literature. We then explain the results of conducting semi-structured interviews with 12 ML practitioners working across many industries, perform qualitative content analysis using grounded theory, and discuss findings. Findings are organised along four distinct dimensions: Organisational, Technical, Operational and Business challenges, which are explained in eleven different themes. Our findings show that MLOps has some challenges that overlap with DevOps as well as some specific only to MLOps, like the complexity of data and model. In our discussion, we summarize these challenges and suggest future recommendations. © 2024, IFIP International Federation for Information Processing.",the rapid improvements in machine learning  ml  and the increasing importance of ml models in numerous industries have resulted in the emergence of mlops  machine learning operations   a discipline focusing on efficiently managing and operationalising ml workflows  this exploratory study investigates the difficulties encountered when implementing mlops within organisations and compares mlops to devops  the study begins by conducting an slr to identify the challenges mentioned in the literature  we then explain the results of conducting semi structured interviews with    ml practitioners working across many industries  perform qualitative content analysis using grounded theory  and discuss findings  findings are organised along four distinct dimensions  organisational  technical  operational and business challenges  which are explained in eleven different themes  our findings show that mlops has some challenges that overlap with devops as well as some specific only to mlops  like the complexity of data and model  in our discussion  we summarize these challenges and suggest future recommendations          ifip international federation for information processing ,10.2410345,4.1566677,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
APPLICATION OF KUBEFLOW AS A UNIVERSAL APPROACH FOR THE DEVELOPMENT AND IMPLEMENTATION OF ARTIFICIAL INTELLIGENCE SYSTEMS,"An overview of the concept of machine learning and processes (Machine Learning and Operation, MLOps), which is a set of techniques for implementation and automatic continuous integration, as well as delivery to the production environment and model training, is made. The concept of MLOps was considered in terms of Kubeflow tools - a cloudnative open-source system running on the Kubernetes platform. The possibility of using modern MLOps solutions to improve the development processes of machine learning information systems has been studied. The results of the operation of the model in the Kubeflow arsenal have been checked using such improvement factors as speed of development, implementation of changes, reduction of time to search for problems, recovery after global interruptions, and decrease of the number of errors in the model. For practical analysis, a publicly available model was deployed in a Kubeflow cluster using the Seldon Core Serving application manifest. The conducted research showed that Kubeflow consists of a set of various open-source components that have a high level of integration with each other through the Kubernetes platform. At the same time, Kubeflow uses the Kubernetes pattern of operators for machine-learning objects extremely effectively. © (2006-2023) Asian Research Publishing Network (ARPN). All rights reserved.",an overview of the concept of machine learning and processes  machine learning and operation  mlops   which is a set of techniques for implementation and automatic continuous integration  as well as delivery to the production environment and model training  is made  the concept of mlops was considered in terms of kubeflow tools   a cloudnative open source system running on the kubernetes platform  the possibility of using modern mlops solutions to improve the development processes of machine learning information systems has been studied  the results of the operation of the model in the kubeflow arsenal have been checked using such improvement factors as speed of development  implementation of changes  reduction of time to search for problems  recovery after global interruptions  and decrease of the number of errors in the model  for practical analysis  a publicly available model was deployed in a kubeflow cluster using the seldon core serving application manifest  the conducted research showed that kubeflow consists of a set of various open source components that have a high level of integration with each other through the kubernetes platform  at the same time  kubeflow uses the kubernetes pattern of operators for machine learning objects extremely effectively                asian research publishing network  arpn   all rights reserved ,8.09094,3.995977,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Mobile advertisement campaigns for boosting in-store visits: A design framework and case study,"Brick-and-mortar retailers seek higher foot traffic in their stores to improve their sales opportunities. In this quest, location-based advertising on mobile devices has emerged as an important marketing tool for targeting potential customers. The design of such advertising campaigns is complex, and their effectiveness depends on the ability to collect and examine data that aids in targeting the right customers at the right time and place. We develop a campaign design framework that explicitly accounts for the costs of acquiring and utilizing targeting data and the heterogeneous effects of such data in affecting the performance outcomes of mobile advertising campaigns. We illustrate the application of our campaign design framework through a real-world case study of a mobile advertising campaign undertaken by a large global retail firm. Our findings suggest that the optimal set of attributes to use for effectively targeting the potential customers of a brick-and-mortar retail store varies with the distance between the customers' current locations and that of the store. As a result, mobile campaign design approaches that utilize all or a naive subset of data attributes for targeted advertising yield lower levels of return on investments, relative to our proposed approach. Based on our results, we discuss implications for the design and deployment of mobile advertising campaigns and for further research on targeted advertising. © 2023 Production and Operations Management Society.",brick and mortar retailers seek higher foot traffic in their stores to improve their sales opportunities  in this quest  location based advertising on mobile devices has emerged as an important marketing tool for targeting potential customers  the design of such advertising campaigns is complex  and their effectiveness depends on the ability to collect and examine data that aids in targeting the right customers at the right time and place  we develop a campaign design framework that explicitly accounts for the costs of acquiring and utilizing targeting data and the heterogeneous effects of such data in affecting the performance outcomes of mobile advertising campaigns  we illustrate the application of our campaign design framework through a real world case study of a mobile advertising campaign undertaken by a large global retail firm  our findings suggest that the optimal set of attributes to use for effectively targeting the potential customers of a brick and mortar retail store varies with the distance between the customers  current locations and that of the store  as a result  mobile campaign design approaches that utilize all or a naive subset of data attributes for targeted advertising yield lower levels of return on investments  relative to our proposed approach  based on our results  we discuss implications for the design and deployment of mobile advertising campaigns and for further research on targeted advertising         production and operations management society ,10.805861,5.3238516,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
"Machine learning (ML) as a service (MLaaS): Enhancing IoT with intelligence, adaptive online deep and reinforcement learning, model sharing, and zero-knowledge model verification","AI has changed our lives in many aspects, including the way we (as humans) interact with internet and computational devices, but also on way devices interact with us, and among them, in most of the processes of the industry and other socioeconomic domains, where machine learning (ML) based applications are getting increasing influence. Internet of Things (IoT) plays a key role in these process interactions, by providing contextual information that requires to be processed for extracting intelligence that would largely improve them. However, the delivery of ML-based applications for IoT domains faces the intrinsic complexity of ML operations, and the online interoperability with IoT devices. In this chapter, we present the IoT-NGIN ML as a service (MLaaS) platform, an MLOps platform devised for the delivery of intelligent applications for IoT. Its services for online deep learning (DL) training and inference, ML model conversion and sharing, and zero-knowledge model verification based on blockchain technology are also presented. © The Editor(s) (if applicable) and The Author(s) 2023. All rights reserved.",ai has changed our lives in many aspects  including the way we  as humans  interact with internet and computational devices  but also on way devices interact with us  and among them  in most of the processes of the industry and other socioeconomic domains  where machine learning  ml  based applications are getting increasing influence  internet of things  iot  plays a key role in these process interactions  by providing contextual information that requires to be processed for extracting intelligence that would largely improve them  however  the delivery of ml based applications for iot domains faces the intrinsic complexity of ml operations  and the online interoperability with iot devices  in this chapter  we present the iot ngin ml as a service  mlaas  platform  an mlops platform devised for the delivery of intelligent applications for iot  its services for online deep learning  dl  training and inference  ml model conversion and sharing  and zero knowledge model verification based on blockchain technology are also presented    the editor s   if applicable  and the author s        all rights reserved ,10.816894,5.3842416,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
How to lead R&D digital transformation in a chemical corporation,"We demonstrate how we lead Research & Development (R&D) digital transformation at Resonac Corporation (former Showa Denko K.K.), a chemical corporation. Successful data-driven R&D requires establishing data collection, storage, analysis, and decision-making processes and an Information Technology infrastructure to support them. We have established R&D data pipelines to collect experimental data using electronic lab notebooks. The collected data are automatically transformed into structured data and stored in a relational database. Machine learning models for predicting material properties are automatically generated based on the database and deployed on a web app. Material scientists can effortlessly search, visualize, and analyze data on Graphical User Interface. Machine learning model predictions are used for the forward and inverse design of novel materials. Machine Learning Operations for efficiently managing the machine learning models and the web app has also been introduced. Graphical abstract: [Figure not available: see fulltext.]. © 2023, The Author(s), under exclusive licence to The Materials Research Society.",we demonstrate how we lead research   development  r d  digital transformation at resonac corporation  former showa denko k k    a chemical corporation  successful data driven r d requires establishing data collection  storage  analysis  and decision making processes and an information technology infrastructure to support them  we have established r d data pipelines to collect experimental data using electronic lab notebooks  the collected data are automatically transformed into structured data and stored in a relational database  machine learning models for predicting material properties are automatically generated based on the database and deployed on a web app  material scientists can effortlessly search  visualize  and analyze data on graphical user interface  machine learning model predictions are used for the forward and inverse design of novel materials  machine learning operations for efficiently managing the machine learning models and the web app has also been introduced  graphical abstract   figure not available  see fulltext            the author s   under exclusive licence to the materials research society ,9.4470005,3.2988005,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
A Cross-Disciplinary Knowledge Management Framework for Artificial Intelligence in Business Projects,"This paper presents a knowledge management framework for designing, monitoring, and optimizing the business value of intelligent services using best practices from both management and machine learning engineering areas. The increasing interest in artificial intelligence has highlighted the difficulty of designing an appropriate business case and monitoring the real business value generated by such services due to the complexity of machine learning methods and techniques. Managers have proven frameworks for constructing key performance indicators, machine learning engineers have developed advanced methods and techniques for evaluating and monitoring Machine Learning (ML) models, and scientists have tested methods for empirically evaluating the added value of innovations. By leveraging the strengths of each discipline, the proposed framework enables managers, machine learning engineers, and scientists to efficiently work together and optimize the value of intelligent services during their lifecycle. We propose processes and procedures for creating, capturing, organizing, storing, sharing, and using knowledge in advanced machine learning projects. He also presents key machine learning methods and techniques for monitoring and optimizing the value of intelligent services over their lifecycle, including the adaptation of MLOps methodology for continuous monitoring, reinforcement learning for continuous improvement, and CausalML methods for identifying the root-causes of changes in the business value. These methods and techniques support knowledge management activities and help formulate a competency framework for team members and project stakeholders. We point out the potential of academic researchers and external advisors as catalyzers in such projects based on real-life implementation. He also proposes a method for designing the ML knowledge flywheel to ensure continuous knowledge transfer and improvement in the business-engineer-academy triangle. The approach is illustrated by a case study of the implementation of a marketing communication optimization system in a large, multinational financial company for more than 20 thousand customers in two European countries. Managers and machine learning engineers can implement the proposed knowledge management framework in various organizations for the efficient design, monitoring, and optimization of the business value of intelligent services. © 2023 Academic Conferences Limited. All rights reserved.",this paper presents a knowledge management framework for designing  monitoring  and optimizing the business value of intelligent services using best practices from both management and machine learning engineering areas  the increasing interest in artificial intelligence has highlighted the difficulty of designing an appropriate business case and monitoring the real business value generated by such services due to the complexity of machine learning methods and techniques  managers have proven frameworks for constructing key performance indicators  machine learning engineers have developed advanced methods and techniques for evaluating and monitoring machine learning  ml  models  and scientists have tested methods for empirically evaluating the added value of innovations  by leveraging the strengths of each discipline  the proposed framework enables managers  machine learning engineers  and scientists to efficiently work together and optimize the value of intelligent services during their lifecycle  we propose processes and procedures for creating  capturing  organizing  storing  sharing  and using knowledge in advanced machine learning projects  he also presents key machine learning methods and techniques for monitoring and optimizing the value of intelligent services over their lifecycle  including the adaptation of mlops methodology for continuous monitoring  reinforcement learning for continuous improvement  and causalml methods for identifying the root causes of changes in the business value  these methods and techniques support knowledge management activities and help formulate a competency framework for team members and project stakeholders  we point out the potential of academic researchers and external advisors as catalyzers in such projects based on real life implementation  he also proposes a method for designing the ml knowledge flywheel to ensure continuous knowledge transfer and improvement in the business engineer academy triangle  the approach is illustrated by a case study of the implementation of a marketing communication optimization system in a large  multinational financial company for more than    thousand customers in two european countries  managers and machine learning engineers can implement the proposed knowledge management framework in various organizations for the efficient design  monitoring  and optimization of the business value of intelligent services         academic conferences limited  all rights reserved ,7.780309,8.624189,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Diagnostic Performance Evaluation of Deep Learning-Based Medical Text Modelling to Predict Pulmonary Diseases from Unstructured Radiology Free-Text Reports,"The third most common cause of death worldwide is attributed to pulmonary diseases, making it imperative to diagnose them promptly. Radiology is a medical discipline that utilizes medical imaging to guide treatment. Radiologists prepare reports interpreting details and findings analysed from medical images. Radiology free-text reports are a rich source of textual information that can be exploited to enhance the efficacy of medical prognosis, treatment and research. Radiology reports exist in an unstructured format as are not suitable by themselves for mathematical computation or machine learning operations. Therefore, natural language processing (NLP) strategies are employed to convert unstructured natural language text into a structured format that can be fed into machine learning (ML) or deep learning (DL) models for information extraction. We propose a DL-based medical text modelling framework incorporating a knowledge base to predict pulmonary diseases from unstructured radiology free-text reports. We make detailed diagnostic performance evaluations of our proposed technique by comparing it with state-of-the-art NLP techniques on radiology free-text reports extracted from two medical institutions. The comprehensive analysis shows that the proposed model achieves superior results compared to existing state-of-the-art text modelling techniques. © 2023 Prague University of Economics and Business. All Rights Reserved.",the third most common cause of death worldwide is attributed to pulmonary diseases  making it imperative to diagnose them promptly  radiology is a medical discipline that utilizes medical imaging to guide treatment  radiologists prepare reports interpreting details and findings analysed from medical images  radiology free text reports are a rich source of textual information that can be exploited to enhance the efficacy of medical prognosis  treatment and research  radiology reports exist in an unstructured format as are not suitable by themselves for mathematical computation or machine learning operations  therefore  natural language processing  nlp  strategies are employed to convert unstructured natural language text into a structured format that can be fed into machine learning  ml  or deep learning  dl  models for information extraction  we propose a dl based medical text modelling framework incorporating a knowledge base to predict pulmonary diseases from unstructured radiology free text reports  we make detailed diagnostic performance evaluations of our proposed technique by comparing it with state of the art nlp techniques on radiology free text reports extracted from two medical institutions  the comprehensive analysis shows that the proposed model achieves superior results compared to existing state of the art text modelling techniques         prague university of economics and business  all rights reserved ,5.6643662,5.176195,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Artificial Intelligence Operating Model: A Proposal Framework for AI Operationalization and Deployment,"At the heart of the new enterprise, across all activities, is a decision factory governed by some kind of intelligence. Among the great promises of Artificial Intelligence (AI) is its ability to lead to a significant evolution in the amount of data received, processed, or generates by companies, particularly those with a digital connotation. To bring about dramatic changes, AI does not need to be science fiction but simply a new way of approaching computerization subjects whether in terms of design, development, or terms of expected results. It should be noted that traditional IT solutions present a form of AI called - Weak AI - while the AI that is the subject of much noise, hype, and promises of transformation and potential for growth is called - Strong AI -. This article aims to present, in a didactic way, a model called D2MO (For Data Ops, ML Ops, Model Ops, and AI Ops) allowing the company to operationalize, in a structured approach, AI subjects, activities, and projects. We target through this article to provide both IT and business experts with a new framework offering a perfect articulation between the different bricks and actors entering into the composition of an AI-based system thus allowing them to operate in harmony and an agile mode while taking advantage of this technology. © 2022 Mustapha Lahlali, Naoual Berbiche and Jamila El Alami. This open-access article is distributed under a Creative Commons Attribution (CC-BY) 4.0 license.",at the heart of the new enterprise  across all activities  is a decision factory governed by some kind of intelligence  among the great promises of artificial intelligence  ai  is its ability to lead to a significant evolution in the amount of data received  processed  or generates by companies  particularly those with a digital connotation  to bring about dramatic changes  ai does not need to be science fiction but simply a new way of approaching computerization subjects whether in terms of design  development  or terms of expected results  it should be noted that traditional it solutions present a form of ai called   weak ai   while the ai that is the subject of much noise  hype  and promises of transformation and potential for growth is called   strong ai    this article aims to present  in a didactic way  a model called d mo  for data ops  ml ops  model ops  and ai ops  allowing the company to operationalize  in a structured approach  ai subjects  activities  and projects  we target through this article to provide both it and business experts with a new framework offering a perfect articulation between the different bricks and actors entering into the composition of an ai based system thus allowing them to operate in harmony and an agile mode while taking advantage of this technology         mustapha lahlali  naoual berbiche and jamila el alami  this open access article is distributed under a creative commons attribution  cc by      license ,11.645933,6.6692023,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Application Of MLOps Practices For Biomedical Image Classification,"With active hardware development, the number of software machine learning-based systems has increased dramatically in all areas of human activity, in particular, in medicine. The use of machine learning elements in software systems requires the organization of a pipeline process of software development, testing, and support. The application of MLOps technologies will improve the quality and speed of system development, as well as simplify the process of adjusting the algorithm parameters to improve the system operation quality. The purpose of this work is to develop an MLOps pipeline that will consider all the necessary stages of software development based on machine learning algorithms for biomedical image processing. © 2022 Copyright for this paper by its authors.",with active hardware development  the number of software machine learning based systems has increased dramatically in all areas of human activity  in particular  in medicine  the use of machine learning elements in software systems requires the organization of a pipeline process of software development  testing  and support  the application of mlops technologies will improve the quality and speed of system development  as well as simplify the process of adjusting the algorithm parameters to improve the system operation quality  the purpose of this work is to develop an mlops pipeline that will consider all the necessary stages of software development based on machine learning algorithms for biomedical image processing         copyright for this paper by its authors ,7.191597,5.0549965,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
A language to define datasets for machine learning; [Un lenguaje para definir datasets para machine learning],[No abstract available], no abstract available ,8.851112,6.610253,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Productive Machine Learning Systems for Industry; [Produktive Machine-Learning-Systeme für die Industrie Notwendige Bausteine und Kompetenzen am Beispiel Predictive Maintenance],"Necessary Building Blocks and Competences Using the Example of Predictive Maintenance. The majority of machine learning projects currently being carried out in industry focus on the pilot phase and are not successfully transferred to productive status. The reason for this is that the prerequisites for the development and operation of a productive solution in industrial companies are often not known and therefore not given. Therefore, this article deals with the differences between machine learning pilot projects and productive systems. It also highlights how the use of MLOps and a suitable competence set-up can increase the probability that a pilot project will be successfully transferred to productive operation.  © 2022 Walter de Gruyter GmbH, Berlin/Boston, Germany.",necessary building blocks and competences using the example of predictive maintenance  the majority of machine learning projects currently being carried out in industry focus on the pilot phase and are not successfully transferred to productive status  the reason for this is that the prerequisites for the development and operation of a productive solution in industrial companies are often not known and therefore not given  therefore  this article deals with the differences between machine learning pilot projects and productive systems  it also highlights how the use of mlops and a suitable competence set up can increase the probability that a pilot project will be successfully transferred to productive operation          walter de gruyter gmbh  berlin boston  germany ,8.218689,4.933529,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Less is more: Simple algorithms for the minimum sum of squares clustering problem,"The clustering problem has many applications in machine learning, operations research and statistics. We propose three algorithms to create starting solutions for improvement algorithms for the minimum sum of squares clustering problem. We test the algorithms on 72 instances that were investigated in the literature. We found five new best known solutions and matched the best known solution for 66 of the remaining 67 instances. Thus, we are able to demonstrate that good starting solutions combined with a simple local search get results comparable with, and sometimes even better than, more sophisticated algorithms used in the literature.  © 2021 The Author(s) 2021. Published by Oxford University Press on behalf of the Institute of Mathematics and its Applications. All rights reserved.",the clustering problem has many applications in machine learning  operations research and statistics  we propose three algorithms to create starting solutions for improvement algorithms for the minimum sum of squares clustering problem  we test the algorithms on    instances that were investigated in the literature  we found five new best known solutions and matched the best known solution for    of the remaining    instances  thus  we are able to demonstrate that good starting solutions combined with a simple local search get results comparable with  and sometimes even better than  more sophisticated algorithms used in the literature          the author s        published by oxford university press on behalf of the institute of mathematics and its applications  all rights reserved ,2.6604877,7.826942,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Structural Analysis of Branch-and-Cut and the Learnability of Gomory Mixed Integer Cuts,"The incorporation of cutting planes within the branch-and-bound algorithm, known as branch-and-cut, forms the backbone of modern integer programming solvers. These solvers are the foremost method for solving discrete optimization problems and have a vast array of applications in machine learning, operations research, and many other fields. Choosing cutting planes effectively is a major research topic in the theory and practice of integer programming. We conduct a novel structural analysis of branch-and-cut that pins down how every step of the algorithm is affected by changes in the parameters defining the cutting planes added to an integer program. Our main application of this analysis is to derive sample complexity guarantees for using machine learning to determine which cutting planes to apply during branch-and-cut. These guarantees apply to infinite families of cutting planes, such as the family of Gomory mixed integer cuts, which are responsible for the main breakthrough speedups of integer programming solvers. We exploit geometric and combinatorial structure of branch-and-cut in our analysis, which provides a key missing piece for the recent generalization theory of branch-and-cut. © 2022 Neural information processing systems foundation. All rights reserved.",the incorporation of cutting planes within the branch and bound algorithm  known as branch and cut  forms the backbone of modern integer programming solvers  these solvers are the foremost method for solving discrete optimization problems and have a vast array of applications in machine learning  operations research  and many other fields  choosing cutting planes effectively is a major research topic in the theory and practice of integer programming  we conduct a novel structural analysis of branch and cut that pins down how every step of the algorithm is affected by changes in the parameters defining the cutting planes added to an integer program  our main application of this analysis is to derive sample complexity guarantees for using machine learning to determine which cutting planes to apply during branch and cut  these guarantees apply to infinite families of cutting planes  such as the family of gomory mixed integer cuts  which are responsible for the main breakthrough speedups of integer programming solvers  we exploit geometric and combinatorial structure of branch and cut in our analysis  which provides a key missing piece for the recent generalization theory of branch and cut         neural information processing systems foundation  all rights reserved ,2.5458863,7.7329483,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
"On the Adoption of Federated Machine Learning: Roles, Activities and Process Life Cycle","Federated Machine Learning is a promising approach for training machine learning models on decentralized data without the need for data centralization. Through a model-to-data approach, Federated Machine Learning yields huge potential from privacy by design to heavily reducing communication costs and offline usage. However, the implementation and management of Federated Machine Learning projects can be challenging, as it involves coordinating multiple parties across different stages of the project life cycle. We observed that Federated Machine Learning is missing clarity over the individual involved roles including their activities, interactions, dependencies, and responsibilities which are needed to establish governance and help practitioners operationalize Federated Machine Learning projects. We argue that a process model, which is closely aligned with established MLOps principles can provide this clarification. In this position paper, we make a case for the necessity of a role model to structure distinct roles, an activity model to understand the involvement and operations of each role, and an artifact model to demonstrate how artifacts are used and structured. Additionally, we argue, that a process model is needed to capture the dependencies and interactions between the roles, activities, and artifacts across the different stages of the life cycle. Furthermore, we describe our research approach and the current status of our ongoing research toward this goal. We believe that our proposed process model will provide a foundation for the governance of Federated Machine Learning projects, and enable practitioners to leverage the benefits of decentralized data computation. Copyright © 2023 by SCITEPRESS - Science and Technology Publications, Lda. Under CC license (CC BY-NC-ND 4.0)",federated machine learning is a promising approach for training machine learning models on decentralized data without the need for data centralization  through a model to data approach  federated machine learning yields huge potential from privacy by design to heavily reducing communication costs and offline usage  however  the implementation and management of federated machine learning projects can be challenging  as it involves coordinating multiple parties across different stages of the project life cycle  we observed that federated machine learning is missing clarity over the individual involved roles including their activities  interactions  dependencies  and responsibilities which are needed to establish governance and help practitioners operationalize federated machine learning projects  we argue that a process model  which is closely aligned with established mlops principles can provide this clarification  in this position paper  we make a case for the necessity of a role model to structure distinct roles  an activity model to understand the involvement and operations of each role  and an artifact model to demonstrate how artifacts are used and structured  additionally  we argue  that a process model is needed to capture the dependencies and interactions between the roles  activities  and artifacts across the different stages of the life cycle  furthermore  we describe our research approach and the current status of our ongoing research toward this goal  we believe that our proposed process model will provide a foundation for the governance of federated machine learning projects  and enable practitioners to leverage the benefits of decentralized data computation  copyright        by scitepress   science and technology publications  lda  under cc license  cc by nc nd     ,10.999309,5.4877753,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
"7th International Conference on Smart City Applications, SCA 2022","The proceedings contain 80 papers. The special focus in this conference is on Smart City Applications. The topics include: Using Practical Activities for Robotics E-Learning: Case of Study on Web-Based Robotics Remote Labs; smart Home and Machine Learning as a Sustainable Healthcare Solution: Review and Perspectives; MLOps: Overview of Current State and Future Directions; cloud Services for Smart Farming: A Case Study of the Veracruz Almond Crops in Portugal; nyon: A Ubiquitous Fall Detection Device for Elders; design of the Content Part of the Information System in Smart Cities from the Perspective of Regional Governments and Security of Residents; security Approaches for Smart Campus; assessing the Implementation of Smart Energy Efficient Street Lighting Projects Within Cities; environmental and Climate Risk Management in Public Procurement: A Proposed Decision Support Tool; marine and Climatic Impacts on the Hydrogeochemical Functioning of Lake Sidi Boughaba (Kenitra, North West, Morocco); Assessment of the Role of Micromobility in ITS by A’WOT Analysis; learning Healthcare Ecosystems for Equity in Health Service Provisioning and Delivery: Smart Cities and the Quintuple Aim; Comparative Study of Optimal Tuning PID Controller for Manipulator Robot; Real-Time Hand Gesture Recognition for Humanoid Robot Control Using Python CVZone; RobVRL@bs: Web-Based Application for Teaching Robotics; implementing Machine Learning-Based Simulation in Physics Virtual Laboratory; ALF - Ambient Assisted Living for Healthcare Framework Based on IoMT and Big Data; Leveraging Moroccan Arabic Sentiment Analysis Using AraBERT and QARIB; Evaluating Dimensionality Reduction Approaches on Erstwhile Hyperion and Newly Launched PRISMA Datasets; transfer Learning for Automated Melanoma Classification System: Data Augmentation; intelligent Multi-sensor Mobile System.",the proceedings contain    papers  the special focus in this conference is on smart city applications  the topics include  using practical activities for robotics e learning  case of study on web based robotics remote labs  smart home and machine learning as a sustainable healthcare solution  review and perspectives  mlops  overview of current state and future directions  cloud services for smart farming  a case study of the veracruz almond crops in portugal  nyon  a ubiquitous fall detection device for elders  design of the content part of the information system in smart cities from the perspective of regional governments and security of residents  security approaches for smart campus  assessing the implementation of smart energy efficient street lighting projects within cities  environmental and climate risk management in public procurement  a proposed decision support tool  marine and climatic impacts on the hydrogeochemical functioning of lake sidi boughaba  kenitra  north west  morocco   assessment of the role of micromobility in its by a wot analysis  learning healthcare ecosystems for equity in health service provisioning and delivery  smart cities and the quintuple aim  comparative study of optimal tuning pid controller for manipulator robot  real time hand gesture recognition for humanoid robot control using python cvzone  robvrl bs  web based application for teaching robotics  implementing machine learning based simulation in physics virtual laboratory  alf   ambient assisted living for healthcare framework based on iomt and big data  leveraging moroccan arabic sentiment analysis using arabert and qarib  evaluating dimensionality reduction approaches on erstwhile hyperion and newly launched prisma datasets  transfer learning for automated melanoma classification system  data augmentation  intelligent multi sensor mobile system ,7.5416856,5.4224,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
IDDM 2022 - Proceedings of the 5th International Conference on Informatics and Data-Driven Medicine,The proceedings contain 27 papers. The topics discussed include: simple neuro-fuzzy system with combined learning for pattern recognition under conditions of short training set in medical diagnostics tasks; appraisal of artificial intelligence for fall prevention fall risk assessment; modeling of small data with unsupervised generative ensemble learning; the structure of the blockchain-based multi-agent system for secure management of medical information; evaluating autonomous-energy-harvesting device lifetime for the Internet of medical things with a petri net formulation considering battery SoH; application Of MLOps practices for biomedical image classification; impact of Russian war on COVID-19 dynamics in Germany: the simulation study by statistical machine learning; and a data-driven approach for neonatal mortality rate forecasting.,the proceedings contain    papers  the topics discussed include  simple neuro fuzzy system with combined learning for pattern recognition under conditions of short training set in medical diagnostics tasks  appraisal of artificial intelligence for fall prevention fall risk assessment  modeling of small data with unsupervised generative ensemble learning  the structure of the blockchain based multi agent system for secure management of medical information  evaluating autonomous energy harvesting device lifetime for the internet of medical things with a petri net formulation considering battery soh  application of mlops practices for biomedical image classification  impact of russian war on covid    dynamics in germany  the simulation study by statistical machine learning  and a data driven approach for neonatal mortality rate forecasting ,4.2124085,6.1181884,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
State-of-the-Art Survey of Cluster Scheduling for Mutable States Data Flow; [面向状态可变数据流的集群调度综述],"Mutable States Data Flow(MS-DF), as a main runtime feature of machine learning systems(e.g. Tensorflow, PyTorch, MxNet), can be represented by a directed graph. Here, each vertex in a MS-DF graph denotes a single operation(e.g. Conv2D, MatMul) which consists of typical machine learning computing processes. And each edge connecting two operations denotes the dependency of these two operations, the term ""dependency"" means the output of an operation is the input of the other operation linked by an edge. Currently, cluster scheduling for MS-DF is one of the main works that can guarantee the execution efficiency of machine learning systems, and it is one of the hot research topics in machine learning system area. Diving into the principle of cluster scheduling for MS-DF, machine learning systems are key factors that affect the performance of cluster scheduling, since they work as a middle layer to decouple the computing of machine learning and cluster resource(e.g. CPU, GPU and FPGA) allocations. By this way, cluster resources are no longer exclusively and statically bound to one computation of machine learning. Instead, machine learning systems may manage different kinds of resources dynamically, but at the cost of increased complexity of cluster scheduling for MS-DF. Under this circumstance, machine learning operations can heavily affect the dynamic management of cluster resources, thus new challenges arise. We demonstrate that these challenges are caused by the following three aspects: (1) the accuracy of profiling operations' heterogeneous resource requirements. (2) the adaptability of operation scheduling decisions. (3) the variability of operation scheduling adjustments. In addition to above challenges, we analyze and summarize the latest researches of cluster scheduling for MS-DF in recent years, and how these researches cope with challenges. (1) We introduce the mechanisms of both machine learning operation perception and cooperation that can be used to profile operations' heterogeneous resource requirement, such mechanisms can estimate the actual operation resource usage through many metrics(e.g. input dataset sizes, operation dependencies), thus we can improve the accuracy of profiling especially when operations have many combinations. (2) We introduce different scheduling decisions with three main factors including operation scheduling constraints, models and algorithms. Such decisions should be able to be deliberately set with different factors, thus we can adaptively provide operations with preferred resources when their states frequently change. (3) We introduce several scheduling adjustment strategies to further improve the performance of cluster scheduling. These strategies include operation migration, scaling, and suspending/resuming. One strategy or hybrid strategies can be useful under certain operation synchronization patterns(e.g. PS, AllReduce). Thus, we can use different strategies for different patterns. At last, we conclude the latest researches with the new trend of machine learning systems and the development of heterogeneous resources. We give our prospective view of the key technologies of cluster scheduling for MS-DF: (1) the multi-level analysis and collaborative characterization of operations' heterogeneous resource requirements. (2) the flexible definition and discovery of operations' complex scheduling constraints. (3) learning-driven optimization of operation scheduling at a low cost. They may improve cluster scheduling for MS-DF in a more efficient and intelligent way. © 2022, Science Press. All right reserved.",mutable states data flow ms df   as a main runtime feature of machine learning systems e g  tensorflow  pytorch  mxnet   can be represented by a directed graph  here  each vertex in a ms df graph denotes a single operation e g  conv d  matmul  which consists of typical machine learning computing processes  and each edge connecting two operations denotes the dependency of these two operations  the term  dependency  means the output of an operation is the input of the other operation linked by an edge  currently  cluster scheduling for ms df is one of the main works that can guarantee the execution efficiency of machine learning systems  and it is one of the hot research topics in machine learning system area  diving into the principle of cluster scheduling for ms df  machine learning systems are key factors that affect the performance of cluster scheduling  since they work as a middle layer to decouple the computing of machine learning and cluster resource e g  cpu  gpu and fpga  allocations  by this way  cluster resources are no longer exclusively and statically bound to one computation of machine learning  instead  machine learning systems may manage different kinds of resources dynamically  but at the cost of increased complexity of cluster scheduling for ms df  under this circumstance  machine learning operations can heavily affect the dynamic management of cluster resources  thus new challenges arise  we demonstrate that these challenges are caused by the following three aspects      the accuracy of profiling operations  heterogeneous resource requirements      the adaptability of operation scheduling decisions      the variability of operation scheduling adjustments  in addition to above challenges  we analyze and summarize the latest researches of cluster scheduling for ms df in recent years  and how these researches cope with challenges      we introduce the mechanisms of both machine learning operation perception and cooperation that can be used to profile operations  heterogeneous resource requirement  such mechanisms can estimate the actual operation resource usage through many metrics e g  input dataset sizes  operation dependencies   thus we can improve the accuracy of profiling especially when operations have many combinations      we introduce different scheduling decisions with three main factors including operation scheduling constraints  models and algorithms  such decisions should be able to be deliberately set with different factors  thus we can adaptively provide operations with preferred resources when their states frequently change      we introduce several scheduling adjustment strategies to further improve the performance of cluster scheduling  these strategies include operation migration  scaling  and suspending resuming  one strategy or hybrid strategies can be useful under certain operation synchronization patterns e g  ps  allreduce   thus  we can use different strategies for different patterns  at last  we conclude the latest researches with the new trend of machine learning systems and the development of heterogeneous resources  we give our prospective view of the key technologies of cluster scheduling for ms df      the multi level analysis and collaborative characterization of operations  heterogeneous resource requirements      the flexible definition and discovery of operations  complex scheduling constraints      learning driven optimization of operation scheduling at a low cost  they may improve cluster scheduling for ms df in a more efficient and intelligent way          science press  all right reserved ,7.7720265,8.431291,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
RelOps – A Whole-of-Organisation Approach for Reliability Analytics,"Reliability analysis on in-service assets uses well-established methods to, for example, determine mean-time-between-failure (MTBF) estimates or identify failure modes. However, the data inputs to these calculations depend on how the raw data from maintenance repair records have been processed. Furthermore, processes to extract and clean raw maintenance data are often ad hoc and performed differently by each engineer. As a result, calculations for asset reliability measures and identification of historical events and failure modes are difficult to replicate. Currently, the process is manual, time-consuming and not scalable. As a solution we present RelOps, a process to achieve standardised, scalable, and efficient end-to-end data handling and processing for organisation-wide reliability analysis. The process is illustrated with a case study showing current practice in MTBF estimation and the opportunities for technical language processing (TLP) to infer MTBF from maintenance work orders raised against a slurry pump.RelOps draws on DevOps and MLOps practices widely used in the software engineering and machine learning communities. The aim of RelOps is to shorten the reliability analysis development lifecycle and provide continuous delivery of quality outputs using a standardised and repeatable process. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",reliability analysis on in service assets uses well established methods to  for example  determine mean time between failure  mtbf  estimates or identify failure modes  however  the data inputs to these calculations depend on how the raw data from maintenance repair records have been processed  furthermore  processes to extract and clean raw maintenance data are often ad hoc and performed differently by each engineer  as a result  calculations for asset reliability measures and identification of historical events and failure modes are difficult to replicate  currently  the process is manual  time consuming and not scalable  as a solution we present relops  a process to achieve standardised  scalable  and efficient end to end data handling and processing for organisation wide reliability analysis  the process is illustrated with a case study showing current practice in mtbf estimation and the opportunities for technical language processing  tlp  to infer mtbf from maintenance work orders raised against a slurry pump relops draws on devops and mlops practices widely used in the software engineering and machine learning communities  the aim of relops is to shorten the reliability analysis development lifecycle and provide continuous delivery of quality outputs using a standardised and repeatable process          the author s   under exclusive license to springer nature switzerland ag ,6.06693,4.6669197,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Maturity Model for Analysis of Machine Learning Operations in Industry,"The next evolutionary technological step in the industry presumes the automation of the elements found within a factory, which can be accomplished through extensive introduction of automatons, computers and Internet of Things (IoT) components. All this seeks to streamline, improve, and increase production at the lowest possible cost and avoid any failure in the creation of the product, following a strategy called “Zero Defect Manufacturing”. Machine Learning Operations (MLOps) provide a ML-based solution to this challenge, promoting the automation of all product-relevant steps, from development to deployment. When integrating different machine learning models within manufacturing operations, it is necessary to have a good understanding of what functionality is needed and what is expected. This article presents a maturity model that can help companies identify and map their current level of implementation of machine learning models. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",the next evolutionary technological step in the industry presumes the automation of the elements found within a factory  which can be accomplished through extensive introduction of automatons  computers and internet of things  iot  components  all this seeks to streamline  improve  and increase production at the lowest possible cost and avoid any failure in the creation of the product  following a strategy called  zero defect manufacturing   machine learning operations  mlops  provide a ml based solution to this challenge  promoting the automation of all product relevant steps  from development to deployment  when integrating different machine learning models within manufacturing operations  it is necessary to have a good understanding of what functionality is needed and what is expected  this article presents a maturity model that can help companies identify and map their current level of implementation of machine learning models          the author s   under exclusive license to springer nature switzerland ag ,10.151819,3.6956227,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
"Proceedings - 2023 IEEE/ACM International Workshop on Deep Learning for Testing and Testing for Deep Learning, DeepTest 2023",The proceedings contain 4 papers. The topics discussed include: metamorphic testing of machine translation models using back translation; a method of identifying causes of prediction errors to accelerate MLOps; DeepSHAP summary for adversarial example detection; and DeepPatch: a patching-based method for repairing deep neural networks.,the proceedings contain   papers  the topics discussed include  metamorphic testing of machine translation models using back translation  a method of identifying causes of prediction errors to accelerate mlops  deepshap summary for adversarial example detection  and deeppatch  a patching based method for repairing deep neural networks ,6.618553,4.9600916,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Mission Control's Deep Learning Accelerator - A Hardware Agnostic Tool for Deploying Deep Learning Models on Low-Powered Edge Processors,"As the spa ce economy grows, there is a n increa sed need for a dva nced a uto nomy a nd computation capabilities on-board the spa ce systems themselves. Whether for spa ce explora tion progra ms such a s Artemis, or for nex t-gen sa tellites for ea rth observa tion a nd remote sensing, the need for complex computa tion on the edge is becoming increa singly importa nt to process the high volumes of da ta being produced, infer key pa tterns, a nd ma ke intelligent decisions without time-consuming ground support. One increa singly popula r method of a chieving a dva nced a utonomy is via Deep Lea rning ba sed Artificia l Intelligence (AI) models. However, tra ditiona lly, such models require a high a mount of compute power for both lea rning and inference a nd a re difficult to deploy on low-power edge devices, such a s spa ce qua lified computers. Mission Control's Deep Lea rning Accelera tor (DLA) is a softwa re sta ck tha t a llows low-power embedded edge processors to perform Sta te of the Art Deep Lea rning inference on, including CPUs, GPUs, a nd FPGAs. The sta ck is designed to be a gnostic of ha rdwa re a nd ea sy -to-use for developers, with a focus on efficiency a nd interopera bility with multiple Ma chine Lea rning fra meworks. The toolcha in is being developed spe cifica lly for spa ceflight a pplica tions, to ena ble deep lea rning on low-powered, resource constra ined, a nd ra dia tion h a rdened semiconductor devices in the a ustere environments found in Spa ce. The DLA ena bles Ma chine Lea rning Developmenta l Ops (MLOps) by a llowing developers a nd scientists to perform Continuous Improvement/Continuous Deployment during a ll pha ses, including prototyping, pre-flight development a nd in-flight opera tions. With the DLA, the typica l MLOps cycle ca n ta ke the following steps: 1. Develop a Deep Ma chine Lea rning model using a high -level progra mming la ngua ge (ex. Python) and common ML fra meworks (ex. PyTorch, TensorFlow). 2. Tra in a nd test the model. 3. Use the DLA to port the model onto a low-powered edge processor, such a s a flight computer for a spa cecra ft. 4. Run the model live on the edge ha rdwa re device. 5. Improve, upda te, a nd susta in the model in-flight, a s necessa ry In 2023, Mission Control will become the first compa ny to deploy deep lea rning-ba sed AI on the Moon a s pa rt of the Emira tes Luna r Mission (ELM). Using our DLA, a Deep Convolutiona l Neura l Network will be used to perform inference on ima ges obta ined from the rover for a utomated terra in cla ssifica tion of the luna r surfa ce. The DLA will a lso be used to deploy a nd upda te a Deep Lea rning model onto a Field Progra mma ble Ga te Arra y (FPGA) on -board the Europea n Spa ce Agency's OPS-SAT experimenta l sa tellite in Fa ll 2022 while in-flight, thus demonstra ting the DLA's ca pa bility to ena ble MLOps in spa ce. © 2022 International Astronautical Federation, IAF. All rights reserved.",as the spa ce economy grows  there is a n increa sed need for a dva nced a uto nomy a nd computation capabilities on board the spa ce systems themselves  whether for spa ce explora tion progra ms such a s artemis  or for nex t gen sa tellites for ea rth observa tion a nd remote sensing  the need for complex computa tion on the edge is becoming increa singly importa nt to process the high volumes of da ta being produced  infer key pa tterns  a nd ma ke intelligent decisions without time consuming ground support  one increa singly popula r method of a chieving a dva nced a utonomy is via deep lea rning ba sed artificia l intelligence  ai  models  however  tra ditiona lly  such models require a high a mount of compute power for both lea rning and inference a nd a re difficult to deploy on low power edge devices  such a s spa ce qua lified computers  mission control s deep lea rning accelera tor  dla  is a softwa re sta ck tha t a llows low power embedded edge processors to perform sta te of the art deep lea rning inference on  including cpus  gpus  a nd fpgas  the sta ck is designed to be a gnostic of ha rdwa re a nd ea sy  to use for developers  with a focus on efficiency a nd interopera bility with multiple ma chine lea rning fra meworks  the toolcha in is being developed spe cifica lly for spa ceflight a pplica tions  to ena ble deep lea rning on low powered  resource constra ined  a nd ra dia tion h a rdened semiconductor devices in the a ustere environments found in spa ce  the dla ena bles ma chine lea rning developmenta l ops  mlops  by a llowing developers a nd scientists to perform continuous improvement continuous deployment during a ll pha ses  including prototyping  pre flight development a nd in flight opera tions  with the dla  the typica l mlops cycle ca n ta ke the following steps     develop a deep ma chine lea rning model using a high  level progra mming la ngua ge  ex  python  and common ml fra meworks  ex  pytorch  tensorflow      tra in a nd test the model     use the dla to port the model onto a low powered edge processor  such a s a flight computer for a spa cecra ft     run the model live on the edge ha rdwa re device     improve  upda te  a nd susta in the model in flight  a s necessa ry in       mission control will become the first compa ny to deploy deep lea rning ba sed ai on the moon a s pa rt of the emira tes luna r mission  elm   using our dla  a deep convolutiona l neura l network will be used to perform inference on ima ges obta ined from the rover for a utomated terra in cla ssifica tion of the luna r surfa ce  the dla will a lso be used to deploy a nd upda te a deep lea rning model onto a field progra mma ble ga te arra y  fpga  on  board the europea n spa ce agency s ops sat experimenta l sa tellite in fa ll      while in flight  thus demonstra ting the dla s ca pa bility to ena ble mlops in spa ce         international astronautical federation  iaf  all rights reserved ,7.961596,7.7187967,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
On the Track to Application Architectures in Public Transport Service Companies,"There are quite some machine learning (ML) models, frameworks, AI-based services or products from different IT solution providers available, which can be used as building blocks to embed and use in IT solution architectures of companies. However, the path from initial prototypical proof of concept solutions until the deployment of proven systems into the operational environment remains a major challenge. The potential of AI-based software components using ML or knowledge engineering (KE) is huge and the majority of small to medium enterprises are still unsure whether their internal developer teams should be extended by additional ML or KE skills to enrich their IT solution architectures with novel AI-based components where appropriate. How can enterprises manage the change and visualize the current state and foreseeable road-map? In the current paper, we propose an AI system landscape for the public transport sector, which is based on existing AI-domains and AI-categories defined by different technical reports of the European Commission. We collect use-cases from three different enterprises in the transportation sector and visualize them on the proposed domain specific AI-landscape. We provide some insights into different maturity levels of different AI-based components and how the different ML and KE based components can be embedded into an AI-based software development life-cycle (SDLC). We visualize, how the AI-based IT-solution architecture evolved over the last decades with respect to coupling and decoupling of layers and tiers in the overall Enterprise Architecture. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.",there are quite some machine learning  ml  models  frameworks  ai based services or products from different it solution providers available  which can be used as building blocks to embed and use in it solution architectures of companies  however  the path from initial prototypical proof of concept solutions until the deployment of proven systems into the operational environment remains a major challenge  the potential of ai based software components using ml or knowledge engineering  ke  is huge and the majority of small to medium enterprises are still unsure whether their internal developer teams should be extended by additional ml or ke skills to enrich their it solution architectures with novel ai based components where appropriate  how can enterprises manage the change and visualize the current state and foreseeable road map  in the current paper  we propose an ai system landscape for the public transport sector  which is based on existing ai domains and ai categories defined by different technical reports of the european commission  we collect use cases from three different enterprises in the transportation sector and visualize them on the proposed domain specific ai landscape  we provide some insights into different maturity levels of different ai based components and how the different ml and ke based components can be embedded into an ai based software development life cycle  sdlc   we visualize  how the ai based it solution architecture evolved over the last decades with respect to coupling and decoupling of layers and tiers in the overall enterprise architecture         by the authors  licensee mdpi  basel  switzerland ,10.992809,6.9317884,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
SINAV: An ASI Study of Future AI Applications on Spatial Rovers,"In the future Mars or Moon rover scenarios it is always supposed to have a high grade of autonomy on board of the rover. The use of Artificial Intelligence can strongly improve the main goal of an increased rover autonomy navigation. The SINAV (Soluzioni Innovative per la Navigazione Autonoma Veloce) (Agenzia Spaziale Italiana (BANDO DI RICERCA PER TECNOLOGIE ABILITANTI TRASVERSALI Area tematica Tecnologie Spaziali: B) Sistemi Autonomi e Intelligenza Artificiale A.S.I. 2018 [1]) study, co-financed by the Agenzia Spaziale Italiana (ASI), is a consistent step toward this main objective of improving navigation autonomy. In this article we briefly describe the challenging environments of Mars and the Moon that is also included in the main requirements of the SINAV study. Particular care has been devoted in the choice of Deep Learning (DL) for this study. Through Deep Neural Networks (DNN) represent a real and consistent advantage in terms of capability and reliability for rover missions without having to constitute a fancy technical solution where AI is forced in the rover navigational loop. Each DNN explains the problem that we need to solve, how it has been addressed in the past mission and the advantages of the proposed solution. A description of the adopted Machine Learning Operations (MLOps) and the different datasets created is also presented. A final description of the particular hardware and software used during the final tests complete the overall description of the main objectives inherent to Deep Learning of the SINAV study. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",in the future mars or moon rover scenarios it is always supposed to have a high grade of autonomy on board of the rover  the use of artificial intelligence can strongly improve the main goal of an increased rover autonomy navigation  the sinav  soluzioni innovative per la navigazione autonoma veloce   agenzia spaziale italiana  bando di ricerca per tecnologie abilitanti trasversali area tematica tecnologie spaziali  b  sistemi autonomi e intelligenza artificiale a s i            study  co financed by the agenzia spaziale italiana  asi   is a consistent step toward this main objective of improving navigation autonomy  in this article we briefly describe the challenging environments of mars and the moon that is also included in the main requirements of the sinav study  particular care has been devoted in the choice of deep learning  dl  for this study  through deep neural networks  dnn  represent a real and consistent advantage in terms of capability and reliability for rover missions without having to constitute a fancy technical solution where ai is forced in the rover navigational loop  each dnn explains the problem that we need to solve  how it has been addressed in the past mission and the advantages of the proposed solution  a description of the adopted machine learning operations  mlops  and the different datasets created is also presented  a final description of the particular hardware and software used during the final tests complete the overall description of the main objectives inherent to deep learning of the sinav study          the author s   under exclusive license to springer nature switzerland ag ,8.912175,7.8656893,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Self-learning Data Foundation for Scientific AI,"The “Self-Learning Data Foundation for AI” is an open-source platform to manage Machine Learning (ML) metadata in complex end-to-end pipelines, and includes the intelligence to optimize data gradation, pipeline configuration, and compute performance. The work addresses several challenges: prioritizing data to reduce movement, tracking lineage to optimize complex ML pipelines, and enabling reproducibility and portability of data selection and ML model development. Off-the-shelf AI metadata management frameworks (such as MLflow or Weights & Biases) focus on fine-grain stage-level metadata, and only track parts of the pipeline, and lineage. Our proposed software layer sits between ML workflows and pipelines and storage/data access. The first implementation of the Data Foundation is the Common Metadata Framework (CMF), which captures metadata and tracks them automatically alongside references to data artifacts and application code. Its git-like nature allows parallel model development by different teams and is well suited for federated environments. It includes intelligence to optimize pipelines and storage, can learn the access patterns from pipeline execution to inform optimizations such as prestaging and caching. It also learns from model inference metrics to build iteratively more robust models. Through a data shaping use case for I/O optimization and an active learning use case to reduce labelling (on DeepCam AI model training on climate data running on NERSC Cori), we show the versatility of the data foundation layer, the potential benefits (4x reduction in training time and 2x reduction in labelling effort), and its central role in complex ML pipelines. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.",the  self learning data foundation for ai  is an open source platform to manage machine learning  ml  metadata in complex end to end pipelines  and includes the intelligence to optimize data gradation  pipeline configuration  and compute performance  the work addresses several challenges  prioritizing data to reduce movement  tracking lineage to optimize complex ml pipelines  and enabling reproducibility and portability of data selection and ml model development  off the shelf ai metadata management frameworks  such as mlflow or weights   biases  focus on fine grain stage level metadata  and only track parts of the pipeline  and lineage  our proposed software layer sits between ml workflows and pipelines and storage data access  the first implementation of the data foundation is the common metadata framework  cmf   which captures metadata and tracks them automatically alongside references to data artifacts and application code  its git like nature allows parallel model development by different teams and is well suited for federated environments  it includes intelligence to optimize pipelines and storage  can learn the access patterns from pipeline execution to inform optimizations such as prestaging and caching  it also learns from model inference metrics to build iteratively more robust models  through a data shaping use case for i o optimization and an active learning use case to reduce labelling  on deepcam ai model training on climate data running on nersc cori   we show the versatility of the data foundation layer  the potential benefits   x reduction in training time and  x reduction in labelling effort   and its central role in complex ml pipelines          the author s   under exclusive license to springer nature switzerland ag ,7.649839,6.199523,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
An Internet of Things Based Crack Monitoring Approach Using Nondestructive Evaluation Data,"Monitoring and quantifying crack initiation and growth are of primary importance both for material performance evaluation and design and for structural damage assessment. While several sensing and evaluation methods related to cracking have been proposed, recent demands for real-time assessment have created the need to connect data acquisition with rapid extraction of information that can be leveraged in both diagnostics and prognostics. This investigation presents a novel approach to leveraging nondestructive evaluation (NDE) datasets in an internet of things (IoT) framework, which is shown to be capable of providing nearly real-time diagnostics for cracking, while creating also the framework to apply prognostics methods. To demonstrate this approach, compacttension specimens of an aluminum alloy were used in laboratory experiments in accordance with ASTM standards. Acoustic emission NDE datasets were acquired and used to produce information that was processed using an in-house-built IoT system capable of edge and cloud computing. The main innovation of this approach is that a combination of IoT hardware and software proves advantageous in implementing a data structure that can then be used in machine learning operations that are suitable for detecting crack initiation.  © 2022 by ASTM International, 100 Barr Harbor Drive, PO Box C700, West Conshohocken, PA 19428-2959.",monitoring and quantifying crack initiation and growth are of primary importance both for material performance evaluation and design and for structural damage assessment  while several sensing and evaluation methods related to cracking have been proposed  recent demands for real time assessment have created the need to connect data acquisition with rapid extraction of information that can be leveraged in both diagnostics and prognostics  this investigation presents a novel approach to leveraging nondestructive evaluation  nde  datasets in an internet of things  iot  framework  which is shown to be capable of providing nearly real time diagnostics for cracking  while creating also the framework to apply prognostics methods  to demonstrate this approach  compacttension specimens of an aluminum alloy were used in laboratory experiments in accordance with astm standards  acoustic emission nde datasets were acquired and used to produce information that was processed using an in house built iot system capable of edge and cloud computing  the main innovation of this approach is that a combination of iot hardware and software proves advantageous in implementing a data structure that can then be used in machine learning operations that are suitable for detecting crack initiation          by astm international      barr harbor drive  po box c     west conshohocken  pa            ,10.388711,7.0297074,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Augmented Intelligence for Ethylene Process,"Augmented Intelligence provides the right information at right time to drive the right decisions without overwhelming operations with “data overload”. Driven by technology, Industry 4.0 is transforming the ethylene process and reshaping operation paradigms to create greater efficiency and synergies in operating strategy and solve challenging problems. An effective implementation of Machine Learning Operations (ML Ops) provides Augmented Intelligence to managers, engineers, and operators in the Oil & Gas Industry (Upstream, Midstream & Downstream), that would otherwise have taken years of operational experience. This paper discusses the intelligent tools developed for an ethylene facility to gain insights for operational improvement through augmented intelligence. This also includes smart techniques and solutions to improve operational efficiency, addressing furnace run length and other reliability objectives, live insights to identify and close operational GAP's. Real-time solution, developed with a state-of-art technology and advanced analytics application for ethylene process industry results in several benefits. © 2022 American Institute of Chemical Engineers. All rights reserved.",augmented intelligence provides the right information at right time to drive the right decisions without overwhelming operations with  data overload   driven by technology  industry     is transforming the ethylene process and reshaping operation paradigms to create greater efficiency and synergies in operating strategy and solve challenging problems  an effective implementation of machine learning operations  ml ops  provides augmented intelligence to managers  engineers  and operators in the oil   gas industry  upstream  midstream   downstream   that would otherwise have taken years of operational experience  this paper discusses the intelligent tools developed for an ethylene facility to gain insights for operational improvement through augmented intelligence  this also includes smart techniques and solutions to improve operational efficiency  addressing furnace run length and other reliability objectives  live insights to identify and close operational gap s  real time solution  developed with a state of art technology and advanced analytics application for ethylene process industry results in several benefits         american institute of chemical engineers  all rights reserved ,10.236744,5.8628874,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
MLOps: Overview of Current State and Future Directions,"This article presents and discuss the industrialization process of ML (Machine Learning) projects with a focus on the principles of MLOps (Machine Learning Operations) and the challenges encountered when putting an ML project into production. The paper also proposes a set of tools used in an MLOps context to facilitate the deployment of ML projects and their production release. This paper is a guide to discover the MLOps domain in its theoretical (MLOps concepts, pipeline and life cycle) and practical (technical and tools) aspects. MLOps must provide answers to the use of ML applications hosted on servers with high performance, also for applications embedded in equipment with minimal sizing, since we are talking about the fourth industrial revolution with the increase of number of sensors in the world generating a mass of data that must be efficiently processed and analyzed. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",this article presents and discuss the industrialization process of ml  machine learning  projects with a focus on the principles of mlops  machine learning operations  and the challenges encountered when putting an ml project into production  the paper also proposes a set of tools used in an mlops context to facilitate the deployment of ml projects and their production release  this paper is a guide to discover the mlops domain in its theoretical  mlops concepts  pipeline and life cycle  and practical  technical and tools  aspects  mlops must provide answers to the use of ml applications hosted on servers with high performance  also for applications embedded in equipment with minimal sizing  since we are talking about the fourth industrial revolution with the increase of number of sensors in the world generating a mass of data that must be efficiently processed and analyzed          the author s   under exclusive license to springer nature switzerland ag ,8.240102,4.764645,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Managing AI in the enterprise: Succeeding with AI projects and MLOps to build sustainable AI organizations,"Delivering AI projects and building an AI organization are two big challenges for enterprises. They determine whether companies succeed or fail in establishing AI and integrating AI into their digital transformation. This book addresses both challenges by bringing together organizational and service design concepts, project management, and testing and quality assurance. It covers crucial, often-overlooked topics such as MLOps, IT risk, security and compliance, and AI ethics. In particular, the book shows how to shape AI projects and the capabilities of an AI line organization in an enterprise. It elaborates critical deliverables and milestones, helping you turn your vision into a corporate reality by efficiently managing and setting goals for data scientists, data engineers, and other IT specialists. For those new to AI or AI in an enterprise setting you will find this book a systematic introduction to the field. You will get the necessary know-how to collaborate with and lead AI specialists and guide them to success. Time-pressured readers will benefit from self-contained sections explaining key topics and providing illustrations for fostering discussions in their next team, project, or management meeting. Reading this book helps you to better sell the business benefits from your AI initiatives and build your skills around scoping and delivering AI projects. You will be better able to work through critical aspects such as quality assurance, security, and ethics when building AI solutions in your organization. What You Will Learn: Clarify the benefits of your AI initiatives and sell them to senior managers. Scope and manage AI projects in your organization. Set up quality assurance and testing for AI models and their integration in complex software solutions. Shape and manage an AI delivery organization, thereby mastering ML Ops. Understand and formulate requirements for the underlying data management infrastructure. Handle AI-related IT security, compliance, and risk topics and understand relevant AI ethics aspects. Who This Book Is For: Experienced IT managers managing data scientists or who want to get involved in managing AI projects, data scientists and other tech professionals who want to progress toward taking on leadership roles in their organization's AI initiatives and who aim to structure AI projects and AI organizations, any line manager and project manager involved in AI projects or in collaborating with AI teams. © 2022 by Klaus Haller. All rights reserved.",delivering ai projects and building an ai organization are two big challenges for enterprises  they determine whether companies succeed or fail in establishing ai and integrating ai into their digital transformation  this book addresses both challenges by bringing together organizational and service design concepts  project management  and testing and quality assurance  it covers crucial  often overlooked topics such as mlops  it risk  security and compliance  and ai ethics  in particular  the book shows how to shape ai projects and the capabilities of an ai line organization in an enterprise  it elaborates critical deliverables and milestones  helping you turn your vision into a corporate reality by efficiently managing and setting goals for data scientists  data engineers  and other it specialists  for those new to ai or ai in an enterprise setting you will find this book a systematic introduction to the field  you will get the necessary know how to collaborate with and lead ai specialists and guide them to success  time pressured readers will benefit from self contained sections explaining key topics and providing illustrations for fostering discussions in their next team  project  or management meeting  reading this book helps you to better sell the business benefits from your ai initiatives and build your skills around scoping and delivering ai projects  you will be better able to work through critical aspects such as quality assurance  security  and ethics when building ai solutions in your organization  what you will learn  clarify the benefits of your ai initiatives and sell them to senior managers  scope and manage ai projects in your organization  set up quality assurance and testing for ai models and their integration in complex software solutions  shape and manage an ai delivery organization  thereby mastering ml ops  understand and formulate requirements for the underlying data management infrastructure  handle ai related it security  compliance  and risk topics and understand relevant ai ethics aspects  who this book is for  experienced it managers managing data scientists or who want to get involved in managing ai projects  data scientists and other tech professionals who want to progress toward taking on leadership roles in their organization s ai initiatives and who aim to structure ai projects and ai organizations  any line manager and project manager involved in ai projects or in collaborating with ai teams         by klaus haller  all rights reserved ,10.840769,6.8509674,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
"OASEES: An Innovative Scope for a DAO-Based Programmable Swarm Solution, for Decentralizing AI Applications Close to Data Generation Locations","As traditional linear models have proved to be ineffective in perspective of the stagnant decision-making and inefficient data federation, the pathway onwards a European data sovereignty dictates for a sustainable and circular economy across diverse market sectors. In this scope, the EU-funded OASEES project has identified the need for a novel, inclusive and disruptive approach regarding the cloud to edge continuum and swarm programmability and also supporting multi-tenant, interoperable, secure and trustworthy deployments. In the present paper we discuss actual challenges for the management and orchestration of edge infrastructure and services to exploit the potential of edge processing. Then we discuss the concept and fundamental features of the OASEES approach together with technology challenges that are to be covered by the intended system development. We also discuss, in brief, a set of several vertical edge applications with significant market impact. © 2023, IFIP International Federation for Information Processing.",as traditional linear models have proved to be ineffective in perspective of the stagnant decision making and inefficient data federation  the pathway onwards a european data sovereignty dictates for a sustainable and circular economy across diverse market sectors  in this scope  the eu funded oasees project has identified the need for a novel  inclusive and disruptive approach regarding the cloud to edge continuum and swarm programmability and also supporting multi tenant  interoperable  secure and trustworthy deployments  in the present paper we discuss actual challenges for the management and orchestration of edge infrastructure and services to exploit the potential of edge processing  then we discuss the concept and fundamental features of the oasees approach together with technology challenges that are to be covered by the intended system development  we also discuss  in brief  a set of several vertical edge applications with significant market impact          ifip international federation for information processing ,10.579186,7.215483,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Implementation and Evaluation of a MLaaS for Document Classification with Continuous Deep Learning Models,"This paper indicates an approach of a continuous training pipeline to enhance deep learning models and assessing their feasibility based on an evaluation. The purpose of this research is to analyze the quality effect of a continuously learning neural network algorithm for document classification by taking user feedback into account. The hypothesis implies that user feedback through active learning increases the precision and thus makes the process of document classification more efficient. For this purpose, based on a utility analysis, the available technologies are identified, and necessary ones are selected for designing a software concept. TensorFlow as a deep learning framework, Tesseract as an OCR engine, and Apache Airflow for the life cycle management and for orchestrating the elements for the continuous training pipeline are used. This implementation of a machine learning as a service prototype allows for exploration into the synergistic effect between the use of active learning, in the form of user feedback, and the quality of document classification achieved by deep learning. In an experiment, the implemented service is used to analyze the models behavior based on three different states. This includes synthetic data and active learning in the form of user feedback through data from data augmentation and simulated realistic data. The result shows that active learning enhanced models indicate a higher accuracy than artificially generated models. The evaluation experiment confirms the hypothesis that user feedback with continuously learning models perform better in terms of generalizing within the document classification. In conclusion, the paper demonstrates the technical requirements for implementing a machine learning as a service and affirms that the use of active learning can be integrated into existing industrial systems. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.",this paper indicates an approach of a continuous training pipeline to enhance deep learning models and assessing their feasibility based on an evaluation  the purpose of this research is to analyze the quality effect of a continuously learning neural network algorithm for document classification by taking user feedback into account  the hypothesis implies that user feedback through active learning increases the precision and thus makes the process of document classification more efficient  for this purpose  based on a utility analysis  the available technologies are identified  and necessary ones are selected for designing a software concept  tensorflow as a deep learning framework  tesseract as an ocr engine  and apache airflow for the life cycle management and for orchestrating the elements for the continuous training pipeline are used  this implementation of a machine learning as a service prototype allows for exploration into the synergistic effect between the use of active learning  in the form of user feedback  and the quality of document classification achieved by deep learning  in an experiment  the implemented service is used to analyze the models behavior based on three different states  this includes synthetic data and active learning in the form of user feedback through data from data augmentation and simulated realistic data  the result shows that active learning enhanced models indicate a higher accuracy than artificially generated models  the evaluation experiment confirms the hypothesis that user feedback with continuously learning models perform better in terms of generalizing within the document classification  in conclusion  the paper demonstrates the technical requirements for implementing a machine learning as a service and affirms that the use of active learning can be integrated into existing industrial systems          the author s   under exclusive license to springer nature switzerland ag ,7.3890843,4.7682743,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
"ISE 2022 - Proceedings of the 1st International Workshop on Intelligent Software Engineering, co-located with 29th Asia-Pacific Software Engineering Conference, APSEC 2022","The proceedings contain 14 papers. The topics discussed include: MediaPipe-based LSTM-autoencoder sarcopenia anomaly detection and requirements for improving detection accuracy; the application of machine learning on the injury prediction of soccer players; real-time twist rebar detection system exploiting GAN-based data augmentation technique; performance evaluation of fire and smoke detection with object based DNN algorithm; business process model annotation techniques: identification, classification and analysis; automatic testing of OCE, a human-centered reinforcement learning system for automated software composition; towards automated open source assessment - an empirical study; load balancing in cloud computing using nature-inspired algorithms: a systematic literature review; and quality assurance in MLOps setting: an industrial perspective.",the proceedings contain    papers  the topics discussed include  mediapipe based lstm autoencoder sarcopenia anomaly detection and requirements for improving detection accuracy  the application of machine learning on the injury prediction of soccer players  real time twist rebar detection system exploiting gan based data augmentation technique  performance evaluation of fire and smoke detection with object based dnn algorithm  business process model annotation techniques  identification  classification and analysis  automatic testing of oce  a human centered reinforcement learning system for automated software composition  towards automated open source assessment   an empirical study  load balancing in cloud computing using nature inspired algorithms  a systematic literature review  and quality assurance in mlops setting  an industrial perspective ,7.070078,5.169499,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Simple Non Regressive Informed Machine Learning Model for Prescriptive Maintenance of Track Circuits in a Subway Environment,"A Track Circuit (TC) System enables automatic train detection and protection functions. A typical TC failure is the False Occupancy (FO), i.e., a TC results occupied for a certain period of time when there is no train on it. FO can be resolved by manually driving a train on the faulty TC with a waste of time and resources. After a FO, operators, based on their experience, need to decide if there is an actual need for maintenance or if the problem is due to other temporary causes. In this paper, we propose a Simple Informed Machine Learning (ML) based model able to automatically prescribe maintenance after a FO fully leveraging on the operator experience. However, ML models in modern industrial MLOps pipelines demand continuous data collection, model re-training, testing, and monitoring, creating a large technical debt. In fact, one of the main requirements of these pipelines is to not be regressive, i.e., not simply improve average performance but not introduce mistakes previously not present (negative flips). In this work we face this problem by empowering the proposed ML with Non Regressive properties. Results on real data coming from a portion of an Italian Metro managed by Hitachi Rail STS will support our proposal. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",a track circuit  tc  system enables automatic train detection and protection functions  a typical tc failure is the false occupancy  fo   i e   a tc results occupied for a certain period of time when there is no train on it  fo can be resolved by manually driving a train on the faulty tc with a waste of time and resources  after a fo  operators  based on their experience  need to decide if there is an actual need for maintenance or if the problem is due to other temporary causes  in this paper  we propose a simple informed machine learning  ml  based model able to automatically prescribe maintenance after a fo fully leveraging on the operator experience  however  ml models in modern industrial mlops pipelines demand continuous data collection  model re training  testing  and monitoring  creating a large technical debt  in fact  one of the main requirements of these pipelines is to not be regressive  i e   not simply improve average performance but not introduce mistakes previously not present  negative flips   in this work we face this problem by empowering the proposed ml with non regressive properties  results on real data coming from a portion of an italian metro managed by hitachi rail sts will support our proposal          the author s   under exclusive license to springer nature switzerland ag ,5.274005,5.215005,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Machine Learning in CNC Machining: Best Practices,"Building machine learning (ML) tools, or systems, for use in manufacturing environments is a challenge that extends far beyond the understanding of the ML algorithm. Yet, these challenges, outside of the algorithm, are less discussed in literature. Therefore, the purpose of this work is to practically illustrate several best practices, and challenges, discovered while building an ML system to detect tool wear in metal CNC machining. Namely, one should focus on the data infrastructure first; begin modeling with simple models; be cognizant of data leakage; use open-source software; and leverage advances in computational power. The ML system developed in this work is built upon classical ML algorithms and is applied to a real-world manufacturing CNC dataset. The best-performing random forest model on the CNC dataset achieves a true positive rate (sensitivity) of 90.3% and a true negative rate (specificity) of 98.3%. The results are suitable for deployment in a production environment and demonstrate the practicality of the classical ML algorithms and techniques used. The system is also tested on the publicly available UC Berkeley milling dataset. All the code is available online so others can reproduce and learn from the results. © 2022 by the authors.",building machine learning  ml  tools  or systems  for use in manufacturing environments is a challenge that extends far beyond the understanding of the ml algorithm  yet  these challenges  outside of the algorithm  are less discussed in literature  therefore  the purpose of this work is to practically illustrate several best practices  and challenges  discovered while building an ml system to detect tool wear in metal cnc machining  namely  one should focus on the data infrastructure first  begin modeling with simple models  be cognizant of data leakage  use open source software  and leverage advances in computational power  the ml system developed in this work is built upon classical ml algorithms and is applied to a real world manufacturing cnc dataset  the best performing random forest model on the cnc dataset achieves a true positive rate  sensitivity  of       and a true negative rate  specificity  of        the results are suitable for deployment in a production environment and demonstrate the practicality of the classical ml algorithms and techniques used  the system is also tested on the publicly available uc berkeley milling dataset  all the code is available online so others can reproduce and learn from the results         by the authors ,3.438707,7.1559505,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Git Workflow for Active Learning: A Development Methodology Proposal for Data-Centric AI Projects,"As soon as Artificial Intelligence (AI) projects grow from small feasibility studies to mature projects, developers and data scientists face new challenges, such as collaboration with other developers, versioning data, or traceability of model metrics and other resulting artifacts. This paper suggests a data-centric AI project with an Active Learning (AL) loop from a developer perspective and presents”Git Workflow for AL”: A methodology proposal to guide teams on how to structure a project and solve implementation challenges. We introduce principles for data, code, as well as automation, and present a new branching workflow. The evaluation shows that the proposed method is an enabler for fulfilling established best practices. Copyright © 2023 by SCITEPRESS - Science and Technology Publications, Lda. Under CC license (CC BY-NC-ND 4.0)",as soon as artificial intelligence  ai  projects grow from small feasibility studies to mature projects  developers and data scientists face new challenges  such as collaboration with other developers  versioning data  or traceability of model metrics and other resulting artifacts  this paper suggests a data centric ai project with an active learning  al  loop from a developer perspective and presents git workflow for al   a methodology proposal to guide teams on how to structure a project and solve implementation challenges  we introduce principles for data  code  as well as automation  and present a new branching workflow  the evaluation shows that the proposed method is an enabler for fulfilling established best practices  copyright        by scitepress   science and technology publications  lda  under cc license  cc by nc nd     ,10.735955,5.6345367,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Open-source tool for model performance analysis for subpopulations,"When a CAD-AI network is created and employed, both safety and effectiveness need to be guaranteed for all subgroups of the target population. We present a novel toolbox for automatic slicing and performance assessment in a generic and modular approach, helping to find the subpopulations where cautiousness is warranted, and the model may need improvement. In a first step slices are generated and saved for further analysis inspired by the existing 'Slice Finder' algorithm. Depending on the type of AI task (classification, object detection, segmentation, instance segmentation...) multiple metrics are evaluated. Both labeled (specificity, sensitivity...), unlabeled (outlier score, confidence score...) and user-defined metrics can be included. Optionally, the confidence interval (CI) is calculated. In a last step, the metric values and CI are used to rank the slices to quickly find the slices of interest. Custom ranking methods can be added, keeping the full process from slice generation up to and including visualization modular and customizable. We illustrate the toolbox with a dermatology classification and object detection use-case. First a single model is evaluated down to crosses of three slices where slices of interest are detected on degree three which would be difficult to find if not automated. Additionally, the usage of unlabeled metrics such as outlier score is illustrated to automatically find slices of interest. © 2023 SPIE.",when a cad ai network is created and employed  both safety and effectiveness need to be guaranteed for all subgroups of the target population  we present a novel toolbox for automatic slicing and performance assessment in a generic and modular approach  helping to find the subpopulations where cautiousness is warranted  and the model may need improvement  in a first step slices are generated and saved for further analysis inspired by the existing  slice finder  algorithm  depending on the type of ai task  classification  object detection  segmentation  instance segmentation     multiple metrics are evaluated  both labeled  specificity  sensitivity      unlabeled  outlier score  confidence score     and user defined metrics can be included  optionally  the confidence interval  ci  is calculated  in a last step  the metric values and ci are used to rank the slices to quickly find the slices of interest  custom ranking methods can be added  keeping the full process from slice generation up to and including visualization modular and customizable  we illustrate the toolbox with a dermatology classification and object detection use case  first a single model is evaluated down to crosses of three slices where slices of interest are detected on degree three which would be difficult to find if not automated  additionally  the usage of unlabeled metrics such as outlier score is illustrated to automatically find slices of interest         spie ,5.102211,6.509267,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
ECLIPSE: Holistic AI System for Preparing Insurer Policy Data,"Reinsurers possess high volumes of policy listings data from insurers, which they use to provide insurers with analytical insights and modeling that guide reinsurance treaties. These insurers often act on the same data for their own internal modeling and analytics needs. The problem is this data is messy and needs significant preparation in order to extract meaningful insights. Traditionally, this has required intensive manual labor from actuaries. However, a host of modern AI techniques and ML system architectures introduced in the past decade can be applied to the problem of insurance data preparation. In this paper, we explore a novel application of AI/ML on policy listings data that poses its own unique challenges, by outlining the holistic AI-based platform we developed, ECLIPSE (Elegant Cleaning and Labeling of Insurance Policies while Standardizing Entities). With ECLIPSE, actuaries not only save time on data preparation but can build more effective loss models and provide crisper insights. © 2022 by the authors.",reinsurers possess high volumes of policy listings data from insurers  which they use to provide insurers with analytical insights and modeling that guide reinsurance treaties  these insurers often act on the same data for their own internal modeling and analytics needs  the problem is this data is messy and needs significant preparation in order to extract meaningful insights  traditionally  this has required intensive manual labor from actuaries  however  a host of modern ai techniques and ml system architectures introduced in the past decade can be applied to the problem of insurance data preparation  in this paper  we explore a novel application of ai ml on policy listings data that poses its own unique challenges  by outlining the holistic ai based platform we developed  eclipse  elegant cleaning and labeling of insurance policies while standardizing entities   with eclipse  actuaries not only save time on data preparation but can build more effective loss models and provide crisper insights         by the authors ,6.4471774,6.0238404,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Adaptive Kernel Firefly Algorithm Based Feature Selection and Q-Learner Machine Learning Models in Cloud,"CC's (Cloud Computing) networks are distributed and dynamic as signals appear/disappear or lose significance. MLTs (Machine learning Techniques) train datasets which sometime are inadequate in terms of sample for inferring information. A dynamic strategy, DevMLOps (Development Machine Learning Operations) used in automatic selections and tunings of MLTs result in significant performance differences. But, the scheme has many disadvantages including continuity in training, more samples and training time in feature selections and increased classification execution times. RFEs (Recursive Feature Eliminations) are computationally very expensive in its operations as it traverses through each feature without considering correlations between them. This problem can be overcome by the use of Wrappers as they select better features by accounting for test and train datasets. The aim of this paper is to use DevQLMLOps for automated tuning and selections based on orchestrations and messaging between containers. The proposed AKFA (Adaptive Kernel Firefly Algorithm) is for selecting features for CNM (Cloud Network Monitoring) operations. AKFA methodology is demonstrated using CNSD (Cloud Network Security Dataset) with satisfactory results in the performance metrics like precision, recall, F-measure and accuracy used. © 2023 CRL Publishing. All rights reserved.",cc s  cloud computing  networks are distributed and dynamic as signals appear disappear or lose significance  mlts  machine learning techniques  train datasets which sometime are inadequate in terms of sample for inferring information  a dynamic strategy  devmlops  development machine learning operations  used in automatic selections and tunings of mlts result in significant performance differences  but  the scheme has many disadvantages including continuity in training  more samples and training time in feature selections and increased classification execution times  rfes  recursive feature eliminations  are computationally very expensive in its operations as it traverses through each feature without considering correlations between them  this problem can be overcome by the use of wrappers as they select better features by accounting for test and train datasets  the aim of this paper is to use devqlmlops for automated tuning and selections based on orchestrations and messaging between containers  the proposed akfa  adaptive kernel firefly algorithm  is for selecting features for cnm  cloud network monitoring  operations  akfa methodology is demonstrated using cnsd  cloud network security dataset  with satisfactory results in the performance metrics like precision  recall  f measure and accuracy used         crl publishing  all rights reserved ,3.4483328,5.4686213,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Deep Lake: a Lakehouse for Deep Learning,"Traditional data lakes provide critical data infrastructure for analytical workloads by enabling time travel, running SQL queries, ingesting data with ACID transactions, and visualizing petabyte-scale datasets on cloud storage. They allow organizations to break down data silos, unlock data-driven decision-making, improve operational efficiency, and reduce costs. However, as deep learning usage increases, traditional data lakes are not well-designed for applications such as natural language processing (NLP), audio processing, computer vision, and applications involving non-tabular datasets. This paper presents Deep Lake, an open-source lakehouse for deep learning applications developed at Activeloop12. Deep Lake maintains the benefits of a vanilla data lake with one key difference: it stores complex data, such as images, videos, annotations, as well as tabular data, in the form of tensors and rapidly streams the data over the network to (a) Tensor Query Language, (b) in-browser visualization engine, or (c) deep learning frameworks without sacrificing GPU utilization. Datasets stored in Deep Lake can be accessed from PyTorch [58], TensorFlow [25], JAX [31], and integrate with numerous MLOps tools. © 2023 13th Annual Conference on Innovative Data Systems Research, CIDR 2023. All rights reserved.",traditional data lakes provide critical data infrastructure for analytical workloads by enabling time travel  running sql queries  ingesting data with acid transactions  and visualizing petabyte scale datasets on cloud storage  they allow organizations to break down data silos  unlock data driven decision making  improve operational efficiency  and reduce costs  however  as deep learning usage increases  traditional data lakes are not well designed for applications such as natural language processing  nlp   audio processing  computer vision  and applications involving non tabular datasets  this paper presents deep lake  an open source lakehouse for deep learning applications developed at activeloop    deep lake maintains the benefits of a vanilla data lake with one key difference  it stores complex data  such as images  videos  annotations  as well as tabular data  in the form of tensors and rapidly streams the data over the network to  a  tensor query language   b  in browser visualization engine  or  c  deep learning frameworks without sacrificing gpu utilization  datasets stored in deep lake can be accessed from pytorch       tensorflow       jax       and integrate with numerous mlops tools           th annual conference on innovative data systems research  cidr       all rights reserved ,9.5305,6.0749497,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Is MLOps different in Industry 4.0? General and Specific Challenges,"An important part of the Industry 4.0 vision is the use of machine learning (ML) techniques to create novel capabilities and flexibility in industrial production processes. Currently, there is a strong emphasis on MLOps as an enabling collection of practices, techniques, and tools to integrate ML into industrial practice. However, while MLOps is often discussed in the context of pure software systems, Industry 4.0 systems received much less attention. So far, there is no specialized research for Industry 4.0 in this regard. In this position paper, we discuss whether MLOps in Industry 4.0 leads to significantly different challenges compared to typical Internet systems. We identify both context-independent MLOps challenges (general challenges) as well as challenges particular to Industry 4.0 (specific challenges) and conclude that MLOps works very similarly in Industry 4.0 systems to pure software systems. This indicates that existing tools and approaches are also mostly suited for the Industry 4.0 context. Copyright © 2022 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.",an important part of the industry     vision is the use of machine learning  ml  techniques to create novel capabilities and flexibility in industrial production processes  currently  there is a strong emphasis on mlops as an enabling collection of practices  techniques  and tools to integrate ml into industrial practice  however  while mlops is often discussed in the context of pure software systems  industry     systems received much less attention  so far  there is no specialized research for industry     in this regard  in this position paper  we discuss whether mlops in industry     leads to significantly different challenges compared to typical internet systems  we identify both context independent mlops challenges  general challenges  as well as challenges particular to industry      specific challenges  and conclude that mlops works very similarly in industry     systems to pure software systems  this indicates that existing tools and approaches are also mostly suited for the industry     context  copyright        by scitepress   science and technology publications  lda  all rights reserved ,10.203769,4.107851,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
"MLOps: Practices, Maturity Models, Roles, Tools, and Challenges - A Systematic Literature Review","Context: The development of machine learning solutions has increased significantly due to the advancement of technology based on artificial intelligence. MLOps have emerged as an approach to minimizing efforts and improving integration between those who are in the process of deploying the models in the production environment. Objective: This paper undertakes a systematic literature review in order to identify practices, standards, roles, maturity models, challenges, and tools related to MLOps. Method: The study is founded on an automatic search method of selected digital libraries that applies selection and quality criteria to identify suitable papers that underpin the research. Results: The search initially found 1,905 articles of which 30 papers were selected for analysis. This analysis led to findings that made it possible to achieve the objectives of the research. Conclusion: The results allowed us to conclude that MLOps is still in its initial stage, and to recognize that there is an opportunity to undertake further academic studies that will prompt organizations to adopt MLOps practices. Copyright © 2022 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.",context  the development of machine learning solutions has increased significantly due to the advancement of technology based on artificial intelligence  mlops have emerged as an approach to minimizing efforts and improving integration between those who are in the process of deploying the models in the production environment  objective  this paper undertakes a systematic literature review in order to identify practices  standards  roles  maturity models  challenges  and tools related to mlops  method  the study is founded on an automatic search method of selected digital libraries that applies selection and quality criteria to identify suitable papers that underpin the research  results  the search initially found       articles of which    papers were selected for analysis  this analysis led to findings that made it possible to achieve the objectives of the research  conclusion  the results allowed us to conclude that mlops is still in its initial stage  and to recognize that there is an opportunity to undertake further academic studies that will prompt organizations to adopt mlops practices  copyright        by scitepress   science and technology publications  lda  all rights reserved ,9.769977,4.421277,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
"In vitro and in vivo antibacterial activities of a novel quinolone compound, OPS-2071, against Clostridioides difficile","OPS-2071 is a novel quinolone antibacterial agent characterized by low oral absorption that reduces the risk of adverse events typical of fluoroquinolone class antibiotics. The in vitro and in vivo antibacterial activities of OPS-2071 against Clostridioides difficile were evaluated in comparison to vancomycin and fidaxomicin. OPS-2071 exhibited potent antibacterial activity against 54 clinically isolated C. difficile strains with a MIC of 0.125mg/ml (MIC50) and 0.5mg/ml (MIC90), making it more active than vancomycin on a concentration basis (MIC50, 2mg/ml; MIC90, 4mg/ml) and comparable to fidaxomicin (MIC50, 0.063mg/ml; MIC90, 8μg/ml). OPS-2071 showed equally potent antibacterial activity against both hypervirulent and nonhypervirulent strains, while a significant difference in susceptibility to fidaxomicin was observed. Spontaneous resistance to OPS-2071 and vancomycin was not observed; however, resistance to fidaxomicin was observed at 4× MIC. The mutant prevention concentration of OPS-2071 was 16-fold lower than those of fidaxomicin and vancomycin, and the postantibiotic effect of OPS-2071 was longer than those of fidaxomicin and vancomycin. Also, OPS-2071 showed low systemic exposure, with OPS-2071 having 2.9% oral bioavailability at 1 mg/kg in rats. Furthermore, OPS-2071 showed significant in vivo efficacy at 0.0313 mg/kg/day (50% effective doses), 39.0-fold and 52.1-fold lower than those of vancomycin and fidaxomicin, respectively, in a hamster model of C. difficile infection. OPS-2071 has the potential to become a new therapeutic option for treating C. difficile infection. © 2021 American Society for Microbiology. All rights reserved.",ops      is a novel quinolone antibacterial agent characterized by low oral absorption that reduces the risk of adverse events typical of fluoroquinolone class antibiotics  the in vitro and in vivo antibacterial activities of ops      against clostridioides difficile were evaluated in comparison to vancomycin and fidaxomicin  ops      exhibited potent antibacterial activity against    clinically isolated c  difficile strains with a mic of      mg ml  mic    and    mg ml  mic     making it more active than vancomycin on a concentration basis  mic     mg ml  mic     mg ml  and comparable to fidaxomicin  mic         mg ml  mic      g ml   ops      showed equally potent antibacterial activity against both hypervirulent and nonhypervirulent strains  while a significant difference in susceptibility to fidaxomicin was observed  spontaneous resistance to ops      and vancomycin was not observed  however  resistance to fidaxomicin was observed at    mic  the mutant prevention concentration of ops      was    fold lower than those of fidaxomicin and vancomycin  and the postantibiotic effect of ops      was longer than those of fidaxomicin and vancomycin  also  ops      showed low systemic exposure  with ops      having      oral bioavailability at   mg kg in rats  furthermore  ops      showed significant in vivo efficacy at        mg kg day      effective doses        fold and      fold lower than those of vancomycin and fidaxomicin  respectively  in a hamster model of c  difficile infection  ops      has the potential to become a new therapeutic option for treating c  difficile infection         american society for microbiology  all rights reserved ,4.7451158,2.9176562,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
"Proceedings - Workshop on Software Engineering for Responsible AI, SE4RAI 2022",The proceedings contain 8 papers. The topics discussed include: operationalizing machine learning models - a systematic literature review; robustness testing of a machine learning-based road object detection system: an industrial case; towards trusting the ethical evolution of autonomous dynamic ecosystems; the concept of ethical digital identities; challenges in machine learning application development: an industrial experience report; non-functional requirements for machine learning: an exploration of system scope and interest; augur: a step towards realistic drift detection in production ML systems; and MLOps: a guide to its adoption in the context of responsible AI.,the proceedings contain   papers  the topics discussed include  operationalizing machine learning models   a systematic literature review  robustness testing of a machine learning based road object detection system  an industrial case  towards trusting the ethical evolution of autonomous dynamic ecosystems  the concept of ethical digital identities  challenges in machine learning application development  an industrial experience report  non functional requirements for machine learning  an exploration of system scope and interest  augur  a step towards realistic drift detection in production ml systems  and mlops  a guide to its adoption in the context of responsible ai ,8.352956,5.4408855,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Interpretation of Machine Learning Model Using Medical Record Visual Analytics,"The state of the art of medical application that being implemented are mostly based on common machine learning model. Nevertheless, one of the drawbacks of the practice of medical diagnosis is the lack of explanation on the proposed solution, which is also known as a black box, without knowing the internal decision process between the input and output. It will lead to untrustworthiness and difficult to understand by the medical expert. They are questioning how the complexity of machine learning methods decide on the output without clear and understandable explanations. Moreover, in machine learning field the characteristic of a black box model may lead to biased data analysis and incorrect output decisions. There is work that uses visual analytics techniques to interpret the machine learning output to ease the understanding of medical experts. However, the functionality of existed and combined visual analytics techniques is not sufficient to visualized and interpreted the output of machine learning operation. Other visual analytic techniques faced the same problem, unreliability to produce strong reason on the output when working with complex machine learning models. This paper analyzed several visual analytics approaches instantiated in machine learning algorithm for medical record analytics. The motivation of this paper is to allow medical experts to understand the interpretation of a black box machine learning model in predicting medical outcome. This paper studied on the effectiveness of visual analytics techniques to identify the appropriate technique to be instantiated to the machine learning algorithm to further elaborate the results obtained by demonstrating transparency, interpretability and explainability of the machine learning algorithm. The visual analytics that are been studied are Local Interpretable Model-agnostic Explanations (LIME) and Shapley Additive exPlanations (SHAP). Based on the comparison of LIME and SHAP methods, this paper found that SHAP has consistent interpretability as compared to LIME. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.",the state of the art of medical application that being implemented are mostly based on common machine learning model  nevertheless  one of the drawbacks of the practice of medical diagnosis is the lack of explanation on the proposed solution  which is also known as a black box  without knowing the internal decision process between the input and output  it will lead to untrustworthiness and difficult to understand by the medical expert  they are questioning how the complexity of machine learning methods decide on the output without clear and understandable explanations  moreover  in machine learning field the characteristic of a black box model may lead to biased data analysis and incorrect output decisions  there is work that uses visual analytics techniques to interpret the machine learning output to ease the understanding of medical experts  however  the functionality of existed and combined visual analytics techniques is not sufficient to visualized and interpreted the output of machine learning operation  other visual analytic techniques faced the same problem  unreliability to produce strong reason on the output when working with complex machine learning models  this paper analyzed several visual analytics approaches instantiated in machine learning algorithm for medical record analytics  the motivation of this paper is to allow medical experts to understand the interpretation of a black box machine learning model in predicting medical outcome  this paper studied on the effectiveness of visual analytics techniques to identify the appropriate technique to be instantiated to the machine learning algorithm to further elaborate the results obtained by demonstrating transparency  interpretability and explainability of the machine learning algorithm  the visual analytics that are been studied are local interpretable model agnostic explanations  lime  and shapley additive explanations  shap   based on the comparison of lime and shap methods  this paper found that shap has consistent interpretability as compared to lime          the author s   under exclusive license to springer nature singapore pte ltd ,5.9664087,5.1059175,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
A Graphical Toolkit for Longitudinal Dataset Maintenance and Predictive Model Training in Health Care,"Background Predictive analytic models, including machine learning (ML) models, are increasingly integrated into electronic health record (EHR)-based decision support tools for clinicians. These models have the potential to improve care, but are challenging to internally validate, implement, and maintain over the long term. Principles of ML operations (MLOps) may inform development of infrastructure to support the entire ML lifecycle, from feature selection to long-term model deployment and retraining. Objectives This study aimed to present the conceptual prototypes for a novel predictive model management system and to evaluate the acceptability of the system among three groups of end users. Methods Based on principles of user-centered software design, human-computer interaction, and ethical design, we created graphical prototypes of a web-based MLOps interface to support the construction, deployment, and maintenance of models using EHR data. To assess the acceptability of the interface, we conducted semistructured user interviews with three groups of users (health informaticians, clinical and data stakeholders, chief information officers) and evaluated preliminary usability using the System Usability Scale (SUS). We subsequently revised prototypes based on user input and developed user case studies. Results Our prototypes include design frameworks for feature selection, model training, deployment, long-term maintenance, visualization over time, and cross-functional collaboration. Users were able to complete 71% of prompted tasks without assistance. The average SUS score of the initial prototype was 75.8 out of 100, translating to a percentile range of 70 to 79, a letter grade of B, and an adjective rating of good. We reviewed persona-based case studies that illustrate functionalities of this novel prototype. Conclusion The initial graphical prototypes of this MLOps system are preliminarily usable and demonstrate an unmet need within the clinical informatics landscape. © 2022 American Institute of Physics Inc.. All rights reserved.",background predictive analytic models  including machine learning  ml  models  are increasingly integrated into electronic health record  ehr  based decision support tools for clinicians  these models have the potential to improve care  but are challenging to internally validate  implement  and maintain over the long term  principles of ml operations  mlops  may inform development of infrastructure to support the entire ml lifecycle  from feature selection to long term model deployment and retraining  objectives this study aimed to present the conceptual prototypes for a novel predictive model management system and to evaluate the acceptability of the system among three groups of end users  methods based on principles of user centered software design  human computer interaction  and ethical design  we created graphical prototypes of a web based mlops interface to support the construction  deployment  and maintenance of models using ehr data  to assess the acceptability of the interface  we conducted semistructured user interviews with three groups of users  health informaticians  clinical and data stakeholders  chief information officers  and evaluated preliminary usability using the system usability scale  sus   we subsequently revised prototypes based on user input and developed user case studies  results our prototypes include design frameworks for feature selection  model training  deployment  long term maintenance  visualization over time  and cross functional collaboration  users were able to complete     of prompted tasks without assistance  the average sus score of the initial prototype was      out of      translating to a percentile range of    to     a letter grade of b  and an adjective rating of good  we reviewed persona based case studies that illustrate functionalities of this novel prototype  conclusion the initial graphical prototypes of this mlops system are preliminarily usable and demonstrate an unmet need within the clinical informatics landscape         american institute of physics inc   all rights reserved ,9.03531,8.38342,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Agility in Software 2.0 – Notebook Interfaces and MLOps with Buttresses and Rebars,"Artificial intelligence through machine learning is increasingly used in the digital society. Solutions based on machine learning bring both great opportunities, thus coined “Software 2.0,” but also great challenges for the engineering community to tackle. Due to the experimental approach used by data scientists when developing machine learning models, agility is an essential characteristic. In this keynote address, we discuss two contemporary development phenomena that are fundamental in machine learning development, i.e., notebook interfaces and MLOps. First, we present a solution that can remedy some of the intrinsic weaknesses of working in notebooks by supporting easy transitions to integrated development environments. Second, we propose reinforced engineering of AI systems by introducing metaphorical buttresses and rebars in the MLOps context. Machine learning-based solutions are dynamic in nature, and we argue that reinforced continuous engineering is required to quality assure the trustworthy AI systems of tomorrow. © 2022, Springer Nature Switzerland AG.",artificial intelligence through machine learning is increasingly used in the digital society  solutions based on machine learning bring both great opportunities  thus coined  software       but also great challenges for the engineering community to tackle  due to the experimental approach used by data scientists when developing machine learning models  agility is an essential characteristic  in this keynote address  we discuss two contemporary development phenomena that are fundamental in machine learning development  i e   notebook interfaces and mlops  first  we present a solution that can remedy some of the intrinsic weaknesses of working in notebooks by supporting easy transitions to integrated development environments  second  we propose reinforced engineering of ai systems by introducing metaphorical buttresses and rebars in the mlops context  machine learning based solutions are dynamic in nature  and we argue that reinforced continuous engineering is required to quality assure the trustworthy ai systems of tomorrow          springer nature switzerland ag ,7.367257,4.6757855,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
"47th International Conference on Very Large Data Bases, VLDB 2021","The proceedings contain 53 papers. The special focus in this conference is on Very Large Data Bases. The topics include: Udo: Universal database optimization using reinforcement learning; internet traffic analysis at scale; the power of summarization in graph mining and learning: Smaller data, faster methods, more interpretability; summarizing patients like mine via an on-demand consultation service; towards scalable online machine learning collaborations with openml; From ML models to intelligent applications: The rise of mlops; designing production-friendly machine learning; tscache: An efficient flash-based caching scheme for time-series data workloads; mp-rw-lsh: An efficient multi-probe lsh solution to anns-l1; view selection over knowledge graphs in triple stores; frequency-hiding order-preserving encryption with small client storage; modularis: Modular relational analytics over heterogeneous distributed platforms; time-topology analysis; quantifying identifiability to choose and audit ε in differentially private deep learning; data management in microservices: State of the practice, challenges, and research directions.",the proceedings contain    papers  the special focus in this conference is on very large data bases  the topics include  udo  universal database optimization using reinforcement learning  internet traffic analysis at scale  the power of summarization in graph mining and learning  smaller data  faster methods  more interpretability  summarizing patients like mine via an on demand consultation service  towards scalable online machine learning collaborations with openml  from ml models to intelligent applications  the rise of mlops  designing production friendly machine learning  tscache  an efficient flash based caching scheme for time series data workloads  mp rw lsh  an efficient multi probe lsh solution to anns l   view selection over knowledge graphs in triple stores  frequency hiding order preserving encryption with small client storage  modularis  modular relational analytics over heterogeneous distributed platforms  time topology analysis  quantifying identifiability to choose and audit   in differentially private deep learning  data management in microservices  state of the practice  challenges  and research directions ,8.208454,7.9061813,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Metamodel Specialisation based Tool Extension,"This paper outlines our Deep Learning Lifecycle Data Management system. It consists of two major parts: the LDM Core Tool - a simple data logging tool; and an Extension Mechanism - this mechanism allows the user to extend the simple LDM Core Tool to match their specific requirements. Current extensions support adding new visualisations for data stored on the server. Our approach allows the Core Tool to be a complete black box; we need only a metamodel denoting the logical structure of the stored data. By then specialising this metamodel we can define an Extension Metamodel which, when communicated to the tool through configuration, allows us to define and thus add the extensions. © 2022 University of Latvia All Rights Reserved.",this paper outlines our deep learning lifecycle data management system  it consists of two major parts  the ldm core tool   a simple data logging tool  and an extension mechanism   this mechanism allows the user to extend the simple ldm core tool to match their specific requirements  current extensions support adding new visualisations for data stored on the server  our approach allows the core tool to be a complete black box  we need only a metamodel denoting the logical structure of the stored data  by then specialising this metamodel we can define an extension metamodel which  when communicated to the tool through configuration  allows us to define and thus add the extensions         university of latvia all rights reserved ,7.678268,4.764667,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
LAOps: Learning Analytics with Privacy-aware MLOps,"The intake of computer science faculty has rapidly increased with simultaneous reductions to course personnel. Presently, the economy is recovering slightly, and students are entering the working life already during their studies. These reasons have fortified demands for flexibility to keep the target graduation time the same as before, even shorten it. Required flexibility is created by increasing distance learning and MOOCs, which challenges students’ self-regulation skills. Teaching methods and systems need to evolve to support students’ progress. At the curriculum design level, such learning analytics tools have already been taken into use. This position paper outlines a next-generation, course-scope analytics tool that utilises data from both the learning management system and Gitlab, which works here as a channel of student submissions. Gitlab provides GitOps, and GitOps will be enhanced with machine learning, thereby transforming as MLOps. MLOps that performs learning analytics, is called here LAOps. For analysis, data is copied to the cloud, and for that, it must be properly protected, after which models are trained and analyses performed. The results are provided to both teachers and students and utilised for personalisation and differentiation of exercises based on students’ skill level. Copyright © 2022 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.",the intake of computer science faculty has rapidly increased with simultaneous reductions to course personnel  presently  the economy is recovering slightly  and students are entering the working life already during their studies  these reasons have fortified demands for flexibility to keep the target graduation time the same as before  even shorten it  required flexibility is created by increasing distance learning and moocs  which challenges students  self regulation skills  teaching methods and systems need to evolve to support students  progress  at the curriculum design level  such learning analytics tools have already been taken into use  this position paper outlines a next generation  course scope analytics tool that utilises data from both the learning management system and gitlab  which works here as a channel of student submissions  gitlab provides gitops  and gitops will be enhanced with machine learning  thereby transforming as mlops  mlops that performs learning analytics  is called here laops  for analysis  data is copied to the cloud  and for that  it must be properly protected  after which models are trained and analyses performed  the results are provided to both teachers and students and utilised for personalisation and differentiation of exercises based on students  skill level  copyright        by scitepress   science and technology publications  lda  all rights reserved ,8.333433,4.764125,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Building an effective data science practice: A framework to bootstrap and manage a successful data science practice,"Gain a deep understanding of data science and the thought process needed to solve problems in that field using the required techniques, technologies and skills that go into forming an interdisciplinary team. This book will enable you to set up an effective team of engineers, data scientists, analysts, and other stakeholders that can collaborate effectively on crucial aspects such as problem formulation, execution of experiments, and model performance evaluation. You'll start by delving into the fundamentals of data science - classes of data science problems, data science techniques and their applications - and gradually build up to building a professional reference operating model for a data science function in an organization. This operating model covers the roles and skills required in a team, the techniques and technologies they use, and the best practices typically followed in executing data science projects. Building an Effective Data Science Practice provides a common base of reference knowledge and solutions, and addresses the kinds of challenges that arise to ensure your data science team is both productive and aligned with the business goals from the very start. Reinforced with real examples, this book allows you to confidently determine the strategic answers to effectively align your business goals with the operations of the data science practice. © 2022 by Vineet Raina and Srinath Krishnamurthy. All rights reserved.",gain a deep understanding of data science and the thought process needed to solve problems in that field using the required techniques  technologies and skills that go into forming an interdisciplinary team  this book will enable you to set up an effective team of engineers  data scientists  analysts  and other stakeholders that can collaborate effectively on crucial aspects such as problem formulation  execution of experiments  and model performance evaluation  you ll start by delving into the fundamentals of data science   classes of data science problems  data science techniques and their applications   and gradually build up to building a professional reference operating model for a data science function in an organization  this operating model covers the roles and skills required in a team  the techniques and technologies they use  and the best practices typically followed in executing data science projects  building an effective data science practice provides a common base of reference knowledge and solutions  and addresses the kinds of challenges that arise to ensure your data science team is both productive and aligned with the business goals from the very start  reinforced with real examples  this book allows you to confidently determine the strategic answers to effectively align your business goals with the operations of the data science practice         by vineet raina and srinath krishnamurthy  all rights reserved ,9.533713,6.227326,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Data centric approach to Chinese Medical Speech Recognition,"Concerning the deleopment of Chinese medical speech recognition technology, this study re-addresses earlier encountered issues in accordance with the process of Machine Learning Engineering for Production (MLOps) from a data centric perspective. First is the new segmentation of speech utterances to meet sentences completeness for all utterances in the colllected Chinese Medical Speech Corpus (ChiMeS). Second is optimization of Joint CTC/Attention model through data augmentation in boosting recognition performance out of very limited speech corpus. Overall, to facilitate the development of Chinese medical speech recognition, this paper contributes: (1) The ChiMeS corpus, the first Chinese Medicine Speech corpus of its kind, which is 14.4 hours, with a total of 7,225 sentences. (2) A trained Joint CTC/Attention ASR model by ChiMeS-14, yielding a Character Error Rate (CER) of 13.65% and a Keyword Error Rate (KER) of 20.82%, respectively, when tested on the ChiMeS-14 testing set. And (3) an evaluation platform set up to compare performance of other ASR models. All the released resources can be found in the ChiMeS portal (https://iclab.ee.ntust.edu.tw/home). © 2021 ROCLING 2021 - Proceedings of the 33rd Conference on Computational Linguistics and Speech Processing. All rights reserved.",concerning the deleopment of chinese medical speech recognition technology  this study re addresses earlier encountered issues in accordance with the process of machine learning engineering for production  mlops  from a data centric perspective  first is the new segmentation of speech utterances to meet sentences completeness for all utterances in the colllected chinese medical speech corpus  chimes   second is optimization of joint ctc attention model through data augmentation in boosting recognition performance out of very limited speech corpus  overall  to facilitate the development of chinese medical speech recognition  this paper contributes      the chimes corpus  the first chinese medicine speech corpus of its kind  which is      hours  with a total of       sentences      a trained joint ctc attention asr model by chimes     yielding a character error rate  cer  of        and a keyword error rate  ker  of         respectively  when tested on the chimes    testing set  and     an evaluation platform set up to compare performance of other asr models  all the released resources can be found in the chimes portal  https   iclab ee ntust edu tw home          rocling        proceedings of the   rd conference on computational linguistics and speech processing  all rights reserved ,4.1395493,6.138046,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
A Digital Twin Architecture Model Applied with MLOps Techniques to Improve Short-Term Energy Consumption Prediction,"Using extensive databases and known algorithms to predict short-term energy consumption comprises most computational solutions based on artificial intelligence today. State-of-the-art approaches validate their prediction models in offline environments that disregard automation, quality monitoring, and retraining challenges present in online scenarios. The existing demand response initiatives lack personalization, thus not engaging consumers. Obtaining specific and valuable recommendations is difficult for most digital platforms due to their solution pattern: Extensive database, specialized algorithms, and using profiles with similar aspects. The challenges and present personalization tactics have been researched by adopting a digital twin model. This study creates a different approach by adding structural topology to build a new category of recommendation platform using the digital twin model with real-time data collected by IoT sensors to improve machine learning methods. A residential study case with 31 IoT smart meter and smart plug devices with 19-month data (measurements performed each second) validated Digital Twin MLOps architecture for personalized demand response suggestions based on online short-term energy consumption prediction. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.",using extensive databases and known algorithms to predict short term energy consumption comprises most computational solutions based on artificial intelligence today  state of the art approaches validate their prediction models in offline environments that disregard automation  quality monitoring  and retraining challenges present in online scenarios  the existing demand response initiatives lack personalization  thus not engaging consumers  obtaining specific and valuable recommendations is difficult for most digital platforms due to their solution pattern  extensive database  specialized algorithms  and using profiles with similar aspects  the challenges and present personalization tactics have been researched by adopting a digital twin model  this study creates a different approach by adding structural topology to build a new category of recommendation platform using the digital twin model with real time data collected by iot sensors to improve machine learning methods  a residential study case with    iot smart meter and smart plug devices with    month data  measurements performed each second  validated digital twin mlops architecture for personalized demand response suggestions based on online short term energy consumption prediction         by the authors  licensee mdpi  basel  switzerland ,7.115746,5.1545053,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
"iStar 2022 - Proceedings of the 15th International iStar Workshop, co-located with 41th International Conference on Conceptual Modeling, ER 2022",The proceedings contain 8 papers. The topics discussed include: using i to analyze collaboration challenges in MLOps project teams; user story quality assessment based on multi-dimensional perspective: a preliminary framework; use of a i extension for machine learning: a real case study; iStar support to open innovation management; towards goal-based generation of reinforcement learning domain simulations; software analytics tools: an intentional view; iTactic: a goal model evaluation tool to support strategic decision-making; and evaluation of iStar 2.0 models using linear programming.,the proceedings contain   papers  the topics discussed include  using i to analyze collaboration challenges in mlops project teams  user story quality assessment based on multi dimensional perspective  a preliminary framework  use of a i extension for machine learning  a real case study  istar support to open innovation management  towards goal based generation of reinforcement learning domain simulations  software analytics tools  an intentional view  itactic  a goal model evaluation tool to support strategic decision making  and evaluation of istar     models using linear programming ,8.986324,6.3811054,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
ModelOps for enhanced decision-making and governance in emergency control rooms,"For mission critical (MC) applications such as bushfire emergency management systems (EMS), understanding the current situation as a disaster unfolds is critical to saving lives, infrastructure and the environment. Incident control-room operators manage complex information and systems, especially with the emergence of Big Data. They are increasingly making decisions supported by artificial intelligence (AI) and machine learning (ML) tools for data analysis, prediction and decision-making. As the volume, speed and complexity of information increases due to more frequent fire events, greater availability of myriad IoT sensors, smart devices, satellite data and burgeoning use of social media, the advances in AI and ML that help to manage Big Data and support decision-making are increasingly perceived as “Black Box”. This paper aims to scope the requirements for bushfire EMS to improve Big Data management and governance of AI/ML. An analysis of ModelOps technology, used increasingly in the commercial sector, is undertaken to determine what components might be fit-for-purpose. The result is a novel set of ModelOps features, EMS requirements and an EMS-ModelOps framework that resolves more than 75% of issues whilst being sufficiently generic to apply to other types of mission-critical applications. © 2022, The Author(s).",for mission critical  mc  applications such as bushfire emergency management systems  ems   understanding the current situation as a disaster unfolds is critical to saving lives  infrastructure and the environment  incident control room operators manage complex information and systems  especially with the emergence of big data  they are increasingly making decisions supported by artificial intelligence  ai  and machine learning  ml  tools for data analysis  prediction and decision making  as the volume  speed and complexity of information increases due to more frequent fire events  greater availability of myriad iot sensors  smart devices  satellite data and burgeoning use of social media  the advances in ai and ml that help to manage big data and support decision making are increasingly perceived as  black box   this paper aims to scope the requirements for bushfire ems to improve big data management and governance of ai ml  an analysis of modelops technology  used increasingly in the commercial sector  is undertaken to determine what components might be fit for purpose  the result is a novel set of modelops features  ems requirements and an ems modelops framework that resolves more than     of issues whilst being sufficiently generic to apply to other types of mission critical applications          the author s  ,11.856739,5.448495,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Ease.ML: A Lifecycle Management System for MLDev and MLOps,"We present Ease.ML, a lifecycle management system for machine learning (ML). Unlike many existing works, which focus on improving individual steps during the lifecycle of ML application development, Ease.ML focuses on managing and automating the entire lifecycle itself. We present user scenarios that have motivated the development of Ease.ML, the eight-step Ease.ML process that covers the lifecycle of ML application development; the foundation of Ease.ML in terms of a probabilistic database model and its connection to information theory; and our lessons learned, which hopefully can inspire future research. © CIDR 2021.All rights reserved",we present ease ml  a lifecycle management system for machine learning  ml   unlike many existing works  which focus on improving individual steps during the lifecycle of ml application development  ease ml focuses on managing and automating the entire lifecycle itself  we present user scenarios that have motivated the development of ease ml  the eight step ease ml process that covers the lifecycle of ml application development  the foundation of ease ml in terms of a probabilistic database model and its connection to information theory  and our lessons learned  which hopefully can inspire future research    cidr      all rights reserved,8.104076,5.3096967,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Application of machine learning in corrosion inhibition study; [PRIMENA MAŠINSKOG UČENJA U PROUČAVANJU INHIBICIJE KOROZIJE],"Artificial intelligence is a branch of science concerned with teaching machines to think and act like humans. Machine learning is concerned with enabling computers to perform tasks without the need for explicit programming. Machine Learning enables computers to learn without the need for explicit programming. Machine Learning is a broad field that encompasses a wide range of machine learning operations such as clustering, classification, and the development of predictive models. Machine Learning (ML) and Deep Learning (DL) research is now finding a home in both industry and academia. Machine Learning technologies are increasingly being used in medical imaging. To detect tumours and other malignant growths in the human body. Deep Learning is making significant contributions to the advancement of industrial robotics. Machine learning algorithms are used in the self-driving car industry to guide the vehicle to its destination. Deep Learning and Machine Learning are also used in corrosion science and engineering. They are used to choose the inhibitor molecules from a large pool of available molecules. © 2022 Authors.",artificial intelligence is a branch of science concerned with teaching machines to think and act like humans  machine learning is concerned with enabling computers to perform tasks without the need for explicit programming  machine learning enables computers to learn without the need for explicit programming  machine learning is a broad field that encompasses a wide range of machine learning operations such as clustering  classification  and the development of predictive models  machine learning  ml  and deep learning  dl  research is now finding a home in both industry and academia  machine learning technologies are increasingly being used in medical imaging  to detect tumours and other malignant growths in the human body  deep learning is making significant contributions to the advancement of industrial robotics  machine learning algorithms are used in the self driving car industry to guide the vehicle to its destination  deep learning and machine learning are also used in corrosion science and engineering  they are used to choose the inhibitor molecules from a large pool of available molecules         authors ,5.9314747,5.157057,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Supervised Compression for Resource-Constrained Edge Computing Systems,"There has been much interest in deploying deep learning algorithms on low-powered devices, including smart-phones, drones, and medical sensors. However, full-scale deep neural networks are often too resource-intensive in terms of energy and storage. As a result, the bulk part of the machine learning operation is therefore often carried out on an edge server, where the data is compressed and transmitted. However, compressing data (such as images) leads to transmitting information irrelevant to the supervised task. Another popular approach is to split the deep network between the device and the server while compressing intermediate features. To date, however, such split computing strategies have barely outperformed the aforementioned naive data compression baselines due to their inefficient approaches to feature compression. This paper adopts ideas from knowledge distillation and neural image compression to compress intermediate feature representations more efficiently. Our supervised compression approach uses a teacher model and a student model with a stochastic bottleneck and learnable prior for entropy coding (Entropic Student). We compare our approach to various neural image and feature compression baselines in three vision tasks and found that it achieves better supervised rate-distortion performance while maintaining smaller end-to-end latency. We furthermore show that the learned feature representations can be tuned to serve multiple downstream tasks.  © 2022 IEEE.",there has been much interest in deploying deep learning algorithms on low powered devices  including smart phones  drones  and medical sensors  however  full scale deep neural networks are often too resource intensive in terms of energy and storage  as a result  the bulk part of the machine learning operation is therefore often carried out on an edge server  where the data is compressed and transmitted  however  compressing data  such as images  leads to transmitting information irrelevant to the supervised task  another popular approach is to split the deep network between the device and the server while compressing intermediate features  to date  however  such split computing strategies have barely outperformed the aforementioned naive data compression baselines due to their inefficient approaches to feature compression  this paper adopts ideas from knowledge distillation and neural image compression to compress intermediate feature representations more efficiently  our supervised compression approach uses a teacher model and a student model with a stochastic bottleneck and learnable prior for entropy coding  entropic student   we compare our approach to various neural image and feature compression baselines in three vision tasks and found that it achieves better supervised rate distortion performance while maintaining smaller end to end latency  we furthermore show that the learned feature representations can be tuned to serve multiple downstream tasks          ieee ,4.83511,7.2044225,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Inference Time of a CamemBERT Deep Learning Model for Sentiment Analysis of COVID Vaccines on Twitter,"In previous work, we implemented a deep learning model with CamemBERT and PyTorch, and built a microservices architecture using the TorchServe serving library. Without TorchServe, inference time was three times faster when the model was loaded once in memory compared when the model was loaded each time. The preloaded model without TorchServe presented comparable inference time with the TorchServe instance. However, using a PyTorch preloaded model in a web application without TorchServe would necessitate to implement functionalities already present in TorchServe. © 2022 The authors and IOS Press.",in previous work  we implemented a deep learning model with camembert and pytorch  and built a microservices architecture using the torchserve serving library  without torchserve  inference time was three times faster when the model was loaded once in memory compared when the model was loaded each time  the preloaded model without torchserve presented comparable inference time with the torchserve instance  however  using a pytorch preloaded model in a web application without torchserve would necessitate to implement functionalities already present in torchserve         the authors and ios press ,7.568295,7.3510756,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Simple monitoring of endocrine-disrupting chemicals using transgenic Arabidopsis plants expressing medaka estrogen receptor,"Endocrine-disrupting chemicals (EDCs) are widespread contaminants that severely affect the endocrine systems of living organisms. In addition to the conventional instrument-based approaches for quantifying organic pollutants, a monitoring method using transgenic plants has also been proposed. Plants carrying a recombinant receptor gene combined with a reporter gene represent a system for the easy detection of ligands that specifically bind to the receptor molecule. Here, the EDC detection sensitivity of transgenic Arabidopsis plants expressing the medaka (Oryzias latipes) estrogen receptor (mER) and green fluorescent protein (GFP) genes, was assessed. Four transgenic Arabidopsis lines, obtained by transformation with expression plasmids constructed using combinations of two types of the ligand-binding domains of mER, the DNA-binding domain of LexA and the transactivation domain of VP16 in the chimeric receptors, showed significant induction of GFP when germinated on a medium contaminated with 1 ng/mL 4-t-octylphenol (OP). The most sensitive XmEV19-2 plants detected 0.1 ng/mL OP and 1 pg/mL 17β-estradiol. GFP expression was suppressed by the insecticides imidacloprid and fipronil, whereas perfluorooctanesulfonic acid induced it at 0.1 ng/mL. Experiments with river water-based medium showed that XmEV19-2 can be used for monitoring polluted waters, detecting OP at concentrations as low as 5 ng/mL. Notably, XmEV19-2 showed a significant decrease in root length when grown on 0.1 ng/mL OP. mER transgenic plants can be a promising tool for simple monitoring of EDCs, without the need for extraction and concentration steps in sample preparation. © 2021 Elsevier Ltd",endocrine disrupting chemicals  edcs  are widespread contaminants that severely affect the endocrine systems of living organisms  in addition to the conventional instrument based approaches for quantifying organic pollutants  a monitoring method using transgenic plants has also been proposed  plants carrying a recombinant receptor gene combined with a reporter gene represent a system for the easy detection of ligands that specifically bind to the receptor molecule  here  the edc detection sensitivity of transgenic arabidopsis plants expressing the medaka  oryzias latipes  estrogen receptor  mer  and green fluorescent protein  gfp  genes  was assessed  four transgenic arabidopsis lines  obtained by transformation with expression plasmids constructed using combinations of two types of the ligand binding domains of mer  the dna binding domain of lexa and the transactivation domain of vp   in the chimeric receptors  showed significant induction of gfp when germinated on a medium contaminated with   ng ml   t octylphenol  op   the most sensitive xmev     plants detected     ng ml op and   pg ml     estradiol  gfp expression was suppressed by the insecticides imidacloprid and fipronil  whereas perfluorooctanesulfonic acid induced it at     ng ml  experiments with river water based medium showed that xmev     can be used for monitoring polluted waters  detecting op at concentrations as low as   ng ml  notably  xmev     showed a significant decrease in root length when grown on     ng ml op  mer transgenic plants can be a promising tool for simple monitoring of edcs  without the need for extraction and concentration steps in sample preparation         elsevier ltd,4.184939,2.7371838,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Predictive values of serum uric acid and NLRP3 inflammasome in pregnant women with hypertensive disorder complicating pregnancy with acute kidney injury; [血清尿酸及NLRP3炎症小体对妊娠期高血压疾病孕妇并发急性肾损伤的预测价值],"Objective To explore the predictive value of pregnant women with hypertensive disorder complicating pregnancy (HDCP) for acute kidney injury (AKI) by serum uric acid (SUA) and NOD-like receptor heat protein domain-related protein(NLRP)3 inflammasome. Methods From January 2017 to December 2020, a total of 90 cases of HDCP pregnant women admitted to the Shanghai First Maternal and Infant Hospital, Tongji University were included into observation group, and according to whether they were concurrent with AKI, they were further divided into AKI subgroup (n=35) and non-AKI subgroup (n = 55). Meanwhile another 90 healthy pregnant women underwent prenatal examination in the same hospital during the same period were selected into control group. Multivariate unconditional logistic regression analysis was used to analyze the influencing factors of AKI in HDCP pregnant women. The receiver operating characteristics (ROC) curves of different indexes to predict HDCP pregnant women complicated with AKI were drawn, and area under the curve (AUC) was calculated. According to the principle of maximum Youden index, the best critical value of different indexes for predicting HDCP complicated with AKI were determined. The procedure followed in this study met the standards formulated by the Ethics Review Committee of shanghai First Maternal and Infant Hospital, Tongji University and has been approved by it (Approval No. KS2204). Informed consent was obtained from each participate. Results CD There were no significant differences between observation group and control group in age, gestational age and gravidity (P>0. 05). (2) The levels of SUA and NLRP3 inflammasome in observation group were significantly higher than those in control group, and the levels of SUA and NLRP3 inflammasome in AKI subgroup were significantly higher than those in non-AKI subgroup, and the differences were statistically significant (P<0. 05). © Univariate analysis of influencing factors of concurrent with AKI in HDCP pregnant women showed that placental abruption, volumes of postpartum hemorrhage and blood pressure might be the influencing factors of concurrent with AKI in HDCP pregnant women (X2 = 5. 442, 9.091, 6.461; P = 0.019, 0.011, 0.039). (4) Multivariate unconditional logistic regression analysis showed that SUA>361. 8 jumol/L (QR = 1.085, 95%C7: 1.062-1.320, P< 0.001) and NLRP3 inflammasome > 5. 6 (OP = 2.732, 95% CI: 1.074-3.665, P = 0. 003), postpartum hemorrhage were 1 000-1 500 mL and >1 500 mL (OP=l. 971, 1. 863, 95%CI: 1. 011-4.540, 1.016-4.950, P = 0.020, 0.019), and blood pressure were > 160-180 mmHg (1 mmHg = 0. 133 kPa) and >180 mmHg (OP=2. 000, 1. 903; 95%CI: 0. 255-1. 784, 0. 245-1. 795; P=0. 001, 0. 001) were independent risk factors caused concurrent of AKI in HDCP pregnant women. (5) The AUC of SUA combined with NLRP3 inflammasome in predicting AKI in HDCP pregnant women was 0. 966 (95%C7: 0. 962-0. 970, P<0. 05). According to the principle of maximum Youden index, the best critical value of combining SUA and NLRP3 inflammasome in predicting AKI in HDCP pregnant women were 371.2 jumol/L, 5.8, and its sensitivity was 97.5% and specificity was 96.8%. Conclusions The combined assessment of SUA and NLRP3 inflammasome has a good predictive performance for the concurrent of AKI in patients with HDCP, and may provide references for prevention, diagnosis and treatment of early AKI during pregnancy. © Chinese Journal of Obstetrics and Gynecology and Pediatrics.All rights reserved",objective to explore the predictive value of pregnant women with hypertensive disorder complicating pregnancy  hdcp  for acute kidney injury  aki  by serum uric acid  sua  and nod like receptor heat protein domain related protein nlrp   inflammasome  methods from january      to december       a total of    cases of hdcp pregnant women admitted to the shanghai first maternal and infant hospital  tongji university were included into observation group  and according to whether they were concurrent with aki  they were further divided into aki subgroup  n     and non aki subgroup  n        meanwhile another    healthy pregnant women underwent prenatal examination in the same hospital during the same period were selected into control group  multivariate unconditional logistic regression analysis was used to analyze the influencing factors of aki in hdcp pregnant women  the receiver operating characteristics  roc  curves of different indexes to predict hdcp pregnant women complicated with aki were drawn  and area under the curve  auc  was calculated  according to the principle of maximum youden index  the best critical value of different indexes for predicting hdcp complicated with aki were determined  the procedure followed in this study met the standards formulated by the ethics review committee of shanghai first maternal and infant hospital  tongji university and has been approved by it  approval no  ks       informed consent was obtained from each participate  results cd there were no significant differences between observation group and control group in age  gestational age and gravidity  p             the levels of sua and nlrp  inflammasome in observation group were significantly higher than those in control group  and the levels of sua and nlrp  inflammasome in aki subgroup were significantly higher than those in non aki subgroup  and the differences were statistically significant  p           univariate analysis of influencing factors of concurrent with aki in hdcp pregnant women showed that placental abruption  volumes of postpartum hemorrhage and blood pressure might be the influencing factors of concurrent with aki in hdcp pregnant women  x                          p                             multivariate unconditional logistic regression analysis showed that sua        jumol l  qr             c                p         and nlrp  inflammasome         op              ci               p            postpartum hemorrhage were             ml and        ml  op l                  ci                             p                  and blood pressure were           mmhg    mmhg          kpa  and      mmhg  op                    ci                                p                 were independent risk factors caused concurrent of aki in hdcp pregnant women      the auc of sua combined with nlrp  inflammasome in predicting aki in hdcp pregnant women was            c                  p         according to the principle of maximum youden index  the best critical value of combining sua and nlrp  inflammasome in predicting aki in hdcp pregnant women were       jumol l       and its sensitivity was       and specificity was        conclusions the combined assessment of sua and nlrp  inflammasome has a good predictive performance for the concurrent of aki in patients with hdcp  and may provide references for prevention  diagnosis and treatment of early aki during pregnancy    chinese journal of obstetrics and gynecology and pediatrics all rights reserved,4.793698,3.045206,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
"Proceedings - 2021 IEEE 14th International Conference on Software Testing, Verification and Validation Workshops, ICSTW 2021",The proceedings contain 41 papers. The topics discussed include: flaky mutants; another concern for mutation testing; test automation with Grad-CAM heatmaps – a future pipe segment in MLOps for vision AI?; agents for automated user experience testing; prioritized test generation guided by software fault prediction; automatic equivalent mutants classification using abstract syntax tree neural network; an environment for benchmarking combinatorial test suite generators; supervised learning for test suit selection in continuous integration; and an empirical study of parallelizing test execution using CUDA unified memory and OpenMP GPU offloading.,the proceedings contain    papers  the topics discussed include  flaky mutants  another concern for mutation testing  test automation with grad cam heatmaps   a future pipe segment in mlops for vision ai   agents for automated user experience testing  prioritized test generation guided by software fault prediction  automatic equivalent mutants classification using abstract syntax tree neural network  an environment for benchmarking combinatorial test suite generators  supervised learning for test suit selection in continuous integration  and an empirical study of parallelizing test execution using cuda unified memory and openmp gpu offloading ,7.1114655,5.1375666,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
"MILeS 2022 - Proceedings of the 2nd International Workshop on Multimodal Immersive Learning Systems, At the 17th European Conference on Technology Enhanced Learning, EC-TEL 2022","The proceedings contain 9 papers. The topics discussed include: MILKI-PSY Cloud: MLOps-based multimodal sensor stream processing pipeline for learning analytics in psychomotor education; we can teach more than we can tell: combining deliberate practice, embodied cognition, and multimodal learning; few-shot keypose detection for learning of psychomotor skills; considerations in feedback and periodization for the multimodal learning experience of running via wearable devices; IMPECT-sports: using an immersive learning system to facilitate the psychomotor skills acquisition process; XR golf putt trainer: user opinions on an innovative real-time feedback too; reflecting on the actionable components of a model for augmented feedback; meaningful feedback from wearable sensor data to train psychomotor skills; and prerequisite knowledge of learning environments in human-robot collaboration for dyadic teams.",the proceedings contain   papers  the topics discussed include  milki psy cloud  mlops based multimodal sensor stream processing pipeline for learning analytics in psychomotor education  we can teach more than we can tell  combining deliberate practice  embodied cognition  and multimodal learning  few shot keypose detection for learning of psychomotor skills  considerations in feedback and periodization for the multimodal learning experience of running via wearable devices  impect sports  using an immersive learning system to facilitate the psychomotor skills acquisition process  xr golf putt trainer  user opinions on an innovative real time feedback too  reflecting on the actionable components of a model for augmented feedback  meaningful feedback from wearable sensor data to train psychomotor skills  and prerequisite knowledge of learning environments in human robot collaboration for dyadic teams ,8.833551,7.796529,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Bleeding during laparoscopic gastric bypass surgery as a risk factor for less favorable outcome. A cohort study from the Scandinavian Obesity Surgery Registry,"Background Intraoperative adverse events are known to be associated with postoperative complications; however, little is known about whether or not blood loss during laparoscopic gastric bypass surgery affects the outcome. Objective To see if intraoperative bleeding was associated with a less favorable outcome, and to identify patient-specific risk factors for intraoperative bleeding. Setting Nationwide, Sweden. Methods Patients who underwent laparoscopic gastric bypass surgery between January 8, 2007, and September 15, 2015, were included in the study. The volume of intraoperative blood loss was compared with data from follow-up at day 30 and 1 and 2 years after surgery. Patient-specific factors were analyzed as potential risk factors for intraoperative bleeding. Results The study included 43,157 patients. Intraoperative bleeding was associated with an increased risk for postoperative complication (100–499 mL, odds ratio [OR] 2.97, 95% confidence interval [95%CI] 2.53–3.50;>500 mL OR 3.34, 95%CI 2.05–5.44), lower weight loss (<100 mL, 82.4±24.19% excess body mass index-loss [%EBMIL]; 100–499 mL, 76.9±24.24 %EBMIL, P<.0001;>500 mL 76.9±23.89 %EBMIL, P =.063) and lower reported quality-of-life 2 years after surgery (<100 mL, Obesity-related Problem scale (OP) 21.1±24.46; 100–499 mL, OP 25.0±26.62, P =.008;>500 mL, OP 25.2±24.46, P =.272). Diabetes (OR 1.30, 95%CI 1.08–1.58), age (OR 1.02, 95%CI 1.02–1.03), and body mass index (OR 1.03, 95%CI 1.02–1.05) were patient-specific risk factors for intraoperative bleeding≥100 mL, whereas intentional preoperative weight loss was associated with a lower risk (OR.50, 95%CI.43–.57). Conclusion Intraoperative bleeding was associated with less favorable outcome after laparoscopic gastric bypass surgery. Age, body mass index, and diabetes were risk factors for intraoperative bleeding, while preoperative weight reduction seems to be protective. © 2017 American Society for Bariatric Surgery",background intraoperative adverse events are known to be associated with postoperative complications  however  little is known about whether or not blood loss during laparoscopic gastric bypass surgery affects the outcome  objective to see if intraoperative bleeding was associated with a less favorable outcome  and to identify patient specific risk factors for intraoperative bleeding  setting nationwide  sweden  methods patients who underwent laparoscopic gastric bypass surgery between january          and september           were included in the study  the volume of intraoperative blood loss was compared with data from follow up at day    and   and   years after surgery  patient specific factors were analyzed as potential risk factors for intraoperative bleeding  results the study included        patients  intraoperative bleeding was associated with an increased risk for postoperative complication          ml  odds ratio  or            confidence interval     ci                 ml or          ci             lower weight loss       ml              excess body mass index loss   ebmil           ml              ebmil  p            ml             ebmil  p        and lower reported quality of life   years after surgery       ml  obesity related problem scale  op                      ml  op             p            ml  op             p         diabetes  or          ci             age  or          ci             and body mass index  or          ci            were patient specific risk factors for intraoperative bleeding     ml  whereas intentional preoperative weight loss was associated with a lower risk  or        ci          conclusion intraoperative bleeding was associated with less favorable outcome after laparoscopic gastric bypass surgery  age  body mass index  and diabetes were risk factors for intraoperative bleeding  while preoperative weight reduction seems to be protective         american society for bariatric surgery,4.648714,3.191308,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Ultrasound-assisted oxidative desulfurization of organosulfur compounds using ferrate(VI) derived from drinking water treatment sludge,"With the increasing demand for cleaner fuel production, the present work proposed a green technology by utilizing ferrate(VI) as an oxidant in the sulphur conversion in the ultrasound-assisted oxidative desulfurization of model fuel. In this study, potassium ferrate derived from drinking water treatment sludge (DWTS) was utilized in the ultrasound assisted oxidative desulfurization of dibenzothiophene (DBT) and benzothiophene (BT). Wet oxidation method was applied in the synthesis of potassium ferrate from DWTS. Elemental analysis of DWTS revealed that the main constituents are 28.85% Fe, 23.70% O and 19.74% Mn, which implies that the sludge as a potential source of iron for ferrate(VI) production. The effect of operating parameters such as organic to aqueous phase ratio (OP), ferrate concentration, phase transfer agent amount (TOAB), and sonication time on the sulphur conversion has been investigated. Optimization studies were performed via response surface methodology using box-behnken design. Optimal condition for DBT conversion was attained at 20 mL OP, 200-ppm ferrate(VI), 200 mg TOAB and 20 min, which provided a 43.91% conversion. On the other hand, a 96.03% BT conversion was achieved at 10 mL OP, 200-ppm ferrate(VI), 100-mg PTA and 20 min. Based from the analysis of variance, sonication time is the only significant factor that could affect % sulfur conversion for BT (F value = 12.47; p value < 0.0087) and DBT (F value = 8.08; p value < 0.0130). © 15th International Symposium on East Asian Resources Recycling Technology, EARTH 2019. All rights reserved.",with the increasing demand for cleaner fuel production  the present work proposed a green technology by utilizing ferrate vi  as an oxidant in the sulphur conversion in the ultrasound assisted oxidative desulfurization of model fuel  in this study  potassium ferrate derived from drinking water treatment sludge  dwts  was utilized in the ultrasound assisted oxidative desulfurization of dibenzothiophene  dbt  and benzothiophene  bt   wet oxidation method was applied in the synthesis of potassium ferrate from dwts  elemental analysis of dwts revealed that the main constituents are        fe         o and        mn  which implies that the sludge as a potential source of iron for ferrate vi  production  the effect of operating parameters such as organic to aqueous phase ratio  op   ferrate concentration  phase transfer agent amount  toab   and sonication time on the sulphur conversion has been investigated  optimization studies were performed via response surface methodology using box behnken design  optimal condition for dbt conversion was attained at    ml op      ppm ferrate vi       mg toab and    min  which provided a        conversion  on the other hand  a        bt conversion was achieved at    ml op      ppm ferrate vi       mg pta and    min  based from the analysis of variance  sonication time is the only significant factor that could affect   sulfur conversion for bt  f value          p value           and dbt  f value         p value                th international symposium on east asian resources recycling technology  earth       all rights reserved ,3.726896,2.1614084,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Data Science Solutions on Azure: Tools and Techniques Using Databricks and MLOps,"Understand and learn the skills needed to use modern tools in Microsoft Azure. This book discusses how to practically apply these tools in the industry, and help drive the transformation of organizations into a knowledge and data-driven entity. It provides an end-to-end understanding of data science life cycle and the techniques to efficiently productionize workloads. © 2020 by Julian Soh and Priyanshi Singh.",understand and learn the skills needed to use modern tools in microsoft azure  this book discusses how to practically apply these tools in the industry  and help drive the transformation of organizations into a knowledge and data driven entity  it provides an end to end understanding of data science life cycle and the techniques to efficiently productionize workloads         by julian soh and priyanshi singh ,9.621281,5.848525,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Context time-sequencing for machine learning and sustainability optimization,"Computer systems designed to help user in their daily activities are becoming a norm. Specially, with the advent of the Internet of Things (IoT) where every device is interconnected with others through internet based protocols, the amount of data and information available has increased. Tracking devices are targeting more and more activities such as fitness, utilities consumption, movement, environment state, weather. Nowadays, a challenge for researchers is to handle such income of data and transform it into meaningful knowledge that can be used to predict, foresight, adapt and control activities. In order to this, it is necessary to interpret contextual information and produce services to anticipate these conditions. This project aim to provide a system for the creation of information and data structures to generate user models based on activity and sensor based contextual-information from IoT devices and apply machine learning operations to anticipate future states. © Springer International Publishing Switzerland 2016.",computer systems designed to help user in their daily activities are becoming a norm  specially  with the advent of the internet of things  iot  where every device is interconnected with others through internet based protocols  the amount of data and information available has increased  tracking devices are targeting more and more activities such as fitness  utilities consumption  movement  environment state  weather  nowadays  a challenge for researchers is to handle such income of data and transform it into meaningful knowledge that can be used to predict  foresight  adapt and control activities  in order to this  it is necessary to interpret contextual information and produce services to anticipate these conditions  this project aim to provide a system for the creation of information and data structures to generate user models based on activity and sensor based contextual information from iot devices and apply machine learning operations to anticipate future states    springer international publishing switzerland      ,4.97698,5.100979,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
OpML 2020 - 2020 USENIX Conference on Operational Machine Learning,The proceedings contain 10 papers. The topics discussed include: DLSpec: a deep learning task exchange specification; finding bottleneck in machine learning model life cycle; detecting feature eligibility illusions in enterprise AI autopilots; time travel and provenance for machine learning pipelines; an experimentation and analytics framework for large-scale AI operations platforms; challenges towards production-ready explainable machine learning; RIANN: real-time incremental learning with approximate nearest neighbor on mobile devices; FlexServe: deployment of PyTorch models as flexible REST endpoints; auto content moderation in C2C e-commerce; and challenges and experiences with MLOps for performance diagnostics in hybrid-cloud enterprise software deployments.,the proceedings contain    papers  the topics discussed include  dlspec  a deep learning task exchange specification  finding bottleneck in machine learning model life cycle  detecting feature eligibility illusions in enterprise ai autopilots  time travel and provenance for machine learning pipelines  an experimentation and analytics framework for large scale ai operations platforms  challenges towards production ready explainable machine learning  riann  real time incremental learning with approximate nearest neighbor on mobile devices  flexserve  deployment of pytorch models as flexible rest endpoints  auto content moderation in c c e commerce  and challenges and experiences with mlops for performance diagnostics in hybrid cloud enterprise software deployments ,8.350332,7.9326706,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Software Architecture Best Practices for Enterprise Artificial Intelligence,"AI systems are increasingly evolving from laboratory experiments in data analysis to increments of productive software products. A professional AI platform must therefore not only function as a laboratory environment but must be designed and procured as a workbench for the development, productive implementation, operation and maintenance of ML models. Subsequently, it needs to integrate within a global software engineering approach. This way, Enterprise Architecture Management (EAM) must implement efficient governance of the development cycle, to enable organization-wide collaboration, to accelerate the go-live and to standardize operations. In this paper we highlight obstacles and show best practices on how architects can integrate data science and AI in their environment. Additionally, we suggest an integrated approach adapting the best practices from both the data science and DevOps. © 2020 Gesellschaft fur Informatik (GI). All rights reserved.",ai systems are increasingly evolving from laboratory experiments in data analysis to increments of productive software products  a professional ai platform must therefore not only function as a laboratory environment but must be designed and procured as a workbench for the development  productive implementation  operation and maintenance of ml models  subsequently  it needs to integrate within a global software engineering approach  this way  enterprise architecture management  eam  must implement efficient governance of the development cycle  to enable organization wide collaboration  to accelerate the go live and to standardize operations  in this paper we highlight obstacles and show best practices on how architects can integrate data science and ai in their environment  additionally  we suggest an integrated approach adapting the best practices from both the data science and devops         gesellschaft fur informatik  gi   all rights reserved ,9.320687,3.996831,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
"Effects of Soil Microbial Diversity on the Phosphate Fraction in the Rhizosphere of Phragmites communis in the Yeyahu Wetland in Beijing, China","In this research, microorganisms in rhizosphere/non-rhizosphere soils of Phragmites communis in the Yeyahu Wetland were studied. A sequential extraction procedure was used to analyze the phosphorus (P) forms in the rhizosphere/non-rhizosphere soil with a variety of plant growth conditions (April, July, October). The soil bacteria community structure and the diversity was measured using the high-throughput of 16S rRNA amplicons. Furthermore, the complete crystallographic analysis (CCA) method was used to analyze the relationship between phosphate solubilizing microorganisms and P transformation in the soil samples. The results showed that the rank order of inorganic P (IP) fractions in the soil was generally as follows: Ca-bound P (Ca-P) >Occluded P (Oc-P) >Fe-bound P (Fe-P) >Exchangeable P (Ex-P) >Al-bound P (Al-P). The IP content was most affected by the growth of Phragmites communis. The minimum content of IP appeared in the vigorous growth period and the total IP content in the rhizosphere soil was generally lower than in the non-rhizosphere soil. The rank order of organic P (OP) fractions were highly resistant OP (HR-OP) >moderately resistant OP (MR-OP) > moderately labile OP (ML-OP) > labile OP (L-OP), and all the components of OP first decreased and then increased with the growth of plant. The major phylogenic groups in rhizosphere/non-rhizosphere soil of Phragmites communis, included Proteobacteria, Acidobacteria, Chloroflexi, and Actinobacteria among which, Proteobacteria was the majority group in the community composition. Furthermore, the rhizosphere/non-rhizosphere microbial community structure was significantly affected by seasonal changes and existing differences between the rhizosphere and non-rhizosphere soils. In addition, the main functional groups of the modal transformation of P bacteria genera were Bacillus, Enterobacter, Pseudomonas, Burkholderia, Acinetobacter, which can make use of most OP and IP, playing an important role in the transformation of P in wetland soils. © 2017, Science Press. All right reserved.",in this research  microorganisms in rhizosphere non rhizosphere soils of phragmites communis in the yeyahu wetland were studied  a sequential extraction procedure was used to analyze the phosphorus  p  forms in the rhizosphere non rhizosphere soil with a variety of plant growth conditions  april  july  october   the soil bacteria community structure and the diversity was measured using the high throughput of   s rrna amplicons  furthermore  the complete crystallographic analysis  cca  method was used to analyze the relationship between phosphate solubilizing microorganisms and p transformation in the soil samples  the results showed that the rank order of inorganic p  ip  fractions in the soil was generally as follows  ca bound p  ca p   occluded p  oc p   fe bound p  fe p   exchangeable p  ex p   al bound p  al p   the ip content was most affected by the growth of phragmites communis  the minimum content of ip appeared in the vigorous growth period and the total ip content in the rhizosphere soil was generally lower than in the non rhizosphere soil  the rank order of organic p  op  fractions were highly resistant op  hr op   moderately resistant op  mr op    moderately labile op  ml op    labile op  l op   and all the components of op first decreased and then increased with the growth of plant  the major phylogenic groups in rhizosphere non rhizosphere soil of phragmites communis  included proteobacteria  acidobacteria  chloroflexi  and actinobacteria among which  proteobacteria was the majority group in the community composition  furthermore  the rhizosphere non rhizosphere microbial community structure was significantly affected by seasonal changes and existing differences between the rhizosphere and non rhizosphere soils  in addition  the main functional groups of the modal transformation of p bacteria genera were bacillus  enterobacter  pseudomonas  burkholderia  acinetobacter  which can make use of most op and ip  playing an important role in the transformation of p in wetland soils          science press  all right reserved ,4.1118803,2.2457826,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Potential role of hCG in apoptosis of human luteinized granulosa cells,"The corpus luteum (CL) forms after ovulation and acts as a temporary endocrine gland that produces progesterone (P4), a hormone that is essential for implantation and maintenance of pregnancy in mammals. In pregnant women, human chorionic gonadotropin (hCG) secreted by the conceptus prevents luteolysis. hCG also increases the survival of cultured human luteinized granulosa cells (hLGCs). To clarify the maintenance mechanism of the human CL, we investigated the effects of hCG and P4 receptor antagonists, onapristone (OP) and RU486, on the viability of hLGCs. With the patients’ consent, hLGCs were isolated from follicular aspirates for in vitro fertilization. The cells were cultured with hCG (0.1, 1, 10, 100 IU/ml), OP (10, 25, 50, 100 μM), RU486 (100 μM), P4 (1, 10, 25, 50 μM) or some combination of the four for 24 h. Cell viability was significantly increased by hCG (100 IU/ml) and significantly decreased by OP (100 μM) compared with the control. Cells treated with hCG and OP together were significantly less viable than the control and OP-treated cells. The combined treatment also significantly increased CASP3 activity and cleaved CASP3 protein expression. Furthermore, P4 addition reversed the reduction in cell viability caused by the combination of hCG and OP treatment. The overall findings suggest that hCG cooperates with P4 to increase survival of hLGCs and to induce apoptosis when P4 action supported by hCG is attenuated in the human CL. © 2015 by the Society for Reproduction and Development.",the corpus luteum  cl  forms after ovulation and acts as a temporary endocrine gland that produces progesterone  p    a hormone that is essential for implantation and maintenance of pregnancy in mammals  in pregnant women  human chorionic gonadotropin  hcg  secreted by the conceptus prevents luteolysis  hcg also increases the survival of cultured human luteinized granulosa cells  hlgcs   to clarify the maintenance mechanism of the human cl  we investigated the effects of hcg and p  receptor antagonists  onapristone  op  and ru     on the viability of hlgcs  with the patients  consent  hlgcs were isolated from follicular aspirates for in vitro fertilization  the cells were cultured with hcg                  iu ml   op                   m   ru          m   p                  m  or some combination of the four for    h  cell viability was significantly increased by hcg      iu ml  and significantly decreased by op       m  compared with the control  cells treated with hcg and op together were significantly less viable than the control and op treated cells  the combined treatment also significantly increased casp  activity and cleaved casp  protein expression  furthermore  p  addition reversed the reduction in cell viability caused by the combination of hcg and op treatment  the overall findings suggest that hcg cooperates with p  to increase survival of hlgcs and to induce apoptosis when p  action supported by hcg is attenuated in the human cl         by the society for reproduction and development ,4.007833,2.7092376,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Comparative study of 8 and 10-bit HEVC encoders,"This paper compares the rate-distortion-complexity (RDC) characteristics of the HEVC Main 10 Profile (M10P) and Main Profile (MP) encoders. The evaluations are performed with HEVC reference encoder (HM) whose M10P and MP are benchmarked with different resolutions, frame rates, and bit depths. The reported RD results are based on bit rate differences for equal PSNR whereas complexities have been profiled with Intel VTune on Intel Core 2 processor. With our 10-bit 4K 120 fps test set, the average bit rate decrements of M10P over MP are 5.8%, 11.6%, and 12.3% in the all-intra (AI), random access (RA), and low-delay B (LB) configurations, respectively. Decreasing the bit depth of this test set to 8 lowers the RD gain of Ml OP only slightly to 5.4% (AI), 11.4% (RA), and 12.1% (LB). The similar trend continues in all our tests even though the RD gain of M10P is decreased over MP with lower resolutions and frame rates. M10P introduces no computational overhead in HM, but it is anticipated to increase complexity and double the memory usage in practical encoders. Hence, the 10-bit HEVC encoding with 8-bit input video is the most recommended option if computation and memory resources are adequate for it. © 2014 IEEE.. © 2014 IEEE.",this paper compares the rate distortion complexity  rdc  characteristics of the hevc main    profile  m  p  and main profile  mp  encoders  the evaluations are performed with hevc reference encoder  hm  whose m  p and mp are benchmarked with different resolutions  frame rates  and bit depths  the reported rd results are based on bit rate differences for equal psnr whereas complexities have been profiled with intel vtune on intel core   processor  with our    bit  k     fps test set  the average bit rate decrements of m  p over mp are              and       in the all intra  ai   random access  ra   and low delay b  lb  configurations  respectively  decreasing the bit depth of this test set to   lowers the rd gain of ml op only slightly to       ai          ra   and        lb   the similar trend continues in all our tests even though the rd gain of m  p is decreased over mp with lower resolutions and frame rates  m  p introduces no computational overhead in hm  but it is anticipated to increase complexity and double the memory usage in practical encoders  hence  the    bit hevc encoding with   bit input video is the most recommended option if computation and memory resources are adequate for it         ieee          ieee ,4.011008,6.1005883,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Challenges and experiences with MLOps for performance diagnostics in hybrid-cloud enterprise software deployments,"This paper presents how VMware addressed the following challenges in operationalizing our ML-based performance diagnostics solution in enterprise hybrid-cloud environments: data governance, model serving and deployment, dealing with system performance drifts, selecting model features, centralized model training pipeline, setting the appropriate alarm threshold, and explainability. We also share the lessons and experiences we learned over the past four years in deploying ML operations at scale for enterprise customers. © OpML 2020 - 2020 USENIX Conference on Operational Machine Learning. All rights reserved.",this paper presents how vmware addressed the following challenges in operationalizing our ml based performance diagnostics solution in enterprise hybrid cloud environments  data governance  model serving and deployment  dealing with system performance drifts  selecting model features  centralized model training pipeline  setting the appropriate alarm threshold  and explainability  we also share the lessons and experiences we learned over the past four years in deploying ml operations at scale for enterprise customers    opml             usenix conference on operational machine learning  all rights reserved ,7.288439,6.4630885,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Non-operative management of blunt abdominal solid organ trauma in adult patients,"Introduction: Despite agreement in the literature that “stable” blunt trauma patients may be managed conservatively, in Egypt many such patients receive operative management. This paper presents the results of a pragmatic, prospective, observational study to evaluate outcomes of non-operative (NOP) versus operative (OP) management of blunt abdominal solid organ trauma in hemodynamically stable adults admitted to Tanta University Emergency Hospital (TUH) in Egypt. Methods: A prospective observational study enrolled adult blunt abdominal trauma patients with solid organ injury at TUH over a 3-year period (June 2014–June 2017). Inclusion criteria were age ≥18 yr, mean arterial pressure >65 mm Hg, heart rate <110 bpm, hematocrit ≥7 mg/dl, and abdominal organ injury diagnosed by ultrasound or computed tomography (CT). Excluded patients were those with pelvis and femur fractures; patients with penetrating abdominal trauma; predominate burn injuries, children and pregnant women. All patients were assigned to non-operative or operative management based on clinician preference. Outcomes of interest were 30-day mortality, blood transfusion volume, and length of stay. Descriptive statistics and χ2 were used to compare outcomes. Results: During the study period, 4254 trauma patients presented to TUH. Of these, 790 had blunt abdominal trauma and 111 (14.1%) met inclusion criteria. Injury severity scores for each group were comparable (24 ± 10 – NOP vs. 28 ± 11 – OP, p = 0.126). NOP received less transfused blood (213.41 ± 360.3 ml [NOP] vs.1155.17 ± 380.4 ml [OP] (p < 0.0001)) but had a longer length of stay (8.29 ± 2.8 [NOP] vs. 6.45 ± 1.97 days [OP] (p = 0.012)). There was no difference in mortality between groups (p = 0.091). Conclusion: Our study demonstrated that non-operative management in Egypt of blunt abdominal trauma was safe and resulted in fewer procedures, fewer units of blood transfused, and no increase in mortality. Longer length of stay for non-operative patients might reflect treating physician caution in their management. © 2020 African Federation for Emergency Medicine",introduction  despite agreement in the literature that  stable  blunt trauma patients may be managed conservatively  in egypt many such patients receive operative management  this paper presents the results of a pragmatic  prospective  observational study to evaluate outcomes of non operative  nop  versus operative  op  management of blunt abdominal solid organ trauma in hemodynamically stable adults admitted to tanta university emergency hospital  tuh  in egypt  methods  a prospective observational study enrolled adult blunt abdominal trauma patients with solid organ injury at tuh over a   year period  june      june        inclusion criteria were age     yr  mean arterial pressure     mm hg  heart rate      bpm  hematocrit    mg dl  and abdominal organ injury diagnosed by ultrasound or computed tomography  ct   excluded patients were those with pelvis and femur fractures  patients with penetrating abdominal trauma  predominate burn injuries  children and pregnant women  all patients were assigned to non operative or operative management based on clinician preference  outcomes of interest were    day mortality  blood transfusion volume  and length of stay  descriptive statistics and    were used to compare outcomes  results  during the study period       trauma patients presented to tuh  of these      had blunt abdominal trauma and             met inclusion criteria  injury severity scores for each group were comparable            nop vs            op  p           nop received less transfused blood                 ml  nop  vs                 ml  op   p            but had a longer length of stay              nop  vs              days  op   p            there was no difference in mortality between groups  p           conclusion  our study demonstrated that non operative management in egypt of blunt abdominal trauma was safe and resulted in fewer procedures  fewer units of blood transfused  and no increase in mortality  longer length of stay for non operative patients might reflect treating physician caution in their management         african federation for emergency medicine,4.6921206,2.9719412,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Development and Optimization of an Intelligent Parking Slot Allotter and Billing System Based on Machine Learning and OCR,"As a key part of automated vehicle technology intelligent parking slot allotter has become a popular research topic. Intelligent parking slot allotter can grant permission to access the parking area with less human inference. This system can capture image of the vehicle, identify the type of vehicle and allot best fit and optimal parking slot based on its size. It extracts the vehicle’s license plate number, entry time, exit time and calculate total time of the vehicle present with in the parking space. Here, sensors are utilized to identify the presence of the vehicle during entry and exit. Two cameras are utilized to extract features. One camera is used to identify the region of interest, vehicle license plate and identify the characters from the license plate. Tesseract engine and optical character recognition (OCR) functions are used to detect characters from the image. Another camera is utilized to extract features like dimensions of the vehicle using machine learning operations such as convolutional neural network (CNN). Based on the size of the vehicle, best fit parking slot is allotted which gives optimal usage of parking area. These days the quantity of vehicles is expanding exceptionally, so that, searching for an empty parking slot turns out to be increasingly troublesome. By installing the intelligent parking slot allotter, in places like, shopping malls, train stations, and airports the need for searching of parking slot significantly reduces. A past study has demonstrated that traffic because of vehicle’s parking slot searching in downtowns of significant urban communities can represent half of the absolute traffic. With such a hefty traffic jam and time delay in parking slot identifying, intelligent parking slot allotter will be in great demand. © 2020, Springer Nature Switzerland AG.",as a key part of automated vehicle technology intelligent parking slot allotter has become a popular research topic  intelligent parking slot allotter can grant permission to access the parking area with less human inference  this system can capture image of the vehicle  identify the type of vehicle and allot best fit and optimal parking slot based on its size  it extracts the vehicle s license plate number  entry time  exit time and calculate total time of the vehicle present with in the parking space  here  sensors are utilized to identify the presence of the vehicle during entry and exit  two cameras are utilized to extract features  one camera is used to identify the region of interest  vehicle license plate and identify the characters from the license plate  tesseract engine and optical character recognition  ocr  functions are used to detect characters from the image  another camera is utilized to extract features like dimensions of the vehicle using machine learning operations such as convolutional neural network  cnn   based on the size of the vehicle  best fit parking slot is allotted which gives optimal usage of parking area  these days the quantity of vehicles is expanding exceptionally  so that  searching for an empty parking slot turns out to be increasingly troublesome  by installing the intelligent parking slot allotter  in places like  shopping malls  train stations  and airports the need for searching of parking slot significantly reduces  a past study has demonstrated that traffic because of vehicle s parking slot searching in downtowns of significant urban communities can represent half of the absolute traffic  with such a hefty traffic jam and time delay in parking slot identifying  intelligent parking slot allotter will be in great demand          springer nature switzerland ag ,5.3624353,5.057385,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Method of detecting malware through analysis of opcodes frequency with machine learning technique,"As the evolution of malware, vast damages are occurred in various industry fields. For this reason, research on malware detection has conducted actively. To improve the security of the network, SDN Quarantined Network (SQN) has been proposed. In this paper, we developed one of malware detection modules in first quarantine station in SQN by using the fact that benign and malicious files have different opcode frequency. And we applied machine learning technique as different way compare to conventional method. we verified that our module is valuable as one of detection modules and our final aim is to mount this module on the SQN system. Therefore, it would be possible more accurate inspection for new type of security attack with multiple detection modules. © Springer Nature Singapore Pte Ltd. 2017.",as the evolution of malware  vast damages are occurred in various industry fields  for this reason  research on malware detection has conducted actively  to improve the security of the network  sdn quarantined network  sqn  has been proposed  in this paper  we developed one of malware detection modules in first quarantine station in sqn by using the fact that benign and malicious files have different opcode frequency  and we applied machine learning technique as different way compare to conventional method  we verified that our module is valuable as one of detection modules and our final aim is to mount this module on the sqn system  therefore  it would be possible more accurate inspection for new type of security attack with multiple detection modules    springer nature singapore pte ltd       ,3.542916,5.556343,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
"10th International Symposium on Business Modeling and Software Design, BMSD 2020","The proceedings contain 28 papers. The special focus in this conference is on Business Modeling and Software Design. The topics include: Model-driven ml-ops for intelligent enterprise applications: vision, approaches and challenges; managing human and artificial knowledge bearers: the creation of a symbiotic knowledge management approach; adaptable knowledge-driven information systems improving knowledge transfers: design of context-sensitive, ar-enabled furniture assemblies; vr-eat: visualization of enterprise architecture tool diagrams in virtual reality; understanding the augmented and virtual reality business ecosystem: an e3-value Approach; business model dependencies: towards conceptualizing dependencies for extending modeling languages for business models; concepts for comparison in models to support decision making; model-based hypothesis engineering for supporting adaptation to uncertain customer needs; an agent-oriented methodology for business process management; process reference models: accelerator for digital transformation; declarative semantics of actions and instructions; bridging the gap between business and technical infrastructures of enterprise information systems: addressing the “vertical fit” problems; iot system design of a v2x application; stakeholder tensions in decision-making for opening government data; automated system for monitoring of educational processes: collection, management, and modeling of data; exploration of data analytics for ground segment in space systems; understanding human generated decision data; enabling collaborative business process elicitation in virtual environments; business processes and the safety of stakeholders: considering the electromagnetic pollution; making enterprise information systems resilient against disruptive events: a conceptual view; a reference model for a service level agreement: in domain of information sharing services; graph-based multi-criteria optimization for business processes; from business modeling to software design.",the proceedings contain    papers  the special focus in this conference is on business modeling and software design  the topics include  model driven ml ops for intelligent enterprise applications  vision  approaches and challenges  managing human and artificial knowledge bearers  the creation of a symbiotic knowledge management approach  adaptable knowledge driven information systems improving knowledge transfers  design of context sensitive  ar enabled furniture assemblies  vr eat  visualization of enterprise architecture tool diagrams in virtual reality  understanding the augmented and virtual reality business ecosystem  an e  value approach  business model dependencies  towards conceptualizing dependencies for extending modeling languages for business models  concepts for comparison in models to support decision making  model based hypothesis engineering for supporting adaptation to uncertain customer needs  an agent oriented methodology for business process management  process reference models  accelerator for digital transformation  declarative semantics of actions and instructions  bridging the gap between business and technical infrastructures of enterprise information systems  addressing the  vertical fit  problems  iot system design of a v x application  stakeholder tensions in decision making for opening government data  automated system for monitoring of educational processes  collection  management  and modeling of data  exploration of data analytics for ground segment in space systems  understanding human generated decision data  enabling collaborative business process elicitation in virtual environments  business processes and the safety of stakeholders  considering the electromagnetic pollution  making enterprise information systems resilient against disruptive events  a conceptual view  a reference model for a service level agreement  in domain of information sharing services  graph based multi criteria optimization for business processes  from business modeling to software design ,7.550157,5.534624,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Scene-level Pose Estimation for Multiple Instances of Densely Packed Objects,"This paper introduces key machine learning operations that allow the realization of robust, joint 6D pose estimation of multiple instances of objects either densely packed or in unstructured piles from RGB-D data. The first objective is to learn semantic and instance-boundary detectors without manual labeling. An adversarial training framework in conjunction with physics-based simulation is used to achieve detectors that behave similarly in synthetic and real data. Given the stochastic output of such detectors, candidates for object poses are sampled. The second objective is to automatically learn a single score for each pose candidate that represents its quality in terms of explaining the entire scene via a gradient boosted tree. The proposed method uses features derived from surface and boundary alignment between the observed scene and the object model placed at hypothesized poses. Scene-level, multi-instance pose estimation is then achieved by an integer linear programming process that selects hypotheses that maximize the sum of the learned individual scores, while respecting constraints, such as avoiding collisions. To evaluate this method, a dataset of densely packed objects with challenging setups for state-of-the-art approaches is collected. Experiments on this dataset and a public one show that the method significantly outperforms alternatives in terms of 6D pose accuracy while trained only with synthetic datasets. © 2019 CoRL. All Rights Reserved.",this paper introduces key machine learning operations that allow the realization of robust  joint  d pose estimation of multiple instances of objects either densely packed or in unstructured piles from rgb d data  the first objective is to learn semantic and instance boundary detectors without manual labeling  an adversarial training framework in conjunction with physics based simulation is used to achieve detectors that behave similarly in synthetic and real data  given the stochastic output of such detectors  candidates for object poses are sampled  the second objective is to automatically learn a single score for each pose candidate that represents its quality in terms of explaining the entire scene via a gradient boosted tree  the proposed method uses features derived from surface and boundary alignment between the observed scene and the object model placed at hypothesized poses  scene level  multi instance pose estimation is then achieved by an integer linear programming process that selects hypotheses that maximize the sum of the learned individual scores  while respecting constraints  such as avoiding collisions  to evaluate this method  a dataset of densely packed objects with challenging setups for state of the art approaches is collected  experiments on this dataset and a public one show that the method significantly outperforms alternatives in terms of  d pose accuracy while trained only with synthetic datasets         corl  all rights reserved ,4.6421504,6.964889,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Machine learning: Technologies and potential application at mining companies,"Implementation of machine learning systems is currently one of the most sought-after spheres of human activities at the interface of information technologies, mathematical analysis and statistics. Machine learning technologies are penetrating into our life through applied software created with the help of artificial intelligence algorithms. It is obvious that machine learning technologies will be developing fast and becoming part of the human information space both in our everyday life and in professional activities. However, building of machine learning systems requires great labour contribution of specialists in the sphere of artificial intelligence and the subject area where this technology is to be applied. The article considers technologies and potential application of machine learning at mining companies. The article describes basic methods of machine learning: unsupervised learning, action learning, semi-supervised machine learning. The criteria are singled out to assess machine learning: operation speed; assessment time; implemented model accuracy; ease of integration; flexible deployment within the subject area; ease of practical application; result visualization. The article describes practical application of machine learning technologies and considers the dispatch system at a mining enterprise (as exemplified by the dispatch system of the mining and transportation complex ""Quarry"" used to increase efficiency of operating management of enterprise performance; to increase reliability and agility of mining and transportation complex performance records and monitoring. There is also a list of equipment performance data that can be stored in the database and used as a basis for processing by machine learning algorithms and obtaining new knowledge. Application of machine learning technologies in the mining industry is a promising and necessary condition for increasing mining efficiency and ensuring environmental security. Selection of the optimal process flow sheet of mining operations, selection of the optimal complex of stripping and mining equipment, optimal planning of mining operations and mining equipment performance control are some of the tasks where machine learning technologies can be used. However, despite prospectivity of machine learning technologies, this trend still remains understudied and requires further research. © The Authors, published by EDP Sciences, 2020.",implementation of machine learning systems is currently one of the most sought after spheres of human activities at the interface of information technologies  mathematical analysis and statistics  machine learning technologies are penetrating into our life through applied software created with the help of artificial intelligence algorithms  it is obvious that machine learning technologies will be developing fast and becoming part of the human information space both in our everyday life and in professional activities  however  building of machine learning systems requires great labour contribution of specialists in the sphere of artificial intelligence and the subject area where this technology is to be applied  the article considers technologies and potential application of machine learning at mining companies  the article describes basic methods of machine learning  unsupervised learning  action learning  semi supervised machine learning  the criteria are singled out to assess machine learning  operation speed  assessment time  implemented model accuracy  ease of integration  flexible deployment within the subject area  ease of practical application  result visualization  the article describes practical application of machine learning technologies and considers the dispatch system at a mining enterprise  as exemplified by the dispatch system of the mining and transportation complex  quarry  used to increase efficiency of operating management of enterprise performance  to increase reliability and agility of mining and transportation complex performance records and monitoring  there is also a list of equipment performance data that can be stored in the database and used as a basis for processing by machine learning algorithms and obtaining new knowledge  application of machine learning technologies in the mining industry is a promising and necessary condition for increasing mining efficiency and ensuring environmental security  selection of the optimal process flow sheet of mining operations  selection of the optimal complex of stripping and mining equipment  optimal planning of mining operations and mining equipment performance control are some of the tasks where machine learning technologies can be used  however  despite prospectivity of machine learning technologies  this trend still remains understudied and requires further research    the authors  published by edp sciences       ,6.913007,4.243142,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
An innovative smartphone-based solution for traffic rule violation detection,"This paper introduces a novel smartphone-based solution to detect different traffic rule violations using a variety of computer vision and networking technologies. We propose the use of smartphones as participatory sensors via their cameras to detect the moving and stationary objects (e.g., cars and lane markers) and understand the resulting driving and traffic violation of each object. We propose novel framework which uses a fast in-mobile traffic violation detector for rapid detection of traffic rule violation. After that, the smartphone transmits the data to the cloud where more powerful computer vision and machine learning operations are used to detect the traffic violation with a higher accuracy. We show that the proposed framework detection is very accurate by combining a) a Haarlike feature cascade detector at the in-mobile level, and b) a deep learning-based classifier, and support-vector machine-based classifiers in the cloud. The accuracy of the deep convolutional network is about 92% for true positive and 95% for true negative. The proposed framework demonstrates a potential for mobilebased traffic violation detection by especially by combining the information of accurate relative position and relative speed. Finally, we propose a real-time scheduling scheme in order to optimize the use of battery and real-time bandwidth of the users given partially known navigation information among the different users in the network, which us the real case. We show that the navigation information is very important in order to better utilize the battery and bandwidth for each user for a small number of users compared to the navigation trajectory length. That is, the utilization of the resources is directly related to the number of available participants, and the accuracy of navigation information. © 2013 The Science and Information (SAI) Organization.",this paper introduces a novel smartphone based solution to detect different traffic rule violations using a variety of computer vision and networking technologies  we propose the use of smartphones as participatory sensors via their cameras to detect the moving and stationary objects  e g   cars and lane markers  and understand the resulting driving and traffic violation of each object  we propose novel framework which uses a fast in mobile traffic violation detector for rapid detection of traffic rule violation  after that  the smartphone transmits the data to the cloud where more powerful computer vision and machine learning operations are used to detect the traffic violation with a higher accuracy  we show that the proposed framework detection is very accurate by combining a  a haarlike feature cascade detector at the in mobile level  and b  a deep learning based classifier  and support vector machine based classifiers in the cloud  the accuracy of the deep convolutional network is about     for true positive and     for true negative  the proposed framework demonstrates a potential for mobilebased traffic violation detection by especially by combining the information of accurate relative position and relative speed  finally  we propose a real time scheduling scheme in order to optimize the use of battery and real time bandwidth of the users given partially known navigation information among the different users in the network  which us the real case  we show that the navigation information is very important in order to better utilize the battery and bandwidth for each user for a small number of users compared to the navigation trajectory length  that is  the utilization of the resources is directly related to the number of available participants  and the accuracy of navigation information         the science and information  sai  organization ,3.619505,5.306181,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
MLOp lifecycle scheme for vision-based inspection process in manufacturing,"Recent advances in machine learning and the proliferation of edge computing have enabled manufacturing industry to integrate machine learning into its operation to boost productivity. In addition to building high performing machine learning models, stakeholders and infrastructures within the industry should be taken into an account in building an operational lifecycle. In this paper, a practical machine learning operation scheme to build the vision inspection process is proposed, which is mainly motivated from field experiences in applying the system in large scale corporate manufacturing plants. We evaluate our scheme in four defect inspection lines in production. The results show that deep neural network models outperform existing algorithms and the scheme is easily extensible to other manufacturing processes.",recent advances in machine learning and the proliferation of edge computing have enabled manufacturing industry to integrate machine learning into its operation to boost productivity  in addition to building high performing machine learning models  stakeholders and infrastructures within the industry should be taken into an account in building an operational lifecycle  in this paper  a practical machine learning operation scheme to build the vision inspection process is proposed  which is mainly motivated from field experiences in applying the system in large scale corporate manufacturing plants  we evaluate our scheme in four defect inspection lines in production  the results show that deep neural network models outperform existing algorithms and the scheme is easily extensible to other manufacturing processes ,8.448663,4.1678596,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Intra- and inter-rater agreement between an ophthalmologist and mid-level ophthalmic personnel to diagnose retinal diseases based on fundus photographs at a primary eye center in Nepal: The Bhaktapur Retina Study,"Background: Early detection can reduce irreversible blindness from retinal diseases. This study aims to assess the intra- and inter-rater agreement of retinal pathologies observed on fundus photographs between an ophthalmologist and two-mid level ophthalmic personnel (MLOPs). Method: A population-based, cross-sectional study was conducted among subjects 60 years and above in the Bhaktapur district of Nepal. Fundus photographs of 500 eyes of 500 subjects were assessed. The macula-centered 45-degree photographs were graded twice by one ophthalmologist and two MLOPs. Intra-rater and inter-rater agreements were assessed for the ophthalmologist and the MLOPs. Result: Mean age was 70.22 years ± 6.94 (SD). Retinal pathologies were observed in 55.6 % of photographs (age-related macular degeneration: 34.2 %; diabetic retinopathy: 4.2 %; retinal vein occlusion: 3.8 %). Twelve (2.4 %) fundus pictures were non-gradable. The intra-rater agreement for overall retinal pathologies, retinal hemorrhage, and maculopathy were substantial both for the ophthalmologist as well as for the MLOPs. There was moderate inter-rater agreement between the ophthalmologist and the first MLOP on second rating for overall retinal pathologies, [kappa (k); 95 % CI = 0.59 (0.51-0.66)], retinal hemorrhage [k; 95 % CI = 0.60 (0.41-0.78)], and maculopathy [k; 95 % CI = 0.52 (0.43-0.60)]. Inter-rater agreement between the ophthalmologist and the second MLOP for second rating was moderate for overall retinal pathologies [k; 95 % CI = 0.52 (0.44-0.60)], substantial agreement for retinal hemorrhage [k; 95 % CI = 0. 68 (0.52-0.84)], moderate agreement for maculopathy [k; 95 % CI = 0.59 (0.50-0.67)]. Conclusion: There is moderate agreement between the MLOPs and the ophthalmologist in grading fundus photographs for retinal hemorrhages and maculopathy. © 2016 The Author(s).",background  early detection can reduce irreversible blindness from retinal diseases  this study aims to assess the intra  and inter rater agreement of retinal pathologies observed on fundus photographs between an ophthalmologist and two mid level ophthalmic personnel  mlops   method  a population based  cross sectional study was conducted among subjects    years and above in the bhaktapur district of nepal  fundus photographs of     eyes of     subjects were assessed  the macula centered    degree photographs were graded twice by one ophthalmologist and two mlops  intra rater and inter rater agreements were assessed for the ophthalmologist and the mlops  result  mean age was       years         sd   retinal pathologies were observed in        of photographs  age related macular degeneration          diabetic retinopathy         retinal vein occlusion          twelve         fundus pictures were non gradable  the intra rater agreement for overall retinal pathologies  retinal hemorrhage  and maculopathy were substantial both for the ophthalmologist as well as for the mlops  there was moderate inter rater agreement between the ophthalmologist and the first mlop on second rating for overall retinal pathologies   kappa  k        ci                      retinal hemorrhage  k       ci                      and maculopathy  k       ci                      inter rater agreement between the ophthalmologist and the second mlop for second rating was moderate for overall retinal pathologies  k       ci                      substantial agreement for retinal hemorrhage  k       ci                       moderate agreement for maculopathy  k       ci                      conclusion  there is moderate agreement between the mlops and the ophthalmologist in grading fundus photographs for retinal hemorrhages and maculopathy         the author s  ,4.876863,3.4079816,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Hydrothermal synthesis and luminescence properties of NBT-Eu nanopowders,"Na0.5Bi0.49Eu0.01TiO3 nanopowders were prepared by the hydrothermal method under different conditions. The synthesized nanopowders were characterized by X-ray diffraction, UV-visible spectra, transmission electron microscopy and photoluminescence spectra. The results reveal that the phase-pure rhombohedral perovskite structure NBT-Eu powders can be prepared at a hydrothermal temperature of 200 ℃ for 24 h with 12 mol·L-1 NaOH and 0.6 mL OP-10. The powders exhibit nanorod shape with a diameter of 15 to 200 nm. Under the excitation of 458 nm light, NBT-Eu nanopowders exhibit the strongest emission at 689 nm, which can be attributed to 5D0→7F4 transition of Eu3+. © 2016, Science Press. All right reserved.",na   bi    eu    tio  nanopowders were prepared by the hydrothermal method under different conditions  the synthesized nanopowders were characterized by x ray diffraction  uv visible spectra  transmission electron microscopy and photoluminescence spectra  the results reveal that the phase pure rhombohedral perovskite structure nbt eu powders can be prepared at a hydrothermal temperature of       for    h with    mol l   naoh and     ml op     the powders exhibit nanorod shape with a diameter of    to     nm  under the excitation of     nm light  nbt eu nanopowders exhibit the strongest emission at     nm  which can be attributed to  d   f  transition of eu            science press  all right reserved ,3.9636285,2.3600914,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
ML health monitor: Taking the pulse of machine learning algorithms in production,"Bringing the research advances in Machine Learning (ML) to production is necessary for businesses to gain value from ML. A key challenge of production ML is the monitoring and management of real-Time prediction quality. This is complicated by the variability of live production data, the absence of real-Time labels and the non-determinism posed by ML techniques themselves. We define ML Health as the real time assessment of ML prediction quality and present an approach to monitoring and improving ML Health. Specifically, a complete solution to monitor and manage ML Health within a realistic full production ML lifecycle. We describe a number of ML Health techniques and assess their efficacy via publicly available datasets. Our solution handles production realities such as scale, heterogeneity and distributed runtimes. We present what we believe is the first solution to production ML Health explored at both an empirical and complete system implementation level. © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.",bringing the research advances in machine learning  ml  to production is necessary for businesses to gain value from ml  a key challenge of production ml is the monitoring and management of real time prediction quality  this is complicated by the variability of live production data  the absence of real time labels and the non determinism posed by ml techniques themselves  we define ml health as the real time assessment of ml prediction quality and present an approach to monitoring and improving ml health  specifically  a complete solution to monitor and manage ml health within a realistic full production ml lifecycle  we describe a number of ml health techniques and assess their efficacy via publicly available datasets  our solution handles production realities such as scale  heterogeneity and distributed runtimes  we present what we believe is the first solution to production ml health explored at both an empirical and complete system implementation level    copyright spie  downloading of the abstract is permitted for personal use only ,8.885613,6.14095,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
"Dynamics of phosphorus fractions in surface soils of different flooding wetlands before and after flow-sediment regulation in the Yellow River Estuary, China","To investigate the dynamics of phosphorus fractions and their influencing factors in the surface soils of estuarine wetlands experiencing different hydrological conditions before and after flow-sediment regulation, soil samples were collected in wetlands (tidal flooding wetlands (TFW), freshwater restoration wetlands (FRW) and freshwater flooding wetlands (FFW) of the Yellow River Estuary in each month from April to October of 2012. Our results showed that the average contents of organic phosphorus (OP) occurred in the following order: FRW soils (60.05 mg/kg) > TFW soils (38.72 mg/kg) > FFW soils (27.56 mg/kg), and accounted for less than 12% of total phosphorus (TP). In contrast to the pattern for OP, FRW soils contained lower inorganic phosphorus (IP) levels than TFW and FFW soils from April to August (p < 0.05). After the flow-sediment regulation, the TP, OP, moderately labile OP (ML-OP) ferrous/aluminum-bound IP (Fe/Al-P), and occluded IP (Oc-P) in the three wetlands decreased. The soluble and loosely bound IP (S/L-P) contents in TFW decreased, while the S/L-P contents in FRW soils increased. The levels of phosphorus fractions were affected by water and salt conditions, soil texture, exchangeable mineral element contents, and nutrient status. The Fe/Al-P and Oc-P in the three types of wetland soils were released, and the increase in S/L-P in FRW soils after the flow-sediment regulation might increase the risk of eutrophication in the coastal waters. The findings of this study could contribute to providing basic data regarding phosphorus fractions in different flooding estuarine wetlands of the Yellow River Estuary and guiding flow-sediment regulations and freshwater restoration to enhance the ecological functions of estuarine wetlands. © 2019 Elsevier B.V.",to investigate the dynamics of phosphorus fractions and their influencing factors in the surface soils of estuarine wetlands experiencing different hydrological conditions before and after flow sediment regulation  soil samples were collected in wetlands  tidal flooding wetlands  tfw   freshwater restoration wetlands  frw  and freshwater flooding wetlands  ffw  of the yellow river estuary in each month from april to october of       our results showed that the average contents of organic phosphorus  op  occurred in the following order  frw soils        mg kg    tfw soils        mg kg    ffw soils        mg kg   and accounted for less than     of total phosphorus  tp   in contrast to the pattern for op  frw soils contained lower inorganic phosphorus  ip  levels than tfw and ffw soils from april to august  p          after the flow sediment regulation  the tp  op  moderately labile op  ml op  ferrous aluminum bound ip  fe al p   and occluded ip  oc p  in the three wetlands decreased  the soluble and loosely bound ip  s l p  contents in tfw decreased  while the s l p contents in frw soils increased  the levels of phosphorus fractions were affected by water and salt conditions  soil texture  exchangeable mineral element contents  and nutrient status  the fe al p and oc p in the three types of wetland soils were released  and the increase in s l p in frw soils after the flow sediment regulation might increase the risk of eutrophication in the coastal waters  the findings of this study could contribute to providing basic data regarding phosphorus fractions in different flooding estuarine wetlands of the yellow river estuary and guiding flow sediment regulations and freshwater restoration to enhance the ecological functions of estuarine wetlands         elsevier b v ,4.526278,1.8259957,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
An intelligent low-power low-cost mobile lab-on-chip yeast cell culture platform,"Cells are the fundamental unit of life activities, and the basis of studying life phenomena. It is very important to observe the growth state of yeast cells for exploring the law of life movement, diagnosis and treatment of diseases, drug screening and so on. This study proposes a kind of intelligent low-cost portable cell culture platform using the microfluidic channel and the special machine learning circuit. The platform can independently complete the whole work of living cell culture and monitoring. For realizing the reusable and low-power deep learning circuit, a complement optimization neural network algorithm for hardware optimization and corresponding multi-clock-domain reusable multi-level precision neural network accelerator circuit were proposed, which can reduce the circuit area and power of convolution operation in all precisions by average 18.11% and 23.5% respectively. Besides, a dynamic multi-level precision control method based on the battery level is proposed to dynamically adjust the precision of machine learning operation, in order to balance the working time and segmentation accuracy of the culture platform. In addition, a microcolumns-based three-port input microfluidic structure was designed for better yeast culture effect. The experiment showed that the culture platform can realize yeast cell culture and achieve almost the same segmentation accuracy as the large biological laboratory with low-power and low-cost. Compared with the previous work, the cost of mass production was reduced by 88.95%, and the equipment volume was 27.1% smaller. At the same time, it can achieve the best balance of working time and working accuracy under the condition of limited power of equipment according to the needs of users. © 2013 IEEE.",cells are the fundamental unit of life activities  and the basis of studying life phenomena  it is very important to observe the growth state of yeast cells for exploring the law of life movement  diagnosis and treatment of diseases  drug screening and so on  this study proposes a kind of intelligent low cost portable cell culture platform using the microfluidic channel and the special machine learning circuit  the platform can independently complete the whole work of living cell culture and monitoring  for realizing the reusable and low power deep learning circuit  a complement optimization neural network algorithm for hardware optimization and corresponding multi clock domain reusable multi level precision neural network accelerator circuit were proposed  which can reduce the circuit area and power of convolution operation in all precisions by average        and       respectively  besides  a dynamic multi level precision control method based on the battery level is proposed to dynamically adjust the precision of machine learning operation  in order to balance the working time and segmentation accuracy of the culture platform  in addition  a microcolumns based three port input microfluidic structure was designed for better yeast culture effect  the experiment showed that the culture platform can realize yeast cell culture and achieve almost the same segmentation accuracy as the large biological laboratory with low power and low cost  compared with the previous work  the cost of mass production was reduced by         and the equipment volume was       smaller  at the same time  it can achieve the best balance of working time and working accuracy under the condition of limited power of equipment according to the needs of users         ieee ,10.12741,3.662917,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
On the expressiveness of Lara: A unified language for linear and relational algebra,"We study the expressive power of the Lara language - a recently proposed unified model for expressing relational and linear algebra operations - both in terms of traditional database query languages and some analytic tasks often performed in machine learning pipelines. We start by showing Lara to be expressive complete with respect to first-order logic with aggregation. Since Lara is parameterized by a set of user-defined functions which allow to transform values in tables, the exact expressive power of the language depends on how these functions are defined. We distinguish two main cases depending on the level of genericity queries are enforced to satisfy. Under strong genericity assumptions the language cannot express matrix convolution, a very important operation in current machine learning operations. This language is also local, and thus cannot express operations such as matrix inverse that exhibit a recursive behavior. For expressing convolution, one can relax the genericity requirement by adding an underlying linear order on the domain. This, however, destroys locality and turns the expressive power of the language much more difficult to understand. In particular, although under complexity assumptions the resulting language can still not express matrix inverse, a proof of this fact without such assumptions seems challenging to obtain. © Pablo Barceló, Nelson Higuera, Jorge Pérez, and Bernardo Subercaseaux; licensed under Creative Commons License CC-BY 23rd International Conference on Database Theory (ICDT 2020).",we study the expressive power of the lara language   a recently proposed unified model for expressing relational and linear algebra operations   both in terms of traditional database query languages and some analytic tasks often performed in machine learning pipelines  we start by showing lara to be expressive complete with respect to first order logic with aggregation  since lara is parameterized by a set of user defined functions which allow to transform values in tables  the exact expressive power of the language depends on how these functions are defined  we distinguish two main cases depending on the level of genericity queries are enforced to satisfy  under strong genericity assumptions the language cannot express matrix convolution  a very important operation in current machine learning operations  this language is also local  and thus cannot express operations such as matrix inverse that exhibit a recursive behavior  for expressing convolution  one can relax the genericity requirement by adding an underlying linear order on the domain  this  however  destroys locality and turns the expressive power of the language much more difficult to understand  in particular  although under complexity assumptions the resulting language can still not express matrix inverse  a proof of this fact without such assumptions seems challenging to obtain    pablo barcel   nelson higuera  jorge p rez  and bernardo subercaseaux  licensed under creative commons license cc by   rd international conference on database theory  icdt       ,6.3270802,6.7820454,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Highway Network Traffic Survey Point Layout Planning Method Based on Machine Learning-Optimization Hybrid Algorithm,"Due to the backward observation and treatment methods of existing expressway traffic survey points, the observation and treatment system simply cannot match with the expressway network survey points and play its own due traffic observation function. The main purpose of this paper is to solve a problem with the overall layout planning of expressway network planning traffic survey observation points on the network. This paper mainly studies and designs a hybrid analysis method, which is a convex nonlinear programming traffic distribution problem and is solved by a frank-wolfe hybrid algorithm. Secondly, in order to fully verify the effectiveness of the design of a supervised machine learning-network optimization hybrid algorithm, a real machine learning large-scale data set is used for testing. The results of mixed data analysis show that ml-op’s mixed analysis algorithm still has a good performance in terms of computational capability and reliability when it is used to deal with large scale bi-level convex nonlinear programming traffic distribution problem. © 2020, Springer Nature Singapore Pte Ltd.",due to the backward observation and treatment methods of existing expressway traffic survey points  the observation and treatment system simply cannot match with the expressway network survey points and play its own due traffic observation function  the main purpose of this paper is to solve a problem with the overall layout planning of expressway network planning traffic survey observation points on the network  this paper mainly studies and designs a hybrid analysis method  which is a convex nonlinear programming traffic distribution problem and is solved by a frank wolfe hybrid algorithm  secondly  in order to fully verify the effectiveness of the design of a supervised machine learning network optimization hybrid algorithm  a real machine learning large scale data set is used for testing  the results of mixed data analysis show that ml op s mixed analysis algorithm still has a good performance in terms of computational capability and reliability when it is used to deal with large scale bi level convex nonlinear programming traffic distribution problem          springer nature singapore pte ltd ,3.645078,7.7792945,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Assistive robots as future caregivers: The RAPP approach,"As our societies are affected by a dramatic demographic change, the percentage of elderly and people requiring support in their daily life is expected to increase in the near future and caregivers will not be enough to assist and support them. Socially interactive robots can help confront this situation not only by physically assisting people but also by functioning as a companion. The rising sales figures of robots point towards a trend break concerning robotics. To lower the cost for developers and to increase their interest in developing robotic applications, the RAPP approach introduces the idea of robots as platforms. RAPP (A Software Platform for Delivering Smart User Empowering Robotic Applications) aims to provide a software platform in order to support the creation and delivery of robotic applications (RApps) targeting people at risk of exclusion, especially older people. The open-source software platform will provide an API with the required functionality for the implementation of RApps. It will also provide access to the robots' sensors and actuators employing higher level commands, by adding a middleware stack with functionalities suitable for different kinds of robots. RAPP will expand the robots' computational and storage capabilities and enable machine learning operations, distributed data collection and processing. Through a special repository for RApps, the platform will support knowledge sharing among robots in order to provide personalized applications based on adaptation to individuals. The use of a common API will facilitate the development of improved applications deployable for a variety of robots. These applications target people with different needs, capabilities and expectations, while at the same time respect their privacy and autonomy. The RAPP approach can lower the cost of robotic applications development and it is expected to have a profound effect in the robotics market. © 2015, Springer International Publishing Switzerland.",as our societies are affected by a dramatic demographic change  the percentage of elderly and people requiring support in their daily life is expected to increase in the near future and caregivers will not be enough to assist and support them  socially interactive robots can help confront this situation not only by physically assisting people but also by functioning as a companion  the rising sales figures of robots point towards a trend break concerning robotics  to lower the cost for developers and to increase their interest in developing robotic applications  the rapp approach introduces the idea of robots as platforms  rapp  a software platform for delivering smart user empowering robotic applications  aims to provide a software platform in order to support the creation and delivery of robotic applications  rapps  targeting people at risk of exclusion  especially older people  the open source software platform will provide an api with the required functionality for the implementation of rapps  it will also provide access to the robots  sensors and actuators employing higher level commands  by adding a middleware stack with functionalities suitable for different kinds of robots  rapp will expand the robots  computational and storage capabilities and enable machine learning operations  distributed data collection and processing  through a special repository for rapps  the platform will support knowledge sharing among robots in order to provide personalized applications based on adaptation to individuals  the use of a common api will facilitate the development of improved applications deployable for a variety of robots  these applications target people with different needs  capabilities and expectations  while at the same time respect their privacy and autonomy  the rapp approach can lower the cost of robotic applications development and it is expected to have a profound effect in the robotics market          springer international publishing switzerland ,9.075446,4.0357385,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
An Introduction to Data Science and Its Applications,"Data science has become a fundamental discipline, both in the field of basic research and in the resolution of applied problems, where statistics and computer science intersect. Thus, from the perspective of the data itself, machine learning, operation research, methods and algorithms, and data mining techniques are aligned to address new challenges characterised by the complexity, volume and heterogeneous nature of data. © 2020, Springer Nature Switzerland AG.",data science has become a fundamental discipline  both in the field of basic research and in the resolution of applied problems  where statistics and computer science intersect  thus  from the perspective of the data itself  machine learning  operation research  methods and algorithms  and data mining techniques are aligned to address new challenges characterised by the complexity  volume and heterogeneous nature of data          springer nature switzerland ag ,6.7687364,4.2764215,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
"Beginning MLOps with MLFlow: Deploy Models in AWS SageMaker, Google Cloud, and Microsoft Azure","Integrate MLOps principles into existing or future projects using MLFlow, operationalize your models, and deploy them in AWS SageMaker, Google Cloud, and Microsoft Azure. ?This book guides you through the process of data analysis, model construction, and training. The authors begin by introducing you to basic data analysis on a credit card data set and teach you how to analyze the features and their relationships to the target variable. You will learn how to build logistic regression models in scikit-learn and PySpark, and you will go through the process of hyperparameter tuning with a validation data set. You will explore three different deployment setups of machine learning models with varying levels of automation to help you better understand MLOps. MLFlow is covered and you will explore how to integrate MLOps into your existing code, allowing you to easily track metrics, parameters, graphs, and models. You will be guided through the process of deploying and querying your models with AWS SageMaker, Google Cloud, and Microsoft Azure. And you will learn how to integrate your MLOps setups using Databricks. © 2021 by Sridhar Alla, Suman Kalyan Adari. All rights reserved.",integrate mlops principles into existing or future projects using mlflow  operationalize your models  and deploy them in aws sagemaker  google cloud  and microsoft azure   this book guides you through the process of data analysis  model construction  and training  the authors begin by introducing you to basic data analysis on a credit card data set and teach you how to analyze the features and their relationships to the target variable  you will learn how to build logistic regression models in scikit learn and pyspark  and you will go through the process of hyperparameter tuning with a validation data set  you will explore three different deployment setups of machine learning models with varying levels of automation to help you better understand mlops  mlflow is covered and you will explore how to integrate mlops into your existing code  allowing you to easily track metrics  parameters  graphs  and models  you will be guided through the process of deploying and querying your models with aws sagemaker  google cloud  and microsoft azure  and you will learn how to integrate your mlops setups using databricks         by sridhar alla  suman kalyan adari  all rights reserved ,7.965685,7.670639,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
"Microbial community composition and activity controls phosphorus transformation in rhizosphere soils of the Yeyahu Wetland in Beijing, China","Microorganisms in the rhizosphere of wetland plants can have a significant impact on phosphorus (P) interception. We investigated the seasonal pattern of microbial community structure and its relationship with different P forms in the rhizosphere of three plants Scirpus planiculmis, Zizania latifolia, and Phragmites australis from the Yeyahu Wetland, China. Chloroform fumigation-extraction was used to determine the soil microbial biomass P (SMBP) and phospholipid fatty acids (PLFA) were used to characterize microbial community composition. P fractions in rhizosphere soil samples were also observed using sequential chemical fractionation. Results showed that the average total PLFA (TPLFA) contents of rhizosphere soils ranged from 34.9 to 40.7 nmol·g−1 and were highest in summer. Bacteria were predominant in the rhizospheres of all three plants, accounting for >63% of TPLFA. Aerobic bacteria, represented by 16:0 PLFA, were most abundant. Both organic P (OP) and inorganic P (IP) accumulated in the rhizosphere during the winter die-back phase. Furthermore, both TPLFA and bacterial PLFA decreased with increases in highly resistant OP (HR-OP), occluded P (Oc-P) and Calcium-bound P (Ca-P). This suggests that bacteria play an important role in P transformation and can make use of various P forms. We also found that SMBP was significantly negatively correlated with labile OP (L-OP), moderately labile OP (ML-OP) and HR-OP, reflecting a high degree of cross correlation between SMBP and the PLFA indices. © 2018 Elsevier B.V.",microorganisms in the rhizosphere of wetland plants can have a significant impact on phosphorus  p  interception  we investigated the seasonal pattern of microbial community structure and its relationship with different p forms in the rhizosphere of three plants scirpus planiculmis  zizania latifolia  and phragmites australis from the yeyahu wetland  china  chloroform fumigation extraction was used to determine the soil microbial biomass p  smbp  and phospholipid fatty acids  plfa  were used to characterize microbial community composition  p fractions in rhizosphere soil samples were also observed using sequential chemical fractionation  results showed that the average total plfa  tplfa  contents of rhizosphere soils ranged from      to      nmol g   and were highest in summer  bacteria were predominant in the rhizospheres of all three plants  accounting for      of tplfa  aerobic bacteria  represented by      plfa  were most abundant  both organic p  op  and inorganic p  ip  accumulated in the rhizosphere during the winter die back phase  furthermore  both tplfa and bacterial plfa decreased with increases in highly resistant op  hr op   occluded p  oc p  and calcium bound p  ca p   this suggests that bacteria play an important role in p transformation and can make use of various p forms  we also found that smbp was significantly negatively correlated with labile op  l op   moderately labile op  ml op  and hr op  reflecting a high degree of cross correlation between smbp and the plfa indices         elsevier b v ,4.2219157,1.9495721,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
An Architecture to Integrate Digital Twins and Machine Learning Operations,"Digital twins (DTs) and artificial intelligence (AI) have attracted significant attention and interest from research and industry communities in recent years. DTs have significant potential to support the widespread adoption of AI, in particular machine learning (ML), for more intelligent and autonomous decision making. The adoption and integration of ML into production environments are often difficult and complex, which results in ML models often underperforming relative to the development and testing environment. Machine learning operations (MLOps) overcome this underperformance by continuously deploying, integrating and (re)training ML models in production environments. This paper introduces an architecture that integrates a system of digital twins with an MLOps platform. This integration is achieved using a tight coupling between a DT (part of the DT system) and an MLOps counterpart (part of the MLOps platform). This tight coupling has the benefit of enabling each DT to have unique ML workflows, which reduces complexity within a system of many DTs and many ML workflows. The paper further introduces a Type DT Aggregate which is the aggregation of DT Instances (DTIs) of the same type. This improves scalability in large systems where many DTIs require ML.
 Keywords
 Industry 4.0
 Digital Twin
 Machine Learning
 MLOps",digital twins  dts  and artificial intelligence  ai  have attracted significant attention and interest from research and industry communities in recent years  dts have significant potential to support the widespread adoption of ai  in particular machine learning  ml   for more intelligent and autonomous decision making  the adoption and integration of ml into production environments are often difficult and complex  which results in ml models often underperforming relative to the development and testing environment  machine learning operations  mlops  overcome this underperformance by continuously deploying  integrating and  re training ml models in production environments  this paper introduces an architecture that integrates a system of digital twins with an mlops platform  this integration is achieved using a tight coupling between a dt  part of the dt system  and an mlops counterpart  part of the mlops platform   this tight coupling has the benefit of enabling each dt to have unique ml workflows  which reduces complexity within a system of many dts and many ml workflows  the paper further introduces a type dt aggregate which is the aggregation of dt instances  dtis  of the same type  this improves scalability in large systems where many dtis require ml   keywords  industry      digital twin  machine learning  mlops,8.315162,5.4848,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Maturity Model for Analysis of Machine Learning Operations in Industry,"The next evolutionary technological step in the industry presumes the automation of the elements found within a factory, which can be accomplished through extensive introduction of automatons, computers and Internet of Things (IoT) components. All this seeks to streamline, improve, and increase production at the lowest possible cost and avoid any failure in the creation of the product, following a strategy called â€œZero Defect Manufacturingâ€. Machine Learning Operations (MLOps) provide a ML-based solution to this challenge, promoting the automation of all product-relevant steps, from development to deployment. When integrating different machine learning models within manufacturing operations, it is necessary to have a good understanding of what functionality is needed and what is expected. This article presents a maturity model that can help companies identify and map their current level of implementation of machine learning models.
 Keywords
 Machine learning
 Manufacturing execution system
 Zero-defect manufacturing
 Manufacturing operations
 CMM
 ISA-95
 MLops",the next evolutionary technological step in the industry presumes the automation of the elements found within a factory  which can be accomplished through extensive introduction of automatons  computers and internet of things  iot  components  all this seeks to streamline  improve  and increase production at the lowest possible cost and avoid any failure in the creation of the product  following a strategy called    zero defect manufacturing     machine learning operations  mlops  provide a ml based solution to this challenge  promoting the automation of all product relevant steps  from development to deployment  when integrating different machine learning models within manufacturing operations  it is necessary to have a good understanding of what functionality is needed and what is expected  this article presents a maturity model that can help companies identify and map their current level of implementation of machine learning models   keywords  machine learning  manufacturing execution system  zero defect manufacturing  manufacturing operations  cmm  isa     mlops,10.180072,3.656289,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Explainable AI for ML Ops,"This chapter explains the significance of blending two emerging technologies in AI/MLâ€”Explainable AI (XAI) and Machine Learning Operations (ML Ops) and demonstrates a focused use case that derives value from leveraging XAI to enhance ML Ops. The chapter starts by laying out the â€œgrowing painsâ€ problems that enterprises are encountering to scale AI. We highlight the relatively low maturity of post-production ML processes thus exposing enterprises to reputation, compliance, and hence financial risk. We give a historical perspective on the rise of AI. Subsequent gain in mindshare of ML Ops is explained. XAI as a solution is introduced. After a brief explanation on XAI, we delve into the experimental setup and detail the results that demonstrate the potential of using XAI to enhance ML Ops. We end the white paper by reiterating the benefits, opportunities, and market potential and finally some recommendations.
 Keywords
 Machine learning
 Explainable AI
 XAI
 Cloud platforms
 Machine learning operations
 ML Ops
 Solution
 Pandemic
 Opportunities",this chapter explains the significance of blending two emerging technologies in ai ml   explainable ai  xai  and machine learning operations  ml ops  and demonstrates a focused use case that derives value from leveraging xai to enhance ml ops  the chapter starts by laying out the    growing pains    problems that enterprises are encountering to scale ai  we highlight the relatively low maturity of post production ml processes thus exposing enterprises to reputation  compliance  and hence financial risk  we give a historical perspective on the rise of ai  subsequent gain in mindshare of ml ops is explained  xai as a solution is introduced  after a brief explanation on xai  we delve into the experimental setup and detail the results that demonstrate the potential of using xai to enhance ml ops  we end the white paper by reiterating the benefits  opportunities  and market potential and finally some recommendations   keywords  machine learning  explainable ai  xai  cloud platforms  machine learning operations  ml ops  solution  pandemic  opportunities,7.6384773,7.564037,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Building an AI Platform,"As an AI startup, it is essential to have a clear strategy for designing, developing, and operating an AI platform that can meet market demands. In the previous chapters, we learned about validating AI products from various perspectives. This chapter will explore the details of building a successful AI platform that involves designing, developing, and operating the AI system. Building an AI platform is a complex process that requires careful consideration of many factors. We will explore the importance of the three pillars of AI platform design: system design, process design, and team design. We will provide a comprehensive framework that unifies these pillars into a single approach to building an effective AI platform. Measuring the maturity of an AI platform is also an essential aspect of the building process. We will discuss how to assess the platform at different stages, from initial development to optimized operation. This chapter will also discuss the challenges and best practices of building an AI platform. We will explore common issues and provide practical solutions to ensure success. To illustrate how the framework and best practices discussed in this chapter can be applied in practice, we will provide a case study of designing, developing, and operating an eKYC AI as a Service platform. This case study will provide real-world examples of the key considerations and decisions in building an effective AI platform. By the end of this chapter, you will have a comprehensive understanding of what it takes to build a successful AI platform and the steps involved in designing, developing, and operating such a system.",as an ai startup  it is essential to have a clear strategy for designing  developing  and operating an ai platform that can meet market demands  in the previous chapters  we learned about validating ai products from various perspectives  this chapter will explore the details of building a successful ai platform that involves designing  developing  and operating the ai system  building an ai platform is a complex process that requires careful consideration of many factors  we will explore the importance of the three pillars of ai platform design  system design  process design  and team design  we will provide a comprehensive framework that unifies these pillars into a single approach to building an effective ai platform  measuring the maturity of an ai platform is also an essential aspect of the building process  we will discuss how to assess the platform at different stages  from initial development to optimized operation  this chapter will also discuss the challenges and best practices of building an ai platform  we will explore common issues and provide practical solutions to ensure success  to illustrate how the framework and best practices discussed in this chapter can be applied in practice  we will provide a case study of designing  developing  and operating an ekyc ai as a service platform  this case study will provide real world examples of the key considerations and decisions in building an effective ai platform  by the end of this chapter  you will have a comprehensive understanding of what it takes to build a successful ai platform and the steps involved in designing  developing  and operating such a system ,11.649738,7.080794,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
MLOps Challenges in Industry 4.0,"An important part of the Industry 4.0 vision is the use of machine learning (ML) techniques to create novel capabilities and flexibility in industrial production processes. Currently, there is a strong emphasis on MLOps as an enabling collection of practices, techniques, and tools to integrate ML into industrial practice. However, while MLOps is often discussed in the context of pure software systems, Industry 4.0 systems received much less attention. So far, there is only little research focusing on MLOps for Industry 4.0. In this paper, we discuss whether MLOps in Industry 4.0 leads to significantly different challenges compared to typical Internet systems. We provide an initial analysis of MLOps approaches and identify both context-independent MLOps challenges (general challenges) as well as challenges particular to Industry 4.0 (specific challenges) and conclude that MLOps works very similarly in Industry 4.0 systems to pure software systems. This indicates that existing tools and approaches are also mostly suited for the Industry 4.0 context.",an important part of the industry     vision is the use of machine learning  ml  techniques to create novel capabilities and flexibility in industrial production processes  currently  there is a strong emphasis on mlops as an enabling collection of practices  techniques  and tools to integrate ml into industrial practice  however  while mlops is often discussed in the context of pure software systems  industry     systems received much less attention  so far  there is only little research focusing on mlops for industry      in this paper  we discuss whether mlops in industry     leads to significantly different challenges compared to typical internet systems  we provide an initial analysis of mlops approaches and identify both context independent mlops challenges  general challenges  as well as challenges particular to industry      specific challenges  and conclude that mlops works very similarly in industry     systems to pure software systems  this indicates that existing tools and approaches are also mostly suited for the industry     context ,10.099444,4.1690497,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Tools for Data Science Developers,"How do we manage data and models? What are the tools we can use to make ourselves more efficient and agile in data science? In this chapter, we will deep dive into the tools and technology that you will depend on daily as an MLOps engineer.",how do we manage data and models  what are the tools we can use to make ourselves more efficient and agile in data science  in this chapter  we will deep dive into the tools and technology that you will depend on daily as an mlops engineer ,9.154637,6.521486,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Teaching Advanced AI Development Techniques with a New Masterâ€™s Program in Artificial Intelligence Engineering,"The paper presents a new Masterâ€™s program Artificial Intelligence Engineering at Ural Federal University created in cooperation with IT companies and partner universities. The aim of the program is to teach engineers who are able to develop complex large-scale software solutions that use artificial intelligence and put the solutions into production. The students study in detail not only the theoretical foundations and practical applications of artificial intelligence for various areas (natural language processing, computer vision, time series analysis, information security) but also contemporary methods and software engineering tools for machine learning operations (MLOps). The students acquire soft skills through project-based learning by solving research or real-world problems provided by partner companies, universities labs and Institutes of Russian Academy of Science. In addition to Ural Federal University, the program was implemented at six partner universities.
 Keywords
 AI engineering
 MLOps
 ML education
 Masterâ€™s program",the paper presents a new master   s program artificial intelligence engineering at ural federal university created in cooperation with it companies and partner universities  the aim of the program is to teach engineers who are able to develop complex large scale software solutions that use artificial intelligence and put the solutions into production  the students study in detail not only the theoretical foundations and practical applications of artificial intelligence for various areas  natural language processing  computer vision  time series analysis  information security  but also contemporary methods and software engineering tools for machine learning operations  mlops   the students acquire soft skills through project based learning by solving research or real world problems provided by partner companies  universities labs and institutes of russian academy of science  in addition to ural federal university  the program was implemented at six partner universities   keywords  ai engineering  mlops  ml education  master   s program,9.2547245,5.5793977,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Deploying Stochastic Systems,"If youâ€™ve made it this far, you already have the skills to build a complete end to end data science system. Data science of course is more than machine learning and code which are really only tools, and to build end to end systems, we need to understand people, processes, and technology, so this chapter will take a step back and give you a birdâ€™s-eye view of the entire MLOps lifecycle, tying in what weâ€™ve learned in previous chapters to formally define each stage. Once we have the lifecycle defined, weâ€™ll be able to analyze it to understand how we can reduce technical debt by considering the interactions between the various stages from data collection and data engineering through to model development and deployment. Weâ€™ll cover some philosophical debates between model-centric vs. data-centric approaches to MLOps and look at how we can move toward continuous delivery, the ultimate litmus test for how much value your models are creating in production. We will also discuss how the rise of generative AI may impact data science development in general, build a CI/CD pipeline for our toolkit, and talk about how we can use pre-build cloud services to deploy your models. Without further ado, letâ€™s explore the stages of the ML lifecycle again and introduce the spiral ML lifecycle formally.",if you   ve made it this far  you already have the skills to build a complete end to end data science system  data science of course is more than machine learning and code which are really only tools  and to build end to end systems  we need to understand people  processes  and technology  so this chapter will take a step back and give you a bird   s eye view of the entire mlops lifecycle  tying in what we   ve learned in previous chapters to formally define each stage  once we have the lifecycle defined  we   ll be able to analyze it to understand how we can reduce technical debt by considering the interactions between the various stages from data collection and data engineering through to model development and deployment  we   ll cover some philosophical debates between model centric vs  data centric approaches to mlops and look at how we can move toward continuous delivery  the ultimate litmus test for how much value your models are creating in production  we will also discuss how the rise of generative ai may impact data science development in general  build a ci cd pipeline for our toolkit  and talk about how we can use pre build cloud services to deploy your models  without further ado  let   s explore the stages of the ml lifecycle again and introduce the spiral ml lifecycle formally ,8.822355,6.718218,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
An Analysis of the Barriers Preventing the Implementation of MLOps,"The rapid improvements in machine learning (ML) and the increasing importance of ML models in numerous industries have resulted in the emergence of MLOps (Machine Learning Operations), a discipline focusing on efficiently managing and operationalising ML workflows. This exploratory study investigates the difficulties encountered when implementing MLOps within organisations and compares MLOps to DevOps. The study begins by conducting an SLR to identify the challenges mentioned in the literature. We then explain the results of conducting semi-structured interviews with 12 ML practitioners working across many industries, perform qualitative content analysis using grounded theory, and discuss findings. Findings are organised along four distinct dimensions: Organisational, Technical, Operational and Business challenges, which are explained in eleven different themes. Our findings show that MLOps has some challenges that overlap with DevOps as well as some specific only to MLOps, like the complexity of data and model. In our discussion, we summarize these challenges and suggest future recommendations.
 Keywords
 Machine learning Operations (MLOps)
 Grounded theory
 Data Science",the rapid improvements in machine learning  ml  and the increasing importance of ml models in numerous industries have resulted in the emergence of mlops  machine learning operations   a discipline focusing on efficiently managing and operationalising ml workflows  this exploratory study investigates the difficulties encountered when implementing mlops within organisations and compares mlops to devops  the study begins by conducting an slr to identify the challenges mentioned in the literature  we then explain the results of conducting semi structured interviews with    ml practitioners working across many industries  perform qualitative content analysis using grounded theory  and discuss findings  findings are organised along four distinct dimensions  organisational  technical  operational and business challenges  which are explained in eleven different themes  our findings show that mlops has some challenges that overlap with devops as well as some specific only to mlops  like the complexity of data and model  in our discussion  we summarize these challenges and suggest future recommendations   keywords  machine learning operations  mlops   grounded theory  data science,10.286124,4.046363,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Foundations for MLOps Systems,"In this chapter, we will discuss foundations for MLOps systems by breaking down the topic into fundamental building blocks that you will apply in future chapters. While we will discuss programming nondeterministic systems, data structures and algorithmic thinking for data science, and how to translate thoughts into executable code, the goal is not to give a fully comprehensive introduction to these areas in a single chapter but instead provide further resources to point you in the right direction and answer an important question: Why do you need to understand mathematics to develop and deploy MLOps systems?",in this chapter  we will discuss foundations for mlops systems by breaking down the topic into fundamental building blocks that you will apply in future chapters  while we will discuss programming nondeterministic systems  data structures and algorithmic thinking for data science  and how to translate thoughts into executable code  the goal is not to give a fully comprehensive introduction to these areas in a single chapter but instead provide further resources to point you in the right direction and answer an important question  why do you need to understand mathematics to develop and deploy mlops systems ,9.314193,6.8489256,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Big Data and Machine Learning,"Google Cloud Platform offers multiple services for the management of big data and the execution of Extract, Transform, Load (ETL) operations. Additionally, it provides tools for the training and deployment of machine learning models. Within this chapter, we will delve into BigQuery and its query execution. Moreover, we will gain insights into employing BigQuery ML for the development of machine learning models. The exploration extends to Google Cloud AI Platform, where we will gain practical experience with Vertex AI for training and deploying machine learning models.",google cloud platform offers multiple services for the management of big data and the execution of extract  transform  load  etl  operations  additionally  it provides tools for the training and deployment of machine learning models  within this chapter  we will delve into bigquery and its query execution  moreover  we will gain insights into employing bigquery ml for the development of machine learning models  the exploration extends to google cloud ai platform  where we will gain practical experience with vertex ai for training and deploying machine learning models ,8.238979,7.656247,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Evolution of circuits for machine learning,"Silver, D. et al. Nature 529, 484â€“489 (2016).
 Article
  PubMed
  Google Scholar
  Liu, X. et al. Lancet Dig. Health 1, e271â€“e297 (2019).
 Article
  Google Scholar
  Chen, T. et al. Nature 577, 341â€“345 (2020).
 Article
  Google Scholar
  Merolla, P. A. et al. Science 345, 668â€“673 (2014).
 Article
  PubMed
  Google Scholar
  Day, A., Wynn, A. & Golden, E. APS March Meet. 2020 abstr. L48.00008 (2020); go.nature.com/2ti4zt1
 Binnig, G., Rohrer, H., Gerber, Ch. & Weibel, E. Phys. Rev. Lett. 50, 120â€“123 (1983).
 Article
  Google Scholar
  Arute, F. et al. Nature 574, 505â€“510 (2019).
 Article
  PubMed
  Google Scholar
  Bose, S. K. et al. Nature Nanotechnol. 10, 1048â€“1052 (2015).
 Article
  PubMed
  Google Scholar
  Schofield, S. R. et al. Phys. Rev. Lett. 91, 136104 (2003).
 Article
  PubMed
  Google Scholar
  Download references",silver  d  et al  nature                         article   pubmed   google scholar   liu  x  et al  lancet dig  health    e      e             article   google scholar   chen  t  et al  nature                         article   google scholar   merolla  p  a  et al  science                         article   pubmed   google scholar   day  a   wynn  a    golden  e  aps march meet       abstr  l                 go nature com  ti zt   binnig  g   rohrer  h   gerber  ch    weibel  e  phys  rev  lett                         article   google scholar   arute  f  et al  nature                         article   pubmed   google scholar   bose  s  k  et al  nature nanotechnol                           article   pubmed   google scholar   schofield  s  r  et al  phys  rev  lett                      article   pubmed   google scholar   download references,9.0183325,7.0371337,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Understanding Business Goals,"In this chapter, we explore the different ways to understand and act upon business goals. One might say that each business knows its own goals and has a solid strategy to achieve those goals. However, it is very easy to drown in the weeds of metrics and goals and target everything and nothing all at once. Now, this is not to discourage and accuse leaders from establishing wrong goals, but more to provide a different view to measuring what is right.",in this chapter  we explore the different ways to understand and act upon business goals  one might say that each business knows its own goals and has a solid strategy to achieve those goals  however  it is very easy to drown in the weeds of metrics and goals and target everything and nothing all at once  now  this is not to discourage and accuse leaders from establishing wrong goals  but more to provide a different view to measuring what is right ,10.465344,6.814576,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Machine Learning Fundamental Concepts,"This chapter takes you on an introductory machine learning journey to familiarize you with all the fundamental basics of this topic. This chapter begins by defining machine learning and then goes on to describe core machine learning concepts like datasets, features and labels, machine learning algorithms, machine learning workflow, and model evaluation metrics. The chapter also covers different types of machine learning, such as supervised and unsupervised learning, as well as machine learning in Microsoft Azure. Youâ€™ll also learn about machine learning tools like Azure Machine Learning Studio and Azure Machine Learning Designer here.",this chapter takes you on an introductory machine learning journey to familiarize you with all the fundamental basics of this topic  this chapter begins by defining machine learning and then goes on to describe core machine learning concepts like datasets  features and labels  machine learning algorithms  machine learning workflow  and model evaluation metrics  the chapter also covers different types of machine learning  such as supervised and unsupervised learning  as well as machine learning in microsoft azure  you   ll also learn about machine learning tools like azure machine learning studio and azure machine learning designer here ,8.546469,7.408506,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Leveraging Remote Work to Accelerate Material Informatics by Implementing Machine Learning Web Applications and Introducing Statistical Analysis Tools for Materials Scientists in a Chemical Corporation,"Using past experimental data is advantageous in material design; however, constructing machine learning models based on this data remains challenging for materials scientists unfamiliar with machine learning. While data scientists can build appropriate machine learning models with their expertise in statistics, machine learning, and computer science, they may need more domain knowledge, particularly tacit knowledge in materials design. Therefore, collaboration between data scientists and materials scientists is necessary, but the differences in expertise between the two groups can hinder the development of materials informatics. In Resonac Corporation, we have leveraged the remote work opportunities caused by COVID-19 to accelerate the usage of materials informatics. We accomplished this by deploying the electronic laboratory notebooks and statistical analysis tool and implementing web applications with a user-friendly Graphical User Interface for materials scientists. As a result, remote work has allowed materials scientists to focus on data organization, statistical data analysis, and the usage of web applications.
 Keywords
 Materials informatics
 Data analysis
 Web application",using past experimental data is advantageous in material design  however  constructing machine learning models based on this data remains challenging for materials scientists unfamiliar with machine learning  while data scientists can build appropriate machine learning models with their expertise in statistics  machine learning  and computer science  they may need more domain knowledge  particularly tacit knowledge in materials design  therefore  collaboration between data scientists and materials scientists is necessary  but the differences in expertise between the two groups can hinder the development of materials informatics  in resonac corporation  we have leveraged the remote work opportunities caused by covid    to accelerate the usage of materials informatics  we accomplished this by deploying the electronic laboratory notebooks and statistical analysis tool and implementing web applications with a user friendly graphical user interface for materials scientists  as a result  remote work has allowed materials scientists to focus on data organization  statistical data analysis  and the usage of web applications   keywords  materials informatics  data analysis  web application,9.427754,3.2866945,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Unifying Organizationsâ€™ Machine Learning Vision,"Data is growing at an unprecedented rate, and as discussed in previous chapters, businesses are struggling to keep up with the demands of scaling their data processing and modeling infrastructure. As more and more data is generated every day by the various telemetry systems, the ability to scale the operations of data science and machine learning becomes increasingly important. However, scaling data processing infrastructure is not as simple as adding more resources, and there are many challenges that arise when working with increased demand for insights and large datasets that constantly grow.",data is growing at an unprecedented rate  and as discussed in previous chapters  businesses are struggling to keep up with the demands of scaling their data processing and modeling infrastructure  as more and more data is generated every day by the various telemetry systems  the ability to scale the operations of data science and machine learning becomes increasingly important  however  scaling data processing infrastructure is not as simple as adding more resources  and there are many challenges that arise when working with increased demand for insights and large datasets that constantly grow ,8.597252,6.2128363,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Application of machine learning algorithm on migration error for the identification of selective letter position impairment in children,"This work presents effective prediction of Letter Position impairments on a sample dataset of 230 children. These students are in primary school grade in a school of West Bengal whose mother language is Bengali. Among the primary school-going children, there exists some percentage of children who are affected with dyslexia or tend to develop reading disabilities. The fundamental deficit of these children is problem with proper letter position encoding skill in a word. This paper proposes computerized identification of children affected with disability to locate actual position of letters within a word. In the first approach, machine learning based algorithms are employed on the migration errors originating from the speech samples of a set of children from a particular school to identify the algorithm that provides the best result. Next, in order to make the diagnosis technique more robust and to validate the results obtained from the first data set of children, the set of techniques are implemented on another set of children from a different school. The speech samples of the students consist of their utterances while they speak English words. The set of words are based on Letter Position Test developed by Kohnen, Friedmann, Mc Arthur & Castles. Machine learning algorithms such as NaÃ¯ve Bayes and support vector machine presents the most efficient method of predicting the letter position impairments among children of primary school grades speaking English as their second language. Results displayed accuracy above 95 percent. The proposed approach in this paper can be applied as a screening mechanism for the identification of dyslexia focusing on letter position impairment among kids in schools.",this work presents effective prediction of letter position impairments on a sample dataset of     children  these students are in primary school grade in a school of west bengal whose mother language is bengali  among the primary school going children  there exists some percentage of children who are affected with dyslexia or tend to develop reading disabilities  the fundamental deficit of these children is problem with proper letter position encoding skill in a word  this paper proposes computerized identification of children affected with disability to locate actual position of letters within a word  in the first approach  machine learning based algorithms are employed on the migration errors originating from the speech samples of a set of children from a particular school to identify the algorithm that provides the best result  next  in order to make the diagnosis technique more robust and to validate the results obtained from the first data set of children  the set of techniques are implemented on another set of children from a different school  the speech samples of the students consist of their utterances while they speak english words  the set of words are based on letter position test developed by kohnen  friedmann  mc arthur   castles  machine learning algorithms such as na  ve bayes and support vector machine presents the most efficient method of predicting the letter position impairments among children of primary school grades speaking english as their second language  results displayed accuracy above    percent  the proposed approach in this paper can be applied as a screening mechanism for the identification of dyslexia focusing on letter position impairment among kids in schools ,5.582379,4.9036894,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Introduction to Machine Learning,"We live in exciting times with smartphones and watches, smart clothes, robots, droids, face recognition, smart personal assistants, recommender systems, self-driving autonomous cars, and 24/7 service chatbots, all of which are artificial intelligence (AI). But what is intelligence? Intelligence might be defined as the ability to acquire and apply knowledge and skills, in other words, to learn and use the skills learned. Artificial intelligence is exactly that but done by computers and software. In real life, people would like to have intelligent machines that can do things people find boring, do inefficiently, or maybe cannot do at all. It could be an extension of human intelligence through using computers, which is artificial intelligence. The core of artificial intelligence is the ability to learn, acquire knowledge and skills, which is machine learning. In machine learning, the machine is learning, reasoning, and self-correcting. Arthur Samuel defined machine learning in 1959 as â€œa field of study that gives computers the ability to learn without being explicitly programmed,â€ which defines machine learning very well.",we live in exciting times with smartphones and watches  smart clothes  robots  droids  face recognition  smart personal assistants  recommender systems  self driving autonomous cars  and      service chatbots  all of which are artificial intelligence  ai   but what is intelligence  intelligence might be defined as the ability to acquire and apply knowledge and skills  in other words  to learn and use the skills learned  artificial intelligence is exactly that but done by computers and software  in real life  people would like to have intelligent machines that can do things people find boring  do inefficiently  or maybe cannot do at all  it could be an extension of human intelligence through using computers  which is artificial intelligence  the core of artificial intelligence is the ability to learn  acquire knowledge and skills  which is machine learning  in machine learning  the machine is learning  reasoning  and self correcting  arthur samuel defined machine learning in      as    a field of study that gives computers the ability to learn without being explicitly programmed     which defines machine learning very well ,9.222713,4.187813,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
AutoTiM - An Open-Source Service for Automated Provisioning and Operation of Time Series Based Machine Learning Models,"The ubiquitous availability of heterogeneous sensor data created by Internet-of-Things (IoT) technologies and Industry 4.0 trends drastically accelerated the development of machine learning applications. AutoML services enable users with sparse machine learning knowledge to develop AI-based applications and rapidly evaluate the feasibility of data-driven ideas. Therefore, there exists a demand for holistic, low-code, end-to-end AutoML systems, which cover all stages of the machine learning lifecycle (i.e., feature engineering, model training, evaluation, versioning, provisioning, etc.). Although there are proprietary, cost-intensive platforms addressing these issues, no open-source solutions covering these aspects are known to us. In this paper we present AutoTiM, an open-source service capable of creating and operating highly performant machine learning models without requiring domain expertise or machine learning knowledge.
 Keywords
 AutoML
 Democratization
 Automated Machine Learning",the ubiquitous availability of heterogeneous sensor data created by internet of things  iot  technologies and industry     trends drastically accelerated the development of machine learning applications  automl services enable users with sparse machine learning knowledge to develop ai based applications and rapidly evaluate the feasibility of data driven ideas  therefore  there exists a demand for holistic  low code  end to end automl systems  which cover all stages of the machine learning lifecycle  i e   feature engineering  model training  evaluation  versioning  provisioning  etc    although there are proprietary  cost intensive platforms addressing these issues  no open source solutions covering these aspects are known to us  in this paper we present autotim  an open source service capable of creating and operating highly performant machine learning models without requiring domain expertise or machine learning knowledge   keywords  automl  democratization  automated machine learning,10.002148,6.4727955,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Infrastructure for MLOps,"This chapter is about infrastructure. You might think of buildings and roads when you hear the word infrastructure, but in MLOps, infrastructure refers to the most fundamental services we need to build more complex systems like training, inference, and model deployment pipelines. For example, we need a way to create data stores that can store features for model training and servers with compute and memory resources for hosting training pipelines. In the next section, we will look at a way we can simplify the process of creating infrastructure by using containers to package up software that can easily be maintained, deployed, and reproduced.",this chapter is about infrastructure  you might think of buildings and roads when you hear the word infrastructure  but in mlops  infrastructure refers to the most fundamental services we need to build more complex systems like training  inference  and model deployment pipelines  for example  we need a way to create data stores that can store features for model training and servers with compute and memory resources for hosting training pipelines  in the next section  we will look at a way we can simplify the process of creating infrastructure by using containers to package up software that can easily be maintained  deployed  and reproduced ,8.255424,6.7276597,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Model Operationalization at Edge Devices,"This Chapter covers the core aspects related to Model Operationalization (ML-Ops). MLOps accelerates the journey of seamlessly building, training, validating and deploying the optimal models in production. This allows for the organization to accelerate their end to end pipeline from capturing the data from different sources and applying governance policies on the data to continuously monitoring the best candidate models deployed in production environment. This chapter further articulates the intersection of ML-Ops at edge devices and optimizations associated with efficiently creating ML-Ops pipeline across said edge devices.",this chapter covers the core aspects related to model operationalization  ml ops   mlops accelerates the journey of seamlessly building  training  validating and deploying the optimal models in production  this allows for the organization to accelerate their end to end pipeline from capturing the data from different sources and applying governance policies on the data to continuously monitoring the best candidate models deployed in production environment  this chapter further articulates the intersection of ml ops at edge devices and optimizations associated with efficiently creating ml ops pipeline across said edge devices ,7.6235757,7.356094,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
AI Startup Exit Strategy,"As discussed in the previous chapters, building a successful AI startup is no easy feat. It requires a deep understanding of complex technology, its operationalization, a sound business model, and the ability to navigate complex market dynamics. But once a startup has gained traction and is on the path to success, the founders need to start thinking about their exit strategy.",as discussed in the previous chapters  building a successful ai startup is no easy feat  it requires a deep understanding of complex technology  its operationalization  a sound business model  and the ability to navigate complex market dynamics  but once a startup has gained traction and is on the path to success  the founders need to start thinking about their exit strategy ,10.683328,7.0245466,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Artificial Intelligence for Edge Computing,"The existing gaps (or some missing monthly observations) in the Gravity Recovery and Climate Experiment (GRACE) data limit its use in climate change studies. Data gaps provide an opportunity to reconstruct the time series of GRACE-derived terrestrial water storage (TWS) product or extend it backward to favor climate change assessments. To address this limitation, the use of machine learning models to reconstruct GRACE data is gradually emerging, emphasizing the importance of accurately filling these data gaps. This chapter demonstrates the utility of an integrated machine learning technique that shows faster convergence rates, finer predictions, and more efficient reconstructive properties for non-linear systems. By exemplifying the reconstruction process of TWS using this technique, this chapter discusses how the reconstruction of GRACE data can help improve understanding of the influence of climate variability on terrestrial hydrology.",the existing gaps  or some missing monthly observations  in the gravity recovery and climate experiment  grace  data limit its use in climate change studies  data gaps provide an opportunity to reconstruct the time series of grace derived terrestrial water storage  tws  product or extend it backward to favor climate change assessments  to address this limitation  the use of machine learning models to reconstruct grace data is gradually emerging  emphasizing the importance of accurately filling these data gaps  this chapter demonstrates the utility of an integrated machine learning technique that shows faster convergence rates  finer predictions  and more efficient reconstructive properties for non linear systems  by exemplifying the reconstruction process of tws using this technique  this chapter discusses how the reconstruction of grace data can help improve understanding of the influence of climate variability on terrestrial hydrology ,6.9742928,6.233799,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Machine Learning as a Service (MLaaS)â€”An Enterprise Perspective,"Machine learning (ML) algorithms due to their outstanding performances are being extensively used in applications covering several different domains. Recently, the increased growth of cloud services provided training infrastructures for complex ML models able to deal with big data, resulting in the enhancement of ML as a Service (MLaaS). Toward this end, ML applications have been deployed in systems, production models, and businesses. ML algorithms involve accessing data, which is often privacy sensitive. The latter may result in security and privacy risks. Toward this end, this work examines MLaaS and its incorporation into businesses, covering a wide range of different sectors. Companies that develop ML applications are reviewed, and trends in ML-related jobs are reported. Moreover, data protection privacy is discussed and the evolution of graphics processing units (GPUs) as a necessary supporting technology for ML applications is also considered.
 Keywords
 MLaaS
 Machine learning as a service
 Artificial intelligence
 MLOps
 Enterprise
 GPUs",machine learning  ml  algorithms due to their outstanding performances are being extensively used in applications covering several different domains  recently  the increased growth of cloud services provided training infrastructures for complex ml models able to deal with big data  resulting in the enhancement of ml as a service  mlaas   toward this end  ml applications have been deployed in systems  production models  and businesses  ml algorithms involve accessing data  which is often privacy sensitive  the latter may result in security and privacy risks  toward this end  this work examines mlaas and its incorporation into businesses  covering a wide range of different sectors  companies that develop ml applications are reviewed  and trends in ml related jobs are reported  moreover  data protection privacy is discussed and the evolution of graphics processing units  gpus  as a necessary supporting technology for ml applications is also considered   keywords  mlaas  machine learning as a service  artificial intelligence  mlops  enterprise  gpus,9.273234,5.498667,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Supervised Learning Algorithms,"Itâ€™s time to do some learning based on the data. Most folks think machine learning is applying an algorithm on given data and then predicting results. Well, itâ€™s not just that. Eighty percent of the work involves data collection, preprocessing, cleaning, feature engineering, transformation, and selecting the best features. The remaining 20 percent is spent on building machine learning models, validation, and deployment. The entire operation is called MLOps (machine learning operations). It is similar to DevOps, but for machine learning. In order to understand and deploy a production model, you should be familiar with each component in MLOps. In this book, the chapters we have covered so far have discussed the 80 percent of the work. If you skipped those chapters, we recommend reading them before you read this chapter. In addition, business and domain knowledge helps you to improve the process throughout.",it   s time to do some learning based on the data  most folks think machine learning is applying an algorithm on given data and then predicting results  well  it   s not just that  eighty percent of the work involves data collection  preprocessing  cleaning  feature engineering  transformation  and selecting the best features  the remaining    percent is spent on building machine learning models  validation  and deployment  the entire operation is called mlops  machine learning operations   it is similar to devops  but for machine learning  in order to understand and deploy a production model  you should be familiar with each component in mlops  in this book  the chapters we have covered so far have discussed the    percent of the work  if you skipped those chapters  we recommend reading them before you read this chapter  in addition  business and domain knowledge helps you to improve the process throughout ,8.672858,7.029089,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Practical and Open Source Best Practices for Ethical Machine Learning,"The acknowledged operational, ethical, legal and governance risks involved in applying Machine Learning (ML) have generated a need for a clear and thoughtful repository of best practices on how to responsibly govern, manage and implement â€œresponsible MLâ€. The Foundation for Best Practices in Machine Learning (a non-profit foundation) seeks to promote responsible ML through creating an open-sourced, freely accessible repository of best practices and associated guides. Its model and organisational guides look at both the technical and institutional requirements needed to promote responsible ML. Both blueprints touch on subjects such as â€œFairness & Non-Discriminationâ€, â€œRepresentativeness & Specificationâ€, â€œProduct Traceabilityâ€, â€œExplainabilityâ€ amongst other topics. Where the organisational guide relates to organisation-wide process and responsibilities (i.e. the necessity of setting proper product definitions and risk portfolios); the model guide details issues ranging from cost function specification and optimisation to selection function characterization, from disparate impact metrics to local explanations and counterfactuals. It also addresses issues concerning thorough product management. These guidelines have been developed principally by senior ML engineers, data scientists, data science managers, and legal professionals for ML engineers, data scientists, data science managers, compliance professionals, legal practitioners, and, more broadly, management. The Foundationâ€™s philosophy is that (a) context is key, (b) responsible ML starts with prudent MLOps and product management, and (c) responsible ML needs to be supported by all aspects of an organisationâ€™s structure.",the acknowledged operational  ethical  legal and governance risks involved in applying machine learning  ml  have generated a need for a clear and thoughtful repository of best practices on how to responsibly govern  manage and implement    responsible ml     the foundation for best practices in machine learning  a non profit foundation  seeks to promote responsible ml through creating an open sourced  freely accessible repository of best practices and associated guides  its model and organisational guides look at both the technical and institutional requirements needed to promote responsible ml  both blueprints touch on subjects such as    fairness   non discrimination        representativeness   specification        product traceability        explainability    amongst other topics  where the organisational guide relates to organisation wide process and responsibilities  i e  the necessity of setting proper product definitions and risk portfolios   the model guide details issues ranging from cost function specification and optimisation to selection function characterization  from disparate impact metrics to local explanations and counterfactuals  it also addresses issues concerning thorough product management  these guidelines have been developed principally by senior ml engineers  data scientists  data science managers  and legal professionals for ml engineers  data scientists  data science managers  compliance professionals  legal practitioners  and  more broadly  management  the foundation   s philosophy is that  a  context is key   b  responsible ml starts with prudent mlops and product management  and  c  responsible ml needs to be supported by all aspects of an organisation   s structure ,10.788166,6.6714973,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Designing Data Spaces The Ecosystem Approach to Competitive Advantage,"In Chapter Two, we surveyed the history of business analytics as a whole, noting that statistics and machine learning developed separately from data warehousing and business intelligence. In this chapter, we pick up where Chapter Two left off with a review of recent trends in machine learning: convergence, competitions, ensemble learning, scalability and deep learning. We devote a section of the chapter to deep learning basics, and with a survey of open source and commercial software for machine learning.
 Keywords
 Machine Learning
 Random Forest
 Neural Network Radial Basis Function
 Deep Learning
 Latent Dirichlet Allocation
 These keywords were added by machine and not by the authors. This process is experimental and the keywords may be updated as the learning algorithm improves.",in chapter two  we surveyed the history of business analytics as a whole  noting that statistics and machine learning developed separately from data warehousing and business intelligence  in this chapter  we pick up where chapter two left off with a review of recent trends in machine learning  convergence  competitions  ensemble learning  scalability and deep learning  we devote a section of the chapter to deep learning basics  and with a survey of open source and commercial software for machine learning   keywords  machine learning  random forest  neural network radial basis function  deep learning  latent dirichlet allocation  these keywords were added by machine and not by the authors  this process is experimental and the keywords may be updated as the learning algorithm improves ,9.398192,7.6745415,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Impacts of Modern AI and ML Trends,"The rapidly advancing field of artificial intelligence (AI) and machine learning (ML) is changing the way we live, work, and interact with technology. With recent advancements in several fields of AI, such as generative AI, we are seeing the potential of this technology, which is being integrated within robotics such as 3D printers and software applications such as Excel and being made available through integration API layers for new business opportunities. However, with this progress comes a new set of challenges and impacts on society that are often not fully understood or appreciated. As AI and ML continue to permeate every aspect of our lives, it's becoming increasingly important for people to be aware of both the capabilities and the potential consequences of these technologies.",the rapidly advancing field of artificial intelligence  ai  and machine learning  ml  is changing the way we live  work  and interact with technology  with recent advancements in several fields of ai  such as generative ai  we are seeing the potential of this technology  which is being integrated within robotics such as  d printers and software applications such as excel and being made available through integration api layers for new business opportunities  however  with this progress comes a new set of challenges and impacts on society that are often not fully understood or appreciated  as ai and ml continue to permeate every aspect of our lives  it s becoming increasingly important for people to be aware of both the capabilities and the potential consequences of these technologies ,10.598506,5.4669356,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Big Data Processing Based on Machine Learning for Multi-user Environments,"Many sources of data yield non-structured data like the Internet of things (IoT), geospatial data, E-commerce, social media, and scientific research that is not appropriate in to traditional, structured warehouses. Nowadays, sophisticated analytical techniques allow companies to obtain perspicacity from data with earlier unachievable levels of accuracy and speed. Real-time analytics for big data is the capability to achieve the most suitable decisions and get significant actions at the best time. First, we present a survey of processing the big data (BD) in real time (RT) and focus on its challenges. Then, we propose an algorithm to handle BD by integration with machine learning operations in multi-user environment optimization operations, reduce maintenance costs and better speed of fault detector and provide common operations necessary to process unstructured information. There are important conditions that have been taken into a concern to guarantee the quality of services (QoS) and transmission velocity and ensure the systemâ€™s physical time synchronization and the correctness of the data processing.
 Keywords
 Big data
 Multi-user environment
 Real-time processing
 Machine learning",many sources of data yield non structured data like the internet of things  iot   geospatial data  e commerce  social media  and scientific research that is not appropriate in to traditional  structured warehouses  nowadays  sophisticated analytical techniques allow companies to obtain perspicacity from data with earlier unachievable levels of accuracy and speed  real time analytics for big data is the capability to achieve the most suitable decisions and get significant actions at the best time  first  we present a survey of processing the big data  bd  in real time  rt  and focus on its challenges  then  we propose an algorithm to handle bd by integration with machine learning operations in multi user environment optimization operations  reduce maintenance costs and better speed of fault detector and provide common operations necessary to process unstructured information  there are important conditions that have been taken into a concern to guarantee the quality of services  qos  and transmission velocity and ensure the system   s physical time synchronization and the correctness of the data processing   keywords  big data  multi user environment  real time processing  machine learning,4.995383,5.1261883,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Hopf physical reservoir computer for reconfigurable sound recognition,"Nowadays, Artificial Intelligence (AI) is powering the data-driven advances that are transforming industries around the planet. AI has become one of the most popular technologies of computer science utilizing to build and develop smart machines. These are cognitive computing systems created to perform actions which can be executed by human intelligence. Major online retailers use AI in analyzing customersâ€™ data to forecast the purchase behavior of consumers. Amazon, Walmart.com and Alibaba employ AI along with forecasting techniques to predict sales and plan inventory accordingly. Data collected from these online retailers indicate they have heavily invested in pricing algorithms that update prices at high speed. According to Vantage Market Research study, global AI in retail market will grow from $2.93 billion USD in 2021 to $17.08 billion by 2028. This paper aims to analyze the impact of AI on the retail industry and how it enhances customer experience which leads to boost companiesâ€™ profit.
 Keywords
 Artificial Intelligence
 Retail Industry
 Predictive Personalization
 Pricing Algorithms",nowadays  artificial intelligence  ai  is powering the data driven advances that are transforming industries around the planet  ai has become one of the most popular technologies of computer science utilizing to build and develop smart machines  these are cognitive computing systems created to perform actions which can be executed by human intelligence  major online retailers use ai in analyzing customers    data to forecast the purchase behavior of consumers  amazon  walmart com and alibaba employ ai along with forecasting techniques to predict sales and plan inventory accordingly  data collected from these online retailers indicate they have heavily invested in pricing algorithms that update prices at high speed  according to vantage market research study  global ai in retail market will grow from       billion usd in      to        billion by       this paper aims to analyze the impact of ai on the retail industry and how it enhances customer experience which leads to boost companies    profit   keywords  artificial intelligence  retail industry  predictive personalization  pricing algorithms,10.505983,7.4525423,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Advances in Engineering and Information Science Toward Smart City and Beyond,"The Hopf oscillator is a nonlinear oscillator that exhibits limit cycle motion. This reservoir computer utilizes the vibratory nature of the oscillator, which makes it an ideal candidate for reconfigurable sound recognition tasks. In this paper, the capabilities of the Hopf reservoir computer performing sound recognition are systematically demonstrated. This work shows that the Hopf reservoir computer can offer superior sound recognition accuracy compared to legacy approaches (e.g., a Mel spectrum + machine learning approach). More importantly, the Hopf reservoir computer operating as a sound recognition system does not require audio preprocessing and has a very simple setup while still offering a high degree of reconfigurability. These features pave the way of applying physical reservoir computing for sound recognition in low power edge devices.",the hopf oscillator is a nonlinear oscillator that exhibits limit cycle motion  this reservoir computer utilizes the vibratory nature of the oscillator  which makes it an ideal candidate for reconfigurable sound recognition tasks  in this paper  the capabilities of the hopf reservoir computer performing sound recognition are systematically demonstrated  this work shows that the hopf reservoir computer can offer superior sound recognition accuracy compared to legacy approaches  e g   a mel spectrum   machine learning approach   more importantly  the hopf reservoir computer operating as a sound recognition system does not require audio preprocessing and has a very simple setup while still offering a high degree of reconfigurability  these features pave the way of applying physical reservoir computing for sound recognition in low power edge devices ,3.8342187,5.427292,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
The importance of expert knowledge in big data and machine learning,"According to popular belief, big data and machine learning provide a wholly novel approach to science that has the potential to revolutionise scientific progress and will ultimately lead to the â€˜end of theoryâ€™. Proponents of this view argue that advanced algorithms are able to mine vast amounts of data relating to a given problem without any prior knowledge and that we do not need to concern ourselves with causality, as correlation is sufficient for handling complex issues. Consequently, the human contribution to scientific progress is deemed to be non-essential and replaceable. We, however, following the position most commonly represented in the philosophy of science, argue that the need for human expertise remains. Based on an analysis of big data and machine learning methods in two case studiesâ€”skin cancer detection and protein foldingâ€”we show that expert knowledge is essential and inherent in the application of these methods. Drawing on this analysis, we establish a classification of the different kinds of expert knowledge that are involved in the application of big data and machine learning in scientific contexts. We address the ramifications of a human-driven expert knowledge approach to big data and machine learning for scientific practice and the discussion about the role of theory. Finally, we show that the ways in which big data and machine learning both influence and are influenced by scientific methodology involve continuous conceptual shifts rather than a rigid paradigm change.",according to popular belief  big data and machine learning provide a wholly novel approach to science that has the potential to revolutionise scientific progress and will ultimately lead to the    end of theory     proponents of this view argue that advanced algorithms are able to mine vast amounts of data relating to a given problem without any prior knowledge and that we do not need to concern ourselves with causality  as correlation is sufficient for handling complex issues  consequently  the human contribution to scientific progress is deemed to be non essential and replaceable  we  however  following the position most commonly represented in the philosophy of science  argue that the need for human expertise remains  based on an analysis of big data and machine learning methods in two case studies   skin cancer detection and protein folding   we show that expert knowledge is essential and inherent in the application of these methods  drawing on this analysis  we establish a classification of the different kinds of expert knowledge that are involved in the application of big data and machine learning in scientific contexts  we address the ramifications of a human driven expert knowledge approach to big data and machine learning for scientific practice and the discussion about the role of theory  finally  we show that the ways in which big data and machine learning both influence and are influenced by scientific methodology involve continuous conceptual shifts rather than a rigid paradigm change ,9.695772,6.1633635,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Digital Transformation Success Achieving Alignment and Delivering Results with the Process Inventory Framework,"This chapter presents a modern Artificial Intelligence (AI)-based computer vision technique for automated quality inspection in complex manufacturing assembly lines. Using automotive manufacturing as an example, the study covers the historical approaches and their challenges in industry. It describes the modern, deep learning AI approach to visual inspection and illustrates the reasons why this approach is now possible and uses IBM Maximo Visual Inspectionâ„¢ as a reference implementation. We share how the application of AI-based computer vision to manufacturing quality inspection processes yields improvements in efficiency and reduction in cost, contrast with traditional machine vision techniques, and conclude with special considerations of application and system architecture.
 Keywords
 Artificial Intelligence (AI)
 Machine vision
 Computer vision
 Deep learning
 Quality inspection
 Lean engineering",this chapter presents a modern artificial intelligence  ai  based computer vision technique for automated quality inspection in complex manufacturing assembly lines  using automotive manufacturing as an example  the study covers the historical approaches and their challenges in industry  it describes the modern  deep learning ai approach to visual inspection and illustrates the reasons why this approach is now possible and uses ibm maximo visual inspection    as a reference implementation  we share how the application of ai based computer vision to manufacturing quality inspection processes yields improvements in efficiency and reduction in cost  contrast with traditional machine vision techniques  and conclude with special considerations of application and system architecture   keywords  artificial intelligence  ai   machine vision  computer vision  deep learning  quality inspection  lean engineering,9.420979,5.939622,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Assimilated Deep Learning to Assess Terrestrial Hydrology,"In this chapter, an assimilated deep learning approach is employed to improve understanding of the links between global climate teleconnection patterns (e.g., ENSO) and changes in terrestrial water storage (TWS). To this end, a hybrid deep learning framework was developed to reconstruct climate-driven TWS and to assess the influence of key climatic drivers on the spatio-temporal distribution of TWS. Using South America as a case study to showcase the potential and utility of this framework, the methodology, challenges, and prospect of machine learning in satellite hydrology are also detailed.",in this chapter  an assimilated deep learning approach is employed to improve understanding of the links between global climate teleconnection patterns  e g   enso  and changes in terrestrial water storage  tws   to this end  a hybrid deep learning framework was developed to reconstruct climate driven tws and to assess the influence of key climatic drivers on the spatio temporal distribution of tws  using south america as a case study to showcase the potential and utility of this framework  the methodology  challenges  and prospect of machine learning in satellite hydrology are also detailed ,7.0756354,6.9637656,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Applying Recent Machine Learning Approaches to Accelerate the Algebraic Multigrid Method for Fluid Simulations,"In this work, we describe our experiences trying to apply recent machine learning (ML) advances to the Algebraic Multigrid (AMG) method to predict better prolongation (interpolation) operators and accelerate solver convergence. Published work often reports results on small, unrepresentative problems, such as 1D equations or very small computational grids. To better understand the performance of these methods on more realistic data, we create a new, reusable dataset of large, sparse matrices by leveraging the recently published Thingi10K dataset of 3D geometries, along with the FTetWild mesher for creating computational meshes that are valid for use in finite element method (FEM) simulations. We run simple 3D Navier-Stokes simulations, and capture the sparse linear systems that arise.
 We consider the integration of ML approaches with established tools and solvers that support distributed computation, such as HYPRE, but achieve little success. The only approach suitable for use with unstructured grid data involves inference against a multi-layer message-passing graph neural network, which is too memory-hungry for practical use, and we find existing frameworks to be unsuitable for efficient distributed inference. Furthermore, the model prediction times far exceed the complete solver time of traditional approaches. While our focus is on inference against trained models, we also note that retraining the proposed neural networks using our dataset remains intractable.
 We conclude that these ML approaches are not yet ready for general use, and that much more research focus is required into how efficient distributed inference against such models can be incorporated into existing HPC workflows.
 Keywords
 HPC-AI
 AMG
 GNN",in this work  we describe our experiences trying to apply recent machine learning  ml  advances to the algebraic multigrid  amg  method to predict better prolongation  interpolation  operators and accelerate solver convergence  published work often reports results on small  unrepresentative problems  such as  d equations or very small computational grids  to better understand the performance of these methods on more realistic data  we create a new  reusable dataset of large  sparse matrices by leveraging the recently published thingi  k dataset of  d geometries  along with the ftetwild mesher for creating computational meshes that are valid for use in finite element method  fem  simulations  we run simple  d navier stokes simulations  and capture the sparse linear systems that arise   we consider the integration of ml approaches with established tools and solvers that support distributed computation  such as hypre  but achieve little success  the only approach suitable for use with unstructured grid data involves inference against a multi layer message passing graph neural network  which is too memory hungry for practical use  and we find existing frameworks to be unsuitable for efficient distributed inference  furthermore  the model prediction times far exceed the complete solver time of traditional approaches  while our focus is on inference against trained models  we also note that retraining the proposed neural networks using our dataset remains intractable   we conclude that these ml approaches are not yet ready for general use  and that much more research focus is required into how efficient distributed inference against such models can be incorporated into existing hpc workflows   keywords  hpc ai  amg  gnn,3.1651473,7.8322463,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Reconfigurable Hardware-Based Acceleration for Machine Learning and Signal Processing,"Certain application areas of signal processing and machine learning, such as robotics, impose technical limitations on the computing hardware, which make the use of generic processors unfeasible. In this paper we propose a framework for the development of dataflow accelerators as a possible solution. The approach is based on model based development and code generation to allow a rapid development of the accelerators and perform a functional verification of the overall system.
 Keywords:
 Robotics,
 Embedded Systems,
 FPGA,
 Hardware Acceleration,
 Dataflow",certain application areas of signal processing and machine learning  such as robotics  impose technical limitations on the computing hardware  which make the use of generic processors unfeasible  in this paper we propose a framework for the development of dataflow accelerators as a possible solution  the approach is based on model based development and code generation to allow a rapid development of the accelerators and perform a functional verification of the overall system   keywords   robotics   embedded systems   fpga   hardware acceleration   dataflow,7.735121,6.8404956,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Liver Disease Prediction Using Machine Learning Algorithm,"Over the last few decades, liver diseases are one of the reasons for a large number of death cases worldwide and have emerged as a life-threatening disease also. By WHO report, around 59% of the mortality and 46% of global diseases are because of chronic diseases and around 35 millions of people worldwide die due to chronic diseases. Now, we are living in the era of information where millions of data are generating from various sources every day. We can use these data to improve our healthcare services or proper identification of diseases. We have collected patient data from open source platform and applied various kinds of data analysis techniques and machine learning (ML) approaches applied to see the pattern of the data sets. Then, a performance comparison between these models is made to get highly accurate model for predicting liver disease.
 Keywords
 Liver disease
 Machine learning
 KNN
 Random forest",over the last few decades  liver diseases are one of the reasons for a large number of death cases worldwide and have emerged as a life threatening disease also  by who report  around     of the mortality and     of global diseases are because of chronic diseases and around    millions of people worldwide die due to chronic diseases  now  we are living in the era of information where millions of data are generating from various sources every day  we can use these data to improve our healthcare services or proper identification of diseases  we have collected patient data from open source platform and applied various kinds of data analysis techniques and machine learning  ml  approaches applied to see the pattern of the data sets  then  a performance comparison between these models is made to get highly accurate model for predicting liver disease   keywords  liver disease  machine learning  knn  random forest,5.3590226,4.995714,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Deployment and Monitoring,"In the summer of 2019, Apple launched its credit card, which involved a partnership with Goldman Sachs. It was designed to emphasize simplicity, privacy, and security (the card did not have a number, CVV security code, expiration date, or signature line). There were also no fees, the interest rates were competitive, and there was a good reward program.",in the summer of       apple launched its credit card  which involved a partnership with goldman sachs  it was designed to emphasize simplicity  privacy  and security  the card did not have a number  cvv security code  expiration date  or signature line   there were also no fees  the interest rates were competitive  and there was a good reward program ,6.758711,7.105932,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
"Product Lifecycle Management. PLM in Transition Times: The Place of Humans and Transformative Technologies 19th IFIP WG 5.1 International Conference, PLM 2022, Grenoble, France, July 10â€“13, 2022, Revised Selected Papers","In this chapter, you will build your own toolkit for model training. We will start by discussing the training and how it relates to the other stages of the MLOps lifecycle including the previous stage feature engineering. Weâ€™ll consider several different problems that make this part of the lifecycle challenging such as identifying runtime bottlenecks, managing features and schema drift, setting up infrastructure for reproducible experiment tracking, and how to store and version the model once itâ€™s trained. Weâ€™ll also look at logging metrics, parameters, and other artifacts and discuss how we can keep the model, code, and data in sync. Now, letâ€™s start by talking at defining the general problem of building training pipelines.",in this chapter  you will build your own toolkit for model training  we will start by discussing the training and how it relates to the other stages of the mlops lifecycle including the previous stage feature engineering  we   ll consider several different problems that make this part of the lifecycle challenging such as identifying runtime bottlenecks  managing features and schema drift  setting up infrastructure for reproducible experiment tracking  and how to store and version the model once it   s trained  we   ll also look at logging metrics  parameters  and other artifacts and discuss how we can keep the model  code  and data in sync  now  let   s start by talking at defining the general problem of building training pipelines ,7.67657,7.7894535,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Azure Machine Learning,Q: Why did Ed get attacked in the haunted jungle?,q  why did ed get attacked in the haunted jungle ,8.721352,6.6767526,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
On-Premise Artificial Intelligence as a Service for Small and Medium Size Setups,"Artificial Intelligence (AI) technologies are moving from customized deployments in specific application domains towards generic solutions horizontally permeating vertical domains and industries. For instance, decisions on when to perform maintenance of roads or bridges, or how to optimize public lighting in view of costs and safety in smart cities are increasingly informed by AI models. With new services introduced to smart cities, and the increasing amount of data collected thereof, the in-time decision support will require the transition from developing mostly static AI models to so called AI as a Service (AIaaS) approach. Various commercial solutions, typically deployed in public cloud, already offer user friendly and easy to use AIaaS, functionality-wise enabling the democratization of such ecosystems. However, open-source equivalent ecosystems supporting private deployment for better control over data, processes and costs, where this is needed, are lagging behind, mostly because they require different sets of advanced skills to select and integrate the most suitable technologies for a given application area. In this chapter, we discuss AIaaS functionality and corresponding technology stack and analyze possible realizations using open source user friendly technologies that are suitable for on-premise small and medium sized setups allowing full control over the data and technological platform without any third-party dependence or vendor lock-in.
 Keywords
 AIaaS
 Infrastructure automation
 Machine learning operations
 Technology stack
 On-premise",artificial intelligence  ai  technologies are moving from customized deployments in specific application domains towards generic solutions horizontally permeating vertical domains and industries  for instance  decisions on when to perform maintenance of roads or bridges  or how to optimize public lighting in view of costs and safety in smart cities are increasingly informed by ai models  with new services introduced to smart cities  and the increasing amount of data collected thereof  the in time decision support will require the transition from developing mostly static ai models to so called ai as a service  aiaas  approach  various commercial solutions  typically deployed in public cloud  already offer user friendly and easy to use aiaas  functionality wise enabling the democratization of such ecosystems  however  open source equivalent ecosystems supporting private deployment for better control over data  processes and costs  where this is needed  are lagging behind  mostly because they require different sets of advanced skills to select and integrate the most suitable technologies for a given application area  in this chapter  we discuss aiaas functionality and corresponding technology stack and analyze possible realizations using open source user friendly technologies that are suitable for on premise small and medium sized setups allowing full control over the data and technological platform without any third party dependence or vendor lock in   keywords  aiaas  infrastructure automation  machine learning operations  technology stack  on premise,9.043796,7.9645524,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Translation of tissue-based artificial intelligence into clinical practice: from discovery to adoption,"Machine learning systems have gained widespread adoption across various industries. This includes highly regulated ones that need to match certain quality requirements based on a given risk exposure. The MLOps paradigm, following a similar approach to DevOps, promises major improvements in quality and speed, with a focus on deploying ML models at a fast pace with high quality on an automated basis. However, traditional point-in-time certifications with manual audits are inadequate for MLOps setups due to frequent changes to the ML system. To overcome this challenge, we propose Continuous Audit-Based Certification (CABC), which uses automated audits to issue or revoke certificates based on an automated assessment of artifacts from the MLOps lifecycle. Our approach utilizes artifacts from the MLOps lifecycle for quality measurements based on standards such as ISO 25012. We propose a risk-based measurement selection, an audit API for standardized retrieval of data for measurement, a tamper-proof data collection process, and an architecture for separation of duties in the certification process. CABC aims to improve efficiency, enhance trust in the ML system, and support highly regulated industries in achieving their quality goals.",machine learning systems have gained widespread adoption across various industries  this includes highly regulated ones that need to match certain quality requirements based on a given risk exposure  the mlops paradigm  following a similar approach to devops  promises major improvements in quality and speed  with a focus on deploying ml models at a fast pace with high quality on an automated basis  however  traditional point in time certifications with manual audits are inadequate for mlops setups due to frequent changes to the ml system  to overcome this challenge  we propose continuous audit based certification  cabc   which uses automated audits to issue or revoke certificates based on an automated assessment of artifacts from the mlops lifecycle  our approach utilizes artifacts from the mlops lifecycle for quality measurements based on standards such as iso        we propose a risk based measurement selection  an audit api for standardized retrieval of data for measurement  a tamper proof data collection process  and an architecture for separation of duties in the certification process  cabc aims to improve efficiency  enhance trust in the ml system  and support highly regulated industries in achieving their quality goals ,7.836927,5.08324,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Financial Data Analytics Theory and Application,"Digital pathology (DP), or the digitization of pathology images, has transformed oncology research and cancer diagnostics. The application of artificial intelligence (AI) and other forms of machine learning (ML) to these images allows for better interpretation of morphology, improved quantitation of biomarkers, introduction of novel concepts to discovery and diagnostics (such as spatial distribution of cellular elements), and the promise of a new paradigm of cancer biomarkers. The application of AI to tissue analysis can take several conceptual approaches, within the domains of language modelling and image analysis, such as Deep Learning Convolutional Neural Networks, Multiple Instance Learning approaches, or the modelling of risk scores and their application to ML. The use of different approaches solves different problems within pathology workflows, including assistive applications for the detection and grading of tumours, quantification of biomarkers, and the delivery of established and new image-based biomarkers for treatment prediction and prognostic purposes. All these AI formats, applied to digital tissue images, are also beginning to transform our approach to clinical trials. In parallel, the novelty of DP/AI devices and the related computational science pipeline introduces new requirements for manufacturers to build into their design, development, regulatory and post-market processes, which may need to be taken into account when using AI applied to tissues in cancer discovery. Finally, DP/AI represents challenge to the way we accredit new diagnostic tools with clinical applicability, the understanding of which will allow cancer patients to have access to a new generation of complex biomarkers.",digital pathology  dp   or the digitization of pathology images  has transformed oncology research and cancer diagnostics  the application of artificial intelligence  ai  and other forms of machine learning  ml  to these images allows for better interpretation of morphology  improved quantitation of biomarkers  introduction of novel concepts to discovery and diagnostics  such as spatial distribution of cellular elements   and the promise of a new paradigm of cancer biomarkers  the application of ai to tissue analysis can take several conceptual approaches  within the domains of language modelling and image analysis  such as deep learning convolutional neural networks  multiple instance learning approaches  or the modelling of risk scores and their application to ml  the use of different approaches solves different problems within pathology workflows  including assistive applications for the detection and grading of tumours  quantification of biomarkers  and the delivery of established and new image based biomarkers for treatment prediction and prognostic purposes  all these ai formats  applied to digital tissue images  are also beginning to transform our approach to clinical trials  in parallel  the novelty of dp ai devices and the related computational science pipeline introduces new requirements for manufacturers to build into their design  development  regulatory and post market processes  which may need to be taken into account when using ai applied to tissues in cancer discovery  finally  dp ai represents challenge to the way we accredit new diagnostic tools with clinical applicability  the understanding of which will allow cancer patients to have access to a new generation of complex biomarkers ,6.33812,3.6770267,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
AIOps Observability and Performance Impact of AI and ML Applications for Central Nervous System Drug Discoveries,"It has been a massive challenge for academia, the scientific community, the medical community, and the pharmaceutical business to develop medications that can affect the central nervous system. Artificial intelligence for IT operations (AIOps) can facilitate this process by involving critical evaluation decisions with AI-driven technologies like Machine Learning Operations (MLOps) to eliminate repetitive inconsequential procedures. Statistically, neurological ailments/diseases are far greater in number than their counterparts or standard therapeutic diseases. The discovery/invention of drugs for central nervous system (CNS) has lagged behind industry standards for too long. Now with the intervention of AIOps, research and discoveries are more accurate and progress at a faster rate. For instance, in Schizophrenia, there can be several permutations and combinations in the underlying disease itself; naturally, effective treatment suffers. Coupled with performance testing of the model will give full confidence to execute the models in parallel for desired output within the expected time. Modern biomedical data, bolstered by significant contributions from AI and ML, offer promising prospects for addressing CNS disorders in effective ways. In this study, we have highlighted the best possible AI- and ML-assisted technological approaches to uncover the mysteries that CNS has posed. There is no straightforward strategy that can be employed as with other body disorders, as the intensity of the underlying disease can vary from patient to patient. This study elaborates on many techniques that have been integrated with AIOps, Performance Testing, and the associated AI, ML, and Deep Learning (DL) applications.
 Keywords
 AIOps
 Observability
 Monitoring
 Performance
 Performance Testing
 Non-functional Testing (NFT)
 Artificial Intelligence (AI)
 Machine Learning (MLOps)
 Central Nervous System (CNS)
 Deep Learning (DL)",it has been a massive challenge for academia  the scientific community  the medical community  and the pharmaceutical business to develop medications that can affect the central nervous system  artificial intelligence for it operations  aiops  can facilitate this process by involving critical evaluation decisions with ai driven technologies like machine learning operations  mlops  to eliminate repetitive inconsequential procedures  statistically  neurological ailments diseases are far greater in number than their counterparts or standard therapeutic diseases  the discovery invention of drugs for central nervous system  cns  has lagged behind industry standards for too long  now with the intervention of aiops  research and discoveries are more accurate and progress at a faster rate  for instance  in schizophrenia  there can be several permutations and combinations in the underlying disease itself  naturally  effective treatment suffers  coupled with performance testing of the model will give full confidence to execute the models in parallel for desired output within the expected time  modern biomedical data  bolstered by significant contributions from ai and ml  offer promising prospects for addressing cns disorders in effective ways  in this study  we have highlighted the best possible ai  and ml assisted technological approaches to uncover the mysteries that cns has posed  there is no straightforward strategy that can be employed as with other body disorders  as the intensity of the underlying disease can vary from patient to patient  this study elaborates on many techniques that have been integrated with aiops  performance testing  and the associated ai  ml  and deep learning  dl  applications   keywords  aiops  observability  monitoring  performance  performance testing  non functional testing  nft   artificial intelligence  ai   machine learning  mlops   central nervous system  cns   deep learning  dl ,11.408104,6.1159415,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Analysis of Prediction Accuracy of Diabetes Using Classifier and Hybrid Machine Learning Techniques,"In the past few years, the growth of diabetes among people became exponential. A health report tells that about 347 million of world populations are affected by diabetes. Diabetes not only affects the older person but the younger generation too. To detect diabetes at an early stage is also a big challenge. This detection will be helpful for decision-making process of medical system. Early prediction of diabetes helps us to save the human life from diabetes. A prolong diabetes leads to the risk of damage in vital organs of human body. So, early prediction of diabetes is very crucial in order to save human being from diabetes. Data analysis is concerned with finding a pattern from a large dataset. This helps us to build certain conclusion out of the available datasets. The analytical process can be done by different machine learning algorithms. This paper presents two sets of machine learning approach for prediction of diabetes. One of them is a classification-based algorithm, and the other one is a hybrid algorithm. In classification, we have taken the random forest algorithm. For hybrid approach, we have chosen XGBoost algorithm. These two algorithms were implemented and compared in order to explore the prediction accuracy in diabetes for two different machine learning approaches and got the mean score 74.10% which is better than the Random Forest algorithm.
 Keywords
 Decision-making system
 Data analysis
 Hybrid algorithm
 Random forest
 XGBoost",in the past few years  the growth of diabetes among people became exponential  a health report tells that about     million of world populations are affected by diabetes  diabetes not only affects the older person but the younger generation too  to detect diabetes at an early stage is also a big challenge  this detection will be helpful for decision making process of medical system  early prediction of diabetes helps us to save the human life from diabetes  a prolong diabetes leads to the risk of damage in vital organs of human body  so  early prediction of diabetes is very crucial in order to save human being from diabetes  data analysis is concerned with finding a pattern from a large dataset  this helps us to build certain conclusion out of the available datasets  the analytical process can be done by different machine learning algorithms  this paper presents two sets of machine learning approach for prediction of diabetes  one of them is a classification based algorithm  and the other one is a hybrid algorithm  in classification  we have taken the random forest algorithm  for hybrid approach  we have chosen xgboost algorithm  these two algorithms were implemented and compared in order to explore the prediction accuracy in diabetes for two different machine learning approaches and got the mean score        which is better than the random forest algorithm   keywords  decision making system  data analysis  hybrid algorithm  random forest  xgboost,5.0542364,4.2686543,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Gender prediction based on University studentsâ€™ complex thinking competency: An analysis from machine learning approaches,"This article aims to study machine learning models to determine their performance in classifying students by gender based on their perception of complex thinking competency. Data were collected from a convenience sample of 605 students from a private university in Mexico with the eComplexity instrument. In this study, we consider the following data analyses: 1) predict studentsâ€™ gender based on their perception of complex thinking competency and sub-competencies from a 25 items questionnaire, 2) analyze modelsâ€™ performance during training and testing stages, and 3) study the modelsâ€™ prediction bias through a confusion matrix analysis. Our results confirm the hypothesis that the four machine learning models (Random Forest, Support Vector Machines, Multi-layer Perception, and One-Dimensional Convolutional Neural Network) can find sufficient differences in the eComplexity data to classify correctly up to 96.94% and 82.14% of the studentsâ€™ gender in the training and testing stage, respectively. The confusion matrix analysis revealed partiality in gender prediction among all machine learning models, even though we have applied an oversampling method to reduce the imbalance dataset. It showed that the most frequent error was to predict Male students as Female class. This paper provides empirical support for analyzing perception data through machine learning models in survey research. This work proposed a novel educational practice based on developing complex thinking competency and machine learning models to facilitate educational itineraries adapted to the training needs of each group to reduce social gaps existing due to gender.",this article aims to study machine learning models to determine their performance in classifying students by gender based on their perception of complex thinking competency  data were collected from a convenience sample of     students from a private university in mexico with the ecomplexity instrument  in this study  we consider the following data analyses     predict students    gender based on their perception of complex thinking competency and sub competencies from a    items questionnaire     analyze models    performance during training and testing stages  and    study the models    prediction bias through a confusion matrix analysis  our results confirm the hypothesis that the four machine learning models  random forest  support vector machines  multi layer perception  and one dimensional convolutional neural network  can find sufficient differences in the ecomplexity data to classify correctly up to        and        of the students    gender in the training and testing stage  respectively  the confusion matrix analysis revealed partiality in gender prediction among all machine learning models  even though we have applied an oversampling method to reduce the imbalance dataset  it showed that the most frequent error was to predict male students as female class  this paper provides empirical support for analyzing perception data through machine learning models in survey research  this work proposed a novel educational practice based on developing complex thinking competency and machine learning models to facilitate educational itineraries adapted to the training needs of each group to reduce social gaps existing due to gender ,5.145873,3.912591,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Identifying and Harnessing the Building Blocks of Machine Learning Pipelines for Sensible Initialization of a Data Science Automation Tool,"As data science continues to grow in popularity, there will be an increasing need to make data science tools more scalable, flexible, and accessible. In particular, automated machine learning (AutoML) systems seek to automate the process of designing and optimizing machine learning pipelines. In this chapter, we present a genetic programming-based AutoML system called TPOT that optimizes a series of feature preprocessors and machine learning models with the goal of maximizing classification accuracy on a supervised classification problem. Further, we analyze a large database of pipelines that were previously used to solve various supervised classification problems and identify 100 short series of machine learning operations that appear the most frequently, which we call the building blocks of machine learning pipelines. We harness these building blocks to initialize TPOT with promising solutions, and find that this sensible initialization method significantly improves TPOTâ€™s performance on one benchmark at no cost of significantly degrading performance on the others. Thus, sensible initialization with machine learning pipeline building blocks shows promise for GP-based AutoML systems, and should be further refined in future work.
 Keywords
 Pipeline optimization
 Hyperparameter optimization
 Automated machine learning
 Sensible initialization
 Building blocks
 Genetic programming
 Pareto optimization
 Multiobjective optimization
 Data science
 Python language",as data science continues to grow in popularity  there will be an increasing need to make data science tools more scalable  flexible  and accessible  in particular  automated machine learning  automl  systems seek to automate the process of designing and optimizing machine learning pipelines  in this chapter  we present a genetic programming based automl system called tpot that optimizes a series of feature preprocessors and machine learning models with the goal of maximizing classification accuracy on a supervised classification problem  further  we analyze a large database of pipelines that were previously used to solve various supervised classification problems and identify     short series of machine learning operations that appear the most frequently  which we call the building blocks of machine learning pipelines  we harness these building blocks to initialize tpot with promising solutions  and find that this sensible initialization method significantly improves tpot   s performance on one benchmark at no cost of significantly degrading performance on the others  thus  sensible initialization with machine learning pipeline building blocks shows promise for gp based automl systems  and should be further refined in future work   keywords  pipeline optimization  hyperparameter optimization  automated machine learning  sensible initialization  building blocks  genetic programming  pareto optimization  multiobjective optimization  data science  python language,7.484022,6.0757384,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Predicting Fishing Effort: Data Collection for Machine Learning Model Using Scientific and Indigenous Method,"In this paper, we will look at a unique, high-value fishing dataset that is created by combining two data sources: fishing boat trajectories catch reports using indigenous techniques (i.e., short-term sea storms, Data about fishes found in different seasons, fish breeding time, the temperature of the seawater, Data is collected using time factors (low and tides), sunset and sunrise, wind directions and many more), and second relevant environmental data from the satellite server (Sea Surface Temperature (SST), chlorophyll (CHL)). The result is a set of semantic trajectories depicting fishing operations in the Arabian Sea over the course of two years. Initial findings from an exploratory analysis of these semantic high-value fishing datasets and preliminary Machine Learning predictive modeling are presented. We highlighted several ways that we want to implement in the near future to learn from data, facts, and knowledge that will be helpful for fisheries management. Other areas of heavy fishing activity are likely to have similar data and might implement strategies similar to those presented here in their own environment.
 Keywords
 Satellite
 Indigenous method
 Data collection
 Machine learning",in this paper  we will look at a unique  high value fishing dataset that is created by combining two data sources  fishing boat trajectories catch reports using indigenous techniques  i e   short term sea storms  data about fishes found in different seasons  fish breeding time  the temperature of the seawater  data is collected using time factors  low and tides   sunset and sunrise  wind directions and many more   and second relevant environmental data from the satellite server  sea surface temperature  sst   chlorophyll  chl    the result is a set of semantic trajectories depicting fishing operations in the arabian sea over the course of two years  initial findings from an exploratory analysis of these semantic high value fishing datasets and preliminary machine learning predictive modeling are presented  we highlighted several ways that we want to implement in the near future to learn from data  facts  and knowledge that will be helpful for fisheries management  other areas of heavy fishing activity are likely to have similar data and might implement strategies similar to those presented here in their own environment   keywords  satellite  indigenous method  data collection  machine learning,9.189332,7.718171,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
The Technology Path to Digitization,"We will explore how advancements in digital technologies are revolutionizing how organizations operate, necessitating the development of a strategy that outlines how these advancements will be leveraged to support the organizationsâ€™ business strategy. Several trends will be examined, including intelligent process automation, data-centric AI, and business modular architectures.",we will explore how advancements in digital technologies are revolutionizing how organizations operate  necessitating the development of a strategy that outlines how these advancements will be leveraged to support the organizations    business strategy  several trends will be examined  including intelligent process automation  data centric ai  and business modular architectures ,10.881313,7.050983,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Exploiting Hardware Accelerators in Clouds,"In this chapter, we plan to provide an overview of cloud accelerators available on different cloud providers. We plan to introduce, show how to program, instantiate and discuss a deployment workflow. The goal is to provide an overview, but each stepâ€™s details shall be discussed in the following sections.",in this chapter  we plan to provide an overview of cloud accelerators available on different cloud providers  we plan to introduce  show how to program  instantiate and discuss a deployment workflow  the goal is to provide an overview  but each step   s details shall be discussed in the following sections ,8.474906,7.2469444,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Heart Disease Prediction Using Machine Learning Techniques,"Heart-related diseases or cardiovascular diseases are the primary purposes behind a large number of deaths on the planet in the course of the most recent couple of decades. It has risen as the most terrifying ailment around the world. Actually, in India, these issues are progressively awful; according to the Journal of the American College of Cardiology in India, the demise rate because of cardiovascular maladies increments around 34% in the middle of 1990â€“2016. Presently, we are in a time of data age where a huge quantity and variety of information is stored in different enterprises like retail, producing, medical clinic, and online networking. We can gather the information and break down the information to foresee the components and reasons for heart diseases so that safety measures can be taken to decrease the demise rate. There exists various types of information investigation instrument and procedure which requires an ideal informational collection; at that point, we can apply distinctive sort of machine learning strategies to anticipate whether the patient can be influenced by heart diseases or not by utilizing the recently gathered datasets. In this paper, we will exhibit how to utilize various kinds of machine learning models like K-nearest neighbor, decision tree classifier, and random forest classifier, and furthermore make a presentation correlation among these models so that we can get accurate precision about a patient having heart disease (Chen et al. in 2011 Computing in Cardiology IEEE, 557â€“560, 2011, [1]), (Kishore et al. Heart attack prediction using deep learning, [2]).
 Keywords
 Heart disease
 Machine learning
 Data analysis
 K-nearest neighbor
 Decision tree classifier
 Random forest classifier",heart related diseases or cardiovascular diseases are the primary purposes behind a large number of deaths on the planet in the course of the most recent couple of decades  it has risen as the most terrifying ailment around the world  actually  in india  these issues are progressively awful  according to the journal of the american college of cardiology in india  the demise rate because of cardiovascular maladies increments around     in the middle of              presently  we are in a time of data age where a huge quantity and variety of information is stored in different enterprises like retail  producing  medical clinic  and online networking  we can gather the information and break down the information to foresee the components and reasons for heart diseases so that safety measures can be taken to decrease the demise rate  there exists various types of information investigation instrument and procedure which requires an ideal informational collection  at that point  we can apply distinctive sort of machine learning strategies to anticipate whether the patient can be influenced by heart diseases or not by utilizing the recently gathered datasets  in this paper  we will exhibit how to utilize various kinds of machine learning models like k nearest neighbor  decision tree classifier  and random forest classifier  and furthermore make a presentation correlation among these models so that we can get accurate precision about a patient having heart disease  chen et al  in      computing in cardiology ieee                          kishore et al  heart attack prediction using deep learning         keywords  heart disease  machine learning  data analysis  k nearest neighbor  decision tree classifier  random forest classifier,5.132063,4.3756146,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Context Time-Sequencing for Machine Learning and Sustainability Optimization,"Computer systems designed to help user in their daily activities are becoming a norm. Specially, with the advent of the Internet of Things (IoT) where every device is interconnected with others through internet based protocols, the amount of data and information available has increased. Tracking devices are targeting more and more activities such as fitness, utilities consumption, movement, environment state, weather. Nowadays, a challenge for researchers is to handle such income of data and transform it into meaningful knowledge that can be used to predict, foresight, adapt and control activities. In order to this, it is necessary to interpret contextual information and produce services to anticipate these conditions. This project aim to provide a system for the creation of information and data structures to generate user models based on activity and sensor based contextual-information from IoT devices and apply machine learning operations to anticipate future states.
 Keywords
 Contextual Information
 Thermal Comfort
 Smart City
 Sustainable Indicator
 Instance Base Learning
 These keywords were added by machine and not by the authors. This process is experimental and the keywords may be updated as the learning algorithm improves.",computer systems designed to help user in their daily activities are becoming a norm  specially  with the advent of the internet of things  iot  where every device is interconnected with others through internet based protocols  the amount of data and information available has increased  tracking devices are targeting more and more activities such as fitness  utilities consumption  movement  environment state  weather  nowadays  a challenge for researchers is to handle such income of data and transform it into meaningful knowledge that can be used to predict  foresight  adapt and control activities  in order to this  it is necessary to interpret contextual information and produce services to anticipate these conditions  this project aim to provide a system for the creation of information and data structures to generate user models based on activity and sensor based contextual information from iot devices and apply machine learning operations to anticipate future states   keywords  contextual information  thermal comfort  smart city  sustainable indicator  instance base learning  these keywords were added by machine and not by the authors  this process is experimental and the keywords may be updated as the learning algorithm improves ,4.9260974,5.190188,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Analysis of Supervised Machine Learning Techniques for Predicting Vehicle Clutch Status,"Today, the automotive world uses various electronic components to inspect vehicle health. Data generated from the vehicle component can be utilized for different applications, such as diagnostics, maintenance, and prognostics (predictive diagnosis). There are satisfactory actions taken from the automotive world for vehicle On Board and off-board diagnostics to perform vehicle diagnostics and maintenance time. Due to human limitations for faster analysis and maintenance predictions, automizing electronics and data science can provide many possible solutions, such as various predictive diagnostics based on historical data. Many researchers are currently working with the different domains on machine learning, data science gives better results in medicine predictions. This can also apply to the automotive world and its applications. This paper contributes to the method based on regression models to predict clutch status based on different parameters acquired from the vehicle CAN bus system and electronic sensors. Various supervised machine learning methods like support vector machine, logistic regression, decision tree, and polynomial regression are used. The results obtained for these models are compared using the accuracy level to predict the vehicle clutch status.
 Keywords
 Vehicle clutch status
 Vehicle maintenance
 Supervised machine learning
 Support vector machine
 Logistic regression
 Decision tree
 Polynomial regression",today  the automotive world uses various electronic components to inspect vehicle health  data generated from the vehicle component can be utilized for different applications  such as diagnostics  maintenance  and prognostics  predictive diagnosis   there are satisfactory actions taken from the automotive world for vehicle on board and off board diagnostics to perform vehicle diagnostics and maintenance time  due to human limitations for faster analysis and maintenance predictions  automizing electronics and data science can provide many possible solutions  such as various predictive diagnostics based on historical data  many researchers are currently working with the different domains on machine learning  data science gives better results in medicine predictions  this can also apply to the automotive world and its applications  this paper contributes to the method based on regression models to predict clutch status based on different parameters acquired from the vehicle can bus system and electronic sensors  various supervised machine learning methods like support vector machine  logistic regression  decision tree  and polynomial regression are used  the results obtained for these models are compared using the accuracy level to predict the vehicle clutch status   keywords  vehicle clutch status  vehicle maintenance  supervised machine learning  support vector machine  logistic regression  decision tree  polynomial regression,5.6285586,5.0275297,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Risk Prediction with Machine Learning in Cesarean Section: Optimizing Healthcare Operational Decisions,"In recent years, data mining is becoming very popular in healthcare and medical research. With its enormous library and a large number of machine learning (ML) algorithms, it is being used for the complex, multidimensional and large data in healthcare systems. Cesarean section or C-section is the widely used method when any abnormality affects the normal birth of a child. The aim of this research is to identify the cesarean section of child birth by considering some important situations of pregnant women using different ML algorithms. In this situation, several data imbalanced techniques were implemented in the cesarean data. Then, various classifiers were applied to the derived balanced and base cesarean sample. After applying ML classifiers, we have received a success rate over 95%.
 Keywords
 C-Section
 ML
 Oversampling
 Classifiers",in recent years  data mining is becoming very popular in healthcare and medical research  with its enormous library and a large number of machine learning  ml  algorithms  it is being used for the complex  multidimensional and large data in healthcare systems  cesarean section or c section is the widely used method when any abnormality affects the normal birth of a child  the aim of this research is to identify the cesarean section of child birth by considering some important situations of pregnant women using different ml algorithms  in this situation  several data imbalanced techniques were implemented in the cesarean data  then  various classifiers were applied to the derived balanced and base cesarean sample  after applying ml classifiers  we have received a success rate over       keywords  c section  ml  oversampling  classifiers,5.103157,3.1230922,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Development and Validation of a Machine Learning-Based Nomogram for Prediction of Ankylosing Spondylitis,"Introduction
 Ankylosing spondylitis (AS) is a chronic progressive inflammatory disease of the spine and its affiliated tissues. AS mainly affects the axial bone, sacroiliac joint, hip joint, spinal facet, and adjacent ligaments. We used machine learning (ML) methods to construct diagnostic models based on blood routine examination, liver function test, and kidney function test of patients with AS. This method will help clinicians enhance diagnostic efficiency and allow patients to receive systematic treatment as soon as possible.
 Methods
 We consecutively screened 348 patients with AS through complete blood routine examination, liver function test, and kidney function test at the First Affiliated Hospital of Guangxi Medical University according to the modified New York criteria (diagnostic criteria for AS). By using random sampling, the patients were randomly divided into training and validation cohorts. The training cohort included 258 patients with AS and 247 patients without AS, and the validation cohort included 90 patients with AS and 113 patients without AS. We used three ML methods (LASSO, random forest, and support vector machine recursive feature elimination) to screen feature variables and then took the intersection to obtain the prediction model. In addition, we used the prediction model on the validation cohort.
 Results
 Seven factorsâ€”erythrocyte sedimentation rate (ESR), red blood cell count (RBC), mean platelet volume (MPV), albumin (ALB), aspartate aminotransferase (AST), and creatinine (Cr)â€”were selected to construct a nomogram diagnostic model through ML. In the training cohort, the C value and area under the curve (AUC) value of this nomogram was 0.878 and 0.8779462, respectively. The C value and AUC value of the nomogram in the validation cohort was 0.823 and 0.8232055, respectively. Calibration curves in the training and validation cohorts showed satisfactory agreement between nomogram predictions and actual probabilities. The decision curve analysis showed that the nonadherence nomogram was clinically useful when intervention was decided at the nonadherence possibility threshold of 1%.
 Conclusion
 Our ML model can satisfactorily predict patients with AS. This nomogram can help orthopedic surgeons devise more personalized and rational clinical strategies.",introduction  ankylosing spondylitis  as  is a chronic progressive inflammatory disease of the spine and its affiliated tissues  as mainly affects the axial bone  sacroiliac joint  hip joint  spinal facet  and adjacent ligaments  we used machine learning  ml  methods to construct diagnostic models based on blood routine examination  liver function test  and kidney function test of patients with as  this method will help clinicians enhance diagnostic efficiency and allow patients to receive systematic treatment as soon as possible   methods  we consecutively screened     patients with as through complete blood routine examination  liver function test  and kidney function test at the first affiliated hospital of guangxi medical university according to the modified new york criteria  diagnostic criteria for as   by using random sampling  the patients were randomly divided into training and validation cohorts  the training cohort included     patients with as and     patients without as  and the validation cohort included    patients with as and     patients without as  we used three ml methods  lasso  random forest  and support vector machine recursive feature elimination  to screen feature variables and then took the intersection to obtain the prediction model  in addition  we used the prediction model on the validation cohort   results  seven factors   erythrocyte sedimentation rate  esr   red blood cell count  rbc   mean platelet volume  mpv   albumin  alb   aspartate aminotransferase  ast   and creatinine  cr    were selected to construct a nomogram diagnostic model through ml  in the training cohort  the c value and area under the curve  auc  value of this nomogram was       and            respectively  the c value and auc value of the nomogram in the validation cohort was       and            respectively  calibration curves in the training and validation cohorts showed satisfactory agreement between nomogram predictions and actual probabilities  the decision curve analysis showed that the nonadherence nomogram was clinically useful when intervention was decided at the nonadherence possibility threshold of      conclusion  our ml model can satisfactorily predict patients with as  this nomogram can help orthopedic surgeons devise more personalized and rational clinical strategies ,4.7764144,2.9868236,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Autonomous Bot Using Machine Learning and Computer Vision,"Self-driving vehicles have the potential to revolutionize urban mobility by providing sustainable, safe, and convenient transportability. In recent years several companies have identified automation as their major area of research and also are investing a huge amount of their financial resources in automating vehicles. This is the period of time where autonomous vehicles are very close to being capable of transporting us to destinations without the aid of drivers in the very near future. In the current generation, the main focus is to make vehicles more automated to provide a better driving experience. These vehicles are designed to drive without or with little human assistance by sensing itâ€™s the environment. This can be achieved by a combination of sensors and processing the data with the help of computer vision technology and machine learning. The vehicle autonomy needs to be conducted with care, keeping in mind the challenges that can be faced during the process. Recognizing the traffic signals, understanding the signs, identifying the lane markings are some of the basic functions that it needs to perform. After gathering all this information, the next task is to understand the predefined protocols and follow them without any fault. This problem can be solved stepwise using some functions from image processing and computer vision technology such as Haar transform, perspective mapping, perspective transformation, canny edge detection, and histogram equalization. This solution is further enhanced by including machine learning, which improves performance with experience, making it more reliable. It should be noted that, although the vehicles promoted by the companies ensure 80% reliability, we are not yet ready to completely adapt to the idea of automated vehicles. This paper hence focuses on the negative of current ideology and makes it reliable enough to pave a way for its immediate implementation. In this paper, the authors have used a microcontroller and a microprocessor, to Arduino uno is used as a microcontroller and Raspberry pi B+â€‰model is used as the microprocessor. To detect the lanes the authors have used image processing using a library called OpenCV. For detecting the traffic signs the authors have used supervised machine learning technique, to capture the images authors have used raspberry pi version 2 cam, using cascade training to classify the positive images from the negative images.",self driving vehicles have the potential to revolutionize urban mobility by providing sustainable  safe  and convenient transportability  in recent years several companies have identified automation as their major area of research and also are investing a huge amount of their financial resources in automating vehicles  this is the period of time where autonomous vehicles are very close to being capable of transporting us to destinations without the aid of drivers in the very near future  in the current generation  the main focus is to make vehicles more automated to provide a better driving experience  these vehicles are designed to drive without or with little human assistance by sensing it   s the environment  this can be achieved by a combination of sensors and processing the data with the help of computer vision technology and machine learning  the vehicle autonomy needs to be conducted with care  keeping in mind the challenges that can be faced during the process  recognizing the traffic signals  understanding the signs  identifying the lane markings are some of the basic functions that it needs to perform  after gathering all this information  the next task is to understand the predefined protocols and follow them without any fault  this problem can be solved stepwise using some functions from image processing and computer vision technology such as haar transform  perspective mapping  perspective transformation  canny edge detection  and histogram equalization  this solution is further enhanced by including machine learning  which improves performance with experience  making it more reliable  it should be noted that  although the vehicles promoted by the companies ensure     reliability  we are not yet ready to completely adapt to the idea of automated vehicles  this paper hence focuses on the negative of current ideology and makes it reliable enough to pave a way for its immediate implementation  in this paper  the authors have used a microcontroller and a microprocessor  to arduino uno is used as a microcontroller and raspberry pi b    model is used as the microprocessor  to detect the lanes the authors have used image processing using a library called opencv  for detecting the traffic signs the authors have used supervised machine learning technique  to capture the images authors have used raspberry pi version   cam  using cascade training to classify the positive images from the negative images ,5.60092,5.202547,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Accelerating the Big Data Analytics by GPU-Based Machine Learning: A Survey,"Today a large volume of structured and unstructured data is being generated online; the main sources for big data are social media profiles, MOOC (massive open online courses) log, social influencer, Internet of Things (IoT) data, the web, transactional applications, stream monitoring technologies, NoSQL (not only structured query language) stored data, log files, legacy document, and so on. There is a need to analyze such huge volume of data at a faster rate by uncovering the hidden patterns and correlation between the data to provide intelligent business decisions with high accuracy. The GPU (graphics processing unit)-enabled machine learning-based techniques are the strongest solution being used to perform big data analytics operation at an accelerated speed. This paper discusses selective GPU-based machine learning algorithms like decision tree, neural network, random forest, Q-learning, SARSA learning, K-means, NB (naive Bayes), AdaBoost, deep learning, support vector machine (SVM), linear regression, logistic regression, Apriori, and HMM (hidden Markov model) being used for big data analysis.
 Keywords
 Machine learning
 Big data
 GPU
 Acceleration
 Analytics",today a large volume of structured and unstructured data is being generated online  the main sources for big data are social media profiles  mooc  massive open online courses  log  social influencer  internet of things  iot  data  the web  transactional applications  stream monitoring technologies  nosql  not only structured query language  stored data  log files  legacy document  and so on  there is a need to analyze such huge volume of data at a faster rate by uncovering the hidden patterns and correlation between the data to provide intelligent business decisions with high accuracy  the gpu  graphics processing unit  enabled machine learning based techniques are the strongest solution being used to perform big data analytics operation at an accelerated speed  this paper discusses selective gpu based machine learning algorithms like decision tree  neural network  random forest  q learning  sarsa learning  k means  nb  naive bayes   adaboost  deep learning  support vector machine  svm   linear regression  logistic regression  apriori  and hmm  hidden markov model  being used for big data analysis   keywords  machine learning  big data  gpu  acceleration  analytics,6.6228757,6.7771807,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
"External control arm analysis: an evaluation of propensity score approaches, G-computation, and doubly debiased machine learning","Background
 An external control arm is a cohort of control patients that are collected from data external to a single-arm trial. To provide an unbiased estimation of efficacy, the clinical profiles of patients from single and external arms should be aligned, typically using propensity score approaches. There are alternative approaches to infer efficacy based on comparisons between outcomes of single-arm patients and machine-learning predictions of control patient outcomes. These methods include G-computation and Doubly Debiased Machine Learning (DDML) and their evaluation for External Control Arms (ECA) analysis is insufficient.
 Methods
 We consider both numerical simulations and a trial replication procedure to evaluate the different statistical approaches: propensity score matching, Inverse Probability of Treatment Weighting (IPTW), G-computation, and DDML. The replication study relies on five type 2 diabetes randomized clinical trials granted by the Yale University Open Data Access (YODA) project. From the pool of five trials, observational experiments are artificially built by replacing a control arm from one trial by an arm originating from another trial and containing similarly-treated patients.
 Results
 Among the different statistical approaches, numerical simulations show that DDML has the smallest bias followed by G-computation. In terms of mean squared error, G-computation usually minimizes mean squared error. Compared to other methods, DDML has varying Mean Squared Error performances that improves with increasing sample sizes. For hypothesis testing, all methods control type I error and DDML is the most conservative. G-computation is the best method in terms of statistical power, and DDML has comparable power at \(n=1000\) but inferior ones for smaller sample sizes. The replication procedure also indicates that G-computation minimizes mean squared error whereas DDML has intermediate performances in between G-computation and propensity score approaches. The confidence intervals of G-computation are the narrowest whereas confidence intervals obtained with DDML are the widest for small sample sizes, which confirms its conservative nature.
 Conclusions
 For external control arm analyses, methods based on outcome prediction models can reduce estimation error and increase statistical power compared to propensity score approaches.",background  an external control arm is a cohort of control patients that are collected from data external to a single arm trial  to provide an unbiased estimation of efficacy  the clinical profiles of patients from single and external arms should be aligned  typically using propensity score approaches  there are alternative approaches to infer efficacy based on comparisons between outcomes of single arm patients and machine learning predictions of control patient outcomes  these methods include g computation and doubly debiased machine learning  ddml  and their evaluation for external control arms  eca  analysis is insufficient   methods  we consider both numerical simulations and a trial replication procedure to evaluate the different statistical approaches  propensity score matching  inverse probability of treatment weighting  iptw   g computation  and ddml  the replication study relies on five type   diabetes randomized clinical trials granted by the yale university open data access  yoda  project  from the pool of five trials  observational experiments are artificially built by replacing a control arm from one trial by an arm originating from another trial and containing similarly treated patients   results  among the different statistical approaches  numerical simulations show that ddml has the smallest bias followed by g computation  in terms of mean squared error  g computation usually minimizes mean squared error  compared to other methods  ddml has varying mean squared error performances that improves with increasing sample sizes  for hypothesis testing  all methods control type i error and ddml is the most conservative  g computation is the best method in terms of statistical power  and ddml has comparable power at   n        but inferior ones for smaller sample sizes  the replication procedure also indicates that g computation minimizes mean squared error whereas ddml has intermediate performances in between g computation and propensity score approaches  the confidence intervals of g computation are the narrowest whereas confidence intervals obtained with ddml are the widest for small sample sizes  which confirms its conservative nature   conclusions  for external control arm analyses  methods based on outcome prediction models can reduce estimation error and increase statistical power compared to propensity score approaches ,4.6723094,3.0223737,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
New advances in prediction and surveillance of preeclampsia: role of machine learning approaches and remote monitoring,"Preeclampsia, a multisystem disorder in pregnancy, is still one of the main causes of maternal morbidity and mortality. Due to a lack of a causative therapy, an accurate prediction of women at risk for the disease and its associated adverse outcomes is of utmost importance to tailor care. In the past two decades, there have been successful improvements in screening as well as in the prediction of the disease in high-risk women. This is due to, among other things, the introduction of biomarkers such as the sFlt-1/PlGF ratio. Recently, the traditional definition of preeclampsia has been expanded based on new insights into the pathophysiology and conclusive evidence on the ability of angiogenic biomarkers to improve detection of preeclampsia-associated maternal and fetal adverse events.
 However, with the widespread availability of digital solutions, such as decision support algorithms and remote monitoring devices, a chance for a further improvement of care arises. Two lines of research and application are promising: First, on the patient side, home monitoring has the potential to transform the traditional care pathway. The importance of the ability to input and access data remotely is a key learning from the COVID-19 pandemic. Second, on the physician side, machine-learning-based decision support algorithms have been shown to improve precision in clinical decision-making. The integration of signals from patient-side remote monitoring devices into predictive algorithms that power physician-side decision support tools offers a chance to further improve care.
 The purpose of this review is to summarize the recent advances in prediction, diagnosis and monitoring of preeclampsia and its associated adverse outcomes. We will review the potential impact of the ability to access to clinical data via remote monitoring. In the combination of advanced, machine learning-based risk calculation and remote monitoring lies an unused potential that allows for a truly patient-centered care.",preeclampsia  a multisystem disorder in pregnancy  is still one of the main causes of maternal morbidity and mortality  due to a lack of a causative therapy  an accurate prediction of women at risk for the disease and its associated adverse outcomes is of utmost importance to tailor care  in the past two decades  there have been successful improvements in screening as well as in the prediction of the disease in high risk women  this is due to  among other things  the introduction of biomarkers such as the sflt   plgf ratio  recently  the traditional definition of preeclampsia has been expanded based on new insights into the pathophysiology and conclusive evidence on the ability of angiogenic biomarkers to improve detection of preeclampsia associated maternal and fetal adverse events   however  with the widespread availability of digital solutions  such as decision support algorithms and remote monitoring devices  a chance for a further improvement of care arises  two lines of research and application are promising  first  on the patient side  home monitoring has the potential to transform the traditional care pathway  the importance of the ability to input and access data remotely is a key learning from the covid    pandemic  second  on the physician side  machine learning based decision support algorithms have been shown to improve precision in clinical decision making  the integration of signals from patient side remote monitoring devices into predictive algorithms that power physician side decision support tools offers a chance to further improve care   the purpose of this review is to summarize the recent advances in prediction  diagnosis and monitoring of preeclampsia and its associated adverse outcomes  we will review the potential impact of the ability to access to clinical data via remote monitoring  in the combination of advanced  machine learning based risk calculation and remote monitoring lies an unused potential that allows for a truly patient centered care ,5.43406,3.2037184,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
"Machine learning strengthened prediction of tracheal, bronchus, and lung cancer deaths due to air pollution","This work pointed out the use of machine learning tools to predict the effect of CO, O3, CH4, and CO2 on TBL (tracheal, bronchus, and lung cancer) deaths from 1990 to 2019. In this study, data from 203 countries/locations were used. We used evaluation metrics like accuracy, area under curve (AUC), recall, precision, and Matthews correlation coefficient (MCC) to determine the prediction efficiency of the models. The models that yielded accuracy between 89 and 90 were selected in this study. The essential features in the prediction process were extracted, and it was found that CO influenced the prediction process. Extra trees classifier, random forest classifier, gradient boosting classifier, and light gradient boosting machine were selected from 14 other classifiers based on the accuracy metric. The best-performing models, according to our benchmark standards, are the extra trees classifier (90.83%), random forest classifier (89.17%), gradient boosting classifier (89.17%), and light gradient boosting machine (89.17). We conclude that machine learning models can be used in predicting mortality, i.e., the number of deaths, and could assist us in predicting the role of air pollutants on TBL deaths globally.",this work pointed out the use of machine learning tools to predict the effect of co  o   ch   and co  on tbl  tracheal  bronchus  and lung cancer  deaths from      to       in this study  data from     countries locations were used  we used evaluation metrics like accuracy  area under curve  auc   recall  precision  and matthews correlation coefficient  mcc  to determine the prediction efficiency of the models  the models that yielded accuracy between    and    were selected in this study  the essential features in the prediction process were extracted  and it was found that co influenced the prediction process  extra trees classifier  random forest classifier  gradient boosting classifier  and light gradient boosting machine were selected from    other classifiers based on the accuracy metric  the best performing models  according to our benchmark standards  are the extra trees classifier           random forest classifier           gradient boosting classifier           and light gradient boosting machine          we conclude that machine learning models can be used in predicting mortality  i e   the number of deaths  and could assist us in predicting the role of air pollutants on tbl deaths globally ,4.891274,3.7739463,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Machine Learning-Based Prototype Design for Rainfall Forecasting,"Predicting rainfall is one of the difficult and uncertain activities that have a significant influence on human society. Predictions that are correct and timely can help to prevent financial and human loss. Using the Computational approach of Machine learning algorithms, rainfall prediction can be performed by extracting and merging latent knowledge from linear and nonlinear trends in prior weather data. This study discusses a series of studies that used data mining algorithms to construct models that predict whether it will rain tomorrow in major Australian cities based on previous meteorological data for that day. Moreover, AutoML (Automated Machine Learning) technique is applied to find out which model will predict higher accuracy. The results demonstrate a comparison of a variety of evaluation measures for different machine learning techniques, as well as their accuracy in predicting rainfall using weather data.
 Keywords
 Rainfall forecast
 AutoML
 Random forest
 Adaboost",predicting rainfall is one of the difficult and uncertain activities that have a significant influence on human society  predictions that are correct and timely can help to prevent financial and human loss  using the computational approach of machine learning algorithms  rainfall prediction can be performed by extracting and merging latent knowledge from linear and nonlinear trends in prior weather data  this study discusses a series of studies that used data mining algorithms to construct models that predict whether it will rain tomorrow in major australian cities based on previous meteorological data for that day  moreover  automl  automated machine learning  technique is applied to find out which model will predict higher accuracy  the results demonstrate a comparison of a variety of evaluation measures for different machine learning techniques  as well as their accuracy in predicting rainfall using weather data   keywords  rainfall forecast  automl  random forest  adaboost,5.3197117,4.2016973,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Data-driven approach to predict the fundamental period of steel-braced RC frames using stacked generalization machine learning models,"The study is directed toward the precise prediction of the fundamental period of steel-braced reinforced concrete (RC) moment-resisting frames through the utilization of stacked generalization, an advanced algorithmic ensemble machine learning technique. To facilitate this, a meticulously curated database comprising 17,280 building models has been automated using the ETABS Application Programming Interface (API). The database encompasses both concentrically braced frames and eccentrically braced frames and employs eigenvalue modal analysis to capture the fundamental periods, incorporating diverse bracing configurations and pivotal building parameters. Utilizing SHapley Additive exPlanations (SHAP), the study rigorously scrutinizes influential parameters that affect the fundamental period. The research introduces three stacking ensemble models, with the most effective model employing Random Forest as the meta-model and an ensemble of Extra Trees, Gradient Boosting, XGBoost, LightGBM, CatBoost, and kNN as base models. Hyperparameter tuning was accomplished through Bayesian Optimization, and a thorough sensitivity analysis was conducted. In rigorous evaluations conducted on the test dataset, the proposed model achieved an exceptionally high coefficient of determination (R2) of 0.9889, coupled with an impressively low root mean square error of 0.056. Further validation through multi-dimensional metrics confirmed the modelâ€™s robust generalization capabilities. Comparative validation against a few popular building code provisions and research models revealed that the proposed model markedly surpasses these benchmarks in predictive accuracy.",the study is directed toward the precise prediction of the fundamental period of steel braced reinforced concrete  rc  moment resisting frames through the utilization of stacked generalization  an advanced algorithmic ensemble machine learning technique  to facilitate this  a meticulously curated database comprising        building models has been automated using the etabs application programming interface  api   the database encompasses both concentrically braced frames and eccentrically braced frames and employs eigenvalue modal analysis to capture the fundamental periods  incorporating diverse bracing configurations and pivotal building parameters  utilizing shapley additive explanations  shap   the study rigorously scrutinizes influential parameters that affect the fundamental period  the research introduces three stacking ensemble models  with the most effective model employing random forest as the meta model and an ensemble of extra trees  gradient boosting  xgboost  lightgbm  catboost  and knn as base models  hyperparameter tuning was accomplished through bayesian optimization  and a thorough sensitivity analysis was conducted  in rigorous evaluations conducted on the test dataset  the proposed model achieved an exceptionally high coefficient of determination  r   of         coupled with an impressively low root mean square error of        further validation through multi dimensional metrics confirmed the model   s robust generalization capabilities  comparative validation against a few popular building code provisions and research models revealed that the proposed model markedly surpasses these benchmarks in predictive accuracy ,5.6723742,5.9089885,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Interdisciplinary AI: A Machine Learning System for Streamlining External Aesthetic and Cultural Influences in Architecture,"Architecture does not exist in a vacuum. Its cultural, conceptual, and aesthetic agendas are constantly influenced by other visual and artistic disciplines ranging from film, photography, painting, and sculpture to fashion, graphic, and industrial design. The formal qualities of the cultural zeitgeist are perpetually influencing contemporary architectural aesthetics. In this paper, we aim to introduce a radical yet methodical approach toward regulating the relationship between human agency and computational form-making by using Machine Learning (ML) as a conceptual design tool for interdisciplinary collaboration and engagement. Through the use of a highly calibrated and customized ML systems that can classify and iterate stylistic approaches that exist outside the disciplinary boundaries of architecture, the technique allows for machine intelligence to design, coordinate, randomize, and iterate external formal and aesthetic qualities as they relate to pattern, color, proportion, hierarchy, and formal language. The human engagement in this design process is limited to the initial curation of input data in the form of image repositories of non-architectural disciplines that the machine learning system can extrapolate from, and consequently in regulating and choosing from the iterations of images the Artificial Neural Networks are capable of producing. In this process, the architect becomes a curator that samples and streamlines external cultural influences while regulating their significance and weight in the final design. By questioning the notion of human agency in the design process and providing creative license to Artificial Intelligence in the conceptual design phase, we aim to develop a novel approach toward humanâ€“machine collaboration that rejects traditional notions of disciplinary autonomy and streamlines the influence of external aesthetic disciplines on contemporary architectural production.",architecture does not exist in a vacuum  its cultural  conceptual  and aesthetic agendas are constantly influenced by other visual and artistic disciplines ranging from film  photography  painting  and sculpture to fashion  graphic  and industrial design  the formal qualities of the cultural zeitgeist are perpetually influencing contemporary architectural aesthetics  in this paper  we aim to introduce a radical yet methodical approach toward regulating the relationship between human agency and computational form making by using machine learning  ml  as a conceptual design tool for interdisciplinary collaboration and engagement  through the use of a highly calibrated and customized ml systems that can classify and iterate stylistic approaches that exist outside the disciplinary boundaries of architecture  the technique allows for machine intelligence to design  coordinate  randomize  and iterate external formal and aesthetic qualities as they relate to pattern  color  proportion  hierarchy  and formal language  the human engagement in this design process is limited to the initial curation of input data in the form of image repositories of non architectural disciplines that the machine learning system can extrapolate from  and consequently in regulating and choosing from the iterations of images the artificial neural networks are capable of producing  in this process  the architect becomes a curator that samples and streamlines external cultural influences while regulating their significance and weight in the final design  by questioning the notion of human agency in the design process and providing creative license to artificial intelligence in the conceptual design phase  we aim to develop a novel approach toward human   machine collaboration that rejects traditional notions of disciplinary autonomy and streamlines the influence of external aesthetic disciplines on contemporary architectural production ,9.40794,3.3630702,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Sentiment Analysis Through Machine Learning: A Review,"Sentimental analysis is gaining popularity in the field of text mining. It is the study of peopleâ€™s opinions about any event, individual, or topic. Users are posting online reviews and opinions about specific products or services and it has become a popular way to share our reviews on the social web, as it is difficult to obtain users' reviews in such a rapid manner through any other means. It also provides us the volume of information on social media like Twitter and Facebook and a range of possible user opinions in a time-saving way. It is difficult as well as interesting due to the bulk amount of information generated by online social media and different kinds of possible opinions. Sentimental analysis on Facebook, Twitter has attracted much attention recently due to its wide applications in various commercial and public sectors. The main focus of this paper is to give a brief overview of sentimental analysis and its techniques and it also provides a comparative analysis of the research done in the field of sentiment analysis. These types of analysis are based on the machine learning approach.
 Keywords
 Sentiment Analysis
 Twitter
 Opinion Mining
 Machine Learning",sentimental analysis is gaining popularity in the field of text mining  it is the study of people   s opinions about any event  individual  or topic  users are posting online reviews and opinions about specific products or services and it has become a popular way to share our reviews on the social web  as it is difficult to obtain users  reviews in such a rapid manner through any other means  it also provides us the volume of information on social media like twitter and facebook and a range of possible user opinions in a time saving way  it is difficult as well as interesting due to the bulk amount of information generated by online social media and different kinds of possible opinions  sentimental analysis on facebook  twitter has attracted much attention recently due to its wide applications in various commercial and public sectors  the main focus of this paper is to give a brief overview of sentimental analysis and its techniques and it also provides a comparative analysis of the research done in the field of sentiment analysis  these types of analysis are based on the machine learning approach   keywords  sentiment analysis  twitter  opinion mining  machine learning,5.1706963,5.529643,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
A Study of iOS Machine Learning and Artificial Intelligence Frameworks and Libraries for Cotton Plant Disease Detection,"Identifying plant disease from leave images using machine learning and artificial intelligence algorithm is a recent trending research area in the technology and agriculture domain. It will fill the gap between hi-tech technology and the old traditional way of doing agriculture. This paper outlines a study of different iOS mobile machine learning and artificial framework and libraries which can be used in plant disease detection in agriculture. This paper also discusses the efficient use of these libraries in the iOS mobile app for better results. Many iOS ML and AI libraries have been studied which can be used directly in the iOS app with offline support, which means without interacting with the server and python language. The main criteria for selecting these libraries are mainly using the libraries directly in the iOS app using either Swift or Objective-C programming language. This will remove the dependency on server-side implementation and the needs of the python programming language. This study is used in designing the architecture of the iOS app for plant leaf disease detection and cotton plant disease classification.
 Keywords
 iOS
 Machine learning
 Artificial intelligence
 Cotton leaf
 Disease detection
 Offline iOS app
 CreateML
 Apple
 Tensor flow
 Swift for TensorFlow
 Classification",identifying plant disease from leave images using machine learning and artificial intelligence algorithm is a recent trending research area in the technology and agriculture domain  it will fill the gap between hi tech technology and the old traditional way of doing agriculture  this paper outlines a study of different ios mobile machine learning and artificial framework and libraries which can be used in plant disease detection in agriculture  this paper also discusses the efficient use of these libraries in the ios mobile app for better results  many ios ml and ai libraries have been studied which can be used directly in the ios app with offline support  which means without interacting with the server and python language  the main criteria for selecting these libraries are mainly using the libraries directly in the ios app using either swift or objective c programming language  this will remove the dependency on server side implementation and the needs of the python programming language  this study is used in designing the architecture of the ios app for plant leaf disease detection and cotton plant disease classification   keywords  ios  machine learning  artificial intelligence  cotton leaf  disease detection  offline ios app  createml  apple  tensor flow  swift for tensorflow  classification,7.8201747,6.069615,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Analysing Machine Learning Techniques in Python for the Prediction of Diabetes Using the Risk Factors as Parameters,"Diabetes is a disease caused due to an increased level of glucose in the blood. Many people around the world suffer from this condition. A lot of research works have been published concerning diabetes, using a variety of classifiers and machine learning models, both for predictions and diagnosis. This paper outlines the effects of some risk factors of diabetes, specifically the effect of BMI, blood pressure and physical activity, using machine learning models. A survey was conducted among a random sample of Indians of various age groups and the data of 251 individuals was gathered after which ML algorithms were applied. The analysis is supported by naÃ¯ve Bayes, logistic regression and random forest algorithms. All the metrics of these algorithms are compared and discussed in this paper, thereby establishing the model having the highest accuracy for the prediction. The model with the highest accuracy and precision can be used or analysed for further computational research on diabetes mellitus.
 Keywords
 Classification algorithms
 NaÃ¯ve Bayes
 Random forest
 Logistic regression
 Machine learning",diabetes is a disease caused due to an increased level of glucose in the blood  many people around the world suffer from this condition  a lot of research works have been published concerning diabetes  using a variety of classifiers and machine learning models  both for predictions and diagnosis  this paper outlines the effects of some risk factors of diabetes  specifically the effect of bmi  blood pressure and physical activity  using machine learning models  a survey was conducted among a random sample of indians of various age groups and the data of     individuals was gathered after which ml algorithms were applied  the analysis is supported by na  ve bayes  logistic regression and random forest algorithms  all the metrics of these algorithms are compared and discussed in this paper  thereby establishing the model having the highest accuracy for the prediction  the model with the highest accuracy and precision can be used or analysed for further computational research on diabetes mellitus   keywords  classification algorithms  na  ve bayes  random forest  logistic regression  machine learning,5.1775484,3.10886,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
A framework for predicting academic orientation using supervised machine learning,"School guidance is declared an integral part of the education and training process, as it accompanies students in their educational and professional choices. Accordingly, the current situation in light of the Covid-19 epidemic requires a reconsideration of school guidance together with the methods of accompanying the student to choose the field that suits his/her personality, knowledge qualifications, perceptual and intellectual skills in order to achieve an excellent educational level that enables the learner to work in future professions. The current study aims to predict a student's potential and provide support for academic guidance. This paper emphasizes the importance of supervised machine learning and classification algorithms to predict the personality type based on student traits. Based on the information gathered, the results of this study indicate that it contributes significantly to providing a comprehensive approach to support academic self-orientation.",school guidance is declared an integral part of the education and training process  as it accompanies students in their educational and professional choices  accordingly  the current situation in light of the covid    epidemic requires a reconsideration of school guidance together with the methods of accompanying the student to choose the field that suits his her personality  knowledge qualifications  perceptual and intellectual skills in order to achieve an excellent educational level that enables the learner to work in future professions  the current study aims to predict a student s potential and provide support for academic guidance  this paper emphasizes the importance of supervised machine learning and classification algorithms to predict the personality type based on student traits  based on the information gathered  the results of this study indicate that it contributes significantly to providing a comprehensive approach to support academic self orientation ,5.6033587,4.2703347,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Dataset Anonimyzation for Machine Learning: An ISP Case Study,"Internet Service Providers technical support needs personal data to predict potential anomalies. In this paper, we performed a comparative study of forecasting performance using raw data and anonymized data, in order to assess how much performance may vary, when plain personal data are replaced by anonymized personal data.
 Keywords
 ISP
 Cryptography
 Customer Premise Equipment
 WISP
 Logistic regression
 Random forest
 Attribute suppression
 Character masking
 Hash
 Pseudo-anonymization
 Data generalization",internet service providers technical support needs personal data to predict potential anomalies  in this paper  we performed a comparative study of forecasting performance using raw data and anonymized data  in order to assess how much performance may vary  when plain personal data are replaced by anonymized personal data   keywords  isp  cryptography  customer premise equipment  wisp  logistic regression  random forest  attribute suppression  character masking  hash  pseudo anonymization  data generalization,6.531228,7.0189104,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
The role of artificial neural network and machine learning in utilizing spatial information,"In this age of the fourth industrial revolution 4.0, the digital world has a plethora of data, including the internet of things, mobile, cybersecurity, social media, forecasts, health data, and so on. The expertise of machine learning and artificial intelligence (AI) is required to soundly evaluate the data and develop related smart and automated applications, These fields use a variety of machine learning techniques including supervised, unsupervised, and reinforcement learning. The objective of the study is to present the role of artificial neural networks and machine learning in utilizing spatial information. Machine learning and AI play an increasingly important role in disaster risk reduction from hazard mapping and forecasting severe occurrences to real-time event detection, situational awareness, and decision assistance. Some of the applications employed in the study to analyze the various ANN domains included weather forecasting, medical diagnosis, aerospace, facial recognition, stock market, social media, signature verification, forensics, robotics, electronics hardware, defense, and seismic data gathering. Machine learning determines the many prediction models for problems involving classification, regression, and clustering using known variables and locations from the training dataset, spatial data that is based on tabular data creates different observations that are geographically related to one another for unknown factors and places. The study presents that the Recurrent neural network and convolutional neural network are the best method in spatial information processing, healthcare, and weather forecasting with greater than 90% accuracy.",in this age of the fourth industrial revolution      the digital world has a plethora of data  including the internet of things  mobile  cybersecurity  social media  forecasts  health data  and so on  the expertise of machine learning and artificial intelligence  ai  is required to soundly evaluate the data and develop related smart and automated applications  these fields use a variety of machine learning techniques including supervised  unsupervised  and reinforcement learning  the objective of the study is to present the role of artificial neural networks and machine learning in utilizing spatial information  machine learning and ai play an increasingly important role in disaster risk reduction from hazard mapping and forecasting severe occurrences to real time event detection  situational awareness  and decision assistance  some of the applications employed in the study to analyze the various ann domains included weather forecasting  medical diagnosis  aerospace  facial recognition  stock market  social media  signature verification  forensics  robotics  electronics hardware  defense  and seismic data gathering  machine learning determines the many prediction models for problems involving classification  regression  and clustering using known variables and locations from the training dataset  spatial data that is based on tabular data creates different observations that are geographically related to one another for unknown factors and places  the study presents that the recurrent neural network and convolutional neural network are the best method in spatial information processing  healthcare  and weather forecasting with greater than     accuracy ,5.3568516,3.3734686,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Machine Learning in Lung Cancer Radiomics,"Lung cancer is the leading cause of cancer-related deaths worldwide. Medical imaging technologies such as computed tomography (CT) and positron emission tomography (PET) are routinely used for non-invasive lung cancer diagnosis. In clinical practice, physicians investigate the characteristics of tumors such as the size, shape and location from CT and PET images to make decisions. Recently, scientists have proposed various computational image features that can capture more information than that directly perceivable by human eyes, which promotes the rise of radiomics. Radiomics is a research field on the conversion of medical images into high-dimensional features with data-driven methods to help subsequent data mining for better clinical decision support. Radiomic analysis has four major steps: image preprocessing, tumor segmentation, feature extraction and clinical prediction. Machine learning, including the high-profile deep learning, facilitates the development and application of radiomic methods. Various radiomic methods have been proposed recently, such as the construction of radiomic signatures, tumor habitat analysis, cluster pattern characterization and end-to-end prediction of tumor properties. These methods have been applied in many studies aiming at lung cancer diagnosis, treatment and monitoring, shedding light on future non-invasive evaluations of the nodule malignancy, histological subtypes, genomic properties and treatment responses. In this review, we summarized and categorized the studies on the general workflow, methods for clinical prediction and clinical applications of machine learning in lung cancer radiomic studies, introduced some commonly-used software tools, and discussed the limitations of current methods and possible future directions.",lung cancer is the leading cause of cancer related deaths worldwide  medical imaging technologies such as computed tomography  ct  and positron emission tomography  pet  are routinely used for non invasive lung cancer diagnosis  in clinical practice  physicians investigate the characteristics of tumors such as the size  shape and location from ct and pet images to make decisions  recently  scientists have proposed various computational image features that can capture more information than that directly perceivable by human eyes  which promotes the rise of radiomics  radiomics is a research field on the conversion of medical images into high dimensional features with data driven methods to help subsequent data mining for better clinical decision support  radiomic analysis has four major steps  image preprocessing  tumor segmentation  feature extraction and clinical prediction  machine learning  including the high profile deep learning  facilitates the development and application of radiomic methods  various radiomic methods have been proposed recently  such as the construction of radiomic signatures  tumor habitat analysis  cluster pattern characterization and end to end prediction of tumor properties  these methods have been applied in many studies aiming at lung cancer diagnosis  treatment and monitoring  shedding light on future non invasive evaluations of the nodule malignancy  histological subtypes  genomic properties and treatment responses  in this review  we summarized and categorized the studies on the general workflow  methods for clinical prediction and clinical applications of machine learning in lung cancer radiomic studies  introduced some commonly used software tools  and discussed the limitations of current methods and possible future directions ,6.2830386,3.6551852,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Client Selection Frameworks Within Federated Machine Learning: The Current Paradigm,"Organisations are increasingly looking for ways to further utilise big data and the benefits that come with this. Previously, this role has been taken by traditional machine learning algorithms. However, these have drawbacks such as computation cost and privacy issues. Federated machine learning (FML) seeks to remedy the downfalls of traditional machine learning. Client selection is one way in which to further improve FML, as which clients that are chosen, and how they operate are a core part of its operation. This paper proposes a potential better way to operate a client selection framework, after reviewing the current literature within academia.
 Keywords
 Federated machine learning
 Client selection framework
 Cyber security",organisations are increasingly looking for ways to further utilise big data and the benefits that come with this  previously  this role has been taken by traditional machine learning algorithms  however  these have drawbacks such as computation cost and privacy issues  federated machine learning  fml  seeks to remedy the downfalls of traditional machine learning  client selection is one way in which to further improve fml  as which clients that are chosen  and how they operate are a core part of its operation  this paper proposes a potential better way to operate a client selection framework  after reviewing the current literature within academia   keywords  federated machine learning  client selection framework  cyber security,6.2296114,7.5283265,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Enhancement of cerebrovascular 4D flow MRI velocity fields using machine learning and computational fluid dynamics simulation data,"Blood flow metrics obtained with four-dimensional (4D) flow phase contrast (PC) magnetic resonance imaging (MRI) can be of great value in clinical and experimental cerebrovascular analysis. However, limitations in both quantitative and qualitative analyses can result from errors inherent to PC MRI. One method that excels in creating low-error, physics-based, velocity fields is computational fluid dynamics (CFD). Augmentation of cerebral 4D flow MRI data with CFD-informed neural networks may provide a method to produce highly accurate physiological flow fields. In this preliminary study, the potential utility of such a method was demonstrated by using high resolution patient-specific CFD data to train a convolutional neural network, and then using the trained network to enhance MRI-derived velocity fields in cerebral blood vessel data sets. Through testing on simulated images, phantom data, and cerebrovascular 4D flow data from 20 patients, the trained network successfully de-noised flow images, decreased velocity error, and enhanced near-vessel-wall velocity quantification and visualization. Such image enhancement can improve experimental and clinical qualitative and quantitative cerebrovascular PC MRI analysis.",blood flow metrics obtained with four dimensional   d  flow phase contrast  pc  magnetic resonance imaging  mri  can be of great value in clinical and experimental cerebrovascular analysis  however  limitations in both quantitative and qualitative analyses can result from errors inherent to pc mri  one method that excels in creating low error  physics based  velocity fields is computational fluid dynamics  cfd   augmentation of cerebral  d flow mri data with cfd informed neural networks may provide a method to produce highly accurate physiological flow fields  in this preliminary study  the potential utility of such a method was demonstrated by using high resolution patient specific cfd data to train a convolutional neural network  and then using the trained network to enhance mri derived velocity fields in cerebral blood vessel data sets  through testing on simulated images  phantom data  and cerebrovascular  d flow data from    patients  the trained network successfully de noised flow images  decreased velocity error  and enhanced near vessel wall velocity quantification and visualization  such image enhancement can improve experimental and clinical qualitative and quantitative cerebrovascular pc mri analysis ,3.368799,4.307006,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Towards Abalone Differentiation Through Machine Learning,"Abalone is a marine species of mollusks of a great lineage with different properties for human consumption. Abalone farming is supported by productive and industrial infrastructure in several countries, including Mexico, where polyculture is being experimented with to optimize operating costs. One of the tasks of the producers is to identify the sex of each abalone to apply certain measures for its growth or to take steps for its preservation. However, this task can be challenging for those just starting the process. This paper presents a case study for classifying abalone sex using machine learning algorithms. A methodology is presented that involves the analysis and processing of information to train and configure four different classification algorithms to recognize three types of classes: male, female, and immature. The results demonstrate the impact of using linear classifiers for this task.
 Keywords
 Abalone classification
 Machine learning
 Data mining",abalone is a marine species of mollusks of a great lineage with different properties for human consumption  abalone farming is supported by productive and industrial infrastructure in several countries  including mexico  where polyculture is being experimented with to optimize operating costs  one of the tasks of the producers is to identify the sex of each abalone to apply certain measures for its growth or to take steps for its preservation  however  this task can be challenging for those just starting the process  this paper presents a case study for classifying abalone sex using machine learning algorithms  a methodology is presented that involves the analysis and processing of information to train and configure four different classification algorithms to recognize three types of classes  male  female  and immature  the results demonstrate the impact of using linear classifiers for this task   keywords  abalone classification  machine learning  data mining,3.9686456,4.868897,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Machine learning to predict no reflow and in-hospital mortality in patients with ST-segment elevation myocardial infarction that underwent primary percutaneous coronary intervention,"Background
 The machine learning algorithm (MLA) was implemented to establish an optimal model to predict the no reflow (NR) process and in-hospital death that occurred in ST-elevation myocardial infarction (STEMI) patients who underwent primary percutaneous coronary intervention (pPCI).
 Methods
 The data were obtained retrospectively from 854 STEMI patients who underwent pPCI. MLA was applied to predict the potential NR phenomenon and confirm the in-hospital mortality. A random sampling method was used to split the data into the training (66.7%) and testing (33.3%) sets. The final results were an average of 10 repeated procedures. The area under the curve (AUC) and the associated 95% confidence intervals (CIs) of the receiver operator characteristic were measured.
 Results
 A random forest algorithm (RAN) had optimal discrimination for the NR phenomenon with an AUC of 0.7891 (95% CI: 0.7093â€“0.8688) compared with 0.6437 (95% CI: 0.5506â€“0.7368) for the decision tree (CTREE), 0.7488 (95% CI: 0.6613â€“0.8363) for the support vector machine (SVM), and 0.681 (95% CI: 0.5767â€“0.7854) for the neural network algorithm (NNET). The optimal RAN AUC for in-hospital mortality was 0.9273 (95% CI: 0.8819â€“0.9728), for SVM, 0.8935 (95% CI: 0.826â€“0.9611); NNET, 0.7756 (95% CI: 0.6559â€“0.8952); and CTREE, 0.7885 (95% CI: 0.6738â€“0.9033).
 Conclusions
 The MLA had a relatively higher performance when evaluating the NR risk and in-hospital mortality in patients with STEMI who underwent pPCI and could be utilized in clinical decision making.",background  the machine learning algorithm  mla  was implemented to establish an optimal model to predict the no reflow  nr  process and in hospital death that occurred in st elevation myocardial infarction  stemi  patients who underwent primary percutaneous coronary intervention  ppci    methods  the data were obtained retrospectively from     stemi patients who underwent ppci  mla was applied to predict the potential nr phenomenon and confirm the in hospital mortality  a random sampling method was used to split the data into the training         and testing         sets  the final results were an average of    repeated procedures  the area under the curve  auc  and the associated     confidence intervals  cis  of the receiver operator characteristic were measured   results  a random forest algorithm  ran  had optimal discrimination for the nr phenomenon with an auc of             ci                   compared with             ci                   for the decision tree  ctree               ci                   for the support vector machine  svm   and            ci                   for the neural network algorithm  nnet   the optimal ran auc for in hospital mortality was             ci                    for svm              ci                   nnet              ci                    and ctree              ci                     conclusions  the mla had a relatively higher performance when evaluating the nr risk and in hospital mortality in patients with stemi who underwent ppci and could be utilized in clinical decision making ,4.792053,3.1772814,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Comprehensive Analysis of Defect Detection Through Image Processing and Machine Learning for Photovoltaic Panels,"Fault identification in Photovoltaic (PV) panels is of prime importance during the regular operation and maintenance of PV power plants. An extensive fault identification process that employs Image Processing, Machine Learning, and Electrical-based techniques has been analyzed comprehensively. Photovoltaic panels are the perfect choice of renewable energy from natural light sources. The energy yield of PV panel is degraded gradually because of dust, discoloration, crack and faults. These faults attribute a production loss of up to 20%, as one faulty panel can bring down the efficiency of the entire plant. It is implied that faulty panels need to be identified as soon as possible, and it is highly critical to resolving issues to ensure effective energy production. The various IP techniques and ML models that elucidate ways to identify PV panel defects have been addressed. Inferences made from this study to help identify three methods for defect detection that stand apart in terms of efficiency. Parametric observations on all three methods are made in terms of F1 Score, Precision, Accuracy and Recall. Numerical values indicate clearly that the Machine Learning method based on AlexNet predicts the Photovoltaic panelâ€™s defect with 0.86 F1 value, 0.89 precision and an accuracy of 85.56%.
 Keywords
 Photovoltaic panel
 Image processing
 Machine learning
 Deep learning",fault identification in photovoltaic  pv  panels is of prime importance during the regular operation and maintenance of pv power plants  an extensive fault identification process that employs image processing  machine learning  and electrical based techniques has been analyzed comprehensively  photovoltaic panels are the perfect choice of renewable energy from natural light sources  the energy yield of pv panel is degraded gradually because of dust  discoloration  crack and faults  these faults attribute a production loss of up to      as one faulty panel can bring down the efficiency of the entire plant  it is implied that faulty panels need to be identified as soon as possible  and it is highly critical to resolving issues to ensure effective energy production  the various ip techniques and ml models that elucidate ways to identify pv panel defects have been addressed  inferences made from this study to help identify three methods for defect detection that stand apart in terms of efficiency  parametric observations on all three methods are made in terms of f  score  precision  accuracy and recall  numerical values indicate clearly that the machine learning method based on alexnet predicts the photovoltaic panel   s defect with      f  value       precision and an accuracy of          keywords  photovoltaic panel  image processing  machine learning  deep learning,6.867414,5.5282946,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Evaluation of Selected Machine Learning Models and Features for Electrical Consumption Prediction in Educational Institutions,"Recently, predictive analytic is making a very good contribution to reliable power supply. It provides advanced techniques to process, interpret and analyze big energy data and make it more valuable. In this article, we have presented a benchmark of the most used features and forecast models to predict the electrical energy consumption of educational institutions. This study uses ASHRAE data set, that contains information about energy types based on historic usage rates and observed weather for many buildings type. The proposed system analyzes only electricity meter reading for college university of educational buildings. The objective of this work is to evaluate the prediction performance of each forecasting model using different type of features (weather and occupancy) and different regressors in order to investigate the impact of input variables.
 Keywords
 Big data
 Machine learning
 Smart grid
 Electrical consumption forecasting",recently  predictive analytic is making a very good contribution to reliable power supply  it provides advanced techniques to process  interpret and analyze big energy data and make it more valuable  in this article  we have presented a benchmark of the most used features and forecast models to predict the electrical energy consumption of educational institutions  this study uses ashrae data set  that contains information about energy types based on historic usage rates and observed weather for many buildings type  the proposed system analyzes only electricity meter reading for college university of educational buildings  the objective of this work is to evaluate the prediction performance of each forecasting model using different type of features  weather and occupancy  and different regressors in order to investigate the impact of input variables   keywords  big data  machine learning  smart grid  electrical consumption forecasting,5.2171226,4.294138,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Explainable AI for ICT: System and Software Architecture,"Artificial Intelligence (AI) has become a revolution in the ICT domain due to the swift progress of analytical techniques and the availability of structured/unstructured data. With the indispensable role of AI in different applications, there are growing concerns over the lack of transparency and explainability. In addition, potential bias may affect the predictions of a model. This is where Explainable Artificial Intelligence (XAI) comes into the picture. XAI increases the trust placed in an AI system by researchers, medical practitioners, and others. Thus, it leads to widespread deployment of AI in healthcare, agriculture, online mart, and many more. The aim is to enlighten practitioners on the understandability and interpretability of EAI systems using a variety of techniques available which can be very advantageous in the ICT domain. In this chapter, we present two different techniques leveraging EAI where a user has to make the right choices based on his requirements. The software architecture of the first techniques is based on a medical diagnosis model where we need to be confident enough to treat a patient as instructed by a black-box model. Another approach presents an online Mart where a reliable pricing method can be developed by ML models that can read through historical sales data. The objective here is to match buyers and sellers, to weigh animals, and to oversee their sale. However, when AI models suggest or recommend a decision, that in itself does not reveal too much (i.e., it acts as a black box). Hence, a model capable of explaining the different factors that impact the price point is essential for the needs of a user.
 Keywords
 Explainable AI
 Healthcare
 Programming frameworks
 Video Analytics
 Internet of Things
 vision-based feature extraction
 ML-based price prediction",artificial intelligence  ai  has become a revolution in the ict domain due to the swift progress of analytical techniques and the availability of structured unstructured data  with the indispensable role of ai in different applications  there are growing concerns over the lack of transparency and explainability  in addition  potential bias may affect the predictions of a model  this is where explainable artificial intelligence  xai  comes into the picture  xai increases the trust placed in an ai system by researchers  medical practitioners  and others  thus  it leads to widespread deployment of ai in healthcare  agriculture  online mart  and many more  the aim is to enlighten practitioners on the understandability and interpretability of eai systems using a variety of techniques available which can be very advantageous in the ict domain  in this chapter  we present two different techniques leveraging eai where a user has to make the right choices based on his requirements  the software architecture of the first techniques is based on a medical diagnosis model where we need to be confident enough to treat a patient as instructed by a black box model  another approach presents an online mart where a reliable pricing method can be developed by ml models that can read through historical sales data  the objective here is to match buyers and sellers  to weigh animals  and to oversee their sale  however  when ai models suggest or recommend a decision  that in itself does not reveal too much  i e   it acts as a black box   hence  a model capable of explaining the different factors that impact the price point is essential for the needs of a user   keywords  explainable ai  healthcare  programming frameworks  video analytics  internet of things  vision based feature extraction  ml based price prediction,6.437278,5.816132,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Business Intelligence,"This is the last chapter of Part IV, â€œThe HOW,â€ where we put everything together to provide guidance as to how to truly scale AI in any enterprise. We have explored â€œThy WHYâ€ most, if not all, companies should be embarking on an urgent AI Transformation. We have also gone deep into the intuition and First Principles of â€œThe WHATâ€ of AI, so the reader should be able to evaluate different algorithms for different situations. We are now in the final chapter on â€œThe HOW,â€ how to bring to live all these capabilities, and in this last chapter, we will explore how to consistently deploy AI at scale across all types of organizations in different industries and sizes.",this is the last chapter of part iv     the how     where we put everything together to provide guidance as to how to truly scale ai in any enterprise  we have explored    thy why    most  if not all  companies should be embarking on an urgent ai transformation  we have also gone deep into the intuition and first principles of    the what    of ai  so the reader should be able to evaluate different algorithms for different situations  we are now in the final chapter on    the how     how to bring to live all these capabilities  and in this last chapter  we will explore how to consistently deploy ai at scale across all types of organizations in different industries and sizes ,10.707285,6.733803,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Scaling AI,"Business intelligence (BI) is an area of information technology that interacts with business domains on the front end of user interactions and is important in terms of its impact on business. Business intelligence in a modern data warehouse environment is not only conceptual, but also essential. In the last chapter, we discussed self-service. It would not be possible without enabling business intelligence tools.",business intelligence  bi  is an area of information technology that interacts with business domains on the front end of user interactions and is important in terms of its impact on business  business intelligence in a modern data warehouse environment is not only conceptual  but also essential  in the last chapter  we discussed self service  it would not be possible without enabling business intelligence tools ,9.498685,7.239001,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
"Predictive Performances of Ensemble Machine Learning Algorithms in Landslide Susceptibility Mapping Using Random Forest, Extreme Gradient Boosting (XGBoost) and Natural Gradient Boosting (NGBoost)","Across the globe, landslides have been recognized as one of the most detrimental geological calamities, especially in hilly terrains. However, the correct determination of landslide-prone fields remained a challenging task due to the nonlinear, complex, and inconsistent nature of landslides. Therefore, it is essential to apply methods with superior capabilities in dealing with real-world problems for properly delineating potential landslide zones. Recently, ensemble learning techniques have been drawn intense interest in landslide susceptibility mapping studies due to their distinct advantages. This present work intended to propose natural gradient boosting (NGBoost), a novel member of the ensemble learning family, for modeling landslide susceptibility for Macka County of Trabzon province, Turkey. The predictive performance of NGBoost was compared to ensemble-based machine learning methods, namely random forest (RF) and XGBoost using five accuracy metrics including overall accuracy (OA), F1 score, Kappa coefficient, area under curve (AUC) value, and root-mean-square error to evaluate its competence and robustness. Besides, SHAP based on the game theory approach was implemented to interpret the influences of the predisposing factors on the produced model. Results indicated that the NGBoost method utilized for landslide susceptibility mapping problem for the first time had the greatest predictive ability (AUCâ€‰=â€‰0.898), followed by XGBoost (AUCâ€‰=â€‰0.871) and RF (AUCâ€‰=â€‰0.863), and outperformed the XGBoost and RF by approximately 6% in terms of OA. McNemarâ€™s statistical significance test results also confirmed the superiority of the proposed NGBoost method over the RF and XGBoost algorithms.",across the globe  landslides have been recognized as one of the most detrimental geological calamities  especially in hilly terrains  however  the correct determination of landslide prone fields remained a challenging task due to the nonlinear  complex  and inconsistent nature of landslides  therefore  it is essential to apply methods with superior capabilities in dealing with real world problems for properly delineating potential landslide zones  recently  ensemble learning techniques have been drawn intense interest in landslide susceptibility mapping studies due to their distinct advantages  this present work intended to propose natural gradient boosting  ngboost   a novel member of the ensemble learning family  for modeling landslide susceptibility for macka county of trabzon province  turkey  the predictive performance of ngboost was compared to ensemble based machine learning methods  namely random forest  rf  and xgboost using five accuracy metrics including overall accuracy  oa   f  score  kappa coefficient  area under curve  auc  value  and root mean square error to evaluate its competence and robustness  besides  shap based on the game theory approach was implemented to interpret the influences of the predisposing factors on the produced model  results indicated that the ngboost method utilized for landslide susceptibility mapping problem for the first time had the greatest predictive ability  auc               followed by xgboost  auc              and rf  auc               and outperformed the xgboost and rf by approximately    in terms of oa  mcnemar   s statistical significance test results also confirmed the superiority of the proposed ngboost method over the rf and xgboost algorithms ,4.5822225,3.3450177,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Optimizing High-Efficiency Quantum Memory with Quantum Machine Learning for Near-Term Quantum Devices,"Quantum memories are a fundamental of any global-scale quantum Internet, high-performance quantum networking and near-term quantum computers. A main problem of quantum memories is the low retrieval efficiency of the quantum systems from the quantum registers of the quantum memory. Here, we define a novel quantum memory called high-retrieval-efficiency (HRE) quantum memory for near-term quantum devices. An HRE quantum memory unit integrates local unitary operations on its hardware level for the optimization of the readout procedure and utilizes the advanced techniques of quantum machine learning. We define the integrated unitary operations of an HRE quantum memory, prove the learning procedure, and evaluate the achievable output signal-to-noise ratio values. We prove that the local unitaries of an HRE quantum memory achieve the optimization of the readout procedure in an unsupervised manner without the use of any labeled data or training sequences. We show that the readout procedure of an HRE quantum memory is realized in a completely blind manner without any information about the input quantum system or about the unknown quantum operation of the quantum register. We evaluate the retrieval efficiency of an HRE quantum memory and the output SNR (signal-to-noise ratio). The results are particularly convenient for gate-model quantum computers and the near-term quantum devices of the quantum Internet.",quantum memories are a fundamental of any global scale quantum internet  high performance quantum networking and near term quantum computers  a main problem of quantum memories is the low retrieval efficiency of the quantum systems from the quantum registers of the quantum memory  here  we define a novel quantum memory called high retrieval efficiency  hre  quantum memory for near term quantum devices  an hre quantum memory unit integrates local unitary operations on its hardware level for the optimization of the readout procedure and utilizes the advanced techniques of quantum machine learning  we define the integrated unitary operations of an hre quantum memory  prove the learning procedure  and evaluate the achievable output signal to noise ratio values  we prove that the local unitaries of an hre quantum memory achieve the optimization of the readout procedure in an unsupervised manner without the use of any labeled data or training sequences  we show that the readout procedure of an hre quantum memory is realized in a completely blind manner without any information about the input quantum system or about the unknown quantum operation of the quantum register  we evaluate the retrieval efficiency of an hre quantum memory and the output snr  signal to noise ratio   the results are particularly convenient for gate model quantum computers and the near term quantum devices of the quantum internet ,4.6025615,7.21076,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Building Inference Pipelines,"If youâ€™ve made it this far, youâ€™ve already created MLOps infrastructure, build a feature store, designed and built an end to end training pipeline complete with MLFlow experiment tracking for reproducibility and model storage in the MLFlow model registry, and tried monitoring and logging. It might seem like youâ€™re almost done; however, weâ€™re still missing a critical piece of the MLOps puzzle: Once youâ€™ve trained your model, what do you do with it?",if you   ve made it this far  you   ve already created mlops infrastructure  build a feature store  designed and built an end to end training pipeline complete with mlflow experiment tracking for reproducibility and model storage in the mlflow model registry  and tried monitoring and logging  it might seem like you   re almost done  however  we   re still missing a critical piece of the mlops puzzle  once you   ve trained your model  what do you do with it ,7.6777244,7.4223905,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Energy metaverse: the conceptual framework with a review of the state-of-the-art methods and technologies,"The transition to green energy systems is vital for addressing climate change, with a focus on renewable sources like wind and solar. This change requires substantial investment, societal adaptations, and managing a complex energy ecosystem. However, no existing evaluation methods support this purpose. The ""energy metaverse"" is proposed as a digital platform that mirrors the energy ecosystem, enabling the design, trial, and assessment of new technologies, business models, and value chains before real-world deployment. Drawing from State-of-the-Art technologies and methodologies, this paper introduces a conceptual framework for the energy metaverse, comprising five essential components: a versatile energy ecosystem data space, an interoperable virtual ecosystem living lab, an energy system models and artificial intelligent algorithms sandbox, a circular value chain co-design toolbox, and an ecosystem lifecycle evaluation software tool. This paper also suggests specific methods and technologies to develop each of these five components of the energy metaverse.",the transition to green energy systems is vital for addressing climate change  with a focus on renewable sources like wind and solar  this change requires substantial investment  societal adaptations  and managing a complex energy ecosystem  however  no existing evaluation methods support this purpose  the  energy metaverse  is proposed as a digital platform that mirrors the energy ecosystem  enabling the design  trial  and assessment of new technologies  business models  and value chains before real world deployment  drawing from state of the art technologies and methodologies  this paper introduces a conceptual framework for the energy metaverse  comprising five essential components  a versatile energy ecosystem data space  an interoperable virtual ecosystem living lab  an energy system models and artificial intelligent algorithms sandbox  a circular value chain co design toolbox  and an ecosystem lifecycle evaluation software tool  this paper also suggests specific methods and technologies to develop each of these five components of the energy metaverse ,7.6906123,5.9678206,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Do Autonomous Vehicles Learn?,"With autonomous driving, a technological system will replace humans in driving automobiles. The car industry, universities, and large IT companies, are currently working on implementing functions permitting a technological system to take on vehicle operation.
 Keywords
 Machine Learning
 Road Traffic
 Hazard Assessment
 Road User
 Autonomous Vehicle
 These keywords were added by machine and not by the authors. This process is experimental and the keywords may be updated as the learning algorithm improves.",with autonomous driving  a technological system will replace humans in driving automobiles  the car industry  universities  and large it companies  are currently working on implementing functions permitting a technological system to take on vehicle operation   keywords  machine learning  road traffic  hazard assessment  road user  autonomous vehicle  these keywords were added by machine and not by the authors  this process is experimental and the keywords may be updated as the learning algorithm improves ,4.9534855,4.7918267,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Intra- and inter-rater agreement between an ophthalmologist and mid-level ophthalmic personnel to diagnose retinal diseases based on fundus photographs at a primary eye center in Nepal: the Bhaktapur Retina Study,"Background
 Early detection can reduce irreversible blindness from retinal diseases. This study aims to assess the intra- and inter-rater agreement of retinal pathologies observed on fundus photographs between an ophthalmologist and two-mid level ophthalmic personnel (MLOPs).
 Method
 A population-based, cross-sectional study was conducted among subjects 60 years and above in the Bhaktapur district of Nepal. Fundus photographs of 500 eyes of 500 subjects were assessed. The macula-centered 45-degree photographs were graded twice by one ophthalmologist and two MLOPs. Intra-rater and inter-rater agreements were assessed for the ophthalmologist and the MLOPs.
 Result
 Mean age was 70.22 yearsâ€‰Â±â€‰6.94 (SD). Retinal pathologies were observed in 55.6 % of photographs (age-related macular degeneration: 34.2 %; diabetic retinopathy: 4.2 %; retinal vein occlusion: 3.8 %). Twelve (2.4 %) fundus pictures were non-gradable. The intra-rater agreement for overall retinal pathologies, retinal hemorrhage, and maculopathy were substantial both for the ophthalmologist as well as for the MLOPs. There was moderate inter-rater agreement between the ophthalmologist and the first MLOP on second rating for overall retinal pathologies, [kappa (k); 95 % CIâ€‰=â€‰0.59 (0.51â€“0.66)], retinal hemorrhage [k; 95â€‰% CIâ€‰=â€‰0.60 (0.41â€“0.78)], and maculopathy [k; 95â€‰% CIâ€‰=â€‰0.52 (0.43â€“0.60)]. Inter-rater agreement between the ophthalmologist and the second MLOP for second rating was moderate for overall retinal pathologies [k; 95 % CIâ€‰=â€‰0.52 (0.44â€“0.60)], substantial agreement for retinal hemorrhage [k; 95 % CIâ€‰=â€‰0. 68 (0.52â€“0.84)], moderate agreement for maculopathy [k; 95 % CIâ€‰=â€‰0.59 (0.50â€“0.67)].
 Conclusion
 There is moderate agreement between the MLOPs and the ophthalmologist in grading fundus photographs for retinal hemorrhages and maculopathy.",background  early detection can reduce irreversible blindness from retinal diseases  this study aims to assess the intra  and inter rater agreement of retinal pathologies observed on fundus photographs between an ophthalmologist and two mid level ophthalmic personnel  mlops    method  a population based  cross sectional study was conducted among subjects    years and above in the bhaktapur district of nepal  fundus photographs of     eyes of     subjects were assessed  the macula centered    degree photographs were graded twice by one ophthalmologist and two mlops  intra rater and inter rater agreements were assessed for the ophthalmologist and the mlops   result  mean age was       years              sd   retinal pathologies were observed in        of photographs  age related macular degeneration          diabetic retinopathy         retinal vein occlusion          twelve         fundus pictures were non gradable  the intra rater agreement for overall retinal pathologies  retinal hemorrhage  and maculopathy were substantial both for the ophthalmologist as well as for the mlops  there was moderate inter rater agreement between the ophthalmologist and the first mlop on second rating for overall retinal pathologies   kappa  k        ci                            retinal hemorrhage  k         ci                            and maculopathy  k         ci                            inter rater agreement between the ophthalmologist and the second mlop for second rating was moderate for overall retinal pathologies  k       ci                            substantial agreement for retinal hemorrhage  k       ci                             moderate agreement for maculopathy  k       ci                             conclusion  there is moderate agreement between the mlops and the ophthalmologist in grading fundus photographs for retinal hemorrhages and maculopathy ,4.938372,3.39199,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Designing and developing smart production planning and control systems in the industry 4.0 era: a methodology and case study,"In furtherance of emerging research within smart production planning and control (PPC), this paper prescribes a methodology for the design and development of a smart PPC system. A smart PPC system uses emerging technologies such as the internet of things, big-data analytics tools and machine learning running on the cloud or on edge devices to enhance performance of PPC processes. It achieves this by using a wider range of data sources from the production system, capturing and utilizing the experience of production planners, using analytics and machine learning to harness insights from the data and allowing dynamic and near real-time action to the continuously changing production system. The proposed methodology is illustrated with a case study in a sweets and snacks manufacturing company, to highlight the key considerations and challenges production managers might face during its application. The case further demonstrates considerations for scalability and flexibility via a loosely coupled, service-oriented architecture and the selection of fitting algorithms respectively to address a business requirement for a short-term, multi-criteria and event-driven production planning and control solution. Finally, the paper further discusses the challenges of PPC in smart manufacturing and the importance of fitting smart technologies to planning environment characteristics.",in furtherance of emerging research within smart production planning and control  ppc   this paper prescribes a methodology for the design and development of a smart ppc system  a smart ppc system uses emerging technologies such as the internet of things  big data analytics tools and machine learning running on the cloud or on edge devices to enhance performance of ppc processes  it achieves this by using a wider range of data sources from the production system  capturing and utilizing the experience of production planners  using analytics and machine learning to harness insights from the data and allowing dynamic and near real time action to the continuously changing production system  the proposed methodology is illustrated with a case study in a sweets and snacks manufacturing company  to highlight the key considerations and challenges production managers might face during its application  the case further demonstrates considerations for scalability and flexibility via a loosely coupled  service oriented architecture and the selection of fitting algorithms respectively to address a business requirement for a short term  multi criteria and event driven production planning and control solution  finally  the paper further discusses the challenges of ppc in smart manufacturing and the importance of fitting smart technologies to planning environment characteristics ,10.612467,7.208312,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Data Science for Entrepreneurship: The Road Ahead,"Recent advancements and trends in data engineering, data analytics, entrepreneurship, and business and societal context in which all this happens will usher a new wave in data entrepreneurship. This calls for new theories, approaches, methods, and techniques and opens up new possibilities for companies to find a competitive edge and, hopefully, to reap the associated benefits. This chapter concludes the book with a kaleidoscopic overview of several important developments, exploring their implications for areas where data science and entrepreneurship meet. Next to a number of implications for practice, this chapter ends with a brief discussion of interesting avenues for future research.
 Keywords
 Data entrepreneurship
 Practical implications
 Future research avenues
 AI software: MLOps
 Edge computing
 Digital twins
 Large-scale experimentation
 Government regulation",recent advancements and trends in data engineering  data analytics  entrepreneurship  and business and societal context in which all this happens will usher a new wave in data entrepreneurship  this calls for new theories  approaches  methods  and techniques and opens up new possibilities for companies to find a competitive edge and  hopefully  to reap the associated benefits  this chapter concludes the book with a kaleidoscopic overview of several important developments  exploring their implications for areas where data science and entrepreneurship meet  next to a number of implications for practice  this chapter ends with a brief discussion of interesting avenues for future research   keywords  data entrepreneurship  practical implications  future research avenues  ai software  mlops  edge computing  digital twins  large scale experimentation  government regulation,10.7937975,6.259691,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Architecting Green Artificial Intelligence Products: Recommendations for Sustainable AI Software Development and Evaluation,"With unabated global warming and climate change, the concept of Green Artificial Intelligence has emerged in which companies in the information and communication sector are increasingly embracing sustainable methods for designing, developing, and applying AI software. This paper examines current research on Green AI coding practices, design principles, use cases, and applications, as well as policy, ethical, and regulatory issues. The overarching premise is that Green Artificial Intelligence is a promising paradigm for mitigating climate change through collaboration. However, it requires a streamlined regulatory framework combining AI policy, industry standards and best practices, and legal frameworks for addressing emerging issues as AI technology evolves.
 Keywords
 Artificial intelligence
 Green AI
 Software
 Sustainability",with unabated global warming and climate change  the concept of green artificial intelligence has emerged in which companies in the information and communication sector are increasingly embracing sustainable methods for designing  developing  and applying ai software  this paper examines current research on green ai coding practices  design principles  use cases  and applications  as well as policy  ethical  and regulatory issues  the overarching premise is that green artificial intelligence is a promising paradigm for mitigating climate change through collaboration  however  it requires a streamlined regulatory framework combining ai policy  industry standards and best practices  and legal frameworks for addressing emerging issues as ai technology evolves   keywords  artificial intelligence  green ai  software  sustainability,12.025492,5.436789,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Sustainable Artificial Intelligence: In Search of Technological Resilience,"Great demands are placed on the role of digital technology and artificial intelligence for sustainable development. External shocks, like the current pandemic, as well as creeping degradation, like the effects of carbon economy on the climate, need convincing concepts to control lasting negative effects on society, environment, and economy. This paper is intended to contribute to the search for ways of enabling resilience through technology.
 High expectations are being put on data driven artificial intelligence in this respect. We consider that artificial intelligence tends to fall short of scientific rigor regarding cause-and-effect relations and discuss the inherent limitations of so-called formal systems that are at the bottom of artificial intelligence systems. We take into view what data analysis and reasoning can deliver regarding the discovery of empirical phenomena, arguing that targeted, reflective data reasoning can well help discover correlations worth further theoretical investigation. We suggest combining established methods of epistemic knowledge generation with data driven artificial intelligence, i.e. human intelligence with machine-based algorithmic intelligence, in support of advanced human-systems integration. For this concept of hybrid intelligence, we provide a procedural framework.
 This methodological approach gets exemplified by the description of recently published cases of a technical application resp. Scientific practice, illustrating the potential of hybrid intelligence for the scientific as well as technical solution of problems. Concluding remarks finally draw the line to future work on sustainable artificial intelligence as a pathway to resilience delivered by technological means.
 Keywords
 Artificial intelligence
 Formal systems
 Data reasoning
 Hybrid intelligence
 Human-systems integration",great demands are placed on the role of digital technology and artificial intelligence for sustainable development  external shocks  like the current pandemic  as well as creeping degradation  like the effects of carbon economy on the climate  need convincing concepts to control lasting negative effects on society  environment  and economy  this paper is intended to contribute to the search for ways of enabling resilience through technology   high expectations are being put on data driven artificial intelligence in this respect  we consider that artificial intelligence tends to fall short of scientific rigor regarding cause and effect relations and discuss the inherent limitations of so called formal systems that are at the bottom of artificial intelligence systems  we take into view what data analysis and reasoning can deliver regarding the discovery of empirical phenomena  arguing that targeted  reflective data reasoning can well help discover correlations worth further theoretical investigation  we suggest combining established methods of epistemic knowledge generation with data driven artificial intelligence  i e  human intelligence with machine based algorithmic intelligence  in support of advanced human systems integration  for this concept of hybrid intelligence  we provide a procedural framework   this methodological approach gets exemplified by the description of recently published cases of a technical application resp  scientific practice  illustrating the potential of hybrid intelligence for the scientific as well as technical solution of problems  concluding remarks finally draw the line to future work on sustainable artificial intelligence as a pathway to resilience delivered by technological means   keywords  artificial intelligence  formal systems  data reasoning  hybrid intelligence  human systems integration,11.2581,5.757913,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
A System for Accessible Artificial Intelligence,"While artificial intelligence (AI) has become widespread, many commercial AI systems are not yet accessible to individual researchers nor the general public due to the deep knowledge of the systems required to use them. We believe that AI has matured to the point where it should be an accessible technology for everyone. We present an ongoing project whose ultimate goal is to deliver an open source, user-friendly AI system that is specialized for machine learning analysis of complex data in the biomedical and health care domains. We discuss how genetic programming can aid in this endeavor, and highlight specific examples where genetic programming has automated machine learning analyses in previous projects.",while artificial intelligence  ai  has become widespread  many commercial ai systems are not yet accessible to individual researchers nor the general public due to the deep knowledge of the systems required to use them  we believe that ai has matured to the point where it should be an accessible technology for everyone  we present an ongoing project whose ultimate goal is to deliver an open source  user friendly ai system that is specialized for machine learning analysis of complex data in the biomedical and health care domains  we discuss how genetic programming can aid in this endeavor  and highlight specific examples where genetic programming has automated machine learning analyses in previous projects ,8.735066,7.0336776,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Measuring What Is Relevant,"In the previous chapter, we saw how important it is for a business to understand its goals, tie them to measurable outcomes, and establish the right monitoring, such as objectives and key result (OKR), on data science and machine learning efforts. In this chapter, we will go deeper into performance measurements and metrics and emphasize understanding second-level metrics.",in the previous chapter  we saw how important it is for a business to understand its goals  tie them to measurable outcomes  and establish the right monitoring  such as objectives and key result  okr   on data science and machine learning efforts  in this chapter  we will go deeper into performance measurements and metrics and emphasize understanding second level metrics ,10.58311,6.8325067,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
My Role in the Internet of Things,Let me tell you about the Internet of Things (IoT) â€“ the trend of physical things becoming connected and available for developers to build services using them.,let me tell you about the internet of things  iot      the trend of physical things becoming connected and available for developers to build services using them ,9.690153,6.5141296,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Ethnography as Data Science,"This final chapter discusses ethnography as a core discipline in data science. Taking the symbolic AI versus connectionism debate as a starting point, it refers to the ethnomethodological notion of accountability to show how ethnography can contribute to the debate around making machine learning more interpretable and explainable. It observes that the main focus of social studies of data science has been in the area of data curation and it argues to expand the scope of the â€œalgorithmic dramaâ€ to include the architectural aspects of machine learning. It states that given the direction deep machine learning is taking towards the design of â€˜ensemblesâ€™ of networks and decision trees, social scientists should devote more attention to how algorithms interact.
 Keywords
 Explainable AI
 xAI
 Interpretability
 Accountability of algorithms",this final chapter discusses ethnography as a core discipline in data science  taking the symbolic ai versus connectionism debate as a starting point  it refers to the ethnomethodological notion of accountability to show how ethnography can contribute to the debate around making machine learning more interpretable and explainable  it observes that the main focus of social studies of data science has been in the area of data curation and it argues to expand the scope of the    algorithmic drama    to include the architectural aspects of machine learning  it states that given the direction deep machine learning is taking towards the design of    ensembles    of networks and decision trees  social scientists should devote more attention to how algorithms interact   keywords  explainable ai  xai  interpretability  accountability of algorithms,10.494968,7.9662056,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Learning and Reasoning with AI: Restructuring Intelligence Organizations Around Innovation,"The advancement of artificial intelligence and machine learning (AI/ML) technologies will significantly impact the intelligence community (IC). This article urges IC elements to prioritize use case analysis, prototype emerging technologies, transform their human capital, and establish the right partnerships to collaborate with government and non-government organizations. IC elements execute activities like other information companies (e.g., financial advisory firms, news organizations, etc.) that collect, process, and analyze data to provide trustworthy informational products to their customers on a demanding schedule. IC elements face the added burden and responsibility that these products may lead to national security decisions involving serious harm, life, and death.
 Closing the gap between decisions and data collection is a top priority for the Intelligence Community (IC). The pace at which data are generated and collected is increasing exponentiallyâ€”and the IC workforce available to analyze and interpret this all-source, cross-domain data is not. Leveraging artificial intelligence, automation, and augmentation technologies to amplify the effectiveness of our workforce will advance mission capability and enhance the ICâ€™s ability to provide needed data interpretation to decision makers â€“ Dan Coats, Director of National Intelligence (ODNI. ICD 101. Retrieved from DNI.gov: https://www.dni.gov/files/documents/ICD/ICD_101.pdf, 2019, October 22)
 .
 Keywords
 Intelligence
 GPT-3
 Innovation
 Automation
 AI or AI/ML
 Ethics
 Culture
 Reasoning
 DoD",the advancement of artificial intelligence and machine learning  ai ml  technologies will significantly impact the intelligence community  ic   this article urges ic elements to prioritize use case analysis  prototype emerging technologies  transform their human capital  and establish the right partnerships to collaborate with government and non government organizations  ic elements execute activities like other information companies  e g   financial advisory firms  news organizations  etc   that collect  process  and analyze data to provide trustworthy informational products to their customers on a demanding schedule  ic elements face the added burden and responsibility that these products may lead to national security decisions involving serious harm  life  and death   closing the gap between decisions and data collection is a top priority for the intelligence community  ic   the pace at which data are generated and collected is increasing exponentially   and the ic workforce available to analyze and interpret this all source  cross domain data is not  leveraging artificial intelligence  automation  and augmentation technologies to amplify the effectiveness of our workforce will advance mission capability and enhance the ic   s ability to provide needed data interpretation to decision makers     dan coats  director of national intelligence  odni  icd      retrieved from dni gov  https   www dni gov files documents icd icd     pdf        october         keywords  intelligence  gpt    innovation  automation  ai or ai ml  ethics  culture  reasoning  dod,9.084812,6.2285776,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Transforming Insurance Business with Data Science,"This chapter introduces readers to data science practices in the insurance industry. The author discusses how these practices have transformed the industry in actuarial and underwriting operations as well as in sales and marketing. The chapter first gives an overview of data scienceâ€™s role in an insurance company. Then, the data science challenges in each stage of an analytics project life cycle are described. The author draws from his experience to provide solution frameworks for each of the challenges. In the end, an example is demonstrated to showcase a complex business challenge in managing the entire customer journey and calculating customer lifetime value in a life insurance company. Ethical considerations of machine learning models are also discussed.
 Keywords
 Data Science
 Machine Learning
 Predictive Model
 Insurance
 Pricing
 Underwriting
 Claims
 Marketing
 Customer Journey
 Lifetime Value
 Project Management",this chapter introduces readers to data science practices in the insurance industry  the author discusses how these practices have transformed the industry in actuarial and underwriting operations as well as in sales and marketing  the chapter first gives an overview of data science   s role in an insurance company  then  the data science challenges in each stage of an analytics project life cycle are described  the author draws from his experience to provide solution frameworks for each of the challenges  in the end  an example is demonstrated to showcase a complex business challenge in managing the entire customer journey and calculating customer lifetime value in a life insurance company  ethical considerations of machine learning models are also discussed   keywords  data science  machine learning  predictive model  insurance  pricing  underwriting  claims  marketing  customer journey  lifetime value  project management,9.848107,5.668746,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Studying the characteristics of AIOps projects on GitHub,"Artificial Intelligence for IT Operations (AIOps) leverages AI approaches to handle the massive amount of data generated during the operations of software systems. Prior works have proposed various AIOps solutions to support different tasks in system operations and maintenance, such as anomaly detection. In this study, we conduct an in-depth analysis of open-source AIOps projects to understand the characteristics of AIOps in practice. We first carefully identify a set of AIOps projects from GitHub and analyze their repository metrics (e.g., the used programming languages). Then, we qualitatively examine the projects to understand their input data, analysis techniques, and goals. Finally, we assess the quality of these projects using different quality metrics, such as the number of bugs. To provide context, we also sample two sets of baseline projects from GitHub: a random sample of machine learning projects and a random sample of general-purposed projects. By comparing different metrics between our identified AIOps projects and these baselines, we derive meaningful insights. Our results reveal a recent and growing interest in AIOps solutions. However, the quality metrics indicate that AIOps projects suffer from more issues than our baseline projects. We also pinpoint the most common issues in AIOps approaches and discuss potential solutions to address these challenges. Our findings offer valuable guidance to researchers and practitioners, enabling them to comprehend the current state of AIOps practices and shed light on different ways of improving AIOpsâ€™ weaker aspects. To the best of our knowledge, this work marks the first attempt to characterize open-source AIOps projects.",artificial intelligence for it operations  aiops  leverages ai approaches to handle the massive amount of data generated during the operations of software systems  prior works have proposed various aiops solutions to support different tasks in system operations and maintenance  such as anomaly detection  in this study  we conduct an in depth analysis of open source aiops projects to understand the characteristics of aiops in practice  we first carefully identify a set of aiops projects from github and analyze their repository metrics  e g   the used programming languages   then  we qualitatively examine the projects to understand their input data  analysis techniques  and goals  finally  we assess the quality of these projects using different quality metrics  such as the number of bugs  to provide context  we also sample two sets of baseline projects from github  a random sample of machine learning projects and a random sample of general purposed projects  by comparing different metrics between our identified aiops projects and these baselines  we derive meaningful insights  our results reveal a recent and growing interest in aiops solutions  however  the quality metrics indicate that aiops projects suffer from more issues than our baseline projects  we also pinpoint the most common issues in aiops approaches and discuss potential solutions to address these challenges  our findings offer valuable guidance to researchers and practitioners  enabling them to comprehend the current state of aiops practices and shed light on different ways of improving aiops    weaker aspects  to the best of our knowledge  this work marks the first attempt to characterize open source aiops projects ,8.208809,4.6825953,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Data-driven Development in the Automotive Industry,"Authors and Affiliations
 ITK Â­Engineering, RÃ¼lzheim, Germany
 Marcus Weber
 ITK Â­Engineering, Holzkirchen, Germany
 Stefan Held",authors and affiliations  itk   engineering  r  lzheim  germany  marcus weber  itk   engineering  holzkirchen  germany  stefan held,8.200491,5.369213,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Leveraging Edge Computing for Mobile Augmented Reality,"Augmented reality (AR) applications are becoming increasingly popular for personal and commercial use, thanks to dropping costs of AR-enabled hardware and commercially viable libraries and APIs. AR applicationsâ€™ ability to insert virtual content into the real world is a product of always-on environmental sensors such as cameras and microphones, coupled with powerful machine learning logic to recognize and respond to a userâ€™s surroundings and behavior. The virtual content generated by the system is then displayed on a hand-held screen such as a smartphone or tablet, a head-mounted display such as the Microsoft Hololens, or a statically mounted display, such as an augmented windshield in a smart vehicle. While the input, transformation, and output phases of the AR processing pipeline are susceptible to certain adversarial attacks, incorporating edge computing into these applications can help to alleviate some of the security concerns. In this chapter, we provide a brief introduction into augmented reality systems and their security concerns, as well as how edge computing can be utilized to help address those concerns.",augmented reality  ar  applications are becoming increasingly popular for personal and commercial use  thanks to dropping costs of ar enabled hardware and commercially viable libraries and apis  ar applications    ability to insert virtual content into the real world is a product of always on environmental sensors such as cameras and microphones  coupled with powerful machine learning logic to recognize and respond to a user   s surroundings and behavior  the virtual content generated by the system is then displayed on a hand held screen such as a smartphone or tablet  a head mounted display such as the microsoft hololens  or a statically mounted display  such as an augmented windshield in a smart vehicle  while the input  transformation  and output phases of the ar processing pipeline are susceptible to certain adversarial attacks  incorporating edge computing into these applications can help to alleviate some of the security concerns  in this chapter  we provide a brief introduction into augmented reality systems and their security concerns  as well as how edge computing can be utilized to help address those concerns ,7.6918216,6.707575,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
World Information Technology Development,"The world sees a stage when economic development largely relies on information industry. Since 2020, new-generation information technology has been impelling production modes to be more intelligentized, industrial forms to be more digital, and industrial organizations to be more platform-based.",the world sees a stage when economic development largely relies on information industry  since       new generation information technology has been impelling production modes to be more intelligentized  industrial forms to be more digital  and industrial organizations to be more platform based ,8.745439,3.3266432,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Medical Image Labeling via Active Learning is 90% Effective,"Medical imaging AI models require large image datasets that have been labeled, or annotated, by medical professionals who are a scarce and expensive resource. Manual image labeling is also a repetitive and thus error-prone activity. We discuss active learning as a methodology to partially automate this process. This paper presents five methods by which standard active learning can be improved: (1) unsupervised structure learning prior to the active learning loop, (2) using a pre-label model to initialize the image prior to human labeling, (3) using an enhanced model inside the learning loop, (4) augmenting the trained model in the loop with an unsupervised model, and (5) improving the acquisition function that chooses the next batch of images to be labeled. We demonstrate in three practical cases, for Covid-19, breast cancer, and colonoscopies, that this method is highly effective in reducing the human workload in labeling. Finally, we discuss some of the obstacles in designing AI systems based on medical images.
 Keywords
 Radiology
 Active learning
 Annotation
 Labeling",medical imaging ai models require large image datasets that have been labeled  or annotated  by medical professionals who are a scarce and expensive resource  manual image labeling is also a repetitive and thus error prone activity  we discuss active learning as a methodology to partially automate this process  this paper presents five methods by which standard active learning can be improved      unsupervised structure learning prior to the active learning loop      using a pre label model to initialize the image prior to human labeling      using an enhanced model inside the learning loop      augmenting the trained model in the loop with an unsupervised model  and     improving the acquisition function that chooses the next batch of images to be labeled  we demonstrate in three practical cases  for covid     breast cancer  and colonoscopies  that this method is highly effective in reducing the human workload in labeling  finally  we discuss some of the obstacles in designing ai systems based on medical images   keywords  radiology  active learning  annotation  labeling,3.6914794,4.7837563,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
General Principles,"General principles for safety and security apply to the whole system; i.e., they cover many quality properties of the CPSs. Therefore, they are presented in this chapter.",general principles for safety and security apply to the whole system  i e   they cover many quality properties of the cpss  therefore  they are presented in this chapter ,9.438049,7.1638947,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Efficient BREV Ensemble Framework: A Case Study of Breast Cancer Prediction,"A number of lethal and toxic synthetic compounds released by industrial operations and by excessive pesticide application are available in the environment. Such substances primarily enter the human food chain via water, air, and soil. Among the variety of these chemicals, organochlorine pesticides have got the highest attention in breast cancer occurrence due to their potential to accumulate in both the food chain and the environment. The rationale is to propose a novel ensemble technique that is BayesNet and Random Forest Ensemble using the Voting approach (BREV). This study evaluates the levels of organochlorine pesticides in females with both benign and malignant breast cancer disease to assess the chemical exposure and its relationship with breast cancer incidence. The levels of 51 chemicals, including DDT, its metabolites, and HCH isomers, are measured in 50 females with benign and malignant breast cancer after blood and adipose tissue samples are obtained. The concentrations of chemicals in females with breast cancer malignancy is contrasted with benign patients and a prediction framework is developed applying an efficacious framework of ensemble machine learning. The findings of the experiments conclude that combining BayesNet and Random Forest algorithms applying the voting approach provides the optimal solution for breast cancer prediction. The proposed framework demonstrates success with a prediction accuracy as high as 90%.
 Keywords
 Ensemble
 Prediction
 Machine learning
 Breast cancer
 Pesticides
 DDT",a number of lethal and toxic synthetic compounds released by industrial operations and by excessive pesticide application are available in the environment  such substances primarily enter the human food chain via water  air  and soil  among the variety of these chemicals  organochlorine pesticides have got the highest attention in breast cancer occurrence due to their potential to accumulate in both the food chain and the environment  the rationale is to propose a novel ensemble technique that is bayesnet and random forest ensemble using the voting approach  brev   this study evaluates the levels of organochlorine pesticides in females with both benign and malignant breast cancer disease to assess the chemical exposure and its relationship with breast cancer incidence  the levels of    chemicals  including ddt  its metabolites  and hch isomers  are measured in    females with benign and malignant breast cancer after blood and adipose tissue samples are obtained  the concentrations of chemicals in females with breast cancer malignancy is contrasted with benign patients and a prediction framework is developed applying an efficacious framework of ensemble machine learning  the findings of the experiments conclude that combining bayesnet and random forest algorithms applying the voting approach provides the optimal solution for breast cancer prediction  the proposed framework demonstrates success with a prediction accuracy as high as       keywords  ensemble  prediction  machine learning  breast cancer  pesticides  ddt,4.664414,2.2853956,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
The Team,"The recruitment of AI talent can be a high-stakes game. In some cases, a company may be willing to offer multi-million dollar packages along with significant equity options.",the recruitment of ai talent can be a high stakes game  in some cases  a company may be willing to offer multi million dollar packages along with significant equity options ,8.244695,3.2410576,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
The Oracle R Technologies and R Enterprise,"Advances in artificial intelligence (AI) have extended the domain of business intelligence (BI) to areas of machine learning and predictive analytics as well as big-data analytics. This has resulted in an expansive set of machine-learning algorithms that can be used to solve real-world BI problems. One of the most popular and widely used languages for machine learning and statistical computing is the R open source language. Its extensive set of algorithms, coupled with its support for rich graphics and data visualization, has made it the language of choice for data analysis and data science.",advances in artificial intelligence  ai  have extended the domain of business intelligence  bi  to areas of machine learning and predictive analytics as well as big data analytics  this has resulted in an expansive set of machine learning algorithms that can be used to solve real world bi problems  one of the most popular and widely used languages for machine learning and statistical computing is the r open source language  its extensive set of algorithms  coupled with its support for rich graphics and data visualization  has made it the language of choice for data analysis and data science ,7.0117044,6.4402394,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Introduction,"This chapter introduces the basic concepts of production scheduling and machine learning. Then, it describes the overview of evolutionary learning approaches, especially genetic programming as well as the overview to use genetic programming for production scheduling. In addition, this chapter introduces interpretable machine learning. Last, the terminology and organisation of the book are introduced to make it easy for readers to follow this book.",this chapter introduces the basic concepts of production scheduling and machine learning  then  it describes the overview of evolutionary learning approaches  especially genetic programming as well as the overview to use genetic programming for production scheduling  in addition  this chapter introduces interpretable machine learning  last  the terminology and organisation of the book are introduced to make it easy for readers to follow this book ,8.247161,7.103228,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Machine learning in drug discovery,Recent patents relating to machine learning in drug discovery and screening.,recent patents relating to machine learning in drug discovery and screening ,8.076345,6.4829297,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Agility in Software 2.0 â€“ Notebook Interfaces and MLOps with Buttresses and Rebars,"Artificial intelligence through machine learning is increasingly used in the digital society. Solutions based on machine learning bring both great opportunities, thus coined â€œSoftware 2.0,â€ but also great challenges for the engineering community to tackle. Due to the experimental approach used by data scientists when developing machine learning models, agility is an essential characteristic. In this keynote address, we discuss two contemporary development phenomena that are fundamental in machine learning development, i.e., notebook interfaces and MLOps. First, we present a solution that can remedy some of the intrinsic weaknesses of working in notebooks by supporting easy transitions to integrated development environments. Second, we propose reinforced engineering of AI systems by introducing metaphorical buttresses and rebars in the MLOps context. Machine learning-based solutions are dynamic in nature, and we argue that reinforced continuous engineering is required to quality assure the trustworthy AI systems of tomorrow.",artificial intelligence through machine learning is increasingly used in the digital society  solutions based on machine learning bring both great opportunities  thus coined    software         but also great challenges for the engineering community to tackle  due to the experimental approach used by data scientists when developing machine learning models  agility is an essential characteristic  in this keynote address  we discuss two contemporary development phenomena that are fundamental in machine learning development  i e   notebook interfaces and mlops  first  we present a solution that can remedy some of the intrinsic weaknesses of working in notebooks by supporting easy transitions to integrated development environments  second  we propose reinforced engineering of ai systems by introducing metaphorical buttresses and rebars in the mlops context  machine learning based solutions are dynamic in nature  and we argue that reinforced continuous engineering is required to quality assure the trustworthy ai systems of tomorrow ,7.1645727,4.583431,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
ModelOps for enhanced decision-making and governance in emergency control rooms,"For mission critical (MC) applications such as bushfire emergency management systems (EMS), understanding the current situation as a disaster unfolds is critical to saving lives, infrastructure and the environment. Incident control-room operators manage complex information and systems, especially with the emergence of Big Data. They are increasingly making decisions supported by artificial intelligence (AI) and machine learning (ML) tools for data analysis, prediction and decision-making. As the volume, speed and complexity of information increases due to more frequent fire events, greater availability of myriad IoT sensors, smart devices, satellite data and burgeoning use of social media, the advances in AI and ML that help to manage Big Data and support decision-making are increasingly perceived as â€œBlack Boxâ€. This paper aims to scope the requirements for bushfire EMS to improve Big Data management and governance of AI/ML. An analysis of ModelOps technology, used increasingly in the commercial sector, is undertaken to determine what components might be fit-for-purpose. The result is a novel set of ModelOps features, EMS requirements and an EMS-ModelOps framework that resolves more than 75% of issues whilst being sufficiently generic to apply to other types of mission-critical applications.",for mission critical  mc  applications such as bushfire emergency management systems  ems   understanding the current situation as a disaster unfolds is critical to saving lives  infrastructure and the environment  incident control room operators manage complex information and systems  especially with the emergence of big data  they are increasingly making decisions supported by artificial intelligence  ai  and machine learning  ml  tools for data analysis  prediction and decision making  as the volume  speed and complexity of information increases due to more frequent fire events  greater availability of myriad iot sensors  smart devices  satellite data and burgeoning use of social media  the advances in ai and ml that help to manage big data and support decision making are increasingly perceived as    black box     this paper aims to scope the requirements for bushfire ems to improve big data management and governance of ai ml  an analysis of modelops technology  used increasingly in the commercial sector  is undertaken to determine what components might be fit for purpose  the result is a novel set of modelops features  ems requirements and an ems modelops framework that resolves more than     of issues whilst being sufficiently generic to apply to other types of mission critical applications ,11.777851,5.3553596,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
AI Models and Methods in Automotive Manufacturing: A Systematic Literature Review,"While artificial intelligence (AI) experienced an increasing interest in industry during the past decade, the true potential and applicability of AI for automotive original equipment manufacturers (OEMs) and suppliers in real-world scenarios have not been clearly understood. Most applications of AI focus on the development of connected and autonomous cars, rather than the optimisation of automotive operations and manufacturing processes. This work, therefore, bridged this gap and shed light on the topic of AI in the context of automotive manufacturing and Industry 4.0. It aimed to promote understanding and provide up-to-date insights on specific models and methods of AI, applications that have been achieved with best practices as well as the problems that were encountered, underpinned with possible future prospects. A systematic literature review approach was adopted to ensure broad and thorough coverage of current knowledge and the identification of relevant literature on the topic. The literature search was confined to papers that were published from 2015 onwards using the databases of IEEE and ScienceDirect as primary sources, with a three-keyword search phrase to narrow down the results and increase specificity. A total of 359 papers were identified and subsequently screened for eligibility, of which 84 papers were selected for quantitative and 79 papers for qualitative analysis. The results of the quantitative analysis confirmed that the topic has markedly increased in significance, with a mere 3 papers published in 2015 and 33 papers in 2021. The majority of papers dealt with solving problems in production (39.29%), quality (35.71%) and assembly (16.67%), whereas supply chain (5.95%) and business intelligence (2.38%) were inadequately represented. The results of the qualitative analysis revealed that machine learning methods dominate current research and automotive applications, with neural networks as the most used out of more than 70 identified models. The industrial applicability was confirmed by many use cases including quality inspection, robot assembly, humanâ€“robot collaboration, material demand prediction or AI-enabled manufacturing decision making. The problems of such applications were mainly attributed to data availability and quality, model development and gaps in simulation, system integration, the complexity of automotive processes, the physical conditions of the system environment and dynamic change. For industrial applications it is thus recommended to further optimise AI methods and models, enabling a wider system integration by harvesting the potential of big data and both edge and cloud computing.
 Keywords
 Artificial intelligence
 AI models and methods
 Automotive manufacturing
 Systematic literature review",while artificial intelligence  ai  experienced an increasing interest in industry during the past decade  the true potential and applicability of ai for automotive original equipment manufacturers  oems  and suppliers in real world scenarios have not been clearly understood  most applications of ai focus on the development of connected and autonomous cars  rather than the optimisation of automotive operations and manufacturing processes  this work  therefore  bridged this gap and shed light on the topic of ai in the context of automotive manufacturing and industry      it aimed to promote understanding and provide up to date insights on specific models and methods of ai  applications that have been achieved with best practices as well as the problems that were encountered  underpinned with possible future prospects  a systematic literature review approach was adopted to ensure broad and thorough coverage of current knowledge and the identification of relevant literature on the topic  the literature search was confined to papers that were published from      onwards using the databases of ieee and sciencedirect as primary sources  with a three keyword search phrase to narrow down the results and increase specificity  a total of     papers were identified and subsequently screened for eligibility  of which    papers were selected for quantitative and    papers for qualitative analysis  the results of the quantitative analysis confirmed that the topic has markedly increased in significance  with a mere   papers published in      and    papers in       the majority of papers dealt with solving problems in production           quality          and assembly           whereas supply chain         and business intelligence         were inadequately represented  the results of the qualitative analysis revealed that machine learning methods dominate current research and automotive applications  with neural networks as the most used out of more than    identified models  the industrial applicability was confirmed by many use cases including quality inspection  robot assembly  human   robot collaboration  material demand prediction or ai enabled manufacturing decision making  the problems of such applications were mainly attributed to data availability and quality  model development and gaps in simulation  system integration  the complexity of automotive processes  the physical conditions of the system environment and dynamic change  for industrial applications it is thus recommended to further optimise ai methods and models  enabling a wider system integration by harvesting the potential of big data and both edge and cloud computing   keywords  artificial intelligence  ai models and methods  automotive manufacturing  systematic literature review,9.018307,4.84178,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
ML in WSN Using IoT for Smart Cities: A Survey,"Artificial intelligence (AI) and machine learning (ML) approaches offer a lot of promise for automating the functioning of internet of things (IoT) nodes in smart cities. Smart traffic monitoring, smart waste management, smart buildings, and patient healthcare monitoring are the most common IoT applications in smart cities. Small IoT nodes based on the low-power Bluetooth and wireless sensor network (WSN) standards are commonly utilized for data transfer to a remote site via gateways. Network coverage and connection difficulties, energy consumption, bandwidth requirements, network lifespan maximization, communication protocols, and state-of-the-art infrastructure are some of the WSN-IoT design issues. Through this chapter, we offer machine learning approaches for typical WSN-IoT nodes deployed in smart city applications as an optimization tool. According to the authorâ€™s understanding, this is the first comprehensive literature review of all machine learning approaches in the subject of low-power WSN-IoT for smart cities. According to the findings of this one-of-a-kind survey chapter, supervised learning algorithms have been utilized the most in smart city applications (61%) compared to reinforcement learning (27%) and unsupervised learning (12%).
 Keywords
 IoT
 Sensor nodes
 WSN-IoT
 AI
 Smart city",artificial intelligence  ai  and machine learning  ml  approaches offer a lot of promise for automating the functioning of internet of things  iot  nodes in smart cities  smart traffic monitoring  smart waste management  smart buildings  and patient healthcare monitoring are the most common iot applications in smart cities  small iot nodes based on the low power bluetooth and wireless sensor network  wsn  standards are commonly utilized for data transfer to a remote site via gateways  network coverage and connection difficulties  energy consumption  bandwidth requirements  network lifespan maximization  communication protocols  and state of the art infrastructure are some of the wsn iot design issues  through this chapter  we offer machine learning approaches for typical wsn iot nodes deployed in smart city applications as an optimization tool  according to the author   s understanding  this is the first comprehensive literature review of all machine learning approaches in the subject of low power wsn iot for smart cities  according to the findings of this one of a kind survey chapter  supervised learning algorithms have been utilized the most in smart city applications       compared to reinforcement learning       and unsupervised learning         keywords  iot  sensor nodes  wsn iot  ai  smart city,7.861608,5.7516217,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Wheat leaf disease classification using modified ResNet50 convolutional neural network model,"During the past few years, most companies have launched experiments on how they can use artificial intelligence (AI) to leverage their data. These experiments generally correspond to prototypes solving a specific business case, such as fraud detection in banking or predictive maintenance for industrial equipment. If the estimated return on investment of the prototype is positive, the technical and business teams start thinking about how to industrialize their experiments. Deployment of AI systems comes with a set of specific challenges, such as data governance, model lifecycle management, and collaborators training and onboarding, among others. Overcoming these challenges hedges most performance risks. However, a new set of risks and challenges, related to ethical considerations, is emerging. In this paper, we review in detail all these challenges, share our experience on best practices that help build well-integrated AI systems, and argue in favor of an ethics-by-design approach to prototyping.",during the past few years  most companies have launched experiments on how they can use artificial intelligence  ai  to leverage their data  these experiments generally correspond to prototypes solving a specific business case  such as fraud detection in banking or predictive maintenance for industrial equipment  if the estimated return on investment of the prototype is positive  the technical and business teams start thinking about how to industrialize their experiments  deployment of ai systems comes with a set of specific challenges  such as data governance  model lifecycle management  and collaborators training and onboarding  among others  overcoming these challenges hedges most performance risks  however  a new set of risks and challenges  related to ethical considerations  is emerging  in this paper  we review in detail all these challenges  share our experience on best practices that help build well integrated ai systems  and argue in favor of an ethics by design approach to prototyping ,11.063276,7.113388,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
"Beginning MLOps with MLFlow Deploy Models in AWS SageMaker, Google Cloud, and Microsoft Azure","Wheat leaf disease prevention and treatment requires an accurate and rapid classification of wheat leaf diseases and their extent. Using healthy wheat, leaf rust, crown, root rot, and wheat loose smut as research objects, this study proposes a deep learning-based technique for classifying wheat leaf diseases. A collaborative generative adversarial network is used as an image imputation in the proposed methodology, allowing a generator and discriminator network to properly estimate the missing data in the dataset using the residual method. It is used to improve feature extraction in wheat leaf images. The major contribution of this study is to use a pre-trained deep learning convolutional neural network architecture as a foundation to improve and construct an automated tool for wheat leaf disease image categorization. To classify wheat leaf diseases, a modification to the Residual Network with 50 layers (ResNet50) is being suggested. The â€²Convâ€², â€²Batch Normalizâ€², and â€²Activation Leaky Reluâ€² layers were added as part of this modification. These layers are inserted into the ResNet50 architecture for accurate feature extraction and discrimination. Extensive tests are carried out to evaluate the proposed model's performance on photos from a large wheat disease classification dataset. The suggested approach outperforms ResNet50, InceptionV3, and DenseNet, according to the experimental findings. The suggested method achieves the greatest identification accuracy of 98.44%. These discoveries might aid in the accurate detection and categorization of wheat leaf diseases.",wheat leaf disease prevention and treatment requires an accurate and rapid classification of wheat leaf diseases and their extent  using healthy wheat  leaf rust  crown  root rot  and wheat loose smut as research objects  this study proposes a deep learning based technique for classifying wheat leaf diseases  a collaborative generative adversarial network is used as an image imputation in the proposed methodology  allowing a generator and discriminator network to properly estimate the missing data in the dataset using the residual method  it is used to improve feature extraction in wheat leaf images  the major contribution of this study is to use a pre trained deep learning convolutional neural network architecture as a foundation to improve and construct an automated tool for wheat leaf disease image categorization  to classify wheat leaf diseases  a modification to the residual network with    layers  resnet    is being suggested  the    conv        batch normaliz     and    activation leaky relu    layers were added as part of this modification  these layers are inserted into the resnet   architecture for accurate feature extraction and discrimination  extensive tests are carried out to evaluate the proposed model s performance on photos from a large wheat disease classification dataset  the suggested approach outperforms resnet    inceptionv   and densenet  according to the experimental findings  the suggested method achieves the greatest identification accuracy of         these discoveries might aid in the accurate detection and categorization of wheat leaf diseases ,3.681193,5.3228693,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Implementation of Personalized Medicine by Artificial Intelligence Platform,"Artificial intelligence (AI) can automate and dramatically accelerate Computer-Aided Detection (CADe) and Computer-Aided Diagnosis (CADx) by automatically processing medical data without the involvement of medical personnel on the screening stage and making it available on a regular basis nationwide. In this position paper, some our recent approaches are reviewed with the proposition to integrate them as a set of modern advanced medical services under the conditional name proactive â€œAI-based platformâ€ (AIP). The main motive is to use the methods of AI, peripheral intelligence (Edge Intelligenceâ€”EI), the Internet of Things (IoT), wearable electronics (WE), and Big Data technologies (BDT). The additional promising way of the further development of AIP should include AI-based personalized medicine (AIPM) that can allow practitioners to find cures tuned for patients. AI-based personalized medicine promises to be transformative for stakeholders involved in the complex diseases. However, clinicians do not understand their suggestions and decisions. That is why the current real challenge is to build AI-based personalized medicine that can be accepted by clinical community. The current EU-funded project â€œknowledge at the tips of your figures (KATY)â€ is presented shortly which grasps the above challenge and proposes an AIPM approach that can bring medical CADe/CADx to the tips of the fingers of clinical community.
 Keywords
 Artificial Intelligence (AI)
 Computer-Aided Detection (CADe)
 Computer-Aided Diagnosis (CADx)
 Deep learning
 Healthcare",artificial intelligence  ai  can automate and dramatically accelerate computer aided detection  cade  and computer aided diagnosis  cadx  by automatically processing medical data without the involvement of medical personnel on the screening stage and making it available on a regular basis nationwide  in this position paper  some our recent approaches are reviewed with the proposition to integrate them as a set of modern advanced medical services under the conditional name proactive    ai based platform     aip   the main motive is to use the methods of ai  peripheral intelligence  edge intelligence   ei   the internet of things  iot   wearable electronics  we   and big data technologies  bdt   the additional promising way of the further development of aip should include ai based personalized medicine  aipm  that can allow practitioners to find cures tuned for patients  ai based personalized medicine promises to be transformative for stakeholders involved in the complex diseases  however  clinicians do not understand their suggestions and decisions  that is why the current real challenge is to build ai based personalized medicine that can be accepted by clinical community  the current eu funded project    knowledge at the tips of your figures  katy     is presented shortly which grasps the above challenge and proposes an aipm approach that can bring medical cade cadx to the tips of the fingers of clinical community   keywords  artificial intelligence  ai   computer aided detection  cade   computer aided diagnosis  cadx   deep learning  healthcare,6.4864025,4.212958,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Introduction,"This chapter discusses introductory topics which are helpful for a basic understanding of the concepts, definitions and methods outlined in the following chapters. It may be skipped for the sake of a faster passage to the more appealing issues or only browsed for a short impression. But if things appear dubious in later chapters this one should be consulted again.
 Keywords
 Search Space
 Input Vector
 Model Function
 Output Vector
 Start Position
 These keywords were added by machine and not by the authors. This process is experimental and the keywords may be updated as the learning algorithm improves.",this chapter discusses introductory topics which are helpful for a basic understanding of the concepts  definitions and methods outlined in the following chapters  it may be skipped for the sake of a faster passage to the more appealing issues or only browsed for a short impression  but if things appear dubious in later chapters this one should be consulted again   keywords  search space  input vector  model function  output vector  start position  these keywords were added by machine and not by the authors  this process is experimental and the keywords may be updated as the learning algorithm improves ,6.001662,5.765422,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Text classification and sentiment analysis,"In the previous chapter, we focused on using image data to learn more about machine learning and build an image classifier. In this chapter, we are going to talk about using text data, cover a few concepts of natural language processing, and build a few experiments around sentiment analysis.",in the previous chapter  we focused on using image data to learn more about machine learning and build an image classifier  in this chapter  we are going to talk about using text data  cover a few concepts of natural language processing  and build a few experiments around sentiment analysis ,8.9819355,7.6987357,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
A Severity-Based Classification Assessment of Code Smells in Kotlin and Java Application,"Code smells instigate due to the consistent adoption of bad programming and implementation styles during the evolution of the software which adversely affects the software quality. They are essentially focused and prioritized for their effective removal based on their severity. The study proposed a hybrid approach for inspecting the severity based on the code smell intensity in Kotlin language and comparing the code smells which are found equivalent in Java language. The research work is examined on five common code smells that are complex method, large class long method, long parameter list, string literal duplication, and too many methods over 30 open-source systems (15 Kotlin/15 Java). The experiment compares different machine learning algorithms for the computation of human-readable code smell detection rules for Kotlin, where the JRip algorithm proved to be the best machine learning algorithm with 96% and 97% of overall precision and accuracy, validated at 10-fold cross-validation. Further, the severity of code smell at the class level is evaluated for prioritization of applications written in Kotlin and Java language. Moreover, the process of severity computation is semiautomated using the CART model, and thus, metric-based severity classification rules are achieved. The experimentation provides a complete understanding of prioritization of code smells in Kotlin and Java and helps to attain prioritized refactoring which will enhance the utilization of resources and minimize the overhead rework cost.",code smells instigate due to the consistent adoption of bad programming and implementation styles during the evolution of the software which adversely affects the software quality  they are essentially focused and prioritized for their effective removal based on their severity  the study proposed a hybrid approach for inspecting the severity based on the code smell intensity in kotlin language and comparing the code smells which are found equivalent in java language  the research work is examined on five common code smells that are complex method  large class long method  long parameter list  string literal duplication  and too many methods over    open source systems     kotlin    java   the experiment compares different machine learning algorithms for the computation of human readable code smell detection rules for kotlin  where the jrip algorithm proved to be the best machine learning algorithm with     and     of overall precision and accuracy  validated at    fold cross validation  further  the severity of code smell at the class level is evaluated for prioritization of applications written in kotlin and java language  moreover  the process of severity computation is semiautomated using the cart model  and thus  metric based severity classification rules are achieved  the experimentation provides a complete understanding of prioritization of code smells in kotlin and java and helps to attain prioritized refactoring which will enhance the utilization of resources and minimize the overhead rework cost ,7.3545113,6.511317,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Hate speech recognition in multilingual text: hinglish documents,"Authors and Affiliations
 ika, Aachen, Germany
 Bastian Lampe, Lennart Reiher, Timo Woopen & Lutz Eckstein",authors and affiliations  ika  aachen  germany  bastian lampe  lennart reiher  timo woopen   lutz eckstein,7.9351387,5.4776187,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Deep learning based cyber bullying early detection using distributed denial of service flow,"The Internet is a boon for mankind but its misuse has been increasing drastically. Social networking platforms such as Facebook, Twitter and Instagram play a predominant role in expressing views by the users. Sometimes users wield abusive or inflammatory language, that may provoke readers. This paper aims to evaluate various machine learning and deep learning techniques to detect hate speech on various social media platforms in the Hinglish (English-Hindi code-mix) language. In this paper, we apply and evaluate several machine learning and deep learning methods, along with various feature extraction and word-embedding techniques, on a consolidated dataset of 20600 instances, for hate speech detection from tweets and comments in Hinglish. The experimental results reveal that deep learning models perform better than machine learning models in general. Among the deep learning models, the CNN-BiLSTM model with word2vec word embedding provides the best results. The model yields 0.876 accuracy, 0.830 precision, 0.840 recall and 0.835 F1-score. These results surpass the recent state-of-art approaches.",the internet is a boon for mankind but its misuse has been increasing drastically  social networking platforms such as facebook  twitter and instagram play a predominant role in expressing views by the users  sometimes users wield abusive or inflammatory language  that may provoke readers  this paper aims to evaluate various machine learning and deep learning techniques to detect hate speech on various social media platforms in the hinglish  english hindi code mix  language  in this paper  we apply and evaluate several machine learning and deep learning methods  along with various feature extraction and word embedding techniques  on a consolidated dataset of       instances  for hate speech detection from tweets and comments in hinglish  the experimental results reveal that deep learning models perform better than machine learning models in general  among the deep learning models  the cnn bilstm model with word vec word embedding provides the best results  the model yields       accuracy        precision        recall and       f  score  these results surpass the recent state of art approaches ,5.5447226,6.3697705,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Cloud Intelligence and Collective Learning for Automated and Connected Driving,"Cyber-bullying has been on the rise especially after the explosive widespread of various cyber-attacks. Various types of techniques have been used to tackle cyber-bullying. These techniques focused primarily on data traffic for monitoring malicious activities. This research proposes a methodology where we can detect early Denial of service (DoS) and Distributed Denial of Service (DDoS) attacks. First, we formulate the problem in a practical scenario by comparing flow and non-flow-based datasets using Mann Whitney U statistical test. Flow and non-flow-based datasets and Artificial Neural Network (ANN) and Support Vector Machine (SVM) is used for classification. To keep original features, we use variance, correlation, Â¾ quartile method to eliminate the unimportant features. The forward selection wrapper method for feature selection is used to find out the best features. To validate the proposed methodology, we take multiple DoS and DDoS single flow and validate it on 10%, 20%, 30%, 40%, and 50%. For validation, the experimental results showâ€‰+â€‰90% accuracy on the early 10% flow.",cyber bullying has been on the rise especially after the explosive widespread of various cyber attacks  various types of techniques have been used to tackle cyber bullying  these techniques focused primarily on data traffic for monitoring malicious activities  this research proposes a methodology where we can detect early denial of service  dos  and distributed denial of service  ddos  attacks  first  we formulate the problem in a practical scenario by comparing flow and non flow based datasets using mann whitney u statistical test  flow and non flow based datasets and artificial neural network  ann  and support vector machine  svm  is used for classification  to keep original features  we use variance  correlation     quartile method to eliminate the unimportant features  the forward selection wrapper method for feature selection is used to find out the best features  to validate the proposed methodology  we take multiple dos and ddos single flow and validate it on                     and      for validation  the experimental results show           accuracy on the early     flow ,3.4008677,5.700386,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Hardness and approximation of submodular minimum linear ordering problems,"Understanding and developing cutting-edge technologies like artificial intelligence are widely seen as complex tasks and significantly strain human cognitive capacity. Cognitive fit theory is an established theory that proposes that task completion performance is enhanced when there is a congruent relationship between the problem statement and task execution. Despite efforts to simplify the tasks, the tasks may still pose a challenge when it comes to understanding and execution. This paper argues that artificial intelligence, particularly no-code artificial intelligence, can reduce human cognitive burden. The paper aims to illustrate how an artificial intelligence artefact can be used to assist humans in transforming a task with a high human cognitive load into a task with a low human cognitive load. A simple game of Tic-Tac-Toe was developed, which is easy to play and comprehend, therefore representing a low human cognitive load. This was followed by an isomorph Scrabble card game, which is more challenging to play, introducing a higher human cognitive load. Winning the latter served as the problem representation in this paper. Two design science research cycles were used during solution development. During the first cycle, an artificial intelligence agent was developed to play and win both games on behalf of the human. The coding required to develop the agent, however, introduced a high human cognitive load. Subsequently, in the second design cycle, an artificial intelligence agent that could win both games was developed using the no-code artificial intelligence platform DataRobot. Overall, this resulted in a low cognitive load in both solving the problem (winning the Scrabble card game) and developing the problem solution (artificial intelligence agent). On a theoretical level, this research contributes to information systems research by demonstrating the value of cognitive fit theory in the context of developing artificial intelligence solutions.
 Keywords
 Artificial intelligence
 cognitive processing
 no-code
 design science artefact
 DataRobot
 cognitive fit theory
 information systems",understanding and developing cutting edge technologies like artificial intelligence are widely seen as complex tasks and significantly strain human cognitive capacity  cognitive fit theory is an established theory that proposes that task completion performance is enhanced when there is a congruent relationship between the problem statement and task execution  despite efforts to simplify the tasks  the tasks may still pose a challenge when it comes to understanding and execution  this paper argues that artificial intelligence  particularly no code artificial intelligence  can reduce human cognitive burden  the paper aims to illustrate how an artificial intelligence artefact can be used to assist humans in transforming a task with a high human cognitive load into a task with a low human cognitive load  a simple game of tic tac toe was developed  which is easy to play and comprehend  therefore representing a low human cognitive load  this was followed by an isomorph scrabble card game  which is more challenging to play  introducing a higher human cognitive load  winning the latter served as the problem representation in this paper  two design science research cycles were used during solution development  during the first cycle  an artificial intelligence agent was developed to play and win both games on behalf of the human  the coding required to develop the agent  however  introduced a high human cognitive load  subsequently  in the second design cycle  an artificial intelligence agent that could win both games was developed using the no code artificial intelligence platform datarobot  overall  this resulted in a low cognitive load in both solving the problem  winning the scrabble card game  and developing the problem solution  artificial intelligence agent   on a theoretical level  this research contributes to information systems research by demonstrating the value of cognitive fit theory in the context of developing artificial intelligence solutions   keywords  artificial intelligence  cognitive processing  no code  design science artefact  datarobot  cognitive fit theory  information systems,2.4215755,7.1914506,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Letâ€™s Play Games: Using No-Code AI to Reduce Human Cognitive Load During AI Solution Development,"The minimum linear ordering problem (MLOP) generalizes well-known combinatorial optimization problems such as minimum linear arrangement and minimum sum set cover. MLOP seeks to minimize an aggregated cost \(f(\cdot )\) due to an ordering \(\sigma \) of the items (say [n]), i.e., \(\min _{\sigma } \sum _{i\in [n]} f(E_{i,\sigma })\), where \(E_{i,\sigma }\) is the set of items mapped by \(\sigma \) to indices [i]. Despite an extensive literature on MLOP variants and approximations for these, it was unclear whether the graphic matroid MLOP was NP-hard. We settle this question through non-trivial reductions from mininimum latency vertex cover and minimum sum vertex cover problems. We further propose a new combinatorial algorithm for approximating monotone submodular MLOP, using the theory of principal partitions. This is in contrast to the rounding algorithm by Iwata et al. (in: APPROX, 2012), using LovÃ¡sz extension of submodular functions. We show a \((2-\frac{1+\ell _{f}}{1+|E|})\)-approximation for monotone submodular MLOP where \(\ell _{f}=\frac{f(E)}{\max _{x\in E}f(\{x\})}\) satisfies \(1 \le \ell _f \le |E|\). Our theory provides new approximation bounds for special cases of the problem, in particular a \((2-\frac{1+r(E)}{1+|E|})\)-approximation for the matroid MLOP, where \(f = r\) is the rank function of a matroid. We further show that minimum latency vertex cover is \(\frac{4}{3}\)-approximable, by which we also lower bound the integrality gap of its natural LP relaxation, which might be of independent interest.",the minimum linear ordering problem  mlop  generalizes well known combinatorial optimization problems such as minimum linear arrangement and minimum sum set cover  mlop seeks to minimize an aggregated cost   f  cdot     due to an ordering    sigma    of the items  say  n    i e      min    sigma    sum   i in  n   f e  i  sigma       where   e  i  sigma     is the set of items mapped by    sigma    to indices  i   despite an extensive literature on mlop variants and approximations for these  it was unclear whether the graphic matroid mlop was np hard  we settle this question through non trivial reductions from mininimum latency vertex cover and minimum sum vertex cover problems  we further propose a new combinatorial algorithm for approximating monotone submodular mlop  using the theory of principal partitions  this is in contrast to the rounding algorithm by iwata et al   in  approx         using lov  sz extension of submodular functions  we show a       frac    ell   f      e      approximation for monotone submodular mlop where    ell   f   frac f e    max   x in e f   x       satisfies      le  ell  f  le  e     our theory provides new approximation bounds for special cases of the problem  in particular a       frac   r e      e      approximation for the matroid mlop  where   f   r   is the rank function of a matroid  we further show that minimum latency vertex cover is    frac         approximable  by which we also lower bound the integrality gap of its natural lp relaxation  which might be of independent interest ,2.4981787,7.866867,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
"Conducting sentiment analysis: Lei L. & Liu D. Elements in Corpus Linguistics, CUP","Sentiment analysis is an important task in corpus linguistics and natural language processing. Based on statistical and machine-learning algorithms, textsâ€™ subjective evaluations and emotional states can be detected, extracted, and classified. Sentiment analysis results are significant to the development of many different industries in the financial, political, medical, and entertainment domains. They are beneficial to make relevant stakeholders have a good command of public attitudes to products, policies, medical treatment, and services in order to make appropriate adjustments. Lei and Liu provide a comprehensive and concise introduction to sentiment analysis to assist students and academics in understanding the theoretical aspects and the application of sentiment analysis.",sentiment analysis is an important task in corpus linguistics and natural language processing  based on statistical and machine learning algorithms  texts    subjective evaluations and emotional states can be detected  extracted  and classified  sentiment analysis results are significant to the development of many different industries in the financial  political  medical  and entertainment domains  they are beneficial to make relevant stakeholders have a good command of public attitudes to products  policies  medical treatment  and services in order to make appropriate adjustments  lei and liu provide a comprehensive and concise introduction to sentiment analysis to assist students and academics in understanding the theoretical aspects and the application of sentiment analysis ,6.3654737,4.2427416,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Cleo: Smart Glasses to Monitor Consumption of Alcohol and Cigarettes,"It is estimated that over 60% of people around the globe consume alcohol and cigars daily. Many people use them beyond the permitted limit, which causes lung cancer, liver and kidney failure. If there is a system that could monitor their intake level, it will alert them in case of excess consumption, which could help them control the intake. To help the users monitor their consumption, we introduce Cleo Eyeglasses in this paper. Cleo is a wearable spectacle device with a mounted camera and single onboard computer that performs custom trained object recognition to identify alcoholic beverages and cigarettes. Upon recognition, a log is automatically maintained in the corresponding mobile application. If the intake exceeds the user threshold, then our system generates an alert to both the user and concerned medical personnel. Cigarette/alcohol consumption can immediately affect the body without noticeable symptoms. Cleo addresses this with keen monitoring of vital body parameters and generates an alert when abnormalities are detected.",it is estimated that over     of people around the globe consume alcohol and cigars daily  many people use them beyond the permitted limit  which causes lung cancer  liver and kidney failure  if there is a system that could monitor their intake level  it will alert them in case of excess consumption  which could help them control the intake  to help the users monitor their consumption  we introduce cleo eyeglasses in this paper  cleo is a wearable spectacle device with a mounted camera and single onboard computer that performs custom trained object recognition to identify alcoholic beverages and cigarettes  upon recognition  a log is automatically maintained in the corresponding mobile application  if the intake exceeds the user threshold  then our system generates an alert to both the user and concerned medical personnel  cigarette alcohol consumption can immediately affect the body without noticeable symptoms  cleo addresses this with keen monitoring of vital body parameters and generates an alert when abnormalities are detected ,5.3653946,5.028483,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Custom Hardware Versus Cloud Computing in Big Data,"The computational and data handling challenges in big data are immense yet a market is steadily growing traditionally supported by technologies such as Hadoop for management and processing of huge and unstructured datasets. With this ever increasing deluge of data we now need the algorithms, tools and computing infrastructure to handle the extremely computationally intense data analytics, looking for patterns and information pertinent to creating a market edge for a range of applications. Cloud computing has provided opportunities for scalable high-performance solutions without the initial outlay of developing and creating the core infrastructure. One vendor in particular, Amazon Web Services, has been leading this field. However, other solutions exist to take on the computational load of big data analytics. This chapter provides an overview of the extent of applications in which big data analytics is used. Then an overview is given of some of the high-performance computing options that are available, ranging from multiple Central Processing Unit (CPU) setups, Graphical Processing Units (GPUs), Field Programmable Gate Arrays (FPGAs) and cloud solutions. The chapter concludes by looking at some of the state of the art solutions for deep learning platforms in which custom hardware such as FPGAs and Application Specific Integrated Circuits (ASICs) are used within a cloud platform for key computational bottlenecks.",the computational and data handling challenges in big data are immense yet a market is steadily growing traditionally supported by technologies such as hadoop for management and processing of huge and unstructured datasets  with this ever increasing deluge of data we now need the algorithms  tools and computing infrastructure to handle the extremely computationally intense data analytics  looking for patterns and information pertinent to creating a market edge for a range of applications  cloud computing has provided opportunities for scalable high performance solutions without the initial outlay of developing and creating the core infrastructure  one vendor in particular  amazon web services  has been leading this field  however  other solutions exist to take on the computational load of big data analytics  this chapter provides an overview of the extent of applications in which big data analytics is used  then an overview is given of some of the high performance computing options that are available  ranging from multiple central processing unit  cpu  setups  graphical processing units  gpus   field programmable gate arrays  fpgas  and cloud solutions  the chapter concludes by looking at some of the state of the art solutions for deep learning platforms in which custom hardware such as fpgas and application specific integrated circuits  asics  are used within a cloud platform for key computational bottlenecks ,9.801146,7.5322866,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Deep learning system for paddy plant disease detection and classification,"Automatic detection and analysis of rice crop diseases is widely required in the farming industry, which can be utilized to avoid squandering financial and other resources, reduce yield losses, and improve treatment efficiency, resulting in healthier crop output. An automated approach was proposed for accurately detecting and classifying diseases from a supplied photograph. The proposed system for the recognition of rice plant diseases adopts a computer visionâ€“based approach that employs the techniques of image processing, machine learning, and deep learning, reducing the reliance on conventional methods to protect paddy crops from diseases like bacterial leaf blight, false smut, brown leaf spot, rice blast, and sheath rot, the five primary diseases that frequently plague the Indian rice fields. Following image pre-processing, image segmentation is employed to determine the diseased section of the paddy plant, with the diseases listed above being identified purely on the basis of their visual contents. An integration of a support vector machine classifier and convolutional neural networks are used to recognize and classify specific varieties of paddy plant diseases. With ReLU and softmax functions, the suggested deep learningâ€“based strategy attained the highest validation accuracy of 0.9145. Following recognition, a predictive remedy is recommended, which can assist agriculture-related individuals and organizations in taking suitable measures to combat these diseases.",automatic detection and analysis of rice crop diseases is widely required in the farming industry  which can be utilized to avoid squandering financial and other resources  reduce yield losses  and improve treatment efficiency  resulting in healthier crop output  an automated approach was proposed for accurately detecting and classifying diseases from a supplied photograph  the proposed system for the recognition of rice plant diseases adopts a computer vision   based approach that employs the techniques of image processing  machine learning  and deep learning  reducing the reliance on conventional methods to protect paddy crops from diseases like bacterial leaf blight  false smut  brown leaf spot  rice blast  and sheath rot  the five primary diseases that frequently plague the indian rice fields  following image pre processing  image segmentation is employed to determine the diseased section of the paddy plant  with the diseases listed above being identified purely on the basis of their visual contents  an integration of a support vector machine classifier and convolutional neural networks are used to recognize and classify specific varieties of paddy plant diseases  with relu and softmax functions  the suggested deep learning   based strategy attained the highest validation accuracy of         following recognition  a predictive remedy is recommended  which can assist agriculture related individuals and organizations in taking suitable measures to combat these diseases ,3.943133,4.9566565,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
"Ethical assurance: a practical approach to the responsible design, development, and deployment of data-driven technologies","This article offers several contributions to the interdisciplinary project of responsible research and innovation in data science and AI. First, it provides a critical analysis of current efforts to establish practical mechanisms for algorithmic auditing and assessment to identify limitations and gaps with these approaches. Second, it provides a brief introduction to the methodology of argument-based assurance and explores how it is currently being applied in the development of safety cases for autonomous and intelligent systems. Third, it generalises this method to incorporate wider ethical, social, and legal considerations, in turn establishing a novel version of argument-based assurance that we call â€˜ethical assurance.â€™ Ethical assurance is presented as a structured method for unifying the myriad practical mechanisms that have been proposed. It is built on a process-based form of project governance that enlists reflective innovation practices to operationalise normative principles, such as sustainability, accountability, transparency, fairness, and explainability. As a set of interlocutory governance mechanisms that span across the data science and AI lifecycle, ethical assurance supports inclusive and participatory ethical deliberation while also remaining grounded in social and technical realities. Finally, this article sets an agenda for ethical assurance, by detailing current challenges, open questions, and next steps, which serve as a springboard to build an active (and interdisciplinary) research programme as well as contribute to ongoing discussions in policy and governance.",this article offers several contributions to the interdisciplinary project of responsible research and innovation in data science and ai  first  it provides a critical analysis of current efforts to establish practical mechanisms for algorithmic auditing and assessment to identify limitations and gaps with these approaches  second  it provides a brief introduction to the methodology of argument based assurance and explores how it is currently being applied in the development of safety cases for autonomous and intelligent systems  third  it generalises this method to incorporate wider ethical  social  and legal considerations  in turn establishing a novel version of argument based assurance that we call    ethical assurance     ethical assurance is presented as a structured method for unifying the myriad practical mechanisms that have been proposed  it is built on a process based form of project governance that enlists reflective innovation practices to operationalise normative principles  such as sustainability  accountability  transparency  fairness  and explainability  as a set of interlocutory governance mechanisms that span across the data science and ai lifecycle  ethical assurance supports inclusive and participatory ethical deliberation while also remaining grounded in social and technical realities  finally  this article sets an agenda for ethical assurance  by detailing current challenges  open questions  and next steps  which serve as a springboard to build an active  and interdisciplinary  research programme as well as contribute to ongoing discussions in policy and governance ,11.920538,5.6468277,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Customized Dataset,"Deep learning has been widely used in various industries such as medicine, biology, and finance and has been deployed on various platforms such as the Internet and mobile terminals. When we introduced the algorithm earlier, most of the datasets were commonly used classic datasets. The downloading, loading, and preprocessing of the dataset can be completed with a few lines of TensorFlow code, which greatly improves the research efficiency. In actual applications, the datasets are different for different application scenarios. For customized datasets, using TensorFlow to complete data loading, designing excellent network model training process, and deploying the trained model to platforms such as mobile and the Internet network is an indispensable link for the implementation of deep learning algorithms.",deep learning has been widely used in various industries such as medicine  biology  and finance and has been deployed on various platforms such as the internet and mobile terminals  when we introduced the algorithm earlier  most of the datasets were commonly used classic datasets  the downloading  loading  and preprocessing of the dataset can be completed with a few lines of tensorflow code  which greatly improves the research efficiency  in actual applications  the datasets are different for different application scenarios  for customized datasets  using tensorflow to complete data loading  designing excellent network model training process  and deploying the trained model to platforms such as mobile and the internet network is an indispensable link for the implementation of deep learning algorithms ,3.2262073,6.7508807,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Azure Data Factory,"So far in your example, you have data sitting in both Azure Data Lake Store and Azure Blob Storage, waiting for the next step in the journey. Chapters 5 and 6 walked through the process of using Azure Stream Analytics to pick the data up from Azure IoT Hub and route it to hot path or cold path destinations, depending on the analysis needs for data insights.
 Keywords
 Data Factory
 Visual Studio
 Hadoop Distribute File System
 Distribute File System
 Linked Service
 These keywords were added by machine and not by the authors. This process is experimental and the keywords may be updated as the learning algorithm improves.",so far in your example  you have data sitting in both azure data lake store and azure blob storage  waiting for the next step in the journey  chapters   and   walked through the process of using azure stream analytics to pick the data up from azure iot hub and route it to hot path or cold path destinations  depending on the analysis needs for data insights   keywords  data factory  visual studio  hadoop distribute file system  distribute file system  linked service  these keywords were added by machine and not by the authors  this process is experimental and the keywords may be updated as the learning algorithm improves ,8.2477865,7.8400917,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Shrubby cinquefoil (Dasiphora fruticosa (L.) Rydb.) mapping in Northwestern Estonia based upon site similarities,"Background
 Different methods have been used to map species and habitat distributions. In this paper, similarity-based reasoningâ€”a methodological approach that has received less attentionâ€”was applied to estimate the distribution and coverage of Dasiphora fruticosa for the region in the Baltic states where grows the most abundant population of this species.
 Methods
 Field observations, after thinning to at least 50 m interval, included 1480 coverage estimations in the species presence locations and 8317 absence locations. Species coverage for the 750 km2 of directly unobserved area was calculated using machine learning in the similarity-based prediction system Constud. Separate predictive sets of site features (e.g. land cover, soil type) and exemplar weights were calibrated for spatial partitions of the study area (probable presence region, unclear region, proved absence region). A modified version of the Gowerâ€™s distance metric, as used in Constud, is described.
 Results
 The resulting maps depicted the predicted coverage, the certainty of decision when predicting presence or absence, and the mean similarity to the exemplar locations used while predicting. Coverage prediction errors were smaller in the unclear partitionâ€”where the species was mostly absentâ€”than in the probable presence partition, where coverage ranged from 0 to 90%.
 Conclusions
 We call for methodological comparisons using the same data set.",background  different methods have been used to map species and habitat distributions  in this paper  similarity based reasoning   a methodological approach that has received less attention   was applied to estimate the distribution and coverage of dasiphora fruticosa for the region in the baltic states where grows the most abundant population of this species   methods  field observations  after thinning to at least    m interval  included      coverage estimations in the species presence locations and      absence locations  species coverage for the     km  of directly unobserved area was calculated using machine learning in the similarity based prediction system constud  separate predictive sets of site features  e g  land cover  soil type  and exemplar weights were calibrated for spatial partitions of the study area  probable presence region  unclear region  proved absence region   a modified version of the gower   s distance metric  as used in constud  is described   results  the resulting maps depicted the predicted coverage  the certainty of decision when predicting presence or absence  and the mean similarity to the exemplar locations used while predicting  coverage prediction errors were smaller in the unclear partition   where the species was mostly absent   than in the probable presence partition  where coverage ranged from   to       conclusions  we call for methodological comparisons using the same data set ,4.1018996,3.4754431,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Verifiable privacy-preserving single-layer perceptron training scheme in cloud computing,"With the advent of artificial intelligence, machine learning has been well explored and extensively applied into numerous fields, such as pattern recognition, image processing and cloud computing. Very recently, machine learning hosted in a cloud service has gained more attentions due to the benefits from the outsourcing paradigm. Based on cloud-aided computation techniques, the heavy computation tasks involved in machine learning process can be off-loaded into the cloud server in a pay-per-use manner, whereas outsourcing large-scale collection of sensitive data risks privacy leakage since the cloud server is semi-honest. Therefore, privacy preservation for the client and verification for the returned results become two challenges to be dealt with. In this paper, we focus on designing a novel privacy-preserving single-layer perceptron training scheme which supports batch patterns training and verification for the training results on the client side. In addition, adopting classical secure two-party computation method, we design a novel lightweight privacy-preserving predictive algorithm. Both two participants learns nothing about otherâ€™s inputs, and the calculation result is only known by one party. Detailed security analysis shows that the proposed scheme can achieve the desired security properties. We also demonstrate the efficiency of our scheme by providing the experimental evaluation on two different real datasets.",with the advent of artificial intelligence  machine learning has been well explored and extensively applied into numerous fields  such as pattern recognition  image processing and cloud computing  very recently  machine learning hosted in a cloud service has gained more attentions due to the benefits from the outsourcing paradigm  based on cloud aided computation techniques  the heavy computation tasks involved in machine learning process can be off loaded into the cloud server in a pay per use manner  whereas outsourcing large scale collection of sensitive data risks privacy leakage since the cloud server is semi honest  therefore  privacy preservation for the client and verification for the returned results become two challenges to be dealt with  in this paper  we focus on designing a novel privacy preserving single layer perceptron training scheme which supports batch patterns training and verification for the training results on the client side  in addition  adopting classical secure two party computation method  we design a novel lightweight privacy preserving predictive algorithm  both two participants learns nothing about other   s inputs  and the calculation result is only known by one party  detailed security analysis shows that the proposed scheme can achieve the desired security properties  we also demonstrate the efficiency of our scheme by providing the experimental evaluation on two different real datasets ,5.2462144,7.2696686,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Prescriptive analytics: a survey of emerging trends and technologies,"This paper provides a survey of the state-of-the-art and future directions of one of the most important emerging technologies within business analytics (BA), namely prescriptive analytics (PSA). BA focuses on data-driven decision-making and consists of three phases: descriptive, predictive, and prescriptive analytics. While descriptive and predictive analytics allow us to analyze past and predict future events, respectively, these activities do not provide any direct support for decision-making. Here, PSA fills the gap between data and decisions. We have observed an increasing interest for in-DBMS PSA systems in both research and industry. Thus, this paper aims to provide a foundation for PSA as a separate field of study. To do this, we first describe the different phases of BA. We then survey classical analytics systems and identify their main limitations for supporting PSA, based on which we introduce the criteria and methodology used in our analysis. We next survey, categorize, and discuss the state-of-the-art within emerging, so-called PSA\(^+\), systems, followed by a presentation of the main challenges and opportunities for next-generation PSA systems. Finally, the main findings are discussed and directions for future research are outlined.",this paper provides a survey of the state of the art and future directions of one of the most important emerging technologies within business analytics  ba   namely prescriptive analytics  psa   ba focuses on data driven decision making and consists of three phases  descriptive  predictive  and prescriptive analytics  while descriptive and predictive analytics allow us to analyze past and predict future events  respectively  these activities do not provide any direct support for decision making  here  psa fills the gap between data and decisions  we have observed an increasing interest for in dbms psa systems in both research and industry  thus  this paper aims to provide a foundation for psa as a separate field of study  to do this  we first describe the different phases of ba  we then survey classical analytics systems and identify their main limitations for supporting psa  based on which we introduce the criteria and methodology used in our analysis  we next survey  categorize  and discuss the state of the art within emerging  so called psa        systems  followed by a presentation of the main challenges and opportunities for next generation psa systems  finally  the main findings are discussed and directions for future research are outlined ,8.432282,5.5352445,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Safety by simulation: theorizing the future of robot regulation,"Mobility robots may soon be among us, triggering a need for safety regulation. Robot safety regulation, however, remains underexplored, with only a few articles analyzing what regulatory approaches could be feasible. This article offers an account of the available regulatory strategies and attempts to theorize the effects of simulation-based safety regulation. The article first discusses the distinctive features of mobility robots as regulatory targets and argues that emergent behavior constitutes the key regulatory concern in designing robot safety regulation regimes. In contrast to many accounts, the article posits that emergent behavior dynamics do not arise from robot autonomy, learning capability, or code unexplainability. Instead, they emerge from the complexity of robot technological constitutions coupled with near-infinite environmental variability and non-linear performance dynamics of the machine learning components. Second, the article reviews rules-based and performance-based regulation and argues that both will fail adequately constrain emergent robot behaviors. The article claims that controlling mobility robots requires a simulation-based regulatory approach. Simulation-based regulation is a novelty with significant theoretical and practical implications. The article argues that the approach signifies a radical break in regulatory forms of knowledge and temporalities. Simulations enact virtual futures to create a new regulatory knowledge type. Practically, the novel safety knowledge type may destabilize the existing conceptual space of safety politics and liability allocation patterns.",mobility robots may soon be among us  triggering a need for safety regulation  robot safety regulation  however  remains underexplored  with only a few articles analyzing what regulatory approaches could be feasible  this article offers an account of the available regulatory strategies and attempts to theorize the effects of simulation based safety regulation  the article first discusses the distinctive features of mobility robots as regulatory targets and argues that emergent behavior constitutes the key regulatory concern in designing robot safety regulation regimes  in contrast to many accounts  the article posits that emergent behavior dynamics do not arise from robot autonomy  learning capability  or code unexplainability  instead  they emerge from the complexity of robot technological constitutions coupled with near infinite environmental variability and non linear performance dynamics of the machine learning components  second  the article reviews rules based and performance based regulation and argues that both will fail adequately constrain emergent robot behaviors  the article claims that controlling mobility robots requires a simulation based regulatory approach  simulation based regulation is a novelty with significant theoretical and practical implications  the article argues that the approach signifies a radical break in regulatory forms of knowledge and temporalities  simulations enact virtual futures to create a new regulatory knowledge type  practically  the novel safety knowledge type may destabilize the existing conceptual space of safety politics and liability allocation patterns ,9.906722,7.0882854,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Ground truth to fake geographies: machine vision and learning in visual practices,"This article investigates the concept of the ground truth as both an epistemic and technical figure of knowledge that is central to discussions of machine vision and media techniques of visuality. While ground truth refers to a set of remote sensing practices, it has a longer history in operational photography, such as aerial reconnaissance. Building on a discussion of this history, this article argues that ground truth has shifted from a reference to the physical, geographical ground to the surface of the images echoing earlier points raised by philosopher Jean-Luc Nancy that there is a ground of the image that is central to the task of analysis beyond representational practices. Furthermore, building on the practices of pattern recognition, composite imaging, and different interpretational techniques, we discuss contemporary practices of machine learning that mobilizes geographical earth observation datasets for experimental purposes, including tests such as â€œfake geographyâ€ as well as artistic practices, to show how ground truth is operationalized in such contexts of AI and visual arts.",this article investigates the concept of the ground truth as both an epistemic and technical figure of knowledge that is central to discussions of machine vision and media techniques of visuality  while ground truth refers to a set of remote sensing practices  it has a longer history in operational photography  such as aerial reconnaissance  building on a discussion of this history  this article argues that ground truth has shifted from a reference to the physical  geographical ground to the surface of the images echoing earlier points raised by philosopher jean luc nancy that there is a ground of the image that is central to the task of analysis beyond representational practices  furthermore  building on the practices of pattern recognition  composite imaging  and different interpretational techniques  we discuss contemporary practices of machine learning that mobilizes geographical earth observation datasets for experimental purposes  including tests such as    fake geography    as well as artistic practices  to show how ground truth is operationalized in such contexts of ai and visual arts ,7.5292554,4.538982,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Social Spread,"In this chapter, I explore several ways in which algorithms interact with the complex dynamics of social media when it comes to fake news. First, I set the stage with some context, issues, and examples that help us better understand what has happened and whatâ€™s at stake. Next, I look at how algorithms have been used to scrape data from social media platforms to provide remarkable quantitative insight into how fake news spreadsâ€”both organically and when part of deliberate disinformation campaigns. Along the way, the role in this spread played by the social media platformsâ€™ own content recommendation algorithms is explored. Attention is then turned to the algorithmic tools that social media companiesâ€”primarily Facebook and Twitterâ€”have used and could potentially use in their battle against harmful misinformation, as well as the limitations and challenges of taking algorithmic approaches to this thorny, multifaceted problem.",in this chapter  i explore several ways in which algorithms interact with the complex dynamics of social media when it comes to fake news  first  i set the stage with some context  issues  and examples that help us better understand what has happened and what   s at stake  next  i look at how algorithms have been used to scrape data from social media platforms to provide remarkable quantitative insight into how fake news spreads   both organically and when part of deliberate disinformation campaigns  along the way  the role in this spread played by the social media platforms    own content recommendation algorithms is explored  attention is then turned to the algorithmic tools that social media companies   primarily facebook and twitter   have used and could potentially use in their battle against harmful misinformation  as well as the limitations and challenges of taking algorithmic approaches to this thorny  multifaceted problem ,7.3672214,6.469872,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
"Data Collection, Presentation and Analysis","This chapter covers the topics of data collection, data presentation and data analysis. It gives attention to data collection for studies based on experiments, on data derived from existing published or unpublished data sets, on observation, on simulation and digital twins, on surveys, on interviews and on focus group discussions. One of the interesting features of this chapter is the section dealing with using measurement scales in quantitative research, including nominal scales, ordinal scales, interval scales and ratio scales. It explains key facets of qualitative research including ethical clearance requirements. The chapter discusses the importance of data visualization as key to effective presentation of data, including tabular forms, graphical forms and visual charts such as those generated by Atlas.ti analytical software.
 Keywords
 Computer science data
 Cybersecurity data analysis
 Cybersecurity experiments
 Information systems data collection
 Information systems visualization",this chapter covers the topics of data collection  data presentation and data analysis  it gives attention to data collection for studies based on experiments  on data derived from existing published or unpublished data sets  on observation  on simulation and digital twins  on surveys  on interviews and on focus group discussions  one of the interesting features of this chapter is the section dealing with using measurement scales in quantitative research  including nominal scales  ordinal scales  interval scales and ratio scales  it explains key facets of qualitative research including ethical clearance requirements  the chapter discusses the importance of data visualization as key to effective presentation of data  including tabular forms  graphical forms and visual charts such as those generated by atlas ti analytical software   keywords  computer science data  cybersecurity data analysis  cybersecurity experiments  information systems data collection  information systems visualization,7.2376976,5.790625,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Obfuscated Malware Detection: Impacts on Detection Methods,"Obfuscated malware poses a challenge to traditional malware detection methods as it uses various techniques to disguise its behavior and evade detection. This paper focuses on the impacts of obfuscated malware detection techniques using a variety of detection methods. Furthermore, this paper discusses the current state of obfuscated malware, the methods used to detect it, and the limitations of those methods. The impact of obfuscation on the effectiveness of detection methods is also discussed. An approach for the creation of advanced detection techniques based on machine learning algorithms is offered, along with an empirical examination of malware detection performance assessment to battle obfuscated malware. Overall, this paper highlights the importance of staying ahead of the constantly evolving threat landscape to safeguard computer networks and systems.
 Keywords
 Obfuscated malware
 Malware detection
 Machine leaning algorithm",obfuscated malware poses a challenge to traditional malware detection methods as it uses various techniques to disguise its behavior and evade detection  this paper focuses on the impacts of obfuscated malware detection techniques using a variety of detection methods  furthermore  this paper discusses the current state of obfuscated malware  the methods used to detect it  and the limitations of those methods  the impact of obfuscation on the effectiveness of detection methods is also discussed  an approach for the creation of advanced detection techniques based on machine learning algorithms is offered  along with an empirical examination of malware detection performance assessment to battle obfuscated malware  overall  this paper highlights the importance of staying ahead of the constantly evolving threat landscape to safeguard computer networks and systems   keywords  obfuscated malware  malware detection  machine leaning algorithm,3.759742,5.974977,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Classification of Flower Species Using Machine Learning Algorithm,"Since its invention, the computer has begun to have an impact on our day-to-day lives. It enhances the grade of our existence by making them more convenient and productive. Allowing a machine to think and learn like a person is an intriguing concept. Machine learning is the process of allowing a computer to build learning skills on its own using pre-programmed knowledge. Pattern recognition can be compared to a system's ability to recognize many types of items. As a result, pattern recognition and machine learning are inextricably linked. The Iris flower is the subject of this paper. Iris has three separate classifications in its dataset: Setosa, Versicolor, and Virginica. These three separate types of Iris will be distinguished by the developed recognition mechanism. Iris is a genus of flowering plants that includes between 260 and 300 species. We are looking at three different species: Setosa, Versicolor, and Virginica. The goal is to determine the flower's species from its petal and sepal measurements. This work should be improved to classify different plant species. This makes it simple for agriculturists and gardeners to understand different plant types simply by providing measurements.
 Keywords
 Setosa
 Versicolor
 Virginica
 Pattern recognition
 Machine learning",since its invention  the computer has begun to have an impact on our day to day lives  it enhances the grade of our existence by making them more convenient and productive  allowing a machine to think and learn like a person is an intriguing concept  machine learning is the process of allowing a computer to build learning skills on its own using pre programmed knowledge  pattern recognition can be compared to a system s ability to recognize many types of items  as a result  pattern recognition and machine learning are inextricably linked  the iris flower is the subject of this paper  iris has three separate classifications in its dataset  setosa  versicolor  and virginica  these three separate types of iris will be distinguished by the developed recognition mechanism  iris is a genus of flowering plants that includes between     and     species  we are looking at three different species  setosa  versicolor  and virginica  the goal is to determine the flower s species from its petal and sepal measurements  this work should be improved to classify different plant species  this makes it simple for agriculturists and gardeners to understand different plant types simply by providing measurements   keywords  setosa  versicolor  virginica  pattern recognition  machine learning,3.9243667,5.5694003,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Statutory Professions in AI Governance and Their Consequences for Explainable AI,"In the previous chapter, we saw the various roles and skills that go into forming an interdisciplinary data science team. In this chapter, we shall look at a few typical team structures that are seen in practice and then cover some pointers around hiring data scientists, with a particular focus on the chief data scientist.",in the previous chapter  we saw the various roles and skills that go into forming an interdisciplinary data science team  in this chapter  we shall look at a few typical team structures that are seen in practice and then cover some pointers around hiring data scientists  with a particular focus on the chief data scientist ,9.423638,6.202565,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Building and Structuring the Team,"Recall the notion from Chapter 1 that the application of the scientific method to data using software is referred to as data science. Data science is thus fundamentally an interdisciplinary activity at the cusp of data analysis and software engineering. As a team leader, you would periodically need to determine the roles necessary to your team and ensure that the appropriate team members with the right mix of data analysis and software engineering skills are available for that role.",recall the notion from chapter   that the application of the scientific method to data using software is referred to as data science  data science is thus fundamentally an interdisciplinary activity at the cusp of data analysis and software engineering  as a team leader  you would periodically need to determine the roles necessary to your team and ensure that the appropriate team members with the right mix of data analysis and software engineering skills are available for that role ,9.118193,6.266477,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
The Skills Framework,"Intentional and accidental harms arising from the use of AI have impacted the health, safety and rights of individuals. While regulatory frameworks are being developed, there remains a lack of consensus on methods necessary to deliver safe AI. The potential for explainable AI (XAI) to contribute to the effectiveness of the regulation of AI is being increasingly examined. Regulation must include methods to ensure compliance on an ongoing basis, though there is an absence of practical proposals on how to achieve this. For XAI to be successfully incorporated into a regulatory system, the individuals who are engaged in interpreting/explaining the model to stakeholders should be sufficiently qualified for the role. Statutory professionals are prevalent in domains in which harm can be done to the health, safety and rights of individuals. The most obvious examples are doctors, engineers and lawyers. Those professionals are required to exercise skill and judgement and to defend their decision making process in the event of harm occurring. We propose that a statutory profession framework be introduced as a necessary part of the AI regulatory framework for compliance and monitoring purposes. We will refer to this new statutory professional as an AI Architect (AIA). This AIA would be responsible to ensure the risk of harm is minimised and accountable in the event that harms occur. The AIA would also be relied on to provide appropriate interpretations/explanations of XAI models to stakeholders. Further, in order to satisfy themselves that the models have been developed in a satisfactory manner, the AIA would require models to have appropriate transparency. Therefore it is likely that the introduction of an AIA system would lead to an increase in the use of XAI to enable AIA to discharge their professional obligations.
 Keywords
 Artificial Intelligence
 XAI
 Governance
 Regulation
 Statutory Profession",intentional and accidental harms arising from the use of ai have impacted the health  safety and rights of individuals  while regulatory frameworks are being developed  there remains a lack of consensus on methods necessary to deliver safe ai  the potential for explainable ai  xai  to contribute to the effectiveness of the regulation of ai is being increasingly examined  regulation must include methods to ensure compliance on an ongoing basis  though there is an absence of practical proposals on how to achieve this  for xai to be successfully incorporated into a regulatory system  the individuals who are engaged in interpreting explaining the model to stakeholders should be sufficiently qualified for the role  statutory professionals are prevalent in domains in which harm can be done to the health  safety and rights of individuals  the most obvious examples are doctors  engineers and lawyers  those professionals are required to exercise skill and judgement and to defend their decision making process in the event of harm occurring  we propose that a statutory profession framework be introduced as a necessary part of the ai regulatory framework for compliance and monitoring purposes  we will refer to this new statutory professional as an ai architect  aia   this aia would be responsible to ensure the risk of harm is minimised and accountable in the event that harms occur  the aia would also be relied on to provide appropriate interpretations explanations of xai models to stakeholders  further  in order to satisfy themselves that the models have been developed in a satisfactory manner  the aia would require models to have appropriate transparency  therefore it is likely that the introduction of an aia system would lead to an increase in the use of xai to enable aia to discharge their professional obligations   keywords  artificial intelligence  xai  governance  regulation  statutory profession,11.886917,6.88397,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Implementation of a Digital Twin of a Process Plant,"In the previous chapter, we saw the various roles and skills that go into forming an interdisciplinary data science team. In this chapter, we shall look at a few typical team structures that are seen in practice and then cover some pointers around hiring data scientists, with a particular focus on the chief data scientist.",in the previous chapter  we saw the various roles and skills that go into forming an interdisciplinary data science team  in this chapter  we shall look at a few typical team structures that are seen in practice and then cover some pointers around hiring data scientists  with a particular focus on the chief data scientist ,9.355868,6.176418,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Applications of MLOps in the Cognitive Cloud Continuum,"Recall the notion from Chapter 1 that the application of the scientific method to data using software is referred to as data science. Data science is thus fundamentally an interdisciplinary activity at the cusp of data analysis and software engineering. As a team leader, you would periodically need to determine the roles necessary to your team and ensure that the appropriate team members with the right mix of data analysis and software engineering skills are available for that role.",recall the notion from chapter   that the application of the scientific method to data using software is referred to as data science  data science is thus fundamentally an interdisciplinary activity at the cusp of data analysis and software engineering  as a team leader  you would periodically need to determine the roles necessary to your team and ensure that the appropriate team members with the right mix of data analysis and software engineering skills are available for that role ,9.136188,6.187233,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Towards Machine Learning in Distributed Array DBMS: Networking Considerations,"Computer networks are veins of modern distributed systems. Array DBMS (Data Base Management Systems) operate on big data which is naturally modeled as arrays, e.g. Earth remote sensing data and numerical simulation. Big data makes array DBMS to be distributed and highly utilize computer networks. The R&D area of array DBMS is relatively young and machine learning is just paving its way to array DBMS. Hence, existing work is this area is rather sparse and is just emerging. This paper considers distributed, large matrix multiplication (LMM) executed directly inside array DBMS. LMM is the core operation for many machine learning techniques on big data. LMM directly inside array DBMS is not well studied and optimized. We present novel LMM approaches for array DBMS and analyze the intricacies of LMM in array DBMS including execution plan construction and network utilization. We carry out performance evaluation in Microsoft Azure Cloud on a network cluster of virtual machines, report insights derived from the experiments, and present our vision for the future machine learning R&D directions based on LMM directly inside array DBMS.
 Keywords
 Distributed machine learning
 Experimental evaluation
 Performance analysis
 Cloud computing
 Matrices
 Vision",computer networks are veins of modern distributed systems  array dbms  data base management systems  operate on big data which is naturally modeled as arrays  e g  earth remote sensing data and numerical simulation  big data makes array dbms to be distributed and highly utilize computer networks  the r d area of array dbms is relatively young and machine learning is just paving its way to array dbms  hence  existing work is this area is rather sparse and is just emerging  this paper considers distributed  large matrix multiplication  lmm  executed directly inside array dbms  lmm is the core operation for many machine learning techniques on big data  lmm directly inside array dbms is not well studied and optimized  we present novel lmm approaches for array dbms and analyze the intricacies of lmm in array dbms including execution plan construction and network utilization  we carry out performance evaluation in microsoft azure cloud on a network cluster of virtual machines  report insights derived from the experiments  and present our vision for the future machine learning r d directions based on lmm directly inside array dbms   keywords  distributed machine learning  experimental evaluation  performance analysis  cloud computing  matrices  vision,5.5279946,7.1711698,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
European Structural and Investment Funds 2021â€“2027: Prediction Analysis Based on Machine Learning Models,"This research presents several machine learning algorithms and prediction models to anticipate the European Structural and Investment Funds (ESIF) application in different European Union (EU) countries. These analyses start with data training from 2014 to 2020 ESIF, to test and predict the application of the future ESI Funds for 2021â€“2027. We deliver an analysis focused on the priorities of each fund, highlighting the differences between the programs in different time periods. In the framework of the European Regional Development Fund (ERDF), we will specifically address the assessment of the following themes: support innovation of small and medium-sized businesses, to greener, low-carbon, and resilient projects with enhanced mobility. In what concerns the European Social Fund (ESF), we will evaluate projects that promote and increase the EUâ€™s employment, social, education, and skills policies, including structural reforms in these areas. Regarding the cohesion funds (CF), we will be targeting the improvements between the two ESIFs, looking at projects in the field of environment and trans-European networks in the area of transport infrastructure (TEN-T). In summary, we will be looking at the future of ESIF through the glasses of artificial intelligence.
 Keywords
 European structural and investment funds
 Predictive analysis models
 Predictive algorithms
 CRISP-DM",this research presents several machine learning algorithms and prediction models to anticipate the european structural and investment funds  esif  application in different european union  eu  countries  these analyses start with data training from      to      esif  to test and predict the application of the future esi funds for              we deliver an analysis focused on the priorities of each fund  highlighting the differences between the programs in different time periods  in the framework of the european regional development fund  erdf   we will specifically address the assessment of the following themes  support innovation of small and medium sized businesses  to greener  low carbon  and resilient projects with enhanced mobility  in what concerns the european social fund  esf   we will evaluate projects that promote and increase the eu   s employment  social  education  and skills policies  including structural reforms in these areas  regarding the cohesion funds  cf   we will be targeting the improvements between the two esifs  looking at projects in the field of environment and trans european networks in the area of transport infrastructure  ten t   in summary  we will be looking at the future of esif through the glasses of artificial intelligence   keywords  european structural and investment funds  predictive analysis models  predictive algorithms  crisp dm,9.22139,7.394855,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Interpretation of Machine Learning Model Using Medical Record Visual Analytics,"The state of the art of medical application that being implemented are mostly based on common machine learning model. Nevertheless, one of the drawbacks of the practice of medical diagnosis is the lack of explanation on the proposed solution, which is also known as a black box, without knowing the internal decision process between the input and output. It will lead to untrustworthiness and difficult to understand by the medical expert. They are questioning how the complexity of machine learning methods decide on the output without clear and understandable explanations. Moreover, in machine learning field the characteristic of a black box model may lead to biased data analysis and incorrect output decisions. There is work that uses visual analytics techniques to interpret the machine learning output to ease the understanding of medical experts. However, the functionality of existed and combined visual analytics techniques is not sufficient to visualized and interpreted the output of machine learning operation. Other visual analytic techniques faced the same problem, unreliability to produce strong reason on the output when working with complex machine learning models. This paper analyzed several visual analytics approaches instantiated in machine learning algorithm for medical record analytics. The motivation of this paper is to allow medical experts to understand the interpretation of a black box machine learning model in predicting medical outcome. This paper studied on the effectiveness of visual analytics techniques to identify the appropriate technique to be instantiated to the machine learning algorithm to further elaborate the results obtained by demonstrating transparency, interpretability and explainability of the machine learning algorithm. The visual analytics that are been studied are Local Interpretable Model-agnostic Explanations (LIME) and Shapley Additive exPlanations (SHAP). Based on the comparison of LIME and SHAP methods, this paper found that SHAP has consistent interpretability as compared to LIME.
 Keywords
 Machine learning
 Interpretability
 Visual analytics",the state of the art of medical application that being implemented are mostly based on common machine learning model  nevertheless  one of the drawbacks of the practice of medical diagnosis is the lack of explanation on the proposed solution  which is also known as a black box  without knowing the internal decision process between the input and output  it will lead to untrustworthiness and difficult to understand by the medical expert  they are questioning how the complexity of machine learning methods decide on the output without clear and understandable explanations  moreover  in machine learning field the characteristic of a black box model may lead to biased data analysis and incorrect output decisions  there is work that uses visual analytics techniques to interpret the machine learning output to ease the understanding of medical experts  however  the functionality of existed and combined visual analytics techniques is not sufficient to visualized and interpreted the output of machine learning operation  other visual analytic techniques faced the same problem  unreliability to produce strong reason on the output when working with complex machine learning models  this paper analyzed several visual analytics approaches instantiated in machine learning algorithm for medical record analytics  the motivation of this paper is to allow medical experts to understand the interpretation of a black box machine learning model in predicting medical outcome  this paper studied on the effectiveness of visual analytics techniques to identify the appropriate technique to be instantiated to the machine learning algorithm to further elaborate the results obtained by demonstrating transparency  interpretability and explainability of the machine learning algorithm  the visual analytics that are been studied are local interpretable model agnostic explanations  lime  and shapley additive explanations  shap   based on the comparison of lime and shap methods  this paper found that shap has consistent interpretability as compared to lime   keywords  machine learning  interpretability  visual analytics,6.10462,5.1489787,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Discrete Facility Location in Machine Learning,"Abstract
 Facility location problems form a broad class of optimization problems extremely popular in combinatorial optimization and operations research. In every facility location problem, one must locate a set of facilities in order to satisfy the demands of customers so as some certain objective function be optimal. Besides numerous applications in public and private sectors, the problems are widely used in machine learning. For example, clustering can be viewed as a facility location problem where we need to partition a set of customers into clusters assigned to open facilities. In this survey we briefly look at how the ideas and approaches arisen in the field of facility location led to modern, popular machine learning algorithms supported by many data mining and machine learning software packages. We also review the state-of-the-art of exact methods and heuristics, as well as some extensions of the basic problems and algorithms in applied machine learning tasks. Note that the main emphasis lies here on discrete facility location problems which, for example, underlie many widely used clustering algorithms (PAM, affinity propagation, etc.). Since the high computational complexity of the conventional facility location-based clustering algorithms hinders their application to modern large-scale real-life datasets; we also survey some modern approaches to implementation of the algorithms for these large data collections.",abstract  facility location problems form a broad class of optimization problems extremely popular in combinatorial optimization and operations research  in every facility location problem  one must locate a set of facilities in order to satisfy the demands of customers so as some certain objective function be optimal  besides numerous applications in public and private sectors  the problems are widely used in machine learning  for example  clustering can be viewed as a facility location problem where we need to partition a set of customers into clusters assigned to open facilities  in this survey we briefly look at how the ideas and approaches arisen in the field of facility location led to modern  popular machine learning algorithms supported by many data mining and machine learning software packages  we also review the state of the art of exact methods and heuristics  as well as some extensions of the basic problems and algorithms in applied machine learning tasks  note that the main emphasis lies here on discrete facility location problems which  for example  underlie many widely used clustering algorithms  pam  affinity propagation  etc    since the high computational complexity of the conventional facility location based clustering algorithms hinders their application to modern large scale real life datasets  we also survey some modern approaches to implementation of the algorithms for these large data collections ,3.0044692,7.979019,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Assistive Robots as Future Caregivers: The RAPP Approach,"As our societies are affected by a dramatic demographic change, the percentage of elderly and people requiring support in their daily life is expected to increase in the near future and caregivers will not be enough to assist and support them. Socially interactive robots can help confront this situation not only by physically assisting people but also by functioning as a companion. The rising sales figures of robots point towards a trend break concerning robotics. To lower the cost for developers and to increase their interest in developing robotic applications, the RAPP approach introduces the idea of robots as platforms. RAPP (A Software Platform for Delivering Smart User Empowering Robotic Applications) aims to provide a software platform in order to support the creation and delivery of robotic applications (RApps) targeting people at risk of exclusion, especially older people. The open-source software platform will provide an API with the required functionality for the implementation of RApps. It will also provide access to the robotsâ€™ sensors and actuators employing higher level commands, by adding a middleware stack with functionalities suitable for different kinds of robots. RAPP will expand the robotsâ€™ computational and storage capabilities and enable machine learning operations, distributed data collection and processing. Through a special repository for RApps, the platform will support knowledge sharing among robots in order to provide personalized applications based on adaptation to individuals. The use of a common API will facilitate the development of improved applications deployable for a variety of robots. These applications target people with different needs, capabilities and expectations, while at the same time respect their privacy and autonomy. The RAPP approach can lower the cost of robotic applications development and it is expected to have a profound effect in the robotics market.
 Keywords
 robotics
 elderly
 inclusion
 assisted living
 cloud robotics",as our societies are affected by a dramatic demographic change  the percentage of elderly and people requiring support in their daily life is expected to increase in the near future and caregivers will not be enough to assist and support them  socially interactive robots can help confront this situation not only by physically assisting people but also by functioning as a companion  the rising sales figures of robots point towards a trend break concerning robotics  to lower the cost for developers and to increase their interest in developing robotic applications  the rapp approach introduces the idea of robots as platforms  rapp  a software platform for delivering smart user empowering robotic applications  aims to provide a software platform in order to support the creation and delivery of robotic applications  rapps  targeting people at risk of exclusion  especially older people  the open source software platform will provide an api with the required functionality for the implementation of rapps  it will also provide access to the robots    sensors and actuators employing higher level commands  by adding a middleware stack with functionalities suitable for different kinds of robots  rapp will expand the robots    computational and storage capabilities and enable machine learning operations  distributed data collection and processing  through a special repository for rapps  the platform will support knowledge sharing among robots in order to provide personalized applications based on adaptation to individuals  the use of a common api will facilitate the development of improved applications deployable for a variety of robots  these applications target people with different needs  capabilities and expectations  while at the same time respect their privacy and autonomy  the rapp approach can lower the cost of robotic applications development and it is expected to have a profound effect in the robotics market   keywords  robotics  elderly  inclusion  assisted living  cloud robotics,9.108204,4.0286837,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Design of Hardware Accelerator for Artificial Neural Networks Using Multi-operand Adder,"Computational requirements of Artificial Neural Networks (ANNs) are so vastly different from the conventional architectures that exploring new computing paradigms, hardware architectures, and their optimization has gained momentum. ANNs use large number of parallel operations because of which their implementation on conventional computer hardware becomes inefficient. This paper presents a new design methodology for Multi-operand adders. These adders require multi-bit carries which makes their design unique. Theoretical upper bound on the size of sum and carry in a multi-operand addition for any base and any number of operands is presented in this paper. This result is used to design modular 4-operand, 4-bit adder. This module computes the partial sums using a look-up-table. These modules can be connected in a hierarchical structure to implement larger adders. Method to build a 16 bit 16 operand adder using this basic 4-bit 4-operand adder block is presented. Verilog simulation results are presented for both 4 Ã— 4 and 16 Ã— 16 adders. Design strategy used for the 16 Ã— 16 adder may further be extended to more number of bits or operands with ease, using the guidelines discussed in the paper.
 Keywords
 Artificial Intelligence
 Deep Learning
 Hardware accelerators
 Hardware optimization
 Massive parallelism
 Multi-operand addition
 Neural computing
 Neural network processor",computational requirements of artificial neural networks  anns  are so vastly different from the conventional architectures that exploring new computing paradigms  hardware architectures  and their optimization has gained momentum  anns use large number of parallel operations because of which their implementation on conventional computer hardware becomes inefficient  this paper presents a new design methodology for multi operand adders  these adders require multi bit carries which makes their design unique  theoretical upper bound on the size of sum and carry in a multi operand addition for any base and any number of operands is presented in this paper  this result is used to design modular   operand    bit adder  this module computes the partial sums using a look up table  these modules can be connected in a hierarchical structure to implement larger adders  method to build a    bit    operand adder using this basic   bit   operand adder block is presented  verilog simulation results are presented for both        and          adders  design strategy used for the          adder may further be extended to more number of bits or operands with ease  using the guidelines discussed in the paper   keywords  artificial intelligence  deep learning  hardware accelerators  hardware optimization  massive parallelism  multi operand addition  neural computing  neural network processor,3.0952568,7.9143624,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
User-Item-Based Hybrid Recommendation System by Employing Mahout Framework,"Recommendation systems are gaining popularity nowadays. Generally, recommendations are used in multiple areas like music, movies online products, news articles, texts, study articles, search engine queries, and social networking tags. Recommender systems use machine learning techniques and data mining algorithms to predict what items should suggest to the users based on some previous information related to the users and their relations to the items. It basically offers the users a limited number of products and services which he/she would like to get among the vast amount of all available items. The growth of information on the Internet, as well as the number of visitors to Web sites, is producing many choices for a customer, but many of those are irrelevant to them. A recommendation system filters this data and refers to the filterâ€™s data to the users. The recommendation system is totally based on its training data, the performing algorithms and the recommending approach. There are many popular approaches like user-based collaborative filtering, item-based collaborative filtering, content-based filtering, and hybrid models. We have implemented three different architectures, item-based, user-based, and factor-based hybrid models in order to build recommender system for an artist. In order to cope up with the huge amount of data, we have used Apache Mahout on top of Hadoop. Mahout is basically a framework and an open source project of Apache. Generally, it is being used for creating scalable machine learning algorithms. Using Mahout, we can fasten the process. Mahout is ready-to-use framework, helps programmers for doing data mining tasks on a large scale of data.
 Keywords
 Recommendation system
 Hybrid approach
 Machine learning
 Apache Mahout
 Hadoop",recommendation systems are gaining popularity nowadays  generally  recommendations are used in multiple areas like music  movies online products  news articles  texts  study articles  search engine queries  and social networking tags  recommender systems use machine learning techniques and data mining algorithms to predict what items should suggest to the users based on some previous information related to the users and their relations to the items  it basically offers the users a limited number of products and services which he she would like to get among the vast amount of all available items  the growth of information on the internet  as well as the number of visitors to web sites  is producing many choices for a customer  but many of those are irrelevant to them  a recommendation system filters this data and refers to the filter   s data to the users  the recommendation system is totally based on its training data  the performing algorithms and the recommending approach  there are many popular approaches like user based collaborative filtering  item based collaborative filtering  content based filtering  and hybrid models  we have implemented three different architectures  item based  user based  and factor based hybrid models in order to build recommender system for an artist  in order to cope up with the huge amount of data  we have used apache mahout on top of hadoop  mahout is basically a framework and an open source project of apache  generally  it is being used for creating scalable machine learning algorithms  using mahout  we can fasten the process  mahout is ready to use framework  helps programmers for doing data mining tasks on a large scale of data   keywords  recommendation system  hybrid approach  machine learning  apache mahout  hadoop,4.9552913,5.3881254,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Classification of Customer Tweets Using Big Data Analytics,"Word of mouth has a great impact on commercial planning and decision-making. Social media is considered as one of the greatest media to spread customerâ€™s opinion about product. Twitter in particular serves as a platform to share people opinion with the words. Decision makers nowadays are seeking analysis approaches on customer tweets to classify whether a customer is satisfied or unhappy. But the enormous number of tweets per seconds and the live streaming of twitter require big data processors in order to support decision-making. In this paper, we propose a recommender system that helps decision makers to fetch customer streaming tweets and classifies their opinion within seconds. We aim to achieve that by applying NaÃ¯ve Bayes algorithm using big data machine learning approach, Apache Hadoop and Mahout tools are used. The result of our finding is a recommender system that can be used to classify any new customer tweets. The accuracy of the model is 99.39% which promises accurate results in identifying negative or positive customer opinion about a product in a tweet.
 Keywords
 Big Data Analytics
 Recommender system
 Mahout
 Tweets
 Sentiment analysis",word of mouth has a great impact on commercial planning and decision making  social media is considered as one of the greatest media to spread customer   s opinion about product  twitter in particular serves as a platform to share people opinion with the words  decision makers nowadays are seeking analysis approaches on customer tweets to classify whether a customer is satisfied or unhappy  but the enormous number of tweets per seconds and the live streaming of twitter require big data processors in order to support decision making  in this paper  we propose a recommender system that helps decision makers to fetch customer streaming tweets and classifies their opinion within seconds  we aim to achieve that by applying na  ve bayes algorithm using big data machine learning approach  apache hadoop and mahout tools are used  the result of our finding is a recommender system that can be used to classify any new customer tweets  the accuracy of the model is        which promises accurate results in identifying negative or positive customer opinion about a product in a tweet   keywords  big data analytics  recommender system  mahout  tweets  sentiment analysis,5.0561943,5.6123214,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
LED: Learnable Encryption with Deniability,"User privacy is an important issue in the cloud machine learning service. In this paper, we raise a new threat about the online machine learning service, which comes from outside superior authority. The authority may ask the user and the cloud to disclose secrets and the authority can monitor the user behavior. We propose a protection approach called learnable encryption with deniability (LED), which can convince the outsider of the fake data and can protect the user privacy.
 Keywords
 Privacy-preserving machine learning
 Learnable encryption
 Deniable encryption",user privacy is an important issue in the cloud machine learning service  in this paper  we raise a new threat about the online machine learning service  which comes from outside superior authority  the authority may ask the user and the cloud to disclose secrets and the authority can monitor the user behavior  we propose a protection approach called learnable encryption with deniability  led   which can convince the outsider of the fake data and can protect the user privacy   keywords  privacy preserving machine learning  learnable encryption  deniable encryption,6.6222258,7.241617,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Anomaly process detection using negative selection algorithm and classification techniques,"Artificial immune system is derived from the biological immune system. This system is an important method for generating detectors that include self-adaption, self- regulation and self-learning which have self/non-self-detection features. This method is used in anomaly process detection where the anomaly is non-self in the system. We present a new combining technique for anomaly process detection. This combined technique is a unification of both negative selection and classification algorithm. The main aim of the proposed techniques is to increase the accuracy in this system while decreasing its training time. In this research, CICIDS 2017 and NSL-KDD dataset with different sets of features and the same number of detectors are used. This paper presents a framework for detecting anomaly processes on a host base computer system which is established on the artificial immune system. We evaluate our technique using machine learning algorithms such as: logistic regression, random forest, decision tree and K-neighbors. Moreover, we use WEKA tool classification to perform a correlation based feature selection on the dataset.",artificial immune system is derived from the biological immune system  this system is an important method for generating detectors that include self adaption  self  regulation and self learning which have self non self detection features  this method is used in anomaly process detection where the anomaly is non self in the system  we present a new combining technique for anomaly process detection  this combined technique is a unification of both negative selection and classification algorithm  the main aim of the proposed techniques is to increase the accuracy in this system while decreasing its training time  in this research  cicids      and nsl kdd dataset with different sets of features and the same number of detectors are used  this paper presents a framework for detecting anomaly processes on a host base computer system which is established on the artificial immune system  we evaluate our technique using machine learning algorithms such as  logistic regression  random forest  decision tree and k neighbors  moreover  we use weka tool classification to perform a correlation based feature selection on the dataset ,3.412104,5.744759,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Application of Artificial Intelligence Techniques for the Creation of Novel Services Based on Connected Vehicles,"New technologies have been progressively integrated into vehicles during the last thirty years. Commercial vehicles today can be seen as 2 tonne IoT devices on wheels that continuously collect high-quality information not only from the internal performance and behaviour of the vehicle but also from the external environment. The adoption of cutting-edge technologies like 5G, Edge Computing and Artificial Intelligence (AI) will be essential pillars for the actual implementation of new Intelligent Transportation Systems (ITS) leveraging Vehicle-to-everything (V2X) paradigm. This paper is focused on the design and implementation of a connected vehicle-based system to enable new services and applications to be developed, by exploiting high-quality data collected from onboard sensors and ECUs and leveraging state-of-the-art machine learning technologies.
 Keywords
 Artificial Intelligence
 Connected vehicle
 SUMO
 V2X
 CAN
 V2V",new technologies have been progressively integrated into vehicles during the last thirty years  commercial vehicles today can be seen as   tonne iot devices on wheels that continuously collect high quality information not only from the internal performance and behaviour of the vehicle but also from the external environment  the adoption of cutting edge technologies like  g  edge computing and artificial intelligence  ai  will be essential pillars for the actual implementation of new intelligent transportation systems  its  leveraging vehicle to everything  v x  paradigm  this paper is focused on the design and implementation of a connected vehicle based system to enable new services and applications to be developed  by exploiting high quality data collected from onboard sensors and ecus and leveraging state of the art machine learning technologies   keywords  artificial intelligence  connected vehicle  sumo  v x  can  v v,6.8640504,7.491106,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Heterogeneous Computing System for Deep Learning,"Various forms of Deep Neural Network (DNN) architectures are used as Deep Learning tools for neural inspired computational systems. The computational power, the bandwidth and the energy requested by the current developments of the domain are very high. The solutions offered by the current architectural environment are far from being efficient. We propose a hybrid computational system for running efficiently the training and inference DNN algorithms. The system is more energy efficient compared with the current solutions, and achieves a higher actual performance per peak performance ratio. The accelerator part of our heterogeneous system is a programmable many-core system with a Map-Scan/Reductive only the cells where architecture. The chapter describes and evaluates the proposed accelerator for the main computational intensive components of a DNN: the fully connected layer, the convolution layer, the pooling layer, and the softmax layer.
 Keywords
 Deep neural network
 Parallel computing
 Heterogeneous computing
 Accelerators",various forms of deep neural network  dnn  architectures are used as deep learning tools for neural inspired computational systems  the computational power  the bandwidth and the energy requested by the current developments of the domain are very high  the solutions offered by the current architectural environment are far from being efficient  we propose a hybrid computational system for running efficiently the training and inference dnn algorithms  the system is more energy efficient compared with the current solutions  and achieves a higher actual performance per peak performance ratio  the accelerator part of our heterogeneous system is a programmable many core system with a map scan reductive only the cells where architecture  the chapter describes and evaluates the proposed accelerator for the main computational intensive components of a dnn  the fully connected layer  the convolution layer  the pooling layer  and the softmax layer   keywords  deep neural network  parallel computing  heterogeneous computing  accelerators,2.8875396,7.3742003,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Application of Soft Computing in Crop Management,"Indian agriculture is overwhelmed by numerous complications; some of them are usual, and some others are artificial like small and fragmented land-holdings, seeds, manures, crop selection, crop planning, fertilizers and biocides, irrigation, lack of mechanization, soil erosion, agricultural marketing, inadequate storage facilities, and so on. With the progression of different and specific outfits for the viability test of crop management are essential for providing reliable data observing to the performance of crop management. Valuable practical data can be collected by utilizing fuzzy logic-based scheme, in contrast with the intrinsic objectivity for collecting the data in gradual progression without any flaw. By dint of subject expertise and with the knowledge of scientific derivation, the approach should inspire to every corners of the country and management of cropping schemes. This paper analyzes the application of soft computing techniques in crop management in the field of farming and organic engineering is manifested. Upcoming progress and implementation using soft computing in the arena of farming and organic work to be think about.
 Keywords
 Crop selection
 Crop planning
 Fuzzy Logic
 Soft computing
 Crop management",indian agriculture is overwhelmed by numerous complications  some of them are usual  and some others are artificial like small and fragmented land holdings  seeds  manures  crop selection  crop planning  fertilizers and biocides  irrigation  lack of mechanization  soil erosion  agricultural marketing  inadequate storage facilities  and so on  with the progression of different and specific outfits for the viability test of crop management are essential for providing reliable data observing to the performance of crop management  valuable practical data can be collected by utilizing fuzzy logic based scheme  in contrast with the intrinsic objectivity for collecting the data in gradual progression without any flaw  by dint of subject expertise and with the knowledge of scientific derivation  the approach should inspire to every corners of the country and management of cropping schemes  this paper analyzes the application of soft computing techniques in crop management in the field of farming and organic engineering is manifested  upcoming progress and implementation using soft computing in the arena of farming and organic work to be think about   keywords  crop selection  crop planning  fuzzy logic  soft computing  crop management,4.270824,2.416302,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Workload Time Series Cumulative Prediction Mechanism for Cloud Resources Using Neural Machine Translation Technique,"Dynamic resource allocation and auto-scaling represent effective solutions for many cloud challenges, such as over-provisioning (i.e., energy-wasting, and Service level Agreement â€œSLAâ€ violation) and under-provisioning (i.e., Quality of Service â€œQoSâ€ dropping) of resources. Early workload prediction techniques play an important role in the success of these solutions. Unfortunately, no prediction technique is perfect and suitable enough for most workloads, particularly in cloud environments. Statistical and machine learning techniques may not be appropriate for predicting workloads, due to instability and dependency of cloud resourcesâ€™ workloads. Although Recurrent Neural Network (RNN) deep learning technique considers these shortcomings, it provides poor results for long-term prediction. On the other hand, Sequence-to-Sequence neural machine translation technique (Seq2Seq) is effectively used for translating long texts. In this paper, workload sequence prediction is treated as a translation problem. Therefore, an Attention Seq2Seq-based technique is proposed for predicting cloud resourcesâ€™ workloads. To validate the proposed technique, real-world dataset collected from a Google cluster of 11 k machines is used. For improving the performance of the proposed technique, a novel procedure called cumulative-validation is proposed as an alternative procedure to cross-validation. Results show the effectiveness of the proposed technique for predicting workloads of cloud resources in terms of accuracy by 98.1% compared to 91% and 85% for other sequence-based techniques, i.e. Continuous Time Markov Chain based models and Long short-term memory based models, respectively. Also, the proposed cumulative-validation procedure achieves a computational time superiority of 57% less compared to the cross-validation with a slight variation of 0.006 in prediction accuracy.",dynamic resource allocation and auto scaling represent effective solutions for many cloud challenges  such as over provisioning  i e   energy wasting  and service level agreement    sla    violation  and under provisioning  i e   quality of service    qos    dropping  of resources  early workload prediction techniques play an important role in the success of these solutions  unfortunately  no prediction technique is perfect and suitable enough for most workloads  particularly in cloud environments  statistical and machine learning techniques may not be appropriate for predicting workloads  due to instability and dependency of cloud resources    workloads  although recurrent neural network  rnn  deep learning technique considers these shortcomings  it provides poor results for long term prediction  on the other hand  sequence to sequence neural machine translation technique  seq seq  is effectively used for translating long texts  in this paper  workload sequence prediction is treated as a translation problem  therefore  an attention seq seq based technique is proposed for predicting cloud resources    workloads  to validate the proposed technique  real world dataset collected from a google cluster of    k machines is used  for improving the performance of the proposed technique  a novel procedure called cumulative validation is proposed as an alternative procedure to cross validation  results show the effectiveness of the proposed technique for predicting workloads of cloud resources in terms of accuracy by       compared to     and     for other sequence based techniques  i e  continuous time markov chain based models and long short term memory based models  respectively  also  the proposed cumulative validation procedure achieves a computational time superiority of     less compared to the cross validation with a slight variation of       in prediction accuracy ,6.6738987,6.6742873,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Sentimental Analysis on Multi-domain Sentiment Dataset Using SVM and Naive Bayes Algorithm,"With the advent of the significant data era, people are confronted with the vast amount of information they receive each day. The quantity of information accrued and processed by Facebook, Twitter, and other significant social networks (such as Instagram) is vast. The Twitter platform encourages users to use 280 characters each to tweet their thoughts. Because tweets can use a limited number of characters, sentiment analysis becomes more accurate. Sentiment analysis is a technique for determining whether a text is positively, negatively, or neutral. Some experiments are conducted using Natural Language Processing Toolkit (NLTK) to determine whether a tweet has a neutral, positive, or negative polarity with accuracy. Moreover, by using NaÃ¯ve Bayes and SVM, the accuracy of the tweets is compared. Finally, the ROC curve will decide the efficiency of both algorithms.
 Keywords
 Twitter
 Social networks
 Sentiment analysis
 Machine Learning
 Natural Language Processing Toolkit (NLTK)
 NaÃ¯ve Bayes
 SVM",with the advent of the significant data era  people are confronted with the vast amount of information they receive each day  the quantity of information accrued and processed by facebook  twitter  and other significant social networks  such as instagram  is vast  the twitter platform encourages users to use     characters each to tweet their thoughts  because tweets can use a limited number of characters  sentiment analysis becomes more accurate  sentiment analysis is a technique for determining whether a text is positively  negatively  or neutral  some experiments are conducted using natural language processing toolkit  nltk  to determine whether a tweet has a neutral  positive  or negative polarity with accuracy  moreover  by using na  ve bayes and svm  the accuracy of the tweets is compared  finally  the roc curve will decide the efficiency of both algorithms   keywords  twitter  social networks  sentiment analysis  machine learning  natural language processing toolkit  nltk   na  ve bayes  svm,5.020293,5.6287065,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Particle swarm optimization and feature selection for intrusion detection system,"The network traffic in the intrusion detection system (IDS) has unpredictable behaviour due to the high computational power. The complexity of the system increases; thus, it is required to investigate the enormous number of features. However, the features that are inappropriate and (or) have some noisy data severely affect the performance of the IDSs. In this study, we have performed feature selection (FS) through a random forest algorithm for reducing irrelevant attributes. It makes the underlying task of intrusion detection effective and efficient. Later, a comparative study is carried through applying different classifiers, e.g., k Nearest Neighbour (k-NN), Support Vector Machine (SVM), Logistic Regression (LR), decision tree (DT) and Naive Bayes (NB) for measuring the different IDS metrics. The particle swarm optimization (PSO) algorithm was applied on the selective features of the NSL-KDD dataset, which cut down the false alarm rate and enhanced the detection rate and the accuracy of the IDS as compared with the mentioned state-of-the-art classifiers. This study includes the accuracy, precision, false-positive rate and the detection rate as performance metrics for the IDSs. The experimental results show low computational complexity, 99.32% efficiency and 99.26% detection rate on the selected features (=10) out of a complete set (= 41).",the network traffic in the intrusion detection system  ids  has unpredictable behaviour due to the high computational power  the complexity of the system increases  thus  it is required to investigate the enormous number of features  however  the features that are inappropriate and  or  have some noisy data severely affect the performance of the idss  in this study  we have performed feature selection  fs  through a random forest algorithm for reducing irrelevant attributes  it makes the underlying task of intrusion detection effective and efficient  later  a comparative study is carried through applying different classifiers  e g   k nearest neighbour  k nn   support vector machine  svm   logistic regression  lr   decision tree  dt  and naive bayes  nb  for measuring the different ids metrics  the particle swarm optimization  pso  algorithm was applied on the selective features of the nsl kdd dataset  which cut down the false alarm rate and enhanced the detection rate and the accuracy of the ids as compared with the mentioned state of the art classifiers  this study includes the accuracy  precision  false positive rate and the detection rate as performance metrics for the idss  the experimental results show low computational complexity         efficiency and        detection rate on the selected features       out of a complete set        ,3.4109292,5.829455,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
DLL: A Fast Deep Neural Network Library,"Deep Learning Library (DLL) is a library for machine learning with deep neural networks that focuses on speed. It supports feed-forward neural networks such as fully-connected Artificial Neural Networks (ANNs) and Convolutional Neural Networks (CNNs). Our main motivation for this work was to propose and evaluate novel software engineering strategies with potential to accelerate runtime for training and inferenceâ€˜. Such strategies are mostly independent of the underlying deep learning algorithms. On three different datasets and for four different neural network models, we compared DLL to five popular deep learning libraries. Experimentally, it is shown that the proposed library is systematically and significantly faster on CPU and GPU. In terms of classification performance, similar accuracies as the other libraries are reported.
 Keywords
 Deep Learning Library (DLL)
 Convolutional Neural Network (CNNs)
 Valid Convolution
 BLAS Library
 Fast Library
 These keywords were added by machine and not by the authors. This process is experimental and the keywords may be updated as the learning algorithm improves.",deep learning library  dll  is a library for machine learning with deep neural networks that focuses on speed  it supports feed forward neural networks such as fully connected artificial neural networks  anns  and convolutional neural networks  cnns   our main motivation for this work was to propose and evaluate novel software engineering strategies with potential to accelerate runtime for training and inference     such strategies are mostly independent of the underlying deep learning algorithms  on three different datasets and for four different neural network models  we compared dll to five popular deep learning libraries  experimentally  it is shown that the proposed library is systematically and significantly faster on cpu and gpu  in terms of classification performance  similar accuracies as the other libraries are reported   keywords  deep learning library  dll   convolutional neural network  cnns   valid convolution  blas library  fast library  these keywords were added by machine and not by the authors  this process is experimental and the keywords may be updated as the learning algorithm improves ,3.2313488,6.940253,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Clinical Natural Language Processing and Health Interoperability to Support Knowledge Management and Governance in Rare Cancers,"Traditional automation technologies alone are not sufficient to enable driverless operation of trains (called Grade of Automation (GoA) 4) on non-restricted infrastructure. The required perception tasks are nowadays realized using Machine Learning (ML) and thus need to be developed and deployed reliably and efficiently. One important aspect to achieve this is to use an MLOps process for tackling improved reproducibility, traceability, collaboration, and continuous adaptation of a driverless operation to changing conditions. MLOps mixes ML application development and operation (Ops) and enables high-frequency software releases and continuous innovation based on the feedback from operations. In this paper, we outline a safe MLOps process for the continuous development and safety assurance of ML-based systems in the railway domain. It integrates system engineering, safety assurance, and the ML life-cycle in a comprehensive workflow. We present the individual stages of the process and their interactions. Moreover, we describe relevant challenges to automate the different stages of the safe MLOps process.",traditional automation technologies alone are not sufficient to enable driverless operation of trains  called grade of automation  goa     on non restricted infrastructure  the required perception tasks are nowadays realized using machine learning  ml  and thus need to be developed and deployed reliably and efficiently  one important aspect to achieve this is to use an mlops process for tackling improved reproducibility  traceability  collaboration  and continuous adaptation of a driverless operation to changing conditions  mlops mixes ml application development and operation  ops  and enables high frequency software releases and continuous innovation based on the feedback from operations  in this paper  we outline a safe mlops process for the continuous development and safety assurance of ml based systems in the railway domain  it integrates system engineering  safety assurance  and the ml life cycle in a comprehensive workflow  we present the individual stages of the process and their interactions  moreover  we describe relevant challenges to automate the different stages of the safe mlops process ,7.969188,4.9084435,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Towards a Software Development Framework for Interconnected Science Ecosystems,"Agile software development embraces change and manifests working software over comprehensive documentation and responding to change over following a plan. The ability to continuously release software has enabled a development approach where experimental features are put to use, and, if they stand the test of real use, they remain in production. Examples of such features include machine learning (ML) models, which are usually pre-trained, but can still evolve in production. However, many domains require more plan-driven approach to avoid hazard to environment and humans, and to mitigate risks in the process. In this paper, we start by presenting continuous software engineering practices in a regulated context, and then apply the results to the emerging practice of MLOps, or continuous delivery of ML features. Furthermore, as a practical contribution, we present a case study regarding Oravizio, first CE-certified medical software for assessing the risks of joint replacement surgeries. Towards the end of the paper, we also reflect the Oravizio experiences to MLOps in regulatory context.",agile software development embraces change and manifests working software over comprehensive documentation and responding to change over following a plan  the ability to continuously release software has enabled a development approach where experimental features are put to use  and  if they stand the test of real use  they remain in production  examples of such features include machine learning  ml  models  which are usually pre trained  but can still evolve in production  however  many domains require more plan driven approach to avoid hazard to environment and humans  and to mitigate risks in the process  in this paper  we start by presenting continuous software engineering practices in a regulated context  and then apply the results to the emerging practice of mlops  or continuous delivery of ml features  furthermore  as a practical contribution  we present a case study regarding oravizio  first ce certified medical software for assessing the risks of joint replacement surgeries  towards the end of the paper  we also reflect the oravizio experiences to mlops in regulatory context ,9.357959,7.149718,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Adaptive Kevin: A Multipurpose AI Assistant for Higher Education,"In this chapter, we will cover the concepts behind the term â€œMLOpsâ€ and go over what it is, why itâ€™s useful, and how itâ€™s implemented.",in this chapter  we will cover the concepts behind the term    mlops    and go over what it is  why it   s useful  and how it   s implemented ,8.601711,6.600844,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
A branch-and-bound multi-parametric programming approach for non-convex multilevel optimization with polyhedral constraints,"In this paper we develop a general but smooth global optimization strategy for nonlinear multilevel programming problems with polyhedral constraints. At each decision level successive convex relaxations are applied over the non-convex terms in combination with a multi-parametric programming approach. The proposed algorithm reaches the approximate global optimum in a finite number of steps through the successive subdivision of the optimization variables that contribute to the non-convexity of the problem and partitioning of the parameter space. The method is implemented and tested for a variety of bilevel, trilevel and fifth level problems which have non-convexity formulation at their inner levels.",in this paper we develop a general but smooth global optimization strategy for nonlinear multilevel programming problems with polyhedral constraints  at each decision level successive convex relaxations are applied over the non convex terms in combination with a multi parametric programming approach  the proposed algorithm reaches the approximate global optimum in a finite number of steps through the successive subdivision of the optimization variables that contribute to the non convexity of the problem and partitioning of the parameter space  the method is implemented and tested for a variety of bilevel  trilevel and fifth level problems which have non convexity formulation at their inner levels ,2.9847336,8.133655,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Toward a safe MLOps process for the continuous development and safety assurance of ML-based systems in the railway domain,"Rare cancers are a significant public health challenge due to their low incidence and complex nature, resulting in limited knowledge and resources for patient care and research. To address this issue, we present a Rare Cancer Data Ecosystem that enables the re-use of existing health data sources for rare cancers across European healthcare systems. Its main goal is to leverage emerging interoperability technologies and artificial intelligence approaches to improve the quality and organization of rare cancer patient care and advance health research. The ecosystem will be developed and tested through an European multidisciplinary project that will cover a regulatory-compliant data governance approach, a standard-based reference architecture, and a set of technical tools to share data, while ensuring data sovereignty policies. We aim to take part to the European Healthcare Data Space by contributing to an open, transparent digital ecosystem. Natural language processing and understanding tools will allow the extraction of health information stored in text form and support data findability and reusability. It will also include a secure pipeline for machine learning models development and deployment in a secure and reliable manner. The ecosystem will also include an augmented analytics and multimodal data navigator, providing a more natural and intuitive experience for users to explore and analyze rare cancer data. Overall, these features, after being piloted with several rare cancer data sources across different countries, will enable the efficient and secure use of existing health data sources for rare cancers, which can lead to improved patient care and health research.
 Keywords
 Rare cancers
 Data governance
 Federated learning",rare cancers are a significant public health challenge due to their low incidence and complex nature  resulting in limited knowledge and resources for patient care and research  to address this issue  we present a rare cancer data ecosystem that enables the re use of existing health data sources for rare cancers across european healthcare systems  its main goal is to leverage emerging interoperability technologies and artificial intelligence approaches to improve the quality and organization of rare cancer patient care and advance health research  the ecosystem will be developed and tested through an european multidisciplinary project that will cover a regulatory compliant data governance approach  a standard based reference architecture  and a set of technical tools to share data  while ensuring data sovereignty policies  we aim to take part to the european healthcare data space by contributing to an open  transparent digital ecosystem  natural language processing and understanding tools will allow the extraction of health information stored in text form and support data findability and reusability  it will also include a secure pipeline for machine learning models development and deployment in a secure and reliable manner  the ecosystem will also include an augmented analytics and multimodal data navigator  providing a more natural and intuitive experience for users to explore and analyze rare cancer data  overall  these features  after being piloted with several rare cancer data sources across different countries  will enable the efficient and secure use of existing health data sources for rare cancers  which can lead to improved patient care and health research   keywords  rare cancers  data governance  federated learning,10.095446,6.4684997,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Towards Regulatory-Compliant MLOps: Oravizioâ€™s Journey from a Machine Learning Experiment to a Deployed Certified Medical Product,"The innovative science of the future must be multi-domain and interconnected to usher in the next generation of â€œself-drivingâ€ laboratories enabling consequential discoveries and transformative inventions. Such a disparate and interconnected ecosystem of scientific instruments will need to evolve using a system-of-systems (SoS) approach. The key to enabling application integration with such an SoS will be the use of Software Development Kits (SDKs). Currently, SDKs facilitate scientific research breakthroughs via algorithmic automation, databases and storage, optimization and structure, pervasive environmental monitoring, among others. However, existing SDKs lack instrument-interoperability and reusability capabilities, do not effectively work in an open federated architectural environment, and are largely isolated within silos of the respective scientific disciplines. Inspired by the scalable SoS framework, this work proposes the development of INTERSECT-SDK to provide a coherent environment for multi-domain scientific applications to benefit from the open federated architecture in an interconnected ecosystem of instruments. This approach will decompose functionality into loosely coupled software services for interoperability among several solutions that do not scale beyond a single domain and/or application. Furthermore, the proposed environment will allow operational and managerial inter-dependence while providing opportunities for the researchers to reuse software components from other domains and build universal solution libraries. We demonstrate this research for microscopy use-case, where we show how INTERSECT-SDK is developing the tools necessary to enable advanced scanning methods and accelerate scientific discovery.
 Keywords
 Autonomous experiments
 SDK
 DevSecOps
 Interconnected science
 Edge computing
 Research infrastructure
 Scientific software
 Scientific workflows
 Federated instruments
 Digital twins",the innovative science of the future must be multi domain and interconnected to usher in the next generation of    self driving    laboratories enabling consequential discoveries and transformative inventions  such a disparate and interconnected ecosystem of scientific instruments will need to evolve using a system of systems  sos  approach  the key to enabling application integration with such an sos will be the use of software development kits  sdks   currently  sdks facilitate scientific research breakthroughs via algorithmic automation  databases and storage  optimization and structure  pervasive environmental monitoring  among others  however  existing sdks lack instrument interoperability and reusability capabilities  do not effectively work in an open federated architectural environment  and are largely isolated within silos of the respective scientific disciplines  inspired by the scalable sos framework  this work proposes the development of intersect sdk to provide a coherent environment for multi domain scientific applications to benefit from the open federated architecture in an interconnected ecosystem of instruments  this approach will decompose functionality into loosely coupled software services for interoperability among several solutions that do not scale beyond a single domain and or application  furthermore  the proposed environment will allow operational and managerial inter dependence while providing opportunities for the researchers to reuse software components from other domains and build universal solution libraries  we demonstrate this research for microscopy use case  where we show how intersect sdk is developing the tools necessary to enable advanced scanning methods and accelerate scientific discovery   keywords  autonomous experiments  sdk  devsecops  interconnected science  edge computing  research infrastructure  scientific software  scientific workflows  federated instruments  digital twins,9.271562,3.6861308,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
What Is MLOps?,"We present an innovative open domain question-answering (ODQA) intelligent workflow architecture that combines a fine-tuned retriever-reader model with a generative question-answering model with Google search functionality capable of answering questions both within and outside the scope of the domain represented by the documents indexed by the retriever. The retriever-reader architecture acts as the default responder, but if the question is outside of its scope or if its confidence score falls below a predefined threshold, the workflow logic triggers the execution of the generative model that reaches out to Google to formulate an answer. The paper describes the proposed workflow architecture, provides a quantitative evaluation of the retriever-reader performance and demonstrates the systemâ€™s flow of execution through several use cases. The paper will be of interest to both researchers and practitioners interested in deploying modern AI-driven ODQA systems.
 Keywords
 Deep learning
 Natural language processing
 Transformers
 AI in higher-education
 Open domain question-answering
 ELECTRA
 Conversational AI
 Adaptive architectures
 Information retrieval",we present an innovative open domain question answering  odqa  intelligent workflow architecture that combines a fine tuned retriever reader model with a generative question answering model with google search functionality capable of answering questions both within and outside the scope of the domain represented by the documents indexed by the retriever  the retriever reader architecture acts as the default responder  but if the question is outside of its scope or if its confidence score falls below a predefined threshold  the workflow logic triggers the execution of the generative model that reaches out to google to formulate an answer  the paper describes the proposed workflow architecture  provides a quantitative evaluation of the retriever reader performance and demonstrates the system   s flow of execution through several use cases  the paper will be of interest to both researchers and practitioners interested in deploying modern ai driven odqa systems   keywords  deep learning  natural language processing  transformers  ai in higher education  open domain question answering  electra  conversational ai  adaptive architectures  information retrieval,11.113584,5.9535813,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Simulated Annealing,"Simulated annealing (SA) is a well-known local search metaheuristic for finding high-quality solutions to both discrete and continuous optimization problems. The algorithm was first proposed and used in statistical mechanics by Metropolis et al. (J Chem Phys 21:1087-1092, 1953). Yet, not until Kirkpatrick et al. (Science 220:671-680, 1983) and Cerny (J Optim Theory Appl 45:41â€“52, 1985) was SA implemented as a heuristic for a notoriously hard combinatorial optimization problem â€“ the traveling salesman problem. Since then, SA has been successfully applied across a broad range of application areas such as finance, machine learning, operations research, etc., where the associated optimization problems can be computationally intractable for large problem instances. In these situations, SA is a serious contender as a convenient, yet effective, optimization tool as it requires no knowledge of the problem structure. Indeed, the key advantage of SA is in its simplicity, which facilitates quick implementation for solving many real-life applications.",simulated annealing  sa  is a well known local search metaheuristic for finding high quality solutions to both discrete and continuous optimization problems  the algorithm was first proposed and used in statistical mechanics by metropolis et al   j chem phys                      yet  not until kirkpatrick et al   science                    and cerny  j optim theory appl                   was sa implemented as a heuristic for a notoriously hard combinatorial optimization problem     the traveling salesman problem  since then  sa has been successfully applied across a broad range of application areas such as finance  machine learning  operations research  etc   where the associated optimization problems can be computationally intractable for large problem instances  in these situations  sa is a serious contender as a convenient  yet effective  optimization tool as it requires no knowledge of the problem structure  indeed  the key advantage of sa is in its simplicity  which facilitates quick implementation for solving many real life applications ,2.5776796,7.7043157,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
RETRACTED ARTICLE: Artificial intelligence-based agriculture automated monitoring systems using WSN,"In this current era, the influence of AI (Artificial Intelligence) is becoming vital for many unsolved problems and to make intelligent solutions. This paper represents the potential of AI in the field of analyzing and implementing the intelligence in agriculture automation using the data collected from the WSN (Wireless Sensor Network) technology. This could help in making improved intelligent decisions. The application of WSN includes collecting, accounting, and analyzing data, which can be used for the process of monitoring the agriculture and its automation inhabitant activities. The method of agriculture automation includes sensors that can be able to measure the humidity, moisture, pressure in the atmosphere, PH level in the water or soil, and more. Enhancing the AI with the help of machine learning algorithm to enable intelligence in the automation will conserve many natural resources such as the consumption of the water, quality of soil/his intelligence will help the agriculturist in many ways. Here various machine-learning algorithms (Artificial Neural Networksâ€”ANN) are tested for selecting a rightful systematic architecture for the process. In this work, it is found that the ANN named GRNN (Generalized Regression Neural Network) is best suited. Through these algorithmic formations, the system can able to produce 95% accuracy when compared to other systems. By using this automated system water is saved of up to 92% and produce a good yield compared with old irrigation systems.",in this current era  the influence of ai  artificial intelligence  is becoming vital for many unsolved problems and to make intelligent solutions  this paper represents the potential of ai in the field of analyzing and implementing the intelligence in agriculture automation using the data collected from the wsn  wireless sensor network  technology  this could help in making improved intelligent decisions  the application of wsn includes collecting  accounting  and analyzing data  which can be used for the process of monitoring the agriculture and its automation inhabitant activities  the method of agriculture automation includes sensors that can be able to measure the humidity  moisture  pressure in the atmosphere  ph level in the water or soil  and more  enhancing the ai with the help of machine learning algorithm to enable intelligence in the automation will conserve many natural resources such as the consumption of the water  quality of soil his intelligence will help the agriculturist in many ways  here various machine learning algorithms  artificial neural networks   ann  are tested for selecting a rightful systematic architecture for the process  in this work  it is found that the ann named grnn  generalized regression neural network  is best suited  through these algorithmic formations  the system can able to produce     accuracy when compared to other systems  by using this automated system water is saved of up to     and produce a good yield compared with old irrigation systems ,4.963706,4.9342203,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
A new approximate query engine based on intelligent capture and fast transformations of granulated data summaries,We outline the processes of intelligent creation and utilization of granulated data summaries in the engine aimed at fast approximate execution of analytical SQL statements. We discuss how to use the introduced engine for the purposes of ad-hoc data exploration over large and quickly increasing data collected in a heterogeneous or distributed fashion. We focus on mechanisms that transform input data summaries into result sets representing query outcomes. We also illustrate how our computational principles can be put together with other paradigms of scaling and harnessing data analytics.,we outline the processes of intelligent creation and utilization of granulated data summaries in the engine aimed at fast approximate execution of analytical sql statements  we discuss how to use the introduced engine for the purposes of ad hoc data exploration over large and quickly increasing data collected in a heterogeneous or distributed fashion  we focus on mechanisms that transform input data summaries into result sets representing query outcomes  we also illustrate how our computational principles can be put together with other paradigms of scaling and harnessing data analytics ,8.521807,7.5998254,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
From the Glass House to the Hive: The Private Sphere in the Era of Intelligent Home Assistant Robots,"This paper introduces a re-conceptualization of the private sphere, following the presence inside the house of intelligent personal assistant robots that observe and act through sensors and actuators, and aggregate the data collected in the Cloud. This processing inserts the personal sphere of individuals into a complex and multi-layered informational structure, a â€œhiveâ€ of private spheres. An abstract model, named Aggregated Privateness Model, is presented herein to explain the dynamics of the â€œhiveâ€. It sheds new light on a more collective dimension of â€˜privateâ€™, a dimension which represents a context by itself, with normative mathematical rules and in which the expectations of privacy of individuals can be infringed based on the uses made of aggregated data. The Model also highlights how the behaviour of the individuals can influence the other private spheres in the cluster, as well as the Aggregation itself, due to a network effect, and how Diffused Network Liability could help compensating for such influences without incurring into practical impossibility.
 Keywords
 Privacy
 Robotics
 Artificial intelligence
 Big data",this paper introduces a re conceptualization of the private sphere  following the presence inside the house of intelligent personal assistant robots that observe and act through sensors and actuators  and aggregate the data collected in the cloud  this processing inserts the personal sphere of individuals into a complex and multi layered informational structure  a    hive    of private spheres  an abstract model  named aggregated privateness model  is presented herein to explain the dynamics of the    hive     it sheds new light on a more collective dimension of    private     a dimension which represents a context by itself  with normative mathematical rules and in which the expectations of privacy of individuals can be infringed based on the uses made of aggregated data  the model also highlights how the behaviour of the individuals can influence the other private spheres in the cluster  as well as the aggregation itself  due to a network effect  and how diffused network liability could help compensating for such influences without incurring into practical impossibility   keywords  privacy  robotics  artificial intelligence  big data,6.428451,6.9460435,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
To Control or Not Control: A Coordination Perspective to Scaling,"In this chapter, we assess the link between scaling, control and organizational achievements. We argue that control is essential to coordinate organizational members towards a common and shared goal and to provide guardrails for scaling. We use the experience of the Aravind Eye Care System, a non-profit organization based in India providing eye care services to poor people to specify the mechanisms employed by Aravind underpinning three popular organizational scaling modesâ€”branching, affiliation and dissemination. Our objective is to show how control and scaling can be combined in order to protect the value base of a social enterprise and at the same time ensure growth.
 Keywords
 Social enterprise
 Scaling
 Coordination
 Control",in this chapter  we assess the link between scaling  control and organizational achievements  we argue that control is essential to coordinate organizational members towards a common and shared goal and to provide guardrails for scaling  we use the experience of the aravind eye care system  a non profit organization based in india providing eye care services to poor people to specify the mechanisms employed by aravind underpinning three popular organizational scaling modes   branching  affiliation and dissemination  our objective is to show how control and scaling can be combined in order to protect the value base of a social enterprise and at the same time ensure growth   keywords  social enterprise  scaling  coordination  control,9.998576,7.104674,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
A big data analytical framework for analyzing solar energy receptors using evolutionary computing approach,"Data science has been empowered with the emerging concept of big data enabling data scalability in many ways. Effective prediction systems for complex analytical problems dealing with big data can be created using evolutionary computing, associate feature selection and reduction techniques. In the current work, we put forward a big data analytical scheme to analyze solar energy receptors based on a set of features. Correct estimation of pressure loss coefficients (PLC) greatly improves the design of a solar collector. Evaluation of PLC is a time and resource consuming process as the flow rate and Reynolds number changes at every junction. Moreover, a suitable and appropriate algebraic expression is not yet defined in the laminar region of flow for approximation of the complex relationship among different geometrical features and flow variables. The overall heat gain of the solar receptor is dependent upon flow rates and flow distribution in risers. Also, the local disturbances during the flow division and combining process from manifold to risers affects the performance of the solar collector. Owing to these reasons, mostly they are calculated using experiments, primarily due to the complexity involved. The proposed big data framework involves acquiring huge feature sets at each point along the flow of thermal fluid. The data is experimentally acquired in a set of around forty features for large number of Reynolds number and discharge ratio variations. Reynolds number varies from 200 to 15,000 while discharge ratio variation is in the range of 0â€“1. Feature reduction in the big data set is done by calculating the relevancy score using ReliefF algorithm that extracts the most relevant features. Later, the framework employs a suitably selected optimal ANN architecture of layers, neurons and activation functions. The selected topology is trained using reduced features sets using Levenbergâ€“Marquardt backpropagation algorithm. Test and validation results bespeaks the efficacy of the proposed strategy and indicate that future PLC values can be forecasted close to experimental data. The relative percent error is around 10% of the experimental data set and is found better than computational fluid dynamics based approaches in terms of memory and processing time.",data science has been empowered with the emerging concept of big data enabling data scalability in many ways  effective prediction systems for complex analytical problems dealing with big data can be created using evolutionary computing  associate feature selection and reduction techniques  in the current work  we put forward a big data analytical scheme to analyze solar energy receptors based on a set of features  correct estimation of pressure loss coefficients  plc  greatly improves the design of a solar collector  evaluation of plc is a time and resource consuming process as the flow rate and reynolds number changes at every junction  moreover  a suitable and appropriate algebraic expression is not yet defined in the laminar region of flow for approximation of the complex relationship among different geometrical features and flow variables  the overall heat gain of the solar receptor is dependent upon flow rates and flow distribution in risers  also  the local disturbances during the flow division and combining process from manifold to risers affects the performance of the solar collector  owing to these reasons  mostly they are calculated using experiments  primarily due to the complexity involved  the proposed big data framework involves acquiring huge feature sets at each point along the flow of thermal fluid  the data is experimentally acquired in a set of around forty features for large number of reynolds number and discharge ratio variations  reynolds number varies from     to        while discharge ratio variation is in the range of        feature reduction in the big data set is done by calculating the relevancy score using relieff algorithm that extracts the most relevant features  later  the framework employs a suitably selected optimal ann architecture of layers  neurons and activation functions  the selected topology is trained using reduced features sets using levenberg   marquardt backpropagation algorithm  test and validation results bespeaks the efficacy of the proposed strategy and indicate that future plc values can be forecasted close to experimental data  the relative percent error is around     of the experimental data set and is found better than computational fluid dynamics based approaches in terms of memory and processing time ,3.9005375,3.4577737,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Emerging Interconnect Technologies for Integrated Circuits and Flexible Electronics,"The chapter examines the latest advancements in electronic interconnect technologies and their effects on system design. It discusses the increasing need for advanced interconnect technologies in catering to faster data transfer, advanced image processing, and stronger computing power, emphasizing the significance of integrating various components into one device. The chapter also analyzes current trends in chip-packages, circuit boards, cables, and connectors, and their contribution to the electronic industry's growth. A brief overview on the trends in the technologies pertaining to high-speed serializer/deserializer, memory and printed/flexible electronics is presented. The chapter offers a comprehensive overview of the most significant trends and advancements in high-speed electronics, making it an indispensable resource for designers and engineers in the field.
 Keywords
 High-speed
 Data Rate
 Chip
 Package
 Connector
 Cable
 Printed Circuit Board",the chapter examines the latest advancements in electronic interconnect technologies and their effects on system design  it discusses the increasing need for advanced interconnect technologies in catering to faster data transfer  advanced image processing  and stronger computing power  emphasizing the significance of integrating various components into one device  the chapter also analyzes current trends in chip packages  circuit boards  cables  and connectors  and their contribution to the electronic industry s growth  a brief overview on the trends in the technologies pertaining to high speed serializer deserializer  memory and printed flexible electronics is presented  the chapter offers a comprehensive overview of the most significant trends and advancements in high speed electronics  making it an indispensable resource for designers and engineers in the field   keywords  high speed  data rate  chip  package  connector  cable  printed circuit board,9.921072,7.7766466,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Big Data Streaming with Spark,"A stream is defined as continuously arriving unbounded data. Analytics of such real-time data has become an utmost necessity. This evolution required a technology capable of efficient computing of data distributed over several clusters. Current parallelized streaming systems lacked consistency, faced difficulty in combining historical data with streaming data, and handling slow nodes. These needs resulted in the birth of Apache Spark API that provides a framework which enables such scalable, error tolerant streaming with high throughput. This chapter introduces many concepts associated with Spark Streaming, including a discussion of supported operations. Finally, two other important platforms and their integration with Spark, namely Apache Kafka and Amazon Kinesis are explored.
 Keywords
 Spark streaming
 D-Streams
 RDD
 Operations
 Structured streaming
 Kafka
 Kinesis
 Pipeline
 Integration with spark",a stream is defined as continuously arriving unbounded data  analytics of such real time data has become an utmost necessity  this evolution required a technology capable of efficient computing of data distributed over several clusters  current parallelized streaming systems lacked consistency  faced difficulty in combining historical data with streaming data  and handling slow nodes  these needs resulted in the birth of apache spark api that provides a framework which enables such scalable  error tolerant streaming with high throughput  this chapter introduces many concepts associated with spark streaming  including a discussion of supported operations  finally  two other important platforms and their integration with spark  namely apache kafka and amazon kinesis are explored   keywords  spark streaming  d streams  rdd  operations  structured streaming  kafka  kinesis  pipeline  integration with spark,8.927528,7.453455,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
K-Means Clustering and Iterative Calculation,"This is our last chapter. Hopefully we have become more and more familiar with Excel. We should have realized that under every main tab, there are quite a few icon groups, each presenting some quick-access tools or features. For example, under the Home tab, there are groups Font, Alignment, Number, Styles, Editing, etc. We can find that under the Formulas tab, the Function Library group organizes functions into different categories including Financial, Logical, Text, Date & Time, Lookup & Reference, and Math & Trig. This Function Library group also lists those Recently Used functions and some other More Functions. Remember that Excel is adding more and more functions, and for general purpose, it is very likely that Excel has all the functions we need for our projects. The same understanding applies to Excelâ€™s built-in features, that is, Excel is likely to have all the built-in features we need.",this is our last chapter  hopefully we have become more and more familiar with excel  we should have realized that under every main tab  there are quite a few icon groups  each presenting some quick access tools or features  for example  under the home tab  there are groups font  alignment  number  styles  editing  etc  we can find that under the formulas tab  the function library group organizes functions into different categories including financial  logical  text  date   time  lookup   reference  and math   trig  this function library group also lists those recently used functions and some other more functions  remember that excel is adding more and more functions  and for general purpose  it is very likely that excel has all the functions we need for our projects  the same understanding applies to excel   s built in features  that is  excel is likely to have all the built in features we need ,9.57243,6.752837,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
SVRCI: An Approach for Semantically Driven Video Recommendation Incorporating Collective Intelligence,"In the modern era, the recommendation of educational resources, specifically in the form of videos, is a needful task. This paper proposes an SVRCI framework for education video recommendation. It is a query-centric knowledge-driven paradigm where the query terms are enriched by loading knowledge graphs from Googleâ€™s knowledge graph (KG) API and subjecting it to structural topic modeling for aggregating relevant topics. Ontology alignment is also achieved to enrich much more relevant auxiliary knowledge. Cosine similarity, Twitter semantic similarity, and concept similarity are the three semantic similarity measures encompassed with differential thresholds for data point selection. The dataset is classified using a solid deep learning GRU classifier and the logistic regression feature control machine learning classifier. The education videos are recommended based on categories or the annotations appended to the videos in the dataset. Overall average precision of 95.66%, accuracy of 96.23%, F-measure of 96.23% and an nDCG of 0.99 has been achieved by this framework.
 Keywords
 Video recommendation
 Collective intelligence
 Semantic similarity
 GRU
 Logistic regression",in the modern era  the recommendation of educational resources  specifically in the form of videos  is a needful task  this paper proposes an svrci framework for education video recommendation  it is a query centric knowledge driven paradigm where the query terms are enriched by loading knowledge graphs from google   s knowledge graph  kg  api and subjecting it to structural topic modeling for aggregating relevant topics  ontology alignment is also achieved to enrich much more relevant auxiliary knowledge  cosine similarity  twitter semantic similarity  and concept similarity are the three semantic similarity measures encompassed with differential thresholds for data point selection  the dataset is classified using a solid deep learning gru classifier and the logistic regression feature control machine learning classifier  the education videos are recommended based on categories or the annotations appended to the videos in the dataset  overall average precision of         accuracy of         f measure of        and an ndcg of      has been achieved by this framework   keywords  video recommendation  collective intelligence  semantic similarity  gru  logistic regression,4.6014695,6.8111577,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Portfolio design for home healthcare devices production using a new data-driven optimization methodology,"Covid-19 pandemic left scars on different industries, and now that we are experiencing the post-pandemic situation, it is essential to plan our next moves. When it comes to home healthcare devices (HHDs), they can be useful in many aspects such as keeping the patients safe at the home. Nowadays, the world is experiencing the post-pandemic situation, then it is needed to adapt to new circumstances as it was done during the pandemic. One of the factors that has been impacted by the new situation is the demand for HHDs which had been increased tremendously during the pandemic. The current study aims to forecast the so-called demand by utilizing machine learning techniques to design a product portfolio considering the shortage cost by benefiting from the Bayesian Bestâ€“Worst method (BBWM). A mixed-integer non-linear mathematical model is proposed to reach this goal which designs a portfolio of devices and determines the number of needed machines to produce them. An HHD manufacturing factory has been considered as a real-life case study to approve the functionality of the proposed methodology. Several businesses that have experienced post-pandemic demand fluctuations may benefit from the findings of this study.",covid    pandemic left scars on different industries  and now that we are experiencing the post pandemic situation  it is essential to plan our next moves  when it comes to home healthcare devices  hhds   they can be useful in many aspects such as keeping the patients safe at the home  nowadays  the world is experiencing the post pandemic situation  then it is needed to adapt to new circumstances as it was done during the pandemic  one of the factors that has been impacted by the new situation is the demand for hhds which had been increased tremendously during the pandemic  the current study aims to forecast the so called demand by utilizing machine learning techniques to design a product portfolio considering the shortage cost by benefiting from the bayesian best   worst method  bbwm   a mixed integer non linear mathematical model is proposed to reach this goal which designs a portfolio of devices and determines the number of needed machines to produce them  an hhd manufacturing factory has been considered as a real life case study to approve the functionality of the proposed methodology  several businesses that have experienced post pandemic demand fluctuations may benefit from the findings of this study ,8.8087435,3.3939877,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Real-Time Traffic Counter Using Mobile Devices,"Automatic traffic counting and classification (ATCC) is a salient step in many applications such as accessing the contribution of traffic to air pollution for clean air strategies and computing the passenger car unit (PCU) for urban road infrastructure planning and management. This work focuses on developing an ATCC system that is low cost, privacy-preserving, and auditable using state-of-the-art AI technology on mobile phones. The camera unit and the GPU compute available within a mobile phone are used to capture the video feed and run the required analytics for detection, tracking and counting in real time. On the target device, we have been able to achieve 12 FPS. On the test data composed of four videos, the solution achieved a counting precision and recall of 0.96 Â± 0.02 and 0.86 Â± 0.03, respectively.",automatic traffic counting and classification  atcc  is a salient step in many applications such as accessing the contribution of traffic to air pollution for clean air strategies and computing the passenger car unit  pcu  for urban road infrastructure planning and management  this work focuses on developing an atcc system that is low cost  privacy preserving  and auditable using state of the art ai technology on mobile phones  the camera unit and the gpu compute available within a mobile phone are used to capture the video feed and run the required analytics for detection  tracking and counting in real time  on the target device  we have been able to achieve    fps  on the test data composed of four videos  the solution achieved a counting precision and recall of              and               respectively ,3.6607606,5.9327397,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Profiling and Cybersecurity: A Perspective from Fundamental Rightsâ€™ Protection in the EU,"In this text we will be assessing to what extent personal data protection is related to the development of AI systems, as well as testing to what extent the General Data Protection Regulation (GDPR) (Regulation 2016/679 of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC.) enables the defense of individuals in the face of some AI applicationsâ€”especially with regard to profiling and automated decisions. Considering the GDPR regulates the processing of data of an identified or identifiable natural person, it would apply when AI systems are building on everyoneâ€™s data, as well as when such systems are used to analyze data and produce inferences on individuals (Datatilsynet - The Norwegian Data Protection Authority, Artificial intelligence and privacy, Report: Oslo, 2018). Herein lies the problem of the opacity of inferences or predictions resulting from data analysis by AI systemsâ€”inferences whose application to everyday situations determines how each of us, as personal data subjects, are perceived and evaluated by others. It is important to assess the existence of legal remedies to challenge operations that result in automated inferences that are not reasonably justified. Thus, we intend to clarify whether the GDPR adequately protects inferred data, in the light of the fundamental right to the protection of personal data provided in Article 8 of the Charter of Fundamental Rights of the European Union (CFREU), under penalty of violating our insusceptibility to instrumentalization and objectificationâ€”in other words, human dignity itself.
 Keywords
 Fundamental right to the protection of personal data
 Profiling
 Automated decisions
 Inferred data
 Article 22 GDPR",in this text we will be assessing to what extent personal data protection is related to the development of ai systems  as well as testing to what extent the general data protection regulation  gdpr   regulation          of    april      on the protection of natural persons with regard to the processing of personal data and on the free movement of such data  and repealing directive       ec   enables the defense of individuals in the face of some ai applications   especially with regard to profiling and automated decisions  considering the gdpr regulates the processing of data of an identified or identifiable natural person  it would apply when ai systems are building on everyone   s data  as well as when such systems are used to analyze data and produce inferences on individuals  datatilsynet   the norwegian data protection authority  artificial intelligence and privacy  report  oslo         herein lies the problem of the opacity of inferences or predictions resulting from data analysis by ai systems   inferences whose application to everyday situations determines how each of us  as personal data subjects  are perceived and evaluated by others  it is important to assess the existence of legal remedies to challenge operations that result in automated inferences that are not reasonably justified  thus  we intend to clarify whether the gdpr adequately protects inferred data  in the light of the fundamental right to the protection of personal data provided in article   of the charter of fundamental rights of the european union  cfreu   under penalty of violating our insusceptibility to instrumentalization and objectification   in other words  human dignity itself   keywords  fundamental right to the protection of personal data  profiling  automated decisions  inferred data  article    gdpr,11.898178,6.4394603,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
A hybrid quantum feature selection algorithm using a quantum inspired graph theoretic approach,"Quantum machine learning bridges the gap between abstract developments in quantum computing and the applied research on machine learning. It generally exposes the synthesis of important machine learning algorithms in a quantum framework. Dimensionality reduction of a dataset with a suitable feature selection strategy is one of the most important tasks in knowledge discovery and data mining. The efficient feature selection strategy helps to improve the overall accuracy of a large dataset in terms of machine learning operations. In this paper, a quantum feature selection algorithm using a graph-theoretic approach has been proposed. The proposed algorithm has used the concept of correlation coefficient based graph-theoretic classical approach initially and then applied the quantum Oracle with CNOT operation to verify whether the dataset is suitable for dimensionality reduction or not. If it is suitable, then our algorithm can efficiently estimate their high correlation values by using quantum parallel amplitude estimation and amplitude amplification techniques. This paper also shows that our proposed algorithm substantially outperforms than some popular classical feature selection algorithms for supervised classification in terms of query complexity of \(O(\frac {k\sqrt {N_{c}^{(k)}N_{f}^{(k)}}}{\epsilon })\), where N is the size of the feature vectors whose values are â©¾ THmin(minimum threshold), k is the number of iterations and where ðœ– is the error for estimating those feature vectors. Compared with the classical counterpart, i.e. the performance of our quantum algorithm quadratically improves than others.",quantum machine learning bridges the gap between abstract developments in quantum computing and the applied research on machine learning  it generally exposes the synthesis of important machine learning algorithms in a quantum framework  dimensionality reduction of a dataset with a suitable feature selection strategy is one of the most important tasks in knowledge discovery and data mining  the efficient feature selection strategy helps to improve the overall accuracy of a large dataset in terms of machine learning operations  in this paper  a quantum feature selection algorithm using a graph theoretic approach has been proposed  the proposed algorithm has used the concept of correlation coefficient based graph theoretic classical approach initially and then applied the quantum oracle with cnot operation to verify whether the dataset is suitable for dimensionality reduction or not  if it is suitable  then our algorithm can efficiently estimate their high correlation values by using quantum parallel amplitude estimation and amplitude amplification techniques  this paper also shows that our proposed algorithm substantially outperforms than some popular classical feature selection algorithms for supervised classification in terms of query complexity of   o  frac  k sqrt  n  c    k  n  f    k      epsilon       where n is the size of the feature vectors whose values are     thmin minimum threshold   k is the number of iterations and where      is the error for estimating those feature vectors  compared with the classical counterpart  i e  the performance of our quantum algorithm quadratically improves than others ,4.490723,7.160371,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
"Fintech, Chain Transactions and Open Banking","This chapter shows that networks widely distribute both big data and fintech applications, allowing fintech firms to execute their activities all around the world. Furthermore, the unbundling of the intermediation process into chains of transactions is leading banking and financial activities outside the scope of supervision. Thus, this chapter investigates the reason fintech applications do not appear to be regulatory-neutral. It also investigates the â€˜acts of fintechâ€™ and the responsibility of individuals in developing network of operations and concludes by assessing the current need for transparency, with regard to both the circulation of financial information in the market and the mitigation of the bargaining power in bilateral transactions.
 Keywords
 Big data
 Open banking
 Unbundling
 Crowdfunding
 Crowd lending
 Fintech chains",this chapter shows that networks widely distribute both big data and fintech applications  allowing fintech firms to execute their activities all around the world  furthermore  the unbundling of the intermediation process into chains of transactions is leading banking and financial activities outside the scope of supervision  thus  this chapter investigates the reason fintech applications do not appear to be regulatory neutral  it also investigates the    acts of fintech    and the responsibility of individuals in developing network of operations and concludes by assessing the current need for transparency  with regard to both the circulation of financial information in the market and the mitigation of the bargaining power in bilateral transactions   keywords  big data  open banking  unbundling  crowdfunding  crowd lending  fintech chains,10.439016,7.9349365,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Assessment of computational approaches in the prediction of spectrogram and chromatogram behaviours of analytes in pharmaceutical analysis: assessment review,"Background
 Today, artificial intelligence-based computational approach is facilitating multitasking and interdisciplinary analytical research. For example, the data gathered during an analytical research project such as spectral and chromatographic data can be used in predictive experimental research. The spectral and chromatographic information plays crucial role in pharmaceutical research, especially use of instrumental analytical approaches and it consume time, man power, and money. Hence, predictive analysis would be beneficial especially in resource-limited settings.
 Main body
 Computational approaches verify data at an early phase of study in research process. Several in silico techniques for predicting analyteâ€™s spectral and chromatographic characteristics have recently been developed. Understanding of these tools may help researchers to accelerate their research with boosted confidence and prevent researchers from being misled by incorrect analytical data. In this communication, the properties of chemical compounds and its relation to chromatographic retention will be discussed, as well as the prediction technique for UV/IR/Raman/NMR spectrograms. This review looked at the reference data of chemical compounds to compare the predictive ability in silico tools along with the percentage error, limitations, and advantages.
 Conclusion
 The computational prediction of analytical characteristics offers a wide range of applications in academic research, bioanalytical method development, computational chemistry, analytical method development, data analysis approaches, material characterization, and validation process.",background  today  artificial intelligence based computational approach is facilitating multitasking and interdisciplinary analytical research  for example  the data gathered during an analytical research project such as spectral and chromatographic data can be used in predictive experimental research  the spectral and chromatographic information plays crucial role in pharmaceutical research  especially use of instrumental analytical approaches and it consume time  man power  and money  hence  predictive analysis would be beneficial especially in resource limited settings   main body  computational approaches verify data at an early phase of study in research process  several in silico techniques for predicting analyte   s spectral and chromatographic characteristics have recently been developed  understanding of these tools may help researchers to accelerate their research with boosted confidence and prevent researchers from being misled by incorrect analytical data  in this communication  the properties of chemical compounds and its relation to chromatographic retention will be discussed  as well as the prediction technique for uv ir raman nmr spectrograms  this review looked at the reference data of chemical compounds to compare the predictive ability in silico tools along with the percentage error  limitations  and advantages   conclusion  the computational prediction of analytical characteristics offers a wide range of applications in academic research  bioanalytical method development  computational chemistry  analytical method development  data analysis approaches  material characterization  and validation process ,3.7466486,2.9112768,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
"From Selecting Best Algorithm to Explaining Why It is: A General Review, Formal Problem Statement and Guidelines Towards to an Empirical Generalization","It has been observed on solution algorithms for problems as sorting, forecasting, classification, clustering, constraint satisfaction, decision, optimization from several disciplines (computational complexity theory, data mining, artificial intelligence, machine learning, operations research) that algorithm performance is better in certain problem instances than other. This paper describes how has been the way for trying to reach the empirical generalization for this phenomenon existing in the experimental relation problem â€“ algorithm. For each understanding level, research questions, problem description were formulated, using the same Riceâ€™s nomenclature and supplementing it; as well as, influence indexes and analysis approaches were described. A diagram about this long trajectory and a reflection is performed, highlighting contributions and scope. It shows that up to now the problem of explaining formally why an algorithm is the best for solving an instance set had remained open. A formal problem statement for describing this phenomenon and a general framework were proposed as a guide for working in adequate way toward generation of theories; which could contribute to build generalized indexes and self-adaptive algorithms to give the best solution to problems.",it has been observed on solution algorithms for problems as sorting  forecasting  classification  clustering  constraint satisfaction  decision  optimization from several disciplines  computational complexity theory  data mining  artificial intelligence  machine learning  operations research  that algorithm performance is better in certain problem instances than other  this paper describes how has been the way for trying to reach the empirical generalization for this phenomenon existing in the experimental relation problem     algorithm  for each understanding level  research questions  problem description were formulated  using the same rice   s nomenclature and supplementing it  as well as  influence indexes and analysis approaches were described  a diagram about this long trajectory and a reflection is performed  highlighting contributions and scope  it shows that up to now the problem of explaining formally why an algorithm is the best for solving an instance set had remained open  a formal problem statement for describing this phenomenon and a general framework were proposed as a guide for working in adequate way toward generation of theories  which could contribute to build generalized indexes and self adaptive algorithms to give the best solution to problems ,2.481975,7.646479,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
An Intelligent Framework for Oversubscription Management in CPU-GPU Unified Memory,"Unified virtual memory (UVM) improves GPU programmability by enabling on-demand data movement between CPU memory and GPU memory. However, due to the limited capacity of GPU device memory, oversubscription overhead becomes a major performance bottleneck for data-intensive workloads running on GPUs with UVM. This paper proposes a novel framework for UVM oversubscription management in discrete CPU-GPU systems. It consists of an access pattern classifier followed by a pattern-specific transformer-based model using a novel loss function aiming to reduce page thrashing. A policy engine is designed to leverage the modelâ€™s result to perform accurate page prefetching and eviction. Our evaluation shows that our proposed framework significantly outperforms the state-of-the-art (SOTA) methods on a set of 11 memory-intensive benchmarks, reducing the number of pages thrashed by 64.4% under 125% memory oversubscription compared to the baseline, while the SOTA method reduces the number of pages thrashed by 17.3%. Compared to the SOTA method, our solution achieves average IPC improvement of 1.52X and 3.66X under 125% and 150% memory oversubscription.",unified virtual memory  uvm  improves gpu programmability by enabling on demand data movement between cpu memory and gpu memory  however  due to the limited capacity of gpu device memory  oversubscription overhead becomes a major performance bottleneck for data intensive workloads running on gpus with uvm  this paper proposes a novel framework for uvm oversubscription management in discrete cpu gpu systems  it consists of an access pattern classifier followed by a pattern specific transformer based model using a novel loss function aiming to reduce page thrashing  a policy engine is designed to leverage the model   s result to perform accurate page prefetching and eviction  our evaluation shows that our proposed framework significantly outperforms the state of the art  sota  methods on a set of    memory intensive benchmarks  reducing the number of pages thrashed by       under      memory oversubscription compared to the baseline  while the sota method reduces the number of pages thrashed by        compared to the sota method  our solution achieves average ipc improvement of     x and     x under      and      memory oversubscription ,4.816283,8.0275135,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
"Spatial Distribution of Different Forms of Soil Phosphorus of a Pingguoli (Pyrus bretschneideri) Orchard in Yanji, China","Abstract
 The distribution of phosphorus in permanent cropping systems such as orchards soil differs from that of other agricultural soils because of the developed root system with a large biomass and long-life cycle of fruit trees. However, our understanding of soil phosphorus in orchards remains poor. This study applied chemical and spectroscopic analyses to compare differences in soil phosphorus between different slope positions and soil horizons of a Pyrus bretschneideri orchard. The results suggested that soil phosphorus of the Pyrus bretschneideri orchard exceeded that in wasteland. Moderately labile organic phosphorus and orthophosphate are the main forms of soil phosphorus in Pyrus bretschneideri orchard and play an important role in phosphorus cycle of Pyrus bretschneideri orchard soil, the continuous supplementation of them can meet the phosphorus nutrient needs of Pyrus bretschneideri trees. Moreover, Pyrus bretschneideri trees mainly obtain nutrients from horizons AB to B, there should be further focus to the depth of 20â€“80 cm of fertilizer application approximately in Haplic Luvisols.",abstract  the distribution of phosphorus in permanent cropping systems such as orchards soil differs from that of other agricultural soils because of the developed root system with a large biomass and long life cycle of fruit trees  however  our understanding of soil phosphorus in orchards remains poor  this study applied chemical and spectroscopic analyses to compare differences in soil phosphorus between different slope positions and soil horizons of a pyrus bretschneideri orchard  the results suggested that soil phosphorus of the pyrus bretschneideri orchard exceeded that in wasteland  moderately labile organic phosphorus and orthophosphate are the main forms of soil phosphorus in pyrus bretschneideri orchard and play an important role in phosphorus cycle of pyrus bretschneideri orchard soil  the continuous supplementation of them can meet the phosphorus nutrient needs of pyrus bretschneideri trees  moreover  pyrus bretschneideri trees mainly obtain nutrients from horizons ab to b  there should be further focus to the depth of         cm of fertilizer application approximately in haplic luvisols ,4.1427,2.0144126,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
A Hippocratic Oath for Mathematicians? Mapping the Landscape of Ethics in Mathematics,"While the consequences of mathematically-based software, algorithms and strategies have become ever wider and better appreciated, ethical reflection on mathematics has remained primitive. We review the somewhat disconnected suggestions of commentators in recent decades with a view to piecing together a coherent approach to ethics in mathematics. Calls for a Hippocratic Oath for mathematicians are examined and it is concluded that while lessons can be learned from the medical profession, the relation of mathematicians to those affected by their work is significantly different. There is something to be learned also from the codes of conduct of cognate but professionalised quantitative disciplines such as engineering and accountancy, as well as from legal principles bearing on professional work. We conclude with recommendations that professional societies in mathematics should sponsor an (international) code of ethics, institutional mission statements for mathematicians and syllabuses of ethics courses for incorporation into mathematics degrees.",while the consequences of mathematically based software  algorithms and strategies have become ever wider and better appreciated  ethical reflection on mathematics has remained primitive  we review the somewhat disconnected suggestions of commentators in recent decades with a view to piecing together a coherent approach to ethics in mathematics  calls for a hippocratic oath for mathematicians are examined and it is concluded that while lessons can be learned from the medical profession  the relation of mathematicians to those affected by their work is significantly different  there is something to be learned also from the codes of conduct of cognate but professionalised quantitative disciplines such as engineering and accountancy  as well as from legal principles bearing on professional work  we conclude with recommendations that professional societies in mathematics should sponsor an  international  code of ethics  institutional mission statements for mathematicians and syllabuses of ethics courses for incorporation into mathematics degrees ,11.9312725,6.319045,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
New frontiers for integrated photonics,"Although optical communications continue to be the main driver for integrated photonics, new applications are emerging in computing and neural networks. That was the message from this yearâ€™s European Conference on Integrated Optics in Milan.",although optical communications continue to be the main driver for integrated photonics  new applications are emerging in computing and neural networks  that was the message from this year   s european conference on integrated optics in milan ,8.440535,3.3016458,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Drawing and Analysis of Bounding Boxes for Object Detection with Anchor-Based Models,"Supervised object detection models are trained to recognize certain objects. These models are classified into two types: single-stage detectors and two-stage detectors. The single-stage detectors just need one pass through the model to anticipate all the bounding boxes, whereas the two-stage detectors require to first estimate the image portions where the object could be located. Due to their speed and simplicity, single-stage anchor-based models are used in many industrial settings. Training such models require bounding boxes that describe the spatial location of an object, which are usually drawn by an expert. However, the question remains, how much area should be considered when drawing the bounding boxes? In this paper, we demonstrate the effects that the size and placement of a rectangular bounding box can have on the performance of the anchor-based models. For this, we first perform experiments on a synthetically generated binary dataset and then on a real-world object detection dataset. Our results show that fixing the size of the bounding boxes can help in improving the performance of the model in the case of single class object detection (approximately 50% improvement in mAP@[.5:.95] for real world dataset). Furthermore, we also demonstrate how freely available tools can be combined for obtaining the best possible semi automated object labeling pipeline.
 Keywords
 Object detection
 Yolo
 Bounding box labelling",supervised object detection models are trained to recognize certain objects  these models are classified into two types  single stage detectors and two stage detectors  the single stage detectors just need one pass through the model to anticipate all the bounding boxes  whereas the two stage detectors require to first estimate the image portions where the object could be located  due to their speed and simplicity  single stage anchor based models are used in many industrial settings  training such models require bounding boxes that describe the spatial location of an object  which are usually drawn by an expert  however  the question remains  how much area should be considered when drawing the bounding boxes  in this paper  we demonstrate the effects that the size and placement of a rectangular bounding box can have on the performance of the anchor based models  for this  we first perform experiments on a synthetically generated binary dataset and then on a real world object detection dataset  our results show that fixing the size of the bounding boxes can help in improving the performance of the model in the case of single class object detection  approximately     improvement in map          for real world dataset   furthermore  we also demonstrate how freely available tools can be combined for obtaining the best possible semi automated object labeling pipeline   keywords  object detection  yolo  bounding box labelling,4.746359,6.8694534,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
False Data Injection Attack Detection in VANET Using Upgraded Grey Wolf Optimization Algorithm Using LSTM Classifier,"Detection of cyberattacks is of utmost importance and is also needed in various applications like VANET. Despite the potential benefits in a number of areas such as traffic management, reduced fuel consumption, and driver assistance, VANET safety is a challenging area in defending itself from various cyber security attacks like False Data Injection Attack (FDIA). In our proposed system, a unique method using Grey Wolf Optimization Algorithm integrated into Long Short-Term Memory (LSTM) model is used to detect the attack FDIA to ensure the trusted data flow in Smart Intelligent Transport System. The primary goal of this system is to address the detection of fake data injection in cyberattacks. It is necessary to effectively control the data flow between the cars and employ the Grey Wolf Optimization method, an optimized feature extraction technique, in order to accomplish this goal. The acquired test and results showed that used technique ought to extra exactly and robustly perceive more than one sort of FDIAs with 98% precision.
 Keywords
 False data injection attack
 Cyber-attack
 VANET
 Deep learning technique
 Grey wolf optimization",detection of cyberattacks is of utmost importance and is also needed in various applications like vanet  despite the potential benefits in a number of areas such as traffic management  reduced fuel consumption  and driver assistance  vanet safety is a challenging area in defending itself from various cyber security attacks like false data injection attack  fdia   in our proposed system  a unique method using grey wolf optimization algorithm integrated into long short term memory  lstm  model is used to detect the attack fdia to ensure the trusted data flow in smart intelligent transport system  the primary goal of this system is to address the detection of fake data injection in cyberattacks  it is necessary to effectively control the data flow between the cars and employ the grey wolf optimization method  an optimized feature extraction technique  in order to accomplish this goal  the acquired test and results showed that used technique ought to extra exactly and robustly perceive more than one sort of fdias with     precision   keywords  false data injection attack  cyber attack  vanet  deep learning technique  grey wolf optimization,4.9245906,4.784889,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
DDPG with Transfer Learning and Meta Learning Framework for Resource Allocation in Underlay Cognitive Radio Network,"Cognitive Radio (CR) is an intelligent device equipped with a Cognitive Engine (CE) capable of making decisions and finding the best policy for a dynamic network. Superior decision-making policy takes extensive learning time. A suitable learning algorithm reduces the learning time and provides a boost to CE capabilities. The underlay CR model allows PU and SU to coexist in the same frequency band by restricting SU interference below an acceptable level. This paper presents an underlay Resource Allocation (RA) model that employs Transfer Learning (TL) and Meta Reinforcement Learning (MRL) to solve a non-convex optimization problem. The allocation of resources is performed by incorporating TL and MRL into the existing Deep Deterministic Policy Gradient (DDPG) method. The merging of TL and MRL accelerates the networkâ€™s learning process and allows it to adapt rapidly to the changing environments. The proposed algorithms are compared to basic Q learning, dueling Deep Q Networks, and hybrid algorithms in terms of Quality of Experience (QoE) metric, learning speed, congestion rate, and stability. The simulation findings indicate that our proposed approach outperforms the existing techniques. The adaptability of the network is also tested by changing the environment from Additive White Gaussian Noise (AWGN) to Rayleigh fading. In addition, trade-offs between network scalability, congestion, and performance are evaluated.",cognitive radio  cr  is an intelligent device equipped with a cognitive engine  ce  capable of making decisions and finding the best policy for a dynamic network  superior decision making policy takes extensive learning time  a suitable learning algorithm reduces the learning time and provides a boost to ce capabilities  the underlay cr model allows pu and su to coexist in the same frequency band by restricting su interference below an acceptable level  this paper presents an underlay resource allocation  ra  model that employs transfer learning  tl  and meta reinforcement learning  mrl  to solve a non convex optimization problem  the allocation of resources is performed by incorporating tl and mrl into the existing deep deterministic policy gradient  ddpg  method  the merging of tl and mrl accelerates the network   s learning process and allows it to adapt rapidly to the changing environments  the proposed algorithms are compared to basic q learning  dueling deep q networks  and hybrid algorithms in terms of quality of experience  qoe  metric  learning speed  congestion rate  and stability  the simulation findings indicate that our proposed approach outperforms the existing techniques  the adaptability of the network is also tested by changing the environment from additive white gaussian noise  awgn  to rayleigh fading  in addition  trade offs between network scalability  congestion  and performance are evaluated ,3.860099,7.5199566,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Low-Effort Place Recognition with WiFi Fingerprints Using Deep Learning,"Using WiFi signals for indoor localization is the main localization modality of the existing personal indoor localization systems operating on mobile devices. WiFi fingerprinting is also used for mobile robots, as WiFi signals are usually available indoors and can provide rough initial position estimate or can be used together with other positioning systems. Currently, the best solutions rely on filtering, manual data analysis, and time-consuming parameter tuning to achieve reliable and accurate localization. In this work, we propose to use deep neural networks to significantly lower the work-force burden of the localization system design, while still achieving satisfactory results. Assuming the state-of-the-art hierarchical approach, we employ the DNN system for building/floor classification. We show that stacked autoencoders allow to efficiently reduce the feature space in order to achieve robust and precise classification. The proposed architecture is verified on the publicly available UJIIndoorLoc dataset and the results are compared with other solutions.
 Keywords
 WiFi
 Fingerprinting
 Indoor localization
 Deep neural networks",using wifi signals for indoor localization is the main localization modality of the existing personal indoor localization systems operating on mobile devices  wifi fingerprinting is also used for mobile robots  as wifi signals are usually available indoors and can provide rough initial position estimate or can be used together with other positioning systems  currently  the best solutions rely on filtering  manual data analysis  and time consuming parameter tuning to achieve reliable and accurate localization  in this work  we propose to use deep neural networks to significantly lower the work force burden of the localization system design  while still achieving satisfactory results  assuming the state of the art hierarchical approach  we employ the dnn system for building floor classification  we show that stacked autoencoders allow to efficiently reduce the feature space in order to achieve robust and precise classification  the proposed architecture is verified on the publicly available ujiindoorloc dataset and the results are compared with other solutions   keywords  wifi  fingerprinting  indoor localization  deep neural networks,3.215673,7.381834,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Target-class guided sample length reduction and training set selection of univariate time-series,"The novelty/anomaly detection in time-series (TS) data is an admired research domain, which is specifically a one-class classification (OCC) task, where only target-class samples are present during training and the samples from other classes are unavailable. The performance of OCC algorithms depends on quality and quantity of features and training samples because all the features/samples are not equally important for target-class representation. The present research focuses on OCC of univariate time-series (UTS) and proposes a novel way to acquire the knowledge of the target-class to ensure its strong separation from the other class samples. Apart from enormous training samples, the large sample length (span) increases the computing complexities together with its innate problem of curse of â€œdimensionalityâ€ (here, sample span is treated as dimension of time-series). In this context, the present article offers a concurrent way of target-class guided sample span reduction and training sample selection for UTS data. Initially, the vector representation is obtained using state-of-the-art dissimilarity-based representation (DBR) techniques and later, a novel target-class supervised sample span reduction algorithm is offered via Eigenspace analysis to obtain the minimal sample span. Furthermore, to select the most promising training samples as target-class representatives, state-of-the-art prototype methods are utilized. Finally, one-class support vector machine (OCSVM), 1-nearest neighbour (1-NN) and isolation forest (IF) are utilized to evaluate the performance of proposed approach. Intensive experiments are performed over the archive of 85 univariate datasets provided by University of California, Riverside (UCR) and University of East Anglia (UEA) (this repository is also known as UCR/UEA archive).",the novelty anomaly detection in time series  ts  data is an admired research domain  which is specifically a one class classification  occ  task  where only target class samples are present during training and the samples from other classes are unavailable  the performance of occ algorithms depends on quality and quantity of features and training samples because all the features samples are not equally important for target class representation  the present research focuses on occ of univariate time series  uts  and proposes a novel way to acquire the knowledge of the target class to ensure its strong separation from the other class samples  apart from enormous training samples  the large sample length  span  increases the computing complexities together with its innate problem of curse of    dimensionality     here  sample span is treated as dimension of time series   in this context  the present article offers a concurrent way of target class guided sample span reduction and training sample selection for uts data  initially  the vector representation is obtained using state of the art dissimilarity based representation  dbr  techniques and later  a novel target class supervised sample span reduction algorithm is offered via eigenspace analysis to obtain the minimal sample span  furthermore  to select the most promising training samples as target class representatives  state of the art prototype methods are utilized  finally  one class support vector machine  ocsvm     nearest neighbour    nn  and isolation forest  if  are utilized to evaluate the performance of proposed approach  intensive experiments are performed over the archive of    univariate datasets provided by university of california  riverside  ucr  and university of east anglia  uea   this repository is also known as ucr uea archive  ,4.3271604,7.1017036,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Isolation Forest Based Anomaly Detection Approach for Wireless Body Area Networks,"Anomalous data detection is an important task for ensuring the quality of data in many real-world applications. Medical healthcare services are one such application where Wireless Body Area Networks (WBAN) is used to track human health situations. Such tracking is achieved by collecting and monitoring the basic physiological vital signs and making them available to the healthcare givers to assess the criticality status of patients, especially in Intensive care units (ICU). Various anomaly detection approaches have been proposed for detecting anomalies collected in WBAN such as statistical, machine learning and deep learning techniques. However, the lack of ground truth data made the job of training such models a difficulty in supervised settings. In this paper, an Isolation Forest-based anomaly detection approach for WBAN (iForestBAN-AD) model is proposed. The iForest technique is fully unsupervised and does not employ any distance measure or density function like most existing techniques and rather detects anomalies based on the concept of isolation. To evaluate the proposed approach, experiments on data samples from real world physiological network records (Physionet) were conducted. The results show the viability of the proposed approach as it achieves around 95% AUC and outperforms many of the existing baseline unsupervised techniques on multivariate dataset samples.
 Keywords
 Anomaly Detection
 Wireless Body Area Network
 Isolation Forest
 Unsupervised Learning
 Internet of Medical Things",anomalous data detection is an important task for ensuring the quality of data in many real world applications  medical healthcare services are one such application where wireless body area networks  wban  is used to track human health situations  such tracking is achieved by collecting and monitoring the basic physiological vital signs and making them available to the healthcare givers to assess the criticality status of patients  especially in intensive care units  icu   various anomaly detection approaches have been proposed for detecting anomalies collected in wban such as statistical  machine learning and deep learning techniques  however  the lack of ground truth data made the job of training such models a difficulty in supervised settings  in this paper  an isolation forest based anomaly detection approach for wban  iforestban ad  model is proposed  the iforest technique is fully unsupervised and does not employ any distance measure or density function like most existing techniques and rather detects anomalies based on the concept of isolation  to evaluate the proposed approach  experiments on data samples from real world physiological network records  physionet  were conducted  the results show the viability of the proposed approach as it achieves around     auc and outperforms many of the existing baseline unsupervised techniques on multivariate dataset samples   keywords  anomaly detection  wireless body area network  isolation forest  unsupervised learning  internet of medical things,3.4982946,5.590834,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Evaluation of low-power devices for smart greenhouse development,"The combination of Artificial Intelligence and the Internet of Things (AIoT) is enabling the next economic revolution in which data and immediacy are at the key players. Agriculture is one of the sectors that can benefit most from the use of AIoT to optimise resources and reduce its environmental footprint. However, this convergence requires computational resources that enable the execution of AI workloads, and in the context of agriculture, ensuring autonomous operation and low energy consumption. In this work, we evaluate TinyML and edge computing platforms to predict the indoor temperature of an operational greenhouse in situ. In particular, the computational/energy trade-off of these platforms is assessed to analyse whether their use in this context is feasible. Two artificial neural networks are adapted to these platforms to predict the indoor temperature of the greenhouse. Our results show that the microcontroller-based devices can offer a competitive and energy-efficient computational alternative to more traditional edge computing approaches for lightweight ML workloads.",the combination of artificial intelligence and the internet of things  aiot  is enabling the next economic revolution in which data and immediacy are at the key players  agriculture is one of the sectors that can benefit most from the use of aiot to optimise resources and reduce its environmental footprint  however  this convergence requires computational resources that enable the execution of ai workloads  and in the context of agriculture  ensuring autonomous operation and low energy consumption  in this work  we evaluate tinyml and edge computing platforms to predict the indoor temperature of an operational greenhouse in situ  in particular  the computational energy trade off of these platforms is assessed to analyse whether their use in this context is feasible  two artificial neural networks are adapted to these platforms to predict the indoor temperature of the greenhouse  our results show that the microcontroller based devices can offer a competitive and energy efficient computational alternative to more traditional edge computing approaches for lightweight ml workloads ,4.987368,8.53435,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
End-to-end automated body composition analyses with integrated quality control for opportunistic assessment of sarcopenia in CT,"Objectives
 To develop a pipeline for automated body composition analysis and skeletal muscle assessment with integrated quality control for large-scale application in opportunistic imaging.
 Methods
 First, a convolutional neural network for extraction of a single slice at the L3/L4 lumbar level was developed on CT scans of 240 patients applying the nnU-Net framework. Second, a 2D competitive dense fully convolutional U-Net for segmentation of visceral and subcutaneous adipose tissue (VAT, SAT), skeletal muscle (SM), and subsequent determination of fatty muscle fraction (FMF) was developed on single CT slices of 1143 patients. For both steps, automated quality control was integrated by a logistic regression model classifying the presence of L3/L4 and a linear regression model predicting the segmentation quality in terms of Dice score. To evaluate the performance of the entire pipeline end-to-end, body composition metrics, and FMF were compared to manual analyses including 364 patients from two centers.
 Results
 Excellent results were observed for slice extraction (z-deviationâ€‰=â€‰2.46â€‰Â±â€‰6.20 mm) and segmentation (Dice score for SMâ€‰=â€‰0.95â€‰Â±â€‰0.04, VATâ€‰=â€‰0.98â€‰Â±â€‰0.02, SATâ€‰=â€‰0.97â€‰Â±â€‰0.04) on the dual-center test set excluding cases with artifacts due to metallic implants. No data were excluded for end-to-end performance analyses. With a restrictive setting of the integrated segmentation quality control, 39 of 364 patients were excluded containing 8 cases with metallic implants. This setting ensured a high agreement between manual and fully automated analyses with mean relative area deviations of Î”SMâ€‰=â€‰3.3â€‰Â±â€‰4.1%, Î”VATâ€‰=â€‰3.0â€‰Â±â€‰4.7%, Î”SATâ€‰=â€‰2.7â€‰Â±â€‰4.3%, and Î”FMFâ€‰=â€‰4.3â€‰Â±â€‰4.4%.
 Conclusions
 This study presents an end-to-end automated deep learning pipeline for large-scale opportunistic assessment of body composition metrics and sarcopenia biomarkers in clinical routine.
 Key Points
 â€¢ Body composition metrics and skeletal muscle quality can be opportunistically determined from routine abdominal CT scans.
 â€¢ A pipeline consisting of two convolutional neural networks allows an end-to-end automated analysis.
 â€¢ Machine-learning-based quality control ensures high agreement between manual and automatic analysis.",objectives  to develop a pipeline for automated body composition analysis and skeletal muscle assessment with integrated quality control for large scale application in opportunistic imaging   methods  first  a convolutional neural network for extraction of a single slice at the l  l  lumbar level was developed on ct scans of     patients applying the nnu net framework  second  a  d competitive dense fully convolutional u net for segmentation of visceral and subcutaneous adipose tissue  vat  sat   skeletal muscle  sm   and subsequent determination of fatty muscle fraction  fmf  was developed on single ct slices of      patients  for both steps  automated quality control was integrated by a logistic regression model classifying the presence of l  l  and a linear regression model predicting the segmentation quality in terms of dice score  to evaluate the performance of the entire pipeline end to end  body composition metrics  and fmf were compared to manual analyses including     patients from two centers   results  excellent results were observed for slice extraction  z deviation                        mm  and segmentation  dice score for sm                         vat                         sat                         on the dual center test set excluding cases with artifacts due to metallic implants  no data were excluded for end to end performance analyses  with a restrictive setting of the integrated segmentation quality control     of     patients were excluded containing   cases with metallic implants  this setting ensured a high agreement between manual and fully automated analyses with mean relative area deviations of   sm                          vat                          sat                        and   fmf                         conclusions  this study presents an end to end automated deep learning pipeline for large scale opportunistic assessment of body composition metrics and sarcopenia biomarkers in clinical routine   key points      body composition metrics and skeletal muscle quality can be opportunistically determined from routine abdominal ct scans       a pipeline consisting of two convolutional neural networks allows an end to end automated analysis       machine learning based quality control ensures high agreement between manual and automatic analysis ,4.8464046,3.3444643,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
"Clustering, Prominence and Social Network Analysis on Incomplete Networks","Social networks are a source of large scale graphs. We study how social network algorithms behave on sparsified versions of such networks with two motivations in mind:
 1.
 In practice, it is challenging to collect, store and process the entire often constantly growing network, so it is important to understand how algorithms behave on incomplete views of a network.
 2.
 Even if one has the full network, algorithms may be infeasible at such large scale, and the only option may be to sparsify the networks to make them computationally tractable while still maintaining the fidelity of the social network algorithms.
 We present a variety of methods for sparsifying a network based on linear regression and linear algebraic sampling for graph reconstruction. We compare the methods against one another with respect to clustering. Specifically, given a graph G, we sample the columns of its adjacency matrix and reconstruct the remaining columns using only those sampled columns to obtain Äœ, the reconstructed approximation of G. We then perform clustering on G and Äœ to get two sets of clusters and compute their modularity, fitness and centrality. Our thorough experimentation reveals that graphs reconstructed through our methodology preserve (in some cases, even improve) community structure while being orders of magnitude more efficient both in storage and computation. We show similar results if the target is prominence of nodes rather than clusters.
 Keywords
 Adjacency Matrix
 Social Network Analysis
 Betweenness Centrality
 Community Detection
 Sampling Algorithm
 These keywords were added by machine and not by the authors. This process is experimental and the keywords may be updated as the learning algorithm improves.",social networks are a source of large scale graphs  we study how social network algorithms behave on sparsified versions of such networks with two motivations in mind       in practice  it is challenging to collect  store and process the entire often constantly growing network  so it is important to understand how algorithms behave on incomplete views of a network       even if one has the full network  algorithms may be infeasible at such large scale  and the only option may be to sparsify the networks to make them computationally tractable while still maintaining the fidelity of the social network algorithms   we present a variety of methods for sparsifying a network based on linear regression and linear algebraic sampling for graph reconstruction  we compare the methods against one another with respect to clustering  specifically  given a graph g  we sample the columns of its adjacency matrix and reconstruct the remaining columns using only those sampled columns to obtain     the reconstructed approximation of g  we then perform clustering on g and    to get two sets of clusters and compute their modularity  fitness and centrality  our thorough experimentation reveals that graphs reconstructed through our methodology preserve  in some cases  even improve  community structure while being orders of magnitude more efficient both in storage and computation  we show similar results if the target is prominence of nodes rather than clusters   keywords  adjacency matrix  social network analysis  betweenness centrality  community detection  sampling algorithm  these keywords were added by machine and not by the authors  this process is experimental and the keywords may be updated as the learning algorithm improves ,4.740085,7.5989776,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Enhanced brain tumor classification using graph convolutional neural network architecture,"The Brain Tumor presents a highly critical situation concerning the brain, characterized by the uncontrolled growth of an abnormal cell cluster. Early brain tumor detection is essential for accurate diagnosis and effective treatment planning. In this paper, a novel Convolutional Neural Network (CNN) based Graph Neural Network (GNN) model is proposed using the publicly available Brain Tumor dataset from Kaggle to predict whether a person has brain tumor or not and if yes then which type (Meningioma, Pituitary or Glioma). The objective of this research and the proposed models is to provide a solution to the non-consideration of non-Euclidean distances in image data and the inability of conventional models to learn on pixel similarity based upon the pixel proximity. To solve this problem, we have proposed a Graph based Convolutional Neural Network (GCNN) model and it is found that the proposed model solves the problem of considering non-Euclidean distances in images. We aimed at improving brain tumor detection and classification using a novel technique which combines GNN and a 26 layered CNN that takes in a Graph input pre-convolved using Graph Convolution operation. The objective of Graph Convolution is to modify the node features (data linked to each node) by combining information from nearby nodes. A standard pre-computed Adjacency matrix is used, and the input graphs were updated as the averaged sum of local neighbor nodes, which carry the regional information about the tumor. These modified graphs are given as the input matrices to a standard 26 layered CNN with Batch Normalization and Dropout layers intact. Five different networks namely Net-0, Net-1, Net-2, Net-3 and Net-4 are proposed, and it is found that Net-2 outperformed the other networks namely Net-0, Net-1, Net-3 and Net-4. The highest accuracy achieved was 95.01% by Net-2. With its current effectiveness, the model we propose represents a critical alternative for the statistical detection of brain tumors in patients who are suspected of having one.",the brain tumor presents a highly critical situation concerning the brain  characterized by the uncontrolled growth of an abnormal cell cluster  early brain tumor detection is essential for accurate diagnosis and effective treatment planning  in this paper  a novel convolutional neural network  cnn  based graph neural network  gnn  model is proposed using the publicly available brain tumor dataset from kaggle to predict whether a person has brain tumor or not and if yes then which type  meningioma  pituitary or glioma   the objective of this research and the proposed models is to provide a solution to the non consideration of non euclidean distances in image data and the inability of conventional models to learn on pixel similarity based upon the pixel proximity  to solve this problem  we have proposed a graph based convolutional neural network  gcnn  model and it is found that the proposed model solves the problem of considering non euclidean distances in images  we aimed at improving brain tumor detection and classification using a novel technique which combines gnn and a    layered cnn that takes in a graph input pre convolved using graph convolution operation  the objective of graph convolution is to modify the node features  data linked to each node  by combining information from nearby nodes  a standard pre computed adjacency matrix is used  and the input graphs were updated as the averaged sum of local neighbor nodes  which carry the regional information about the tumor  these modified graphs are given as the input matrices to a standard    layered cnn with batch normalization and dropout layers intact  five different networks namely net    net    net    net   and net   are proposed  and it is found that net   outperformed the other networks namely net    net    net   and net    the highest accuracy achieved was        by net    with its current effectiveness  the model we propose represents a critical alternative for the statistical detection of brain tumors in patients who are suspected of having one ,3.8621423,5.128497,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Spatiotemporal semantic network for ENSO forecasting over long time horizon,"El NiÃ±o-Southern Oscillation (ENSO) has substantial influence on global climate variability and is responsible for extreme weather events such as drought and heavy rains, along with global ecosystem modifications. The successful prediction of ENSO is of considerable interest to reducing economic and social adverse effects. Recently, deep learning models show great potential in this task. However, despite decades of efforts, predicting ENSO at lead times of more than one year remains a major challenge and most of these existing studies focus on the single channel of meteorological data, ignoring the spatial and temporal dependence of these factors. To capture the spatiotemporal information of meteorological factors as well as promote the skill of ENSO forecasting over longer time horizon, we propose an end-to-end deep learning model SpatioTemporal Semantic Network named STSNet, which consists of three main modules: (1) Geographic Semantic Enhancement Module (GSEM) distinguishes the geographic semantics of various latitudes and longitudes through a learnable adaptive weight matrix. (2) A novel SpatioTemporal Convolutional Module(STCM) is designed specially to extract the multidimensional features by alternating the execution of temporal and spatial convolution and temporal attention. (3) Multi-scale temporal information is combined and exploited in Three-stream Temporal Scale Module (3sTSM) to further enhance the performance. Integrating these modules gives a powerful feature extractor STSNet, which has multi-scale receptive fields across both spatial and temporal dimensions. In order to verify the effectiveness and progressiveness of our model, we execute experiments on Historical Climate Observation and Simulation Dataset. The results show that STSNet can simultaneously provide effective ENSO prediction for 16 months, with higher correlation and lower deviation compared with other deep learning models.",el ni  o southern oscillation  enso  has substantial influence on global climate variability and is responsible for extreme weather events such as drought and heavy rains  along with global ecosystem modifications  the successful prediction of enso is of considerable interest to reducing economic and social adverse effects  recently  deep learning models show great potential in this task  however  despite decades of efforts  predicting enso at lead times of more than one year remains a major challenge and most of these existing studies focus on the single channel of meteorological data  ignoring the spatial and temporal dependence of these factors  to capture the spatiotemporal information of meteorological factors as well as promote the skill of enso forecasting over longer time horizon  we propose an end to end deep learning model spatiotemporal semantic network named stsnet  which consists of three main modules      geographic semantic enhancement module  gsem  distinguishes the geographic semantics of various latitudes and longitudes through a learnable adaptive weight matrix      a novel spatiotemporal convolutional module stcm  is designed specially to extract the multidimensional features by alternating the execution of temporal and spatial convolution and temporal attention      multi scale temporal information is combined and exploited in three stream temporal scale module   stsm  to further enhance the performance  integrating these modules gives a powerful feature extractor stsnet  which has multi scale receptive fields across both spatial and temporal dimensions  in order to verify the effectiveness and progressiveness of our model  we execute experiments on historical climate observation and simulation dataset  the results show that stsnet can simultaneously provide effective enso prediction for    months  with higher correlation and lower deviation compared with other deep learning models ,4.3439775,6.5335793,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
A Comprehensive Classification of Deep Learning Libraries,"Deep learning (DL) networks are composed of multiple processing layers that learn data representations with multiple levels of abstraction. In recent years, DL networks have significantly improved the state of the art across different domains, including speech processing, text mining, pattern recognition, object detection, robotics, and big data analytics. Generally, a researcher or practitioner who is planning to use DL networks for the first time faces difficulties in selecting suitable software tools. The present article provides a comprehensive list and taxonomy of current programming languages and software tools that can be utilized for implementation of DL networks. The motivation of this article is hence to create awareness among researchers, especially beginners, regarding the various languages and interfaces that are available to implement deep learning and to provide a simplified ontological basis for selecting between them.
 Keywords
 Deep learning
 Deep learning libraries
 Machine learning
 Deep belief network",deep learning  dl  networks are composed of multiple processing layers that learn data representations with multiple levels of abstraction  in recent years  dl networks have significantly improved the state of the art across different domains  including speech processing  text mining  pattern recognition  object detection  robotics  and big data analytics  generally  a researcher or practitioner who is planning to use dl networks for the first time faces difficulties in selecting suitable software tools  the present article provides a comprehensive list and taxonomy of current programming languages and software tools that can be utilized for implementation of dl networks  the motivation of this article is hence to create awareness among researchers  especially beginners  regarding the various languages and interfaces that are available to implement deep learning and to provide a simplified ontological basis for selecting between them   keywords  deep learning  deep learning libraries  machine learning  deep belief network,9.264797,7.4529376,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Outsourced k-Means Clustering over Encrypted Data Under Multiple Keys in Spark Framework,"As the quantity of data produced is rapidly rising in recent years, clients lack of computational and storage resources tend to outsource data mining tasks to cloud service providers in order to improve efficiency and save costs. Itâ€™s also increasing common for clients to perform collaborative mining to maximize profits. However, due to the rise of privacy leakage issues, the data contributed by clients should be encrypted under their own keys. This paper focuses on privacy-preserving k-means clustering over the joint datasets from multiple sources. Unfortunately, existing secure outsourcing protocols are either restricted to a single key setting or quite inefficient because of frequent client-to-server interactions, making it impractical for wide application. To address these issues, we propose a set of secure building blocks and outsourced clustering protocol under Spark framework. Theoretical analysis shows that our scheme protects the confidentiality of the joint database and mining results in the standard threat model with small computation and communication overhead. Experimental results also demonstrate its significant efficiency improvements compared with existing methods.
 Keywords
 Outsourced k-means clustering
 Multiple keys
 Cloud environment
 Spark framework",as the quantity of data produced is rapidly rising in recent years  clients lack of computational and storage resources tend to outsource data mining tasks to cloud service providers in order to improve efficiency and save costs  it   s also increasing common for clients to perform collaborative mining to maximize profits  however  due to the rise of privacy leakage issues  the data contributed by clients should be encrypted under their own keys  this paper focuses on privacy preserving k means clustering over the joint datasets from multiple sources  unfortunately  existing secure outsourcing protocols are either restricted to a single key setting or quite inefficient because of frequent client to server interactions  making it impractical for wide application  to address these issues  we propose a set of secure building blocks and outsourced clustering protocol under spark framework  theoretical analysis shows that our scheme protects the confidentiality of the joint database and mining results in the standard threat model with small computation and communication overhead  experimental results also demonstrate its significant efficiency improvements compared with existing methods   keywords  outsourced k means clustering  multiple keys  cloud environment  spark framework,5.269757,7.3927894,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
A robust framework to generate surveillance video summaries using combination of zernike moments and r-transform and deep neural network,"A huge number of cameras records scenes everywhere, generating enormous bulks of videos. Processing these huge masses of videos and detection of abnormal object activities demands adequate resources like time, manpower, and hardware storage, etc. To cope with the aforementioned challenges, our proposed model for an automatic video summarization of abnormal events plays an important role in providing the well-organized storage, quick browsing, and retrieval of the large collection of video data without losing important aspects due to its lightweight. In this research, abnormal object activity detection and summary generation are performed based on two stages i.e. 1) machine learning technique for key event detection, 2) deep learning algorithm to remove extra frames generating summarized video. Firstly, Silhouette images are formed, and two feature descriptors such as Zernike Moments and R-Transform are used to create a combined feature vector. The combined feature vector provides more informative features from images and makes our model lightweight keeping only relevant features. Furthermore, on the combined feature vector, K Nearest Neighbor (KNN) clustering is applied to extract keyframes sequentially. In the end, to improve the performance, Deep Learning Algorithm i.e. ALexNet is trained over preprocessed frames from the dataset. Moreover, the DL classifier aims to eliminate the non-Key Frames and generate surveillance video summaries demonstrating abnormal object activities. The efficiency of the proposed algorithm is analyzed performing an extensive experimentation attaining 99% accuracy approximately.",a huge number of cameras records scenes everywhere  generating enormous bulks of videos  processing these huge masses of videos and detection of abnormal object activities demands adequate resources like time  manpower  and hardware storage  etc  to cope with the aforementioned challenges  our proposed model for an automatic video summarization of abnormal events plays an important role in providing the well organized storage  quick browsing  and retrieval of the large collection of video data without losing important aspects due to its lightweight  in this research  abnormal object activity detection and summary generation are performed based on two stages i e     machine learning technique for key event detection     deep learning algorithm to remove extra frames generating summarized video  firstly  silhouette images are formed  and two feature descriptors such as zernike moments and r transform are used to create a combined feature vector  the combined feature vector provides more informative features from images and makes our model lightweight keeping only relevant features  furthermore  on the combined feature vector  k nearest neighbor  knn  clustering is applied to extract keyframes sequentially  in the end  to improve the performance  deep learning algorithm i e  alexnet is trained over preprocessed frames from the dataset  moreover  the dl classifier aims to eliminate the non key frames and generate surveillance video summaries demonstrating abnormal object activities  the efficiency of the proposed algorithm is analyzed performing an extensive experimentation attaining     accuracy approximately ,3.1132183,6.9678383,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
"Images, Videos, and BigData","Images and videos are really BigData, even before the concept of BigData was initiated or created. For many companies, image related data occupies 80â€‰% of their storage. Therefore, data processing related to images is an essential topic in data science. The tasks concerning images and videos are mainly object search, recognition, and tracking. Current and future applications of images and videos include security and surveillance, medical imaging, traffic monitoring, industrial measurements, document recognition, automated driving, and more. In this chapter, we focus on massive image data processing and computer vision. We will still focus on machine learning algorithms. Images and video always require most of the storage space and by having applications over the Internet, we can say that image related problems are always BigData problems. Even with other applications, we still need to consider massive data processing. For instance, automated driving is a challenge to data science.
 In BigData related image processing, we will discuss the following topics in this chapter: (1) An overview of image and video segmentation, (2) Data storage and fast image segmentation, (3) Feature extraction, (4) Learning and training, and (5) Classification and decision making.
 Keywords
 Image Segmentation
 Maximum Entropy
 Object Tracking
 Laplacian Matrix
 Haar Wavelet
 These keywords were added by machine and not by the authors. This process is experimental and the keywords may be updated as the learning algorithm improves.",images and videos are really bigdata  even before the concept of bigdata was initiated or created  for many companies  image related data occupies        of their storage  therefore  data processing related to images is an essential topic in data science  the tasks concerning images and videos are mainly object search  recognition  and tracking  current and future applications of images and videos include security and surveillance  medical imaging  traffic monitoring  industrial measurements  document recognition  automated driving  and more  in this chapter  we focus on massive image data processing and computer vision  we will still focus on machine learning algorithms  images and video always require most of the storage space and by having applications over the internet  we can say that image related problems are always bigdata problems  even with other applications  we still need to consider massive data processing  for instance  automated driving is a challenge to data science   in bigdata related image processing  we will discuss the following topics in this chapter      an overview of image and video segmentation      data storage and fast image segmentation      feature extraction      learning and training  and     classification and decision making   keywords  image segmentation  maximum entropy  object tracking  laplacian matrix  haar wavelet  these keywords were added by machine and not by the authors  this process is experimental and the keywords may be updated as the learning algorithm improves ,5.53497,5.4855213,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Big Data in Power Generation,"The coal-fired power plant regularly produces enormous amounts of data from its sensors, control and monitoring systems. The Volume of this data will be increasing due to widely available smart meters, Wi-Fi devices and rapidly developing IT systems. Big data technology gives the opportunity to use such types and volumes of data and could be an adequate solution in the areas, which have been untouched by information technology yet. This paper describes the possibility to use big data technology to improve internal processes on the example of a coal-fired power plant. Review of applying new technologies is made from an internal point of view, drawing from the professional experience of the authors. We are taking a closer look into the power generation process and trying to find areas to develop insights, hopefully enabling us to create more value for the industry.
 Keywords
 Big data
 Power industry
 Coal power plant
 Predictive analytics",the coal fired power plant regularly produces enormous amounts of data from its sensors  control and monitoring systems  the volume of this data will be increasing due to widely available smart meters  wi fi devices and rapidly developing it systems  big data technology gives the opportunity to use such types and volumes of data and could be an adequate solution in the areas  which have been untouched by information technology yet  this paper describes the possibility to use big data technology to improve internal processes on the example of a coal fired power plant  review of applying new technologies is made from an internal point of view  drawing from the professional experience of the authors  we are taking a closer look into the power generation process and trying to find areas to develop insights  hopefully enabling us to create more value for the industry   keywords  big data  power industry  coal power plant  predictive analytics,8.80319,6.1319985,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Requirements for Machine Learning Methodology Software Tooling,"A number of machine learning process models (SEMMA, KDD, CRISP-DM, CRISP-ML(Q), Data-to-Value, etc.) have been recently proposed to facilitate the development of machine learning models in their organizational context. While the existing proposals vary with respect to complexity and suitability for particular tasks, it would be desirable to have software tools that embody and support these methodologies and make it easier for project teams to capture, share among team members and stakeholders, and preserve the relevant project information pertaining to the various process stages. Various existing software systems cover parts such as team and communication management (Confluence, Jira, Slack, Zoom, etc.), project management (scrum, kanban, etc.), data and information management (Model Management Platform, cf. (Weber and Hirmer, Business Information Systems. Springer International Publishing, Cham, 2020), inter alia), or experimentation (RapidMiner, Orange, Weka, Tensorflow, etc.), but we are not aware of any management tools that tie them together and ensure methodology compliance. To the best of our knowledge, to date, no requirement analysis exists for a system that meets the need to provide guidance to teams for how to follow a machine learning methodology nor for managing all of a projectâ€™s metadata throughout its entire life cycle. To this end, we present an analysis and resulting collection of a set of 29 requirements for the software tooling for machine learning methodologies, derived from properties of the methodologies, user stories, and introspection of the authors.
 Keywords
 Methodology
 Software tooling
 Machine learning
 CRISP-DM
 Data-to-Value",a number of machine learning process models  semma  kdd  crisp dm  crisp ml q   data to value  etc   have been recently proposed to facilitate the development of machine learning models in their organizational context  while the existing proposals vary with respect to complexity and suitability for particular tasks  it would be desirable to have software tools that embody and support these methodologies and make it easier for project teams to capture  share among team members and stakeholders  and preserve the relevant project information pertaining to the various process stages  various existing software systems cover parts such as team and communication management  confluence  jira  slack  zoom  etc    project management  scrum  kanban  etc    data and information management  model management platform  cf   weber and hirmer  business information systems  springer international publishing  cham         inter alia   or experimentation  rapidminer  orange  weka  tensorflow  etc    but we are not aware of any management tools that tie them together and ensure methodology compliance  to the best of our knowledge  to date  no requirement analysis exists for a system that meets the need to provide guidance to teams for how to follow a machine learning methodology nor for managing all of a project   s metadata throughout its entire life cycle  to this end  we present an analysis and resulting collection of a set of    requirements for the software tooling for machine learning methodologies  derived from properties of the methodologies  user stories  and introspection of the authors   keywords  methodology  software tooling  machine learning  crisp dm  data to value,8.609987,5.164477,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Agriculture Industry Case Study: Predicting a Cash Crop Yield,"This chapter covers an agriculture industry-based case study for predicting a cash crop yield. The case study gives you an idea of the challenges faced by a mid-sized agri-conglomerate trying to reach the next level and become as big as the vision of its founder. The problem of crop yield is very important for such organizations due to the fact that they want to maximize their land resources to get the highest revenue possible. What you will primarily learn in the case study is the fact that a companyâ€™s vision should be tied to the machine learning operation that it is undertaking; otherwise it will be a wasteful expenditure. This is what I tell most of my clients when they hire me for consultation to look at how their current machine learning application helps them. Does it lower costs? If so, by how much to increase revenue? Then by how much? The goal of the project has to be quantifiable or it will not be successful but it will give dissatisfaction to the business owners and stakeholders. So read onâ€¦",this chapter covers an agriculture industry based case study for predicting a cash crop yield  the case study gives you an idea of the challenges faced by a mid sized agri conglomerate trying to reach the next level and become as big as the vision of its founder  the problem of crop yield is very important for such organizations due to the fact that they want to maximize their land resources to get the highest revenue possible  what you will primarily learn in the case study is the fact that a company   s vision should be tied to the machine learning operation that it is undertaking  otherwise it will be a wasteful expenditure  this is what i tell most of my clients when they hire me for consultation to look at how their current machine learning application helps them  does it lower costs  if so  by how much to increase revenue  then by how much  the goal of the project has to be quantifiable or it will not be successful but it will give dissatisfaction to the business owners and stakeholders  so read on   ,9.737597,6.778925,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Active Dataset Generation for Meta-learning System Quality Improvement,"Meta-learning use meta-features to formally describe datasets and find possible dependencies of algorithm performance from them. But there is not enough of various datasets to fill a meta-feature space with acceptable density for future algorithm performance prediction. To solve this problem we can use active learning. But it is required ability to generate nontrivial datasets that can help to improve the quality of the meta-learning system. In this paper we experimentally compare several such approaches based on maximize diversity and Bayesian optimization.
 Keywords
 Machine learning
 Meta-learning
 Active learning
 Evolutionary Computation
 Optimization",meta learning use meta features to formally describe datasets and find possible dependencies of algorithm performance from them  but there is not enough of various datasets to fill a meta feature space with acceptable density for future algorithm performance prediction  to solve this problem we can use active learning  but it is required ability to generate nontrivial datasets that can help to improve the quality of the meta learning system  in this paper we experimentally compare several such approaches based on maximize diversity and bayesian optimization   keywords  machine learning  meta learning  active learning  evolutionary computation  optimization,2.7700531,8.142708,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Machine-Human Interaction: A Paradigm Shift?,"The abstract should summarize the contents of the paper in short terms, i.e. 150â€“250 words. In this article, I perform a preliminary exploration on hypothesised the paradigm shift from human-initiated interaction to machine-initiated interaction. There are consequences and structural issues that need to be highlighted when considering such an important topic beyond the academic setting and ontological issues. While continuing to develop the theoretical work related to evaluating this shift, I use this as an opportunity to ask a classic â€œso whatâ€ question. What matters when machines are the ones trying to initiate interactions with humans? Specifically, what happens to parts of humanity that are often excluded from issues related to the deployment of AI in society? How can such groups, which are often marginalised react and to machines that act autonomously? To do this, I chose Black Twitter as the main case study of this article to explore if and how marginalisation can occur when machines initiate interactions with humans. Recently, Twitter has become the ground of much experimentation with AI deployed by its operators. However, it is also the experiment ground for third-party â€œbotsâ€ that interact with humans, often, without the latter being aware that of the interaction undertaken is with a machine. The article is part of a larger study investigating if there are significant differences between the way machines and members of Black Twitter interact with one another.
 Keywords
 Human-computer interaction
 Artificial intelligence
 Paradigm shift
 Twitter
 Black twitter
 Bots
 Marginalisation",the abstract should summarize the contents of the paper in short terms  i e            words  in this article  i perform a preliminary exploration on hypothesised the paradigm shift from human initiated interaction to machine initiated interaction  there are consequences and structural issues that need to be highlighted when considering such an important topic beyond the academic setting and ontological issues  while continuing to develop the theoretical work related to evaluating this shift  i use this as an opportunity to ask a classic    so what    question  what matters when machines are the ones trying to initiate interactions with humans  specifically  what happens to parts of humanity that are often excluded from issues related to the deployment of ai in society  how can such groups  which are often marginalised react and to machines that act autonomously  to do this  i chose black twitter as the main case study of this article to explore if and how marginalisation can occur when machines initiate interactions with humans  recently  twitter has become the ground of much experimentation with ai deployed by its operators  however  it is also the experiment ground for third party    bots    that interact with humans  often  without the latter being aware that of the interaction undertaken is with a machine  the article is part of a larger study investigating if there are significant differences between the way machines and members of black twitter interact with one another   keywords  human computer interaction  artificial intelligence  paradigm shift  twitter  black twitter  bots  marginalisation,10.891769,6.619752,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Selection of Auxiliary Objectives Using Landscape Features and Offline Learned Classifier,"In order to increase the performance of an evolutionary algorithm, additional auxiliary optimization objectives may be added. It is hard to predict which auxiliary objectives will be the most efficient at different stages of optimization. Thus, the problem of dynamic selection between auxiliary objectives appears. This paper proposes a new method for efficient selection of auxiliary objectives, which uses fitness landscape information and problem meta-features. An offline learned meta-classifier is used to dynamically predict the most efficient auxiliary objective during the main optimization run performed by an evolutionary algorithm. An empirical evaluation on two benchmark combinatorial optimization problems (Traveling Salesman and Job Shop Scheduling problems) shows that the proposed approach outperforms similar known methods of auxiliary objective selection.
 Keywords
 Evolutionary algorithms
 Multi-objective optimization
 Auxiliary objectives
 Fitness landscape features",in order to increase the performance of an evolutionary algorithm  additional auxiliary optimization objectives may be added  it is hard to predict which auxiliary objectives will be the most efficient at different stages of optimization  thus  the problem of dynamic selection between auxiliary objectives appears  this paper proposes a new method for efficient selection of auxiliary objectives  which uses fitness landscape information and problem meta features  an offline learned meta classifier is used to dynamically predict the most efficient auxiliary objective during the main optimization run performed by an evolutionary algorithm  an empirical evaluation on two benchmark combinatorial optimization problems  traveling salesman and job shop scheduling problems  shows that the proposed approach outperforms similar known methods of auxiliary objective selection   keywords  evolutionary algorithms  multi objective optimization  auxiliary objectives  fitness landscape features,2.6105692,7.9123406,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Detecting students-at-risk in computer programming classes with learning analytics from studentsâ€™ digital footprints,"Different sources of data about students, ranging from static demographics to dynamic behavior logs, can be harnessed from a variety sources at Higher Education Institutions. Combining these assembles a rich digital footprint for students, which can enable institutions to better understand student behaviour and to better prepare for guiding students towards reaching their academic potential. This paper presents a new research methodology to automatically detect students â€œat-riskâ€ of failing an assignment in computer programming modules (courses) and to simultaneously support adaptive feedback. By leveraging historical student data, we built predictive models using studentsâ€™ offline (static) information including student characteristics and demographics, and online (dynamic) resources using programming and behaviour activity logs. Predictions are generated weekly during semester. Overall, the predictive and personalised feedback helped to reduce the gap between the lower and higher-performing students. Furthermore, students praised the prediction and the personalised feedback, conveying strong recommendations for future students to use the system. We also found that students who followed their personalised guidance and recommendations performed better in examinations.",different sources of data about students  ranging from static demographics to dynamic behavior logs  can be harnessed from a variety sources at higher education institutions  combining these assembles a rich digital footprint for students  which can enable institutions to better understand student behaviour and to better prepare for guiding students towards reaching their academic potential  this paper presents a new research methodology to automatically detect students    at risk    of failing an assignment in computer programming modules  courses  and to simultaneously support adaptive feedback  by leveraging historical student data  we built predictive models using students    offline  static  information including student characteristics and demographics  and online  dynamic  resources using programming and behaviour activity logs  predictions are generated weekly during semester  overall  the predictive and personalised feedback helped to reduce the gap between the lower and higher performing students  furthermore  students praised the prediction and the personalised feedback  conveying strong recommendations for future students to use the system  we also found that students who followed their personalised guidance and recommendations performed better in examinations ,9.222166,8.055002,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Fast deep neural networks for image processing using posits and ARM scalable vector extension,"With the advent of image processing and computer vision for automotive under real-time constraints, the need for fast and architecture-optimized arithmetic operations is crucial. Alternative and efficient representations for real numbers are starting to be explored, and among them, the recently introduced posit\(^{\mathrm{TM}}\) number system is highly promising. Furthermore, with the implementation of the architecture-specific mathematical library thoroughly targeting single-instruction multiple-data (SIMD) engines, the acceleration provided to deep neural networks framework is increasing. In this paper, we present the implementation of some core image processing operations exploiting the posit arithmetic and the ARM scalable vector extension SIMD engine. Moreover, we present applications of real-time image processing to the autonomous driving scenario, presenting benchmarks on the tinyDNN deep neural network (DNN) framework.",with the advent of image processing and computer vision for automotive under real time constraints  the need for fast and architecture optimized arithmetic operations is crucial  alternative and efficient representations for real numbers are starting to be explored  and among them  the recently introduced posit     mathrm tm     number system is highly promising  furthermore  with the implementation of the architecture specific mathematical library thoroughly targeting single instruction multiple data  simd  engines  the acceleration provided to deep neural networks framework is increasing  in this paper  we present the implementation of some core image processing operations exploiting the posit arithmetic and the arm scalable vector extension simd engine  moreover  we present applications of real time image processing to the autonomous driving scenario  presenting benchmarks on the tinydnn deep neural network  dnn  framework ,4.1060824,6.041787,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Automated Quality Assessment of Incident Tickets for Smart Service Continuity,"Customer management operations, such as Incident Management (IM), are traditionally performed manually often resulting in time consuming and error-prone activities. Artificial Intelligence (AI) software systems and connected information management can help handle the discontinuities in critical business tasks. AI Incident Management (AIIM) becomes therefore a set of practices and tools to resolve incidents by means of AI-enabled organizational processes and methodologies. The software automation of AIIM could reduce unplanned interruptions of service and let customers resume their work as quick as possible.
 While several techniques were presented in the literature to automatically identify the problems described in incident tickets by customers, this paper focuses on the qualitative analysis of the provided descriptions and on using such analysis within the context of an AI-enabled business organizational process. When an incident ticket does not describe properly the problem, the analyst must ask the customer for additional details which could require several long-lasting interactions. This paper overviews ACQUA, an AIIM approach that uses machine-learning to automatically assess the quality of ticket descriptions with the goals of removing the need of additional communications and guiding the customers to properly describe the incident.
 Keywords
 Incident Management
 Service continuity
 Digital transformation
 Artificial intelligence
 Natural Language Processing",customer management operations  such as incident management  im   are traditionally performed manually often resulting in time consuming and error prone activities  artificial intelligence  ai  software systems and connected information management can help handle the discontinuities in critical business tasks  ai incident management  aiim  becomes therefore a set of practices and tools to resolve incidents by means of ai enabled organizational processes and methodologies  the software automation of aiim could reduce unplanned interruptions of service and let customers resume their work as quick as possible   while several techniques were presented in the literature to automatically identify the problems described in incident tickets by customers  this paper focuses on the qualitative analysis of the provided descriptions and on using such analysis within the context of an ai enabled business organizational process  when an incident ticket does not describe properly the problem  the analyst must ask the customer for additional details which could require several long lasting interactions  this paper overviews acqua  an aiim approach that uses machine learning to automatically assess the quality of ticket descriptions with the goals of removing the need of additional communications and guiding the customers to properly describe the incident   keywords  incident management  service continuity  digital transformation  artificial intelligence  natural language processing,6.082855,4.700645,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
SWIoTA: Anomaly Detection for Distributed Ledger Technology-Based Internet of Things (IOTA) Using Sliding Window (SW) Technique,"IOTA is a Digital Ledger Technology (DLT) prototype for IoT applications that has attracted a rising popularity in recent years. One issue that acts as obstacle to its widespread adoption are the cybersecurity concerns. Some of the security concerns in IOTA include Denial of Service (DoS) double spending, parasite attacks, and DDoS attacks. In this work, we developed a Machine-Learning (ML) approach to create security threat index that can be utilized to proactively provide defenses to the IOTA decentralized infrastructure as well as individual nodes against potential compromises. Our approach is established on the sliding window customized technique to classify the data generated from the DAG-based nodes for cybersecurity anomaly detection. To validate the approach, we implemented â€œDoS attacksâ€ threat model in the DLT-based IoT environment using Raspberry Pi devices and experimented our security methods and algorithms in this environment. The preliminary experimental results are promising.
 Keywords
 Distributed ledger technology
 Internet of Things
 Tangle
 Cybersecurity
 Sliding Window technique
 Anomaly detection
 Machine learning",iota is a digital ledger technology  dlt  prototype for iot applications that has attracted a rising popularity in recent years  one issue that acts as obstacle to its widespread adoption are the cybersecurity concerns  some of the security concerns in iota include denial of service  dos  double spending  parasite attacks  and ddos attacks  in this work  we developed a machine learning  ml  approach to create security threat index that can be utilized to proactively provide defenses to the iota decentralized infrastructure as well as individual nodes against potential compromises  our approach is established on the sliding window customized technique to classify the data generated from the dag based nodes for cybersecurity anomaly detection  to validate the approach  we implemented    dos attacks    threat model in the dlt based iot environment using raspberry pi devices and experimented our security methods and algorithms in this environment  the preliminary experimental results are promising   keywords  distributed ledger technology  internet of things  tangle  cybersecurity  sliding window technique  anomaly detection  machine learning,3.206652,5.5184264,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Using Big Data and Serverless Architecture to Follow the Emotional Response to the COVID-19 Pandemic in Mexico,"The emergence of the COVID-19 pandemic has led to an unprecedented change in the lifestyle routines of millions of people. Beyond the multiple repercussions of the pandemic, we are also facing significant challenges in the populationâ€™s mental health and health programs. Typical techniques to measure the populationâ€™s mental health are semiautomatic. Social media allow us to know habits and daily life, making this data a rich silo for understanding emotional and mental well-being. This study aims to build a resilient and flexible system that allows us to track and measure the sentiment changes of a given population, in our case, the Mexican people, in response to the COVID-19 pandemic. We built an extensive data system utilizing modern cloud-based serverless architectures to analyze 760,064,879 public domain tweets collected from a public access repository to examine the collective shifts in the general mood about the pandemic evolution, news cycles, and governmental policies using open sentiment analysis tools. We provide metrics, advantages, and challenges of developing serverless cloud-based architectures for a natural language processing project of a large magnitude.
 Keywords
 Sentiment analysis
 Big data
 COVID-19
 Machine learning
 Mexico
 Twitter",the emergence of the covid    pandemic has led to an unprecedented change in the lifestyle routines of millions of people  beyond the multiple repercussions of the pandemic  we are also facing significant challenges in the population   s mental health and health programs  typical techniques to measure the population   s mental health are semiautomatic  social media allow us to know habits and daily life  making this data a rich silo for understanding emotional and mental well being  this study aims to build a resilient and flexible system that allows us to track and measure the sentiment changes of a given population  in our case  the mexican people  in response to the covid    pandemic  we built an extensive data system utilizing modern cloud based serverless architectures to analyze             public domain tweets collected from a public access repository to examine the collective shifts in the general mood about the pandemic evolution  news cycles  and governmental policies using open sentiment analysis tools  we provide metrics  advantages  and challenges of developing serverless cloud based architectures for a natural language processing project of a large magnitude   keywords  sentiment analysis  big data  covid     machine learning  mexico  twitter,5.006787,5.81511,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Boulder falls in Hong Kong â€” insights from power law relationships and supervised machine learning,"Intelligently predicting the frequency and volume of natural hazards, including boulder falls, attracts widespread attention in earth science and engineering communities. Taking Hong Kong, China, which is a highly developed and densely populated city, as a research example, the present paper statistically studies the occurrence of boulder falls based on power law relationships and supervised machine learning. The 2002â€“2016 boulder fall inventory of Hong Kong, which consists of 194 boulder falls, is compiled and analyzed in detail, including volume and spatial distributions. Based on the findings, a power law relationship with the b-value greater than one is particularly proposed for Hong Kong, which then allows major boulder falls (volume â‰¥1 m3) occurring in two subsequent years to be accurately predicted. In order to predict volume ranges of potential boulder falls, eight supervised machine learning algorithms are trained and validated based on sixty-five filtered samples with five represented features. Two key conclusions are drawn from the findings. First, the geological settings, altitudes, and gradients of source locations are demonstrated to be three triggering factors of different volume ranges of boulder falls. Second, the logistic regression algorithm has the best performance in predicting boulder fall volumes among all the algorithms. The f1-score of 5-fold cross-validation is 72.9%, and the prediction accuracy of the test dataset is 75.8%. We are confident that the methodologies and results in this paper will pave the way for analyzing other types of natural terrain hazards in addition to boulder falls in the long run.",intelligently predicting the frequency and volume of natural hazards  including boulder falls  attracts widespread attention in earth science and engineering communities  taking hong kong  china  which is a highly developed and densely populated city  as a research example  the present paper statistically studies the occurrence of boulder falls based on power law relationships and supervised machine learning  the             boulder fall inventory of hong kong  which consists of     boulder falls  is compiled and analyzed in detail  including volume and spatial distributions  based on the findings  a power law relationship with the b value greater than one is particularly proposed for hong kong  which then allows major boulder falls  volume      m   occurring in two subsequent years to be accurately predicted  in order to predict volume ranges of potential boulder falls  eight supervised machine learning algorithms are trained and validated based on sixty five filtered samples with five represented features  two key conclusions are drawn from the findings  first  the geological settings  altitudes  and gradients of source locations are demonstrated to be three triggering factors of different volume ranges of boulder falls  second  the logistic regression algorithm has the best performance in predicting boulder fall volumes among all the algorithms  the f  score of   fold cross validation is        and the prediction accuracy of the test dataset is        we are confident that the methodologies and results in this paper will pave the way for analyzing other types of natural terrain hazards in addition to boulder falls in the long run ,4.2116957,3.4925292,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Deep learning based classification of dynamic processes in time-resolved X-ray tomographic microscopy,"Time-resolved X-ray tomographic microscopy is an invaluable technique to investigate dynamic processes in 3D for extended time periods. Because of the limited signal-to-noise ratio caused by the short exposure times and sparse angular sampling frequency, obtaining quantitative information through post-processing remains challenging and requires intensive manual labor. This severely limits the accessible experimental parameter space and so, prevents fully exploiting the capabilities of the dedicated time-resolved X-ray tomographic stations. Though automatic approaches, often exploiting iterative reconstruction methods, are currently being developed, the required computational costs typically remain high. Here, we propose a highly efficient reconstruction and classification pipeline (SIRT-FBP-MS-D-DIFF) that combines an algebraic filter approximation and machine learning to significantly reduce the computational time. The dynamic features are reconstructed by standard filtered back-projection with an algebraic filter to approximate iterative reconstruction quality in a computationally efficient manner. The raw reconstructions are post-processed with a trained convolutional neural network to extract the dynamic features from the low signal-to-noise ratio reconstructions in a fully automatic manner. The capabilities of the proposed pipeline are demonstrated on three different dynamic fuel cell datasets, one exploited for training and two for testing without network retraining. The proposed approach enables automatic processing of several hundreds of datasets in a single day on a single GPU node readily available at most institutions, so extending the possibilities in future dynamic X-ray tomographic investigations.",time resolved x ray tomographic microscopy is an invaluable technique to investigate dynamic processes in  d for extended time periods  because of the limited signal to noise ratio caused by the short exposure times and sparse angular sampling frequency  obtaining quantitative information through post processing remains challenging and requires intensive manual labor  this severely limits the accessible experimental parameter space and so  prevents fully exploiting the capabilities of the dedicated time resolved x ray tomographic stations  though automatic approaches  often exploiting iterative reconstruction methods  are currently being developed  the required computational costs typically remain high  here  we propose a highly efficient reconstruction and classification pipeline  sirt fbp ms d diff  that combines an algebraic filter approximation and machine learning to significantly reduce the computational time  the dynamic features are reconstructed by standard filtered back projection with an algebraic filter to approximate iterative reconstruction quality in a computationally efficient manner  the raw reconstructions are post processed with a trained convolutional neural network to extract the dynamic features from the low signal to noise ratio reconstructions in a fully automatic manner  the capabilities of the proposed pipeline are demonstrated on three different dynamic fuel cell datasets  one exploited for training and two for testing without network retraining  the proposed approach enables automatic processing of several hundreds of datasets in a single day on a single gpu node readily available at most institutions  so extending the possibilities in future dynamic x ray tomographic investigations ,4.5452213,7.12944,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Extended Formulations via Decision Diagrams,"We propose a general algorithm of constructing an extended formulation for any given set of linear constraints with integer coefficients. Our algorithm consists of two phases: first construct a decision diagram (V, E) that somehow represents a given \(m \times n\) constraint matrix, and then build an equivalent set of |E| linear constraints over \(n+|V|\) variables. That is, the size of the resultant extended formulation depends not explicitly on the number m of the original constraints, but on its decision diagram representation. Therefore, we may significantly reduce the computation time and space for optimization problems with integer constraint matrices by solving them under the extended formulations, especially when we obtain concise decision diagram representations for the matrices. We demonstrate the effectiveness of our extended formulations for mixed integer programming and the 1-norm regularized soft margin optimization tasks over synthetic and real datasets.
 Eligible for best student paper.
 Keywords
 Extend formulation
 Decision diagrams
 Mixed integer programs",we propose a general algorithm of constructing an extended formulation for any given set of linear constraints with integer coefficients  our algorithm consists of two phases  first construct a decision diagram  v  e  that somehow represents a given   m  times n   constraint matrix  and then build an equivalent set of  e  linear constraints over   n  v    variables  that is  the size of the resultant extended formulation depends not explicitly on the number m of the original constraints  but on its decision diagram representation  therefore  we may significantly reduce the computation time and space for optimization problems with integer constraint matrices by solving them under the extended formulations  especially when we obtain concise decision diagram representations for the matrices  we demonstrate the effectiveness of our extended formulations for mixed integer programming and the   norm regularized soft margin optimization tasks over synthetic and real datasets   eligible for best student paper   keywords  extend formulation  decision diagrams  mixed integer programs,3.228091,7.9787846,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
A Dual-BRAM Solution for BTSx Instructions on FPGA Processors,"Processing time is very important in biomedical equipment and affects decision taking, result interpretation or calculus for a variety of targeted applications: ECG, PPG or SpO2. To answer the need for rapid medical application prototyping, we present a solution to optimize instruction execution on FPGA processors. The targeted applications account for multiple input signal acquisition in a scenario of body worn sensors. This work addresses the implementation of bit/byte-oriented register operations, reducing the operating time of the processor by simultaneously reading and writing from/in the memory block. During customary execution, bit/byte test skip instructions introduce a one clock-cycle delay. This paper proposes a dual-instruction memory solution, implemented using block RAM modules, to eliminate the respective execution delay. The proposed solution enables the simultaneous retrieval of two instructions which would follow the execution path, regardless whether the skip decision has been taken or not. The VHDL implementation of the proposed solution was simulated in Vivado and was validated on an Artix7 35T and a Kintex Ultrascale+ FPGA respectively.
 Keywords
 Biomedical equipment
 Biomedical signal processing
 FPGA processor
 BTX instruction",processing time is very important in biomedical equipment and affects decision taking  result interpretation or calculus for a variety of targeted applications  ecg  ppg or spo   to answer the need for rapid medical application prototyping  we present a solution to optimize instruction execution on fpga processors  the targeted applications account for multiple input signal acquisition in a scenario of body worn sensors  this work addresses the implementation of bit byte oriented register operations  reducing the operating time of the processor by simultaneously reading and writing from in the memory block  during customary execution  bit byte test skip instructions introduce a one clock cycle delay  this paper proposes a dual instruction memory solution  implemented using block ram modules  to eliminate the respective execution delay  the proposed solution enables the simultaneous retrieval of two instructions which would follow the execution path  regardless whether the skip decision has been taken or not  the vhdl implementation of the proposed solution was simulated in vivado and was validated on an artix    t and a kintex ultrascale  fpga respectively   keywords  biomedical equipment  biomedical signal processing  fpga processor  btx instruction,3.7727096,6.047902,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
BIM and Data Integration: A Workflow for the Implementation of Digital Twins,"In recent years, the massive development of digital technologies for capturing data from sensors, located both in-side buildings and in the urban environment, made necessary an expansion of the traditional semantic domains of the construction industry with reference to BIM-based information management processes. The integration of data between BIM models and IoT devices enables the creation of Digital Twins (DTs) of built heritage assets, capable of connecting data coming continuously from sensors with digital models of those assets. This enables the management of large masses of data produced at various stages of the building lifecycle, making it possible to experiment with Artificial Intelligence (AI) and data analytics for predictive analysis of building system behavior and performance. This paper presents the results of a research, which aimed to develop a methodological and operational workflow for the creation of Digital Twin of buildings. The interoperability offered by the IFC schema allowed the use of an external platform for linking different semantic fields. Thus, on the one hand, a federated BIM model was created, and on the other hand, real-time acquired data from a system of sensors in-stalled at different locations in the building were recorded and stored in a central server.
 Keywords
 BIM
 FM
 AI
 IoT
 Big data
 Digital twin",in recent years  the massive development of digital technologies for capturing data from sensors  located both in side buildings and in the urban environment  made necessary an expansion of the traditional semantic domains of the construction industry with reference to bim based information management processes  the integration of data between bim models and iot devices enables the creation of digital twins  dts  of built heritage assets  capable of connecting data coming continuously from sensors with digital models of those assets  this enables the management of large masses of data produced at various stages of the building lifecycle  making it possible to experiment with artificial intelligence  ai  and data analytics for predictive analysis of building system behavior and performance  this paper presents the results of a research  which aimed to develop a methodological and operational workflow for the creation of digital twin of buildings  the interoperability offered by the ifc schema allowed the use of an external platform for linking different semantic fields  thus  on the one hand  a federated bim model was created  and on the other hand  real time acquired data from a system of sensors in stalled at different locations in the building were recorded and stored in a central server   keywords  bim  fm  ai  iot  big data  digital twin,10.293262,7.028612,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Convolutional Neural Networks for Image Recognition in Mixed Reality Using Voice Command Labeling,"In the context of the Industrial Internet of Things (IIoT), image and object recognition has become an important factor. Camera systems provide information to realize sophisticated monitoring applications, quality control solutions, or reliable prediction approaches. During the last years, the evolution of smart glasses has enabled new technical solutions as they can be seen as mobile and ubiquitous cameras. As an important aspect in this context, the recognition of objects from images must be reliably solved to realize the previously mentioned solutions. Therefore, algorithms need to be trained with labeled input to recognize differences in input images. We simplify this labeling process using voice commands in Mixed Reality. The generated input from the mixed-reality labeling is put into a convolutional neural network. The latter is trained to classify the images with different objects. In this work, we describe the development of this mixed-reality prototype with its backend architecture. Furthermore, we test the classification robustness with image distortion filters. We validated our approach with format parts from a blister machine provided by a pharmaceutical packaging company in Germany. Our results indicate that the proposed architecture is at least suitable for small classification problems and not sensitive to distortions.
 Keywords
 Mixed Realiy
 Image recognition
 Convolutional Neural Networks",in the context of the industrial internet of things  iiot   image and object recognition has become an important factor  camera systems provide information to realize sophisticated monitoring applications  quality control solutions  or reliable prediction approaches  during the last years  the evolution of smart glasses has enabled new technical solutions as they can be seen as mobile and ubiquitous cameras  as an important aspect in this context  the recognition of objects from images must be reliably solved to realize the previously mentioned solutions  therefore  algorithms need to be trained with labeled input to recognize differences in input images  we simplify this labeling process using voice commands in mixed reality  the generated input from the mixed reality labeling is put into a convolutional neural network  the latter is trained to classify the images with different objects  in this work  we describe the development of this mixed reality prototype with its backend architecture  furthermore  we test the classification robustness with image distortion filters  we validated our approach with format parts from a blister machine provided by a pharmaceutical packaging company in germany  our results indicate that the proposed architecture is at least suitable for small classification problems and not sensitive to distortions   keywords  mixed realiy  image recognition  convolutional neural networks,4.394977,5.5300894,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Laying Out the Framework,"To this point, we have focused entirely on the theoretical aspects of outlier and anomaly detection. We will still need to delve into theory on several other occasions in later chapters, but we have enough to get started on developing a proper anomaly detection service.",to this point  we have focused entirely on the theoretical aspects of outlier and anomaly detection  we will still need to delve into theory on several other occasions in later chapters  but we have enough to get started on developing a proper anomaly detection service ,9.763811,5.465532,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
â€œAutonomous weaponsâ€ as a geopolitical signifier in a national power play: analysing AI imaginaries in Chinese and US military policies,"â€œAutonomous weapon systemsâ€ (AWS) have been subject to intense discussions for years. Numerous political, academic and legal actors are debating their consequences, with many calling for strict regulation or even a global ban. Surprisingly, it often remains unclear which technologies the term AWS refers to and also in what sense these systems can be characterised as autonomous at all. Despite being feared by many, weapons that are completely self-governing and beyond human control are more of a conceptual possibility than an actual military reality.
 As will be argued, the conflicting interpretations of AWS are largely the result of the diverse meanings that are constructed in political discourses. These interpretations convert specific understandings of AI into strategic assets and consequently hinder the establishment of common ethical standards and legal regulations. In particular, this article looks at the publicly available military AI strategies and position papers by China and the USA. It analyses how AWS technologies, understood as evoking sociotechnical imaginaries, are politicised to serve particular national interests.
 The article presents the current theoretical debate, which has sought to find a functional definition of AWS that is sufficiently unambiguous for regulatory or military contexts. Approaching AWS as a phenomenon that is embedded in a particular sociotechnical imaginary, however, flags up the ways in which nation states portray themselves as part of a global AI race, competing over economic, military and geopolitical advantages. Nation states do not just enforce their geopolitical ambitions through a fierce realpolitik rhetoric but also play around with ambiguities in definitions. This especially holds true for China and the USA, since they are regarded and regard themselves as hegemonic antagonists, presenting competing self-conceptions that are apparent in their histories, political doctrines and identities. The way they showcase their AI-driven military prowess indicates an ambivalent rhetoric of legal sobriety, tech-regulation and aggressive national dominance. AWS take on the role of signifiers that are employed to foster political legitimacy or to spark deliberate confusion and deterrence.",   autonomous weapon systems     aws  have been subject to intense discussions for years  numerous political  academic and legal actors are debating their consequences  with many calling for strict regulation or even a global ban  surprisingly  it often remains unclear which technologies the term aws refers to and also in what sense these systems can be characterised as autonomous at all  despite being feared by many  weapons that are completely self governing and beyond human control are more of a conceptual possibility than an actual military reality   as will be argued  the conflicting interpretations of aws are largely the result of the diverse meanings that are constructed in political discourses  these interpretations convert specific understandings of ai into strategic assets and consequently hinder the establishment of common ethical standards and legal regulations  in particular  this article looks at the publicly available military ai strategies and position papers by china and the usa  it analyses how aws technologies  understood as evoking sociotechnical imaginaries  are politicised to serve particular national interests   the article presents the current theoretical debate  which has sought to find a functional definition of aws that is sufficiently unambiguous for regulatory or military contexts  approaching aws as a phenomenon that is embedded in a particular sociotechnical imaginary  however  flags up the ways in which nation states portray themselves as part of a global ai race  competing over economic  military and geopolitical advantages  nation states do not just enforce their geopolitical ambitions through a fierce realpolitik rhetoric but also play around with ambiguities in definitions  this especially holds true for china and the usa  since they are regarded and regard themselves as hegemonic antagonists  presenting competing self conceptions that are apparent in their histories  political doctrines and identities  the way they showcase their ai driven military prowess indicates an ambivalent rhetoric of legal sobriety  tech regulation and aggressive national dominance  aws take on the role of signifiers that are employed to foster political legitimacy or to spark deliberate confusion and deterrence ,11.67813,6.357024,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Choosing Exploration Process Path in Data Mining Processes for Complex Internet Objects,"We present an experimental case study of a novel and original framework for classifying aggregate objects, i.e. objects that consist of other objects. The features of the aggregated objects are converted into the features of aggregate ones, by use of aggregate functions. The choice of the functions, along with the specific method of classification can be automated by choosing of one of several process paths, and different paths can be picked for different parts of the domain. The results are encouraging and show that our approach allowing for automated choice, can be beneficial for the data mining results.
 Keywords
 Data mining
 Complex objects",we present an experimental case study of a novel and original framework for classifying aggregate objects  i e  objects that consist of other objects  the features of the aggregated objects are converted into the features of aggregate ones  by use of aggregate functions  the choice of the functions  along with the specific method of classification can be automated by choosing of one of several process paths  and different paths can be picked for different parts of the domain  the results are encouraging and show that our approach allowing for automated choice  can be beneficial for the data mining results   keywords  data mining  complex objects,4.1015615,4.8556976,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Art Generation Using Speech Emotions,"Translation of speech to image directly without text is an interesting and useful topic due to the potential application in computer-aided design, human-to-computer interaction, creation of an art form, etc. So, we have focused on developing a novel deep learning and GANs-based model which will take speech as an input from the user, analyze the emotions associated with it and accordingly generate the artwork which has been demanded by the user which will in turn provide a personalized experience. Concept of convolutional VQGAN is used to explore codebook consisting of context-rich visual parts, and the entire composition is modeled with autoregressive transformer architecture. Concept of CLIPâ€”Contrastive Language Image-Pre-Trainingâ€”also uses transformers a model which is trained to find which particular caption from a collection of captions will best fit with the given image used in our project. The input speech is classified into eight different emotions using MLP classifier trained of RAVDESS emotional speech audio dataset, and this acts as a base filter for the VQGAN model. Text converted from speech plays an important role in producing the final output image using CLIP model. VQGANâ€‰+â€‰CLIP model together utilizes both emotions and text to generate more personalized artwork.
 Keywords
 VQGAN
 CLIP
 Art generation
 Speech emotions",translation of speech to image directly without text is an interesting and useful topic due to the potential application in computer aided design  human to computer interaction  creation of an art form  etc  so  we have focused on developing a novel deep learning and gans based model which will take speech as an input from the user  analyze the emotions associated with it and accordingly generate the artwork which has been demanded by the user which will in turn provide a personalized experience  concept of convolutional vqgan is used to explore codebook consisting of context rich visual parts  and the entire composition is modeled with autoregressive transformer architecture  concept of clip   contrastive language image pre training   also uses transformers a model which is trained to find which particular caption from a collection of captions will best fit with the given image used in our project  the input speech is classified into eight different emotions using mlp classifier trained of ravdess emotional speech audio dataset  and this acts as a base filter for the vqgan model  text converted from speech plays an important role in producing the final output image using clip model  vqgan       clip model together utilizes both emotions and text to generate more personalized artwork   keywords  vqgan  clip  art generation  speech emotions,6.2152114,5.3523355,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Driving Big Data Capabilities and Sustainable Innovation in Organisations,"Big data can not only provide a glimpse into the current state of a business, but may also provide a foundation for discovering new business opportunities, driving process improvement and innovation and ultimately improving the bottom line. However, realising this explicit value from big data is not without challenges. It is estimated that few big data endeavours succeed, with only a small portion of analytic insights actually delivering measurable business value. The challenges are multifaceted, including factors such as a lack of an overall big data strategy, insufficient buy-in from executive management, resistance to technology adoption, inadequate technical and soft skills and team structures, and poorly-directed investments. Without an understanding of the current landscape or state of the art as far as technology and advanced analytics are concerned, along with a clear roadmap to guide their big data efforts, organisations will find it more difficult to realise the value that big data promises. In this paper some of the uncertainties and challenges faced by organisations with respect to big data are addressed, by presenting a model which evaluates an organisationâ€™s capabilities with regard to data centricity and provide an actionable roadmap for the implementation and improvement of big data endeavours. This enables organisations to focus their efforts on creating value from big data, where the model informs continuous efforts in improving organisational efficiency and effectiveness, and driving sustainable innovation.
 Keywords
 Big data
 Data-centric
 Maturity model",big data can not only provide a glimpse into the current state of a business  but may also provide a foundation for discovering new business opportunities  driving process improvement and innovation and ultimately improving the bottom line  however  realising this explicit value from big data is not without challenges  it is estimated that few big data endeavours succeed  with only a small portion of analytic insights actually delivering measurable business value  the challenges are multifaceted  including factors such as a lack of an overall big data strategy  insufficient buy in from executive management  resistance to technology adoption  inadequate technical and soft skills and team structures  and poorly directed investments  without an understanding of the current landscape or state of the art as far as technology and advanced analytics are concerned  along with a clear roadmap to guide their big data efforts  organisations will find it more difficult to realise the value that big data promises  in this paper some of the uncertainties and challenges faced by organisations with respect to big data are addressed  by presenting a model which evaluates an organisation   s capabilities with regard to data centricity and provide an actionable roadmap for the implementation and improvement of big data endeavours  this enables organisations to focus their efforts on creating value from big data  where the model informs continuous efforts in improving organisational efficiency and effectiveness  and driving sustainable innovation   keywords  big data  data centric  maturity model,11.039768,5.493901,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Effective Non-invasive Runway Monitoring System Development Using Dual Sensor Devices,"At airports, the runways are always troubled by the presence of ice, water, cracks, foreign objects, etc. To avoid such problems the runway is supposed to be monitored regularly. To monitor the runways a large number of techniques are available such as runway inspection mobile vans. These techniques are largely human dependent and need interruptions in the runwayâ€™s operations for inspection. In this position paper, we suggest an alternative way to monitor the runway. This method is non-invasive in nature with the involvement of Light Detection and Ranging (LIDAR) sensors. In the methodology, we describe the schemes of labelling the data obtained from LIDAR using MARWIS sensors fitted in a mobile van. We describe the entire system and the underlying technology involved in developing the system. The proposed system has the potential of developing an efficient runway monitoring system because the LIDAR technology has proved its efficiency in several terrestrial mapping and monitoring systems.
 Keywords
 Runway monitoring
 LIDAR
 Machine learning",at airports  the runways are always troubled by the presence of ice  water  cracks  foreign objects  etc  to avoid such problems the runway is supposed to be monitored regularly  to monitor the runways a large number of techniques are available such as runway inspection mobile vans  these techniques are largely human dependent and need interruptions in the runway   s operations for inspection  in this position paper  we suggest an alternative way to monitor the runway  this method is non invasive in nature with the involvement of light detection and ranging  lidar  sensors  in the methodology  we describe the schemes of labelling the data obtained from lidar using marwis sensors fitted in a mobile van  we describe the entire system and the underlying technology involved in developing the system  the proposed system has the potential of developing an efficient runway monitoring system because the lidar technology has proved its efficiency in several terrestrial mapping and monitoring systems   keywords  runway monitoring  lidar  machine learning,4.8596663,4.8226748,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
RAPP: A Robotic-Oriented Ecosystem for Delivering Smart User Empowering Applications for Older People,"It is a general truth that increase of age is associated with a level of mental and physical decline but unfortunately the former are often accompanied by social exclusion leading to marginalization and eventually further acceleration of the aging process. A new approach in alleviating the social exclusion of older people involves the use of assistive robots. As robots rapidly invade everyday life, the need of new software paradigms in order to address the userâ€™s unique needs becomes critical. In this paper we present a novel architectural design, the RAPP [a software platform to deliver smart, user empowering robotic applications (RApps)] framework that attempts to address this issue. The proposed framework has been designed in a cloud-based approach, integrating robotic devices and their respective applications. We aim to facilitate seamless development of RApps compatible with a wide range of supported robots and available to the public through a unified online store.",it is a general truth that increase of age is associated with a level of mental and physical decline but unfortunately the former are often accompanied by social exclusion leading to marginalization and eventually further acceleration of the aging process  a new approach in alleviating the social exclusion of older people involves the use of assistive robots  as robots rapidly invade everyday life  the need of new software paradigms in order to address the user   s unique needs becomes critical  in this paper we present a novel architectural design  the rapp  a software platform to deliver smart  user empowering robotic applications  rapps   framework that attempts to address this issue  the proposed framework has been designed in a cloud based approach  integrating robotic devices and their respective applications  we aim to facilitate seamless development of rapps compatible with a wide range of supported robots and available to the public through a unified online store ,9.082843,4.111278,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Customising the Interactive Film,"Interactive films in the form of non-linear branching narratives remain popular, yet non-linear filmic experiences can be created in completely different ways. This paper details how such a project entitled Youâ€¢Who? was envisaged and produced in the form of an exhibitable interactive artwork. There is no interaction whilst the film is being watched because it is rendered with user-supplied data such as a webcam photograph and voice recording captured voluntarily before the experience of watching begins. The paper explains the conceptual basis of the project, technical aspects of its implementation, observations from its public showings, and future directions of a potential genre that might tentatively be called â€˜customised filmâ€™.
 Keywords
 Customised Film
 Interactive Film
 Non-Linear Narrative",interactive films in the form of non linear branching narratives remain popular  yet non linear filmic experiences can be created in completely different ways  this paper details how such a project entitled you   who  was envisaged and produced in the form of an exhibitable interactive artwork  there is no interaction whilst the film is being watched because it is rendered with user supplied data such as a webcam photograph and voice recording captured voluntarily before the experience of watching begins  the paper explains the conceptual basis of the project  technical aspects of its implementation  observations from its public showings  and future directions of a potential genre that might tentatively be called    customised film      keywords  customised film  interactive film  non linear narrative,9.466396,6.4791117,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Feature Selection in Texts,"Feature selection is used in many application areas relevant to expert and intelligent systems, such as machine learning, data mining, cheminformatics and natural language processing. In this study we propose methods for feature selection and features analysis based on Support Vector Machines (SVM) with linear kernels. We explore how these techniques can be used to obtain some interesting information for further exploration of text data. The results provide satisfactory observations which may lead to progress in feature selection field.
 Keywords
 Feature selection
 Text classification
 Dimension reduction
 Support Vector Machines",feature selection is used in many application areas relevant to expert and intelligent systems  such as machine learning  data mining  cheminformatics and natural language processing  in this study we propose methods for feature selection and features analysis based on support vector machines  svm  with linear kernels  we explore how these techniques can be used to obtain some interesting information for further exploration of text data  the results provide satisfactory observations which may lead to progress in feature selection field   keywords  feature selection  text classification  dimension reduction  support vector machines,5.691211,4.2619147,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Designing a Deep-Learning Neural Network Chip to Detect Hardware Errors Using Brooksâ€“Iyengar Algorithm,"In this chapter, we discuss the implementation details of a deep-learning neural network (DNN) with nodes having the Brooksâ€“Iyengar algorithms running on a chip (or a single chip computer) that can provide efficient and scalable fault tolerant systems. However, implementations of such DNN and their training often have to deal with a trade-off between efficiency and flexibility. Pure software solutions on general-purpose processors tend to be slow because they do not take advantage of the inherent parallelism, whereas hardware realizations usually rely on optimizations that reduce the range of applicable network topologies, or attempt to increase processing efficiency by means of low-precision data representation.
 Keywords
 Deep learning
 Hardware
 Error detection
 Brooksâ€“Iyengar algorithm
 Distributed sensing
 Sensor networks
 Distributed computation
 Intelligent algorithms",in this chapter  we discuss the implementation details of a deep learning neural network  dnn  with nodes having the brooks   iyengar algorithms running on a chip  or a single chip computer  that can provide efficient and scalable fault tolerant systems  however  implementations of such dnn and their training often have to deal with a trade off between efficiency and flexibility  pure software solutions on general purpose processors tend to be slow because they do not take advantage of the inherent parallelism  whereas hardware realizations usually rely on optimizations that reduce the range of applicable network topologies  or attempt to increase processing efficiency by means of low precision data representation   keywords  deep learning  hardware  error detection  brooks   iyengar algorithm  distributed sensing  sensor networks  distributed computation  intelligent algorithms,3.8285313,7.7526126,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
"Towards Differentiating Business Intelligence, Big Data, Data Analytics and Knowledge Discovery","Confusion, ambiguity and misunderstanding of the concepts and terminology regarding different approaches concerned with analysing massive data sets (Business Intelligence, Big Data, Data Analytics and Knowledge Discovery) was identified as a significant issue faced by many academics, fellow researchers, industry professionals and domain experts. In that context, a need to critically evaluate these concept and approaches focusing on their similarities, differences and relationships was identified as useful for further research and industry professionals. In this position paper, we critically review these four approaches and produce a framework, which provides visual representation of the relationship between them to effectively support their identification and easier differentiation.
 Keywords
 Business Intelligence
 Big Data
 Data Analytics
 Knowledge Discovery",confusion  ambiguity and misunderstanding of the concepts and terminology regarding different approaches concerned with analysing massive data sets  business intelligence  big data  data analytics and knowledge discovery  was identified as a significant issue faced by many academics  fellow researchers  industry professionals and domain experts  in that context  a need to critically evaluate these concept and approaches focusing on their similarities  differences and relationships was identified as useful for further research and industry professionals  in this position paper  we critically review these four approaches and produce a framework  which provides visual representation of the relationship between them to effectively support their identification and easier differentiation   keywords  business intelligence  big data  data analytics  knowledge discovery,9.069374,5.4237585,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Combinatorial optimization with physics-inspired graph neural networks,"Combinatorial optimization problems are pervasive across science and industry. Modern deep learning tools are poised to solve these problems at unprecedented scales, but a unifying framework that incorporates insights from statistical physics is still outstanding. Here we demonstrate how graph neural networks can be used to solve combinatorial optimization problems. Our approach is broadly applicable to canonical NP-hard problems in the form of quadratic unconstrained binary optimization problems, such as maximum cut, minimum vertex cover, maximum independent set, as well as Ising spin glasses and higher-order generalizations thereof in the form of polynomial unconstrained binary optimization problems. We apply a relaxation strategy to the problem Hamiltonian to generate a differentiable loss function with which we train the graph neural network and apply a simple projection to integer variables once the unsupervised training process has completed. We showcase our approach with numerical results for the canonical maximum cut and maximum independent set problems. We find that the graph neural network optimizer performs on par or outperforms existing solvers, with the ability to scale beyond the state of the art to problems with millions of variables.",combinatorial optimization problems are pervasive across science and industry  modern deep learning tools are poised to solve these problems at unprecedented scales  but a unifying framework that incorporates insights from statistical physics is still outstanding  here we demonstrate how graph neural networks can be used to solve combinatorial optimization problems  our approach is broadly applicable to canonical np hard problems in the form of quadratic unconstrained binary optimization problems  such as maximum cut  minimum vertex cover  maximum independent set  as well as ising spin glasses and higher order generalizations thereof in the form of polynomial unconstrained binary optimization problems  we apply a relaxation strategy to the problem hamiltonian to generate a differentiable loss function with which we train the graph neural network and apply a simple projection to integer variables once the unsupervised training process has completed  we showcase our approach with numerical results for the canonical maximum cut and maximum independent set problems  we find that the graph neural network optimizer performs on par or outperforms existing solvers  with the ability to scale beyond the state of the art to problems with millions of variables ,3.1677794,8.277443,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Segmentation-free composite character recognition (CR) in bilingual handwritten text for Gurumukhiâ€“English scripts,"Segmentation and CR subprocesses play a vital role in any text recognition system like document, scene, and video text recognition. It is a quite challenging task to maintain the actual shape of character or matra during segmentation of text. However, this work proposes a segmentation-free approach to recognize the composite characters for Gurumukhi. A new dataset of composite characters has been designed with 307 classes for Gurumukhi script to evaluate the proposed methodology. Two-level classification with the help of two different CNN architectures is proposed to train the model with 307 classes. The pretrained deep network models like Vgg19 and ResNet50 with the help of transfer learning have been used to accelerate the classification of diverse training data. In feature extraction process, various kinds of handcrafted and deep learning features are extracted and classified using SVM and RF. For bilingual text recognition, script identification approach has been proposed using Vgg19 features and bagging-based ensemble classifier. Further, the efficiency of proposed work has been evaluated by comparing the results of composite dataset with those of presegmented dataset of individual characters and modifiers. To extend the scope of work to bilingual text recognition, four different kinds of datasets have been considered. The composite dataset has been able to achieve the highest accuracy of 99% using proposed approach which stands quite close to the accuracy of presegmented dataset.",segmentation and cr subprocesses play a vital role in any text recognition system like document  scene  and video text recognition  it is a quite challenging task to maintain the actual shape of character or matra during segmentation of text  however  this work proposes a segmentation free approach to recognize the composite characters for gurumukhi  a new dataset of composite characters has been designed with     classes for gurumukhi script to evaluate the proposed methodology  two level classification with the help of two different cnn architectures is proposed to train the model with     classes  the pretrained deep network models like vgg   and resnet   with the help of transfer learning have been used to accelerate the classification of diverse training data  in feature extraction process  various kinds of handcrafted and deep learning features are extracted and classified using svm and rf  for bilingual text recognition  script identification approach has been proposed using vgg   features and bagging based ensemble classifier  further  the efficiency of proposed work has been evaluated by comparing the results of composite dataset with those of presegmented dataset of individual characters and modifiers  to extend the scope of work to bilingual text recognition  four different kinds of datasets have been considered  the composite dataset has been able to achieve the highest accuracy of     using proposed approach which stands quite close to the accuracy of presegmented dataset ,3.6800418,5.415906,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
A Computer Vision-Based Water Level Monitoring System for Touchless and Sustainable Water Dispensing,"In recent years, the need for contactless and sustainable systems has become increasingly relevant. The traditional water dispensers, which require contact with the dispenser and often involve single-use plastic cups or bottles, are not only unhygienic but also contribute to environmental pollution. This paper presents a touchless water dispenser system that uses artificial intelligence (AI) to control the dispensing of water or any liquid beverage. The system is designed to fill a container under the nozzle, dispense water when the container is aligned with the flow, and stop dispensing when the container is full, all without requiring any physical contact. This approach ensures compliance with hygiene regulations and promotes environmental sustainability by eliminating the need for plastic bottles or cups, making it a â€œplastic-freeâ€ and â€œzero wasteâ€ system. The prototype is based on a computer vision approach that employs an RGB camera and a Raspberry Pi board, which allows for real-time image processing and machine learning operations. The system uses image processing techniques to detect the presence of a container under the nozzle and then utilizes AI algorithms to control the flow of liquid. The system is trained using machine learning models and optimized to ensure accuracy and efficiency. We discuss the development and implementation of the touchless water dispenser system, including the hardware and software components used, the algorithms employed, and the testing and evaluation of the system. The results of our experiments show that the touchless water dispenser system is highly accurate and efficient, and it offers a safe and sustainable alternative to traditional water dispensers. The system has the potential to be used in a variety of settings, including public spaces, hospitals, schools, and offices, where hygiene and sustainability are of utmost importance.
 Keywords
 Touchless Water Dispenser
 Computer Vision
 Artificial Intelligence
 Sustainability",in recent years  the need for contactless and sustainable systems has become increasingly relevant  the traditional water dispensers  which require contact with the dispenser and often involve single use plastic cups or bottles  are not only unhygienic but also contribute to environmental pollution  this paper presents a touchless water dispenser system that uses artificial intelligence  ai  to control the dispensing of water or any liquid beverage  the system is designed to fill a container under the nozzle  dispense water when the container is aligned with the flow  and stop dispensing when the container is full  all without requiring any physical contact  this approach ensures compliance with hygiene regulations and promotes environmental sustainability by eliminating the need for plastic bottles or cups  making it a    plastic free    and    zero waste    system  the prototype is based on a computer vision approach that employs an rgb camera and a raspberry pi board  which allows for real time image processing and machine learning operations  the system uses image processing techniques to detect the presence of a container under the nozzle and then utilizes ai algorithms to control the flow of liquid  the system is trained using machine learning models and optimized to ensure accuracy and efficiency  we discuss the development and implementation of the touchless water dispenser system  including the hardware and software components used  the algorithms employed  and the testing and evaluation of the system  the results of our experiments show that the touchless water dispenser system is highly accurate and efficient  and it offers a safe and sustainable alternative to traditional water dispensers  the system has the potential to be used in a variety of settings  including public spaces  hospitals  schools  and offices  where hygiene and sustainability are of utmost importance   keywords  touchless water dispenser  computer vision  artificial intelligence  sustainability,4.927012,4.7968373,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Towards Continuous Safety Assessment in Context of DevOps,"To select videos to compose a change detection dataset, we can consider the videosâ€™ difficulty level. We need to use difficulty maps, which store values representing the pixelsâ€™ difficulty level, to estimate these levels. The problem is that ground truth is needed to generate a difficulty map, and generating the ground truth requires manual attribution of labels to the pixels of the frames. Identifying the difficulty level of a video before producing its ground truth allows researchers to obtain the difficulty level, select the videos considering this information, and, subsequently, generate ground truths only for the videos with different difficulty levels. Datasets containing videos with different difficulty levels can evaluate an algorithm more adequately. In this research, we developed a method to generate difficulty maps of a video without using its ground truth. Our method uses the videos and the ground truths from the CDNet 2014 dataset to generate difficulty maps to train a pix2pix neural network. The results showed that the trained network could generate difficulty maps similar to those generated by the traditional approach.",to select videos to compose a change detection dataset  we can consider the videos    difficulty level  we need to use difficulty maps  which store values representing the pixels    difficulty level  to estimate these levels  the problem is that ground truth is needed to generate a difficulty map  and generating the ground truth requires manual attribution of labels to the pixels of the frames  identifying the difficulty level of a video before producing its ground truth allows researchers to obtain the difficulty level  select the videos considering this information  and  subsequently  generate ground truths only for the videos with different difficulty levels  datasets containing videos with different difficulty levels can evaluate an algorithm more adequately  in this research  we developed a method to generate difficulty maps of a video without using its ground truth  our method uses the videos and the ground truths from the cdnet      dataset to generate difficulty maps to train a pix pix neural network  the results showed that the trained network could generate difficulty maps similar to those generated by the traditional approach ,3.4408944,6.168886,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Managing AI in the Enterprise Succeeding with AI Projects and MLOps to Build Sustainable AI Organizations,"Promoted by the internet companies, continuous delivery is more and more appealing to industries which develop systems with safety-critical functions. Since safety-critical systems must meet regulatory requirements and require specific safety assessment processes in addition to the normal development steps, enabling continuous delivery of software in safety-critical systems requires the automation of the safety assessment process in the delivery pipeline. In this paper, we outline a continuous delivery pipeline for realizing continuous safety assessment in software-intensive safety-critical systems based on model-based safety assessment methods.
 Keywords
 Safety assessment
 Agile
 DevOps
 Continuous delivery",promoted by the internet companies  continuous delivery is more and more appealing to industries which develop systems with safety critical functions  since safety critical systems must meet regulatory requirements and require specific safety assessment processes in addition to the normal development steps  enabling continuous delivery of software in safety critical systems requires the automation of the safety assessment process in the delivery pipeline  in this paper  we outline a continuous delivery pipeline for realizing continuous safety assessment in software intensive safety critical systems based on model based safety assessment methods   keywords  safety assessment  agile  devops  continuous delivery,7.7640595,5.2033563,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Smart article: application of intelligent platforms in next generation biomedical publications,"Production of scientific data has been accelerated exponentially though ease of access to the required knowledge is still challenging. Hence, the emergence of new frameworks to allow more efficient storage of information would be beneficial. Attaining intelligent platforms enable the smart article to serve as a forum for exchanging idea among experts of academic disciplines for a rapid and efficient scientific discourse.",production of scientific data has been accelerated exponentially though ease of access to the required knowledge is still challenging  hence  the emergence of new frameworks to allow more efficient storage of information would be beneficial  attaining intelligent platforms enable the smart article to serve as a forum for exchanging idea among experts of academic disciplines for a rapid and efficient scientific discourse ,10.639896,7.2595634,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
"Automated detection, categorisation and developersâ€™ experience with the violations of honesty in mobile apps","Human values such as honesty, social responsibility, fairness, privacy, and the like are things considered important by individuals and society. Software systems, including mobile software applications (apps), may ignore or violate such values, leading to negative effects in various ways for individuals and society. While some works have investigated different aspects of human values in software engineering, this mixed-methods study focuses on honesty as a critical human value. In particular, we studied (i) how to detect honesty violations in mobile apps, (ii) the types of honesty violations in mobile apps, and (iii) the perspectives of app developers on these detected honesty violations. We first develop and evaluate 7 machine learning (ML) models to automatically detect violations of the value of honesty in app reviews from an end-user perspective. The most promising was a Deep Neural Network model with F1 score of 0.921. We then conducted a manual analysis of 401 reviews containing honesty violations and characterised honesty violations in mobile apps into 10 categories: unfair cancellation and refund policies; false advertisements; delusive subscriptions; cheating systems; inaccurate information; unfair fees; no service; deletion of reviews; impersonation; and fraudulent-looking apps. A developer survey and interview study with mobile developers then identified 7 key causes behind honesty violations in mobile apps and 8 strategies to avoid or fix such violations. The findings of our developer study also articulate the negative consequences that honesty violations might bring for businesses, developers, and users. Finally, the app developersâ€™ feedback shows that our prototype ML-based models can have promising benefits in practice.",human values such as honesty  social responsibility  fairness  privacy  and the like are things considered important by individuals and society  software systems  including mobile software applications  apps   may ignore or violate such values  leading to negative effects in various ways for individuals and society  while some works have investigated different aspects of human values in software engineering  this mixed methods study focuses on honesty as a critical human value  in particular  we studied  i  how to detect honesty violations in mobile apps   ii  the types of honesty violations in mobile apps  and  iii  the perspectives of app developers on these detected honesty violations  we first develop and evaluate   machine learning  ml  models to automatically detect violations of the value of honesty in app reviews from an end user perspective  the most promising was a deep neural network model with f  score of        we then conducted a manual analysis of     reviews containing honesty violations and characterised honesty violations in mobile apps into    categories  unfair cancellation and refund policies  false advertisements  delusive subscriptions  cheating systems  inaccurate information  unfair fees  no service  deletion of reviews  impersonation  and fraudulent looking apps  a developer survey and interview study with mobile developers then identified   key causes behind honesty violations in mobile apps and   strategies to avoid or fix such violations  the findings of our developer study also articulate the negative consequences that honesty violations might bring for businesses  developers  and users  finally  the app developers    feedback shows that our prototype ml based models can have promising benefits in practice ,4.6939726,2.6259966,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
The Pipeline,"Data curation process for Analytics and Data Science typically involves collecting data from large number of heterogenous and federated source systems with varied schema structures. To make these datasets interoperable, their metadata needs to be standardized. This process, also known as Metadata Harmonization, is predominantly a manual effort involving several hours of concentrated work that leads to reduced efficiency of ML-Ops lifecycle. This paper aims to demonstrate the automation of metadata harmonization using Machine Learning. It focuses on using entity resolution and contextual embedding methods to capture hidden relationships among data columns that help identify similarities in metadata, and thereby, help in automated mapping of columns to a standard schema. This study also addresses the automated derivation of the correct ontological structure for the target data model using ML. While prior competing approaches address manual metadata harmonization problem by proposing usage of semantic middleware, data dictionaries and matching rules this approach recommends novel usage of Machine Learning which improves efficacy of overall lifecycle.
 Keywords
 Metadata harmonization
 Metadata crosswalking
 Data curation
 Metadata contextual embedding",data curation process for analytics and data science typically involves collecting data from large number of heterogenous and federated source systems with varied schema structures  to make these datasets interoperable  their metadata needs to be standardized  this process  also known as metadata harmonization  is predominantly a manual effort involving several hours of concentrated work that leads to reduced efficiency of ml ops lifecycle  this paper aims to demonstrate the automation of metadata harmonization using machine learning  it focuses on using entity resolution and contextual embedding methods to capture hidden relationships among data columns that help identify similarities in metadata  and thereby  help in automated mapping of columns to a standard schema  this study also addresses the automated derivation of the correct ontological structure for the target data model using ml  while prior competing approaches address manual metadata harmonization problem by proposing usage of semantic middleware  data dictionaries and matching rules this approach recommends novel usage of machine learning which improves efficacy of overall lifecycle   keywords  metadata harmonization  metadata crosswalking  data curation  metadata contextual embedding,5.965773,7.555183,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Artificial Intelligence and Its Applications,"The goal of all machine learning (ML) activity is to turn raw data into some prediction or classification or insight. Raw data appears on the left or at the beginning of this pipeline, and on the right or at the end comes the insight/prediction/classification and so on. Although each machine learning task will require a different pipeline, the basic structure or the building blocks remain the same. ML.NET offers several types/interfaces to make the creation of this pipeline easier. A broad understanding of these concepts will help you understand how ML.NET works under the hood.",the goal of all machine learning  ml  activity is to turn raw data into some prediction or classification or insight  raw data appears on the left or at the beginning of this pipeline  and on the right or at the end comes the insight prediction classification and so on  although each machine learning task will require a different pipeline  the basic structure or the building blocks remain the same  ml net offers several types interfaces to make the creation of this pipeline easier  a broad understanding of these concepts will help you understand how ml net works under the hood ,8.449749,7.4343143,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Automated Metadata Harmonization Using Entity Resolution and Contextual Embedding,"This chapter provides complete information on artificial intelligence and its usage in the various industries. In this chapter, we described different learning methods such as supervised, unsupervised, and reinforcement. The various algorithms based on these learning methods are also described in this chapter. The emerging research in the field of AI is covered in the chapter. Finally, chapter gives industrial applications of AI and production cycle for AI-powered industry.
 Keywords
 Artificial intelligence
 Machine learning
 Deep learning
 Financial
 Manufacturing
 Healthcare
 Computer vision
 Convolutional neural network",this chapter provides complete information on artificial intelligence and its usage in the various industries  in this chapter  we described different learning methods such as supervised  unsupervised  and reinforcement  the various algorithms based on these learning methods are also described in this chapter  the emerging research in the field of ai is covered in the chapter  finally  chapter gives industrial applications of ai and production cycle for ai powered industry   keywords  artificial intelligence  machine learning  deep learning  financial  manufacturing  healthcare  computer vision  convolutional neural network,11.137576,6.1900873,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Effects of multimodal low-opioid anesthesia protocol during on-pump coronary artery bypass grafting: a prospective cohort study,"Background
 The most favorable anesthesia protocol during on-pump coronary artery bypass grafting (CABG) in patients with coronary heart disease remains unclear, despite previous publications regarding the interaction between anesthesia protocol and postoperative complications. The aim of the study was to compare the effect of a multimodal low-opioid anesthesia protocol (MLOP) on early postoperative complications during on-pump CABG.
 Methods
 A single-center prospective cohort study including 120 patients undergoing on-pump CABG aged 18 to 65 years, divided into two groups according to undergoing MLOP or routine-opioid anesthesia protocol (ROP). The analyzed parameters were plasma IL-6 levels, complications, duration of mechanical ventilation, length of intensive care unit stay, and hospitalization.
 Results
 In the MLOP group, the levels of IL-6 at the end of the surgery were 25.6% significantly lower compared to the ROP group (33.4â€‰Â±â€‰9.4 vs. 44.9â€‰Â±â€‰15.9, pâ€‰<â€‰0.0001), the duration of mechanical ventilation was significantly shorter (2.0 (2.0; 3.0) h vs. 4.0 (3.0; 5.0) h, pâ€‰<â€‰0.001), the incidence of low cardiac output syndrome was almost two and half times lower (7 (11.7%) vs. 16 (26.7%), pâ€‰=â€‰0.037), and also the incidence of postoperative atrial fibrillation was significantly lower (9 (15.0%) vs. 19 (31.7%), pâ€‰=â€‰0.031).
 Conclusion
 Our study confirms that using MLOP was characterized by significantly lower levels of IL-6 at the end of surgery and a lower incidence of low cardiac output syndrome and postoperative atrial fibrillation than ROP.
 Trial registration
 The study is registered in clinicaltrials.gov â„–NCT05514652.",background  the most favorable anesthesia protocol during on pump coronary artery bypass grafting  cabg  in patients with coronary heart disease remains unclear  despite previous publications regarding the interaction between anesthesia protocol and postoperative complications  the aim of the study was to compare the effect of a multimodal low opioid anesthesia protocol  mlop  on early postoperative complications during on pump cabg   methods  a single center prospective cohort study including     patients undergoing on pump cabg aged    to    years  divided into two groups according to undergoing mlop or routine opioid anesthesia protocol  rop   the analyzed parameters were plasma il   levels  complications  duration of mechanical ventilation  length of intensive care unit stay  and hospitalization   results  in the mlop group  the levels of il   at the end of the surgery were       significantly lower compared to the rop group                  vs                    p                the duration of mechanical ventilation was significantly shorter                 h vs                 h  p               the incidence of low cardiac output syndrome was almost two and half times lower            vs              p               and also the incidence of postoperative atrial fibrillation was significantly lower            vs              p                conclusion  our study confirms that using mlop was characterized by significantly lower levels of il   at the end of surgery and a lower incidence of low cardiac output syndrome and postoperative atrial fibrillation than rop   trial registration  the study is registered in clinicaltrials gov    nct         ,4.563537,3.0056198,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Organic P transformations and release from riparian soils responding to water level fluctuation,"To manage eutrophication of reservoirs, it is important to consider the potential for unexpected releases of organic phosphorus (OP) from areas around the reservoir where the water level fluctuates. In this study, we investigated the absorption and release of OP from a riparian soil/sediment from the Miyun Reservoir under fluctuating water levels using laboratory simulations. The total organic phosphorus (TOP) content in the soils/sediments ranged from 250.76 to 298.62 mg/kg, which accounted for between 5.6 and 38.5% of the total phosphorus (TP) content. We measured three OP fractions and found that the concentration of moderately labile OP (MLOP) was the highest, followed by labile OP (LOP), and the concentration of non-labile OP (NLOP) was the lowest. As the soils and sediments dried, they adsorbed phosphorus (P). The inorganic phosphorus (IP) contents were significantly and negatively correlated with the LOP and MLOP contents, indicating exchange between IP with these two fractions when the concentrations of bioavailable phosphorus in the soil are low. During flooding, the physicochemical properties varied at the sedimentâ€“water interface, inducing the release of Fe/Al-P. Some of the LOP and MLOP in the sediments were mineralized to IP. Our results suggest that when there are external P inputs, P may be released when sediments around a reservoir are subjected to wetting and drying as water levels fluctuate, which may cause P enrichment in reservoirs, especially in areas with poor water exchange.",to manage eutrophication of reservoirs  it is important to consider the potential for unexpected releases of organic phosphorus  op  from areas around the reservoir where the water level fluctuates  in this study  we investigated the absorption and release of op from a riparian soil sediment from the miyun reservoir under fluctuating water levels using laboratory simulations  the total organic phosphorus  top  content in the soils sediments ranged from        to        mg kg  which accounted for between     and       of the total phosphorus  tp  content  we measured three op fractions and found that the concentration of moderately labile op  mlop  was the highest  followed by labile op  lop   and the concentration of non labile op  nlop  was the lowest  as the soils and sediments dried  they adsorbed phosphorus  p   the inorganic phosphorus  ip  contents were significantly and negatively correlated with the lop and mlop contents  indicating exchange between ip with these two fractions when the concentrations of bioavailable phosphorus in the soil are low  during flooding  the physicochemical properties varied at the sediment   water interface  inducing the release of fe al p  some of the lop and mlop in the sediments were mineralized to ip  our results suggest that when there are external p inputs  p may be released when sediments around a reservoir are subjected to wetting and drying as water levels fluctuate  which may cause p enrichment in reservoirs  especially in areas with poor water exchange ,4.1224766,1.8264152,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Changes in soil phosphorus fractions following the conversion of Chinese fir plantations to evergreen broad-leaved forests in subtropical China,"Forest conversion is a common management practice in forestry, yet the effects of forest conversion on the transformation of phosphorus (P) fractions remain unclear. This work aims at assessing the changes in soil P fractions, including total P (TP), available P (AP), inorganic P (Pi), organic P (Po) and microbial biomass P (MBP) after natural conversion of Chinese fir plantations (CFP) to evergreen broad-leaved forests (EBLF) in subtropical China. Results showed the contents of soil TP and Po were not affected by the forest conversion, but soil AP and MBP concentrations and their proportion significantly increased with forest conversion from CFP to EBLF. The contents of soil P fractions were significantly accumulated in the topsoil (0â€“20 cm) in the studied forests. Additionally, soil P contents were higher in the winterâ€“spring seasons than in the summerâ€“fall seasons during the period of study. Soil AP content was positively correlated with TP, Po, Pi, labile organophosphorus (LOP), moderate labile organophosphorus (MLOP), moderate resistant organophosphorus (MROP), aluminumâ€“bound P (Alâ€“P), ironâ€“bound P (Feâ€“P) and MBP contents in EBLF, while the content of soil AP was positively related to Po, LOP, MLOP, Alâ€“P, Feâ€“P and MBP contents in CFP. Path analysis showed that the most important factor in affecting soil P availability was Po (LOP and HROP) in EBLF stands and was Alâ€“P in CFP stands. Our study suggested that management practices in conserving soil Pi (especially in Alâ€“P) in the CFP and in increasing Po inputs in the EBLF would improve soil P availability in subtropical forests.",forest conversion is a common management practice in forestry  yet the effects of forest conversion on the transformation of phosphorus  p  fractions remain unclear  this work aims at assessing the changes in soil p fractions  including total p  tp   available p  ap   inorganic p  pi   organic p  po  and microbial biomass p  mbp  after natural conversion of chinese fir plantations  cfp  to evergreen broad leaved forests  eblf  in subtropical china  results showed the contents of soil tp and po were not affected by the forest conversion  but soil ap and mbp concentrations and their proportion significantly increased with forest conversion from cfp to eblf  the contents of soil p fractions were significantly accumulated in the topsoil         cm  in the studied forests  additionally  soil p contents were higher in the winter   spring seasons than in the summer   fall seasons during the period of study  soil ap content was positively correlated with tp  po  pi  labile organophosphorus  lop   moderate labile organophosphorus  mlop   moderate resistant organophosphorus  mrop   aluminum   bound p  al   p   iron   bound p  fe   p  and mbp contents in eblf  while the content of soil ap was positively related to po  lop  mlop  al   p  fe   p and mbp contents in cfp  path analysis showed that the most important factor in affecting soil p availability was po  lop and hrop  in eblf stands and was al   p in cfp stands  our study suggested that management practices in conserving soil pi  especially in al   p  in the cfp and in increasing po inputs in the eblf would improve soil p availability in subtropical forests ,4.350107,2.2601244,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Hydrogels from norbornene-functionalized carboxymethyl cellulose using a UV-initiated thiol-ene click reaction,"Abstract
 Chemically crosslinked cellulose hydrogels have wide applications in agriculture and biomedicine, but most crosslinking methods involve potentially toxic crosslinking chemistries or lack significant control over the final modulus of the material. To overcome these challenges, carboxymethyl cellulose (CMC) hydrogels were synthesized utilizing thiol-ene click chemistry. CMC was functionalized with norbornene groups through a base catalyzed, water-borne functionalization reaction with carbic anhydride, yielding a reactive norbornene group. Both reaction pH and anhydride concentration could be used to control the degree of norbornene functionalization of CMC up to 45% norbornene functionalization per CMC repeat unit. This new norbornene functionalized CMC (cCMC) was crosslinked though a UV-light initiated thiol-ene reaction with a 2,2â€²-(ethylenedioxy)diethanethiol (DEG) crosslinker. Both the ratio of thiols to norbornenes and the irradiation time could be varied at a constant polymer concentration to control the modulus over an order of magnitude. Interestingly, thiol to norbornene ratios of 1:2 and 1:1 yielded the same modulus values, which was attributed to the crosslinking limiting chain mobility early in the reaction and preventing increased crosslink density as the reaction progressed. Hydrolytic degradation of the hydrogels yielded two degradation regimes of initial burst release and continuous daily release. Burst release behavior was tied to the thiol to norbornene ratio used to fabricate the hydrogel, while the daily degradation rate could be correlated to the crosslinking density. Due to its straightforward synthesis and significant control over modulus and degradation rates, cCMC offers high utility for future applications where cellulose derived hydrogels are needed.
 Graphical abstract",abstract  chemically crosslinked cellulose hydrogels have wide applications in agriculture and biomedicine  but most crosslinking methods involve potentially toxic crosslinking chemistries or lack significant control over the final modulus of the material  to overcome these challenges  carboxymethyl cellulose  cmc  hydrogels were synthesized utilizing thiol ene click chemistry  cmc was functionalized with norbornene groups through a base catalyzed  water borne functionalization reaction with carbic anhydride  yielding a reactive norbornene group  both reaction ph and anhydride concentration could be used to control the degree of norbornene functionalization of cmc up to     norbornene functionalization per cmc repeat unit  this new norbornene functionalized cmc  ccmc  was crosslinked though a uv light initiated thiol ene reaction with a         ethylenedioxy diethanethiol  deg  crosslinker  both the ratio of thiols to norbornenes and the irradiation time could be varied at a constant polymer concentration to control the modulus over an order of magnitude  interestingly  thiol to norbornene ratios of     and     yielded the same modulus values  which was attributed to the crosslinking limiting chain mobility early in the reaction and preventing increased crosslink density as the reaction progressed  hydrolytic degradation of the hydrogels yielded two degradation regimes of initial burst release and continuous daily release  burst release behavior was tied to the thiol to norbornene ratio used to fabricate the hydrogel  while the daily degradation rate could be correlated to the crosslinking density  due to its straightforward synthesis and significant control over modulus and degradation rates  ccmc offers high utility for future applications where cellulose derived hydrogels are needed   graphical abstract,3.6036282,1.8318855,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Artificial Neural Network,"Artificial Neural Networks (ANNs) are known to be one of the most prevalent intelligent systems whose architecture is modeled by mimicking the human brain. Most of the real-life problems that has been solved so far followed the dimension of natural systems. ANN model has been developed and tested in a blasting operation. Blasting operations can damage mine plant and structure, especially in cases where the design has not been done properly particularly if the vibrations induced are sufficiently high. Therefore, prediction of the peak particle velocity (PPV) resulting from the blasting operations in an open-pit mine is necessary. Dataset obtained from a mine plant was tested using ANN model. Considering known values of the distance between source and measurement points (D), the maximum charge per delay (WD), and scaled distance (SD), the overall regression value R2 of 0.95468 suggests that the output tracks the targets effectively, meaning that ANN model could be useful for the prediction of PPV.",artificial neural networks  anns  are known to be one of the most prevalent intelligent systems whose architecture is modeled by mimicking the human brain  most of the real life problems that has been solved so far followed the dimension of natural systems  ann model has been developed and tested in a blasting operation  blasting operations can damage mine plant and structure  especially in cases where the design has not been done properly particularly if the vibrations induced are sufficiently high  therefore  prediction of the peak particle velocity  ppv  resulting from the blasting operations in an open pit mine is necessary  dataset obtained from a mine plant was tested using ann model  considering known values of the distance between source and measurement points  d   the maximum charge per delay  wd   and scaled distance  sd   the overall regression value r  of         suggests that the output tracks the targets effectively  meaning that ann model could be useful for the prediction of ppv ,3.665647,2.0689876,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Error-Correcting Neural Networks for Two-Dimensional Curvature Computation in the Level-set Method,"We present an error-neural-modeling-based strategy for approximating two-dimensional curvature in the level-set method. Our main contribution is a redesigned hybrid solver [Larios-CÃ¡rdenas and Gibou, J. Comput. Phys. (May 2022), 10.1016/j.jcp.2022.111291] that relies on numerical schemes to enable machine-learning operations on demand. In particular, our routine features double predicting to harness curvature symmetry invariance in favor of precision and stability. The core of this solver is a multilayer perceptron trained on circular- and sinusoidal-interface samples. Its role is to quantify the error in numerical curvature approximations and emit corrected estimates for select grid vertices along the free boundary. These corrections arise in response to preprocessed context level-set, curvature, and gradient data. To promote neural capacity, we have adopted sample negative-curvature normalization, reorientation, and reflection-based augmentation. In the same manner, our system incorporates dimensionality reduction, well-balancedness, and regularization to minimize outlying effects. Our training approach is likewise scalable across mesh sizes. For this purpose, we have introduced dimensionless parametrization and probabilistic subsampling during data production. Together, all these elements have improved the accuracy and efficiency of curvature calculations around under-resolved regions. In most experiments, our strategy has outperformed the numerical baseline at twice the number of redistancing steps while requiring only a fraction of the cost.",we present an error neural modeling based strategy for approximating two dimensional curvature in the level set method  our main contribution is a redesigned hybrid solver  larios c  rdenas and gibou  j  comput  phys   may                j jcp              that relies on numerical schemes to enable machine learning operations on demand  in particular  our routine features double predicting to harness curvature symmetry invariance in favor of precision and stability  the core of this solver is a multilayer perceptron trained on circular  and sinusoidal interface samples  its role is to quantify the error in numerical curvature approximations and emit corrected estimates for select grid vertices along the free boundary  these corrections arise in response to preprocessed context level set  curvature  and gradient data  to promote neural capacity  we have adopted sample negative curvature normalization  reorientation  and reflection based augmentation  in the same manner  our system incorporates dimensionality reduction  well balancedness  and regularization to minimize outlying effects  our training approach is likewise scalable across mesh sizes  for this purpose  we have introduced dimensionless parametrization and probabilistic subsampling during data production  together  all these elements have improved the accuracy and efficiency of curvature calculations around under resolved regions  in most experiments  our strategy has outperformed the numerical baseline at twice the number of redistancing steps while requiring only a fraction of the cost ,4.2357183,6.5481906,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Learning User Preferences for Recommender System Using YouTube Videos Tags,"Recommender systems have become essential in several domains to deal with the problem of information overload. Collaborative filtering is one of the most popularly used paradigm of recommender systems for over a decade. The personalized recommender systems use past preference history of the users to make future recommendations for them. The cold start problem of recommender system concerns with the personalized recommendation to the users having no or few past history. In this work we propose an approach to learn implicit user preferences by making use of YouTube Video Tags. The profile of a new user is created from his/her preferences in watching the YouTube videos. This profile is generic and may be used for a wide variety of domains of recommender systems. In this work we have used it for a biography recommender system. However this may be used for several other types of recommender system.
 Keywords
 User profile discovery
 Cold start problem
 Tagging
 Personalization
 Implicit ratings
 Collaborative filtering",recommender systems have become essential in several domains to deal with the problem of information overload  collaborative filtering is one of the most popularly used paradigm of recommender systems for over a decade  the personalized recommender systems use past preference history of the users to make future recommendations for them  the cold start problem of recommender system concerns with the personalized recommendation to the users having no or few past history  in this work we propose an approach to learn implicit user preferences by making use of youtube video tags  the profile of a new user is created from his her preferences in watching the youtube videos  this profile is generic and may be used for a wide variety of domains of recommender systems  in this work we have used it for a biography recommender system  however this may be used for several other types of recommender system   keywords  user profile discovery  cold start problem  tagging  personalization  implicit ratings  collaborative filtering,5.5561156,5.066286,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Power-efficient combinatorial optimization using intrinsic noise in memristor Hopfield neural networks,"To tackle important combinatorial optimization problems, a variety of annealing-inspired computing accelerators, based on several different technology platforms, have been proposed, including quantum-, optical- and electronics-based approaches. However, to be of use in industrial applications, further improvements in speed and energy efficiency are necessary. Here, we report a memristor-based annealing system that uses an energy-efficient neuromorphic architecture based on a Hopfield neural network. Our analogueâ€“digital computing approach creates an optimization solver in which massively parallel operations are performed in a dense crossbar array that can inject the needed computational noise through the analogue array and device errors, amplified or dampened by using a novel feedback algorithm. We experimentally show that the approach can solve non-deterministic polynomial-time (NP)-hard max-cut problems by harnessing the intrinsic hardware noise. We also use experimentally grounded simulations to explore scalability with problem size, which suggest that our memristor-based approach can offer a solution throughput over four orders of magnitude higher per power consumption relative to current quantum, optical and fully digital approaches.",to tackle important combinatorial optimization problems  a variety of annealing inspired computing accelerators  based on several different technology platforms  have been proposed  including quantum   optical  and electronics based approaches  however  to be of use in industrial applications  further improvements in speed and energy efficiency are necessary  here  we report a memristor based annealing system that uses an energy efficient neuromorphic architecture based on a hopfield neural network  our analogue   digital computing approach creates an optimization solver in which massively parallel operations are performed in a dense crossbar array that can inject the needed computational noise through the analogue array and device errors  amplified or dampened by using a novel feedback algorithm  we experimentally show that the approach can solve non deterministic polynomial time  np  hard max cut problems by harnessing the intrinsic hardware noise  we also use experimentally grounded simulations to explore scalability with problem size  which suggest that our memristor based approach can offer a solution throughput over four orders of magnitude higher per power consumption relative to current quantum  optical and fully digital approaches ,4.6020346,8.349602,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Exploring the Potential of eXplainable AI in Identifying Errors and Biases,"Artificial intelligence has virtually pervaded every field and its adaptation is a catalyst for organizational growth. However, the potential of artificial intelligence is often associated with a difficulty to understand the logic veiling behind its decision making. This is essentially the premise upon which XAI or eXplainable AI functions. In this field of study, researchers attempt to streamline techniques to provide an explanation for the decisions that the machines make. We endeavor to delve deeper into what explainable means and the repercussions of the lack of definition associated with the term. We intend to show in this paper that an evaluation system based solely on how easy it is to understand an explanation, without taking into account aspects such as fidelity, might produce potentially harmful explanation interfaces.
 Keywords
 XAI
 Artificial intelligence
 Machine learning
 Decision making",artificial intelligence has virtually pervaded every field and its adaptation is a catalyst for organizational growth  however  the potential of artificial intelligence is often associated with a difficulty to understand the logic veiling behind its decision making  this is essentially the premise upon which xai or explainable ai functions  in this field of study  researchers attempt to streamline techniques to provide an explanation for the decisions that the machines make  we endeavor to delve deeper into what explainable means and the repercussions of the lack of definition associated with the term  we intend to show in this paper that an evaluation system based solely on how easy it is to understand an explanation  without taking into account aspects such as fidelity  might produce potentially harmful explanation interfaces   keywords  xai  artificial intelligence  machine learning  decision making,10.962656,6.587274,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
A Hybrid Product Recommendation System Based on Weather Analysis,"Product recommendation becomes to be one most revenue-generating technologies that every e-commerce website is using. For enhancing the purchase rate and user engagement, various product recommendations are available in the e-commerce website. Most of the external contexts are also taken into consideration for the product recommendation. This type of external context analysis sometimes will provide better recommendations when compared to the user-generated data. This paper proposes an idea of product recommendation using the weather. Here we predict the weather for the coming days using logistic regression and analyze the weather using big data analytics. Based on the analysis, we will sort the products and recommend a product in the same weather.
 Keywords
 Big data
 Product recommendation
 Content-based recommendation
 Logistic regression
 Recommendation system",product recommendation becomes to be one most revenue generating technologies that every e commerce website is using  for enhancing the purchase rate and user engagement  various product recommendations are available in the e commerce website  most of the external contexts are also taken into consideration for the product recommendation  this type of external context analysis sometimes will provide better recommendations when compared to the user generated data  this paper proposes an idea of product recommendation using the weather  here we predict the weather for the coming days using logistic regression and analyze the weather using big data analytics  based on the analysis  we will sort the products and recommend a product in the same weather   keywords  big data  product recommendation  content based recommendation  logistic regression  recommendation system,5.3349376,5.1042805,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Analysis of Long-Term Rainfall Trends Over Punjab State Derived from CHIRPS Data in the Google Earth Engine Platform,"Rainfall is an important parameter which indirectly affects the economy and food security. Due to the change in climate, the rainfall dynamics have changed a lot in the past few years. Study of the rainfall trends is very important for a country like India where there is a lot of dependency on timely availability of water. In this study, the rainfall trends over Punjab state have been analysed for the time period 1987â€“2020 using the Climate Hazards Group InfraRed Precipitation with Station data (CHIRPS) version 2.0 final, in the Google Earth Engine (GEE) cloud platform. CHIRPS integrate 0.05Â° resolution satellite imagery with in situ station data to create a gridded time series rainfall data set. Doing such big data analysis for a complete state is a very complex job as it involves a lot of time, storage and computing power. This paper explores the computing capabilities of the cloud-based Google Earth Engine (GEE) using which such data analytics can be performed using a simple computer with Internet connectivity.
 Keywords
 Google Earth engine
 GEE
 CHIRPS
 Rainfall
 Punjab
 Cloud computing
 Big data",rainfall is an important parameter which indirectly affects the economy and food security  due to the change in climate  the rainfall dynamics have changed a lot in the past few years  study of the rainfall trends is very important for a country like india where there is a lot of dependency on timely availability of water  in this study  the rainfall trends over punjab state have been analysed for the time period             using the climate hazards group infrared precipitation with station data  chirps  version     final  in the google earth engine  gee  cloud platform  chirps integrate        resolution satellite imagery with in situ station data to create a gridded time series rainfall data set  doing such big data analysis for a complete state is a very complex job as it involves a lot of time  storage and computing power  this paper explores the computing capabilities of the cloud based google earth engine  gee  using which such data analytics can be performed using a simple computer with internet connectivity   keywords  google earth engine  gee  chirps  rainfall  punjab  cloud computing  big data,5.228122,4.828522,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Distinguishing between Crohnâ€™s disease and ulcerative colitis using deep learning models with interpretability,"Crohnâ€™s disease and ulcerative colitis are two chronic diseases that cause inflammation in the tissues of the entire gastrointestinal tract and are described by the term inflammatory bowel disease. Gastroenterologists find it difficult to evaluate endoscopic images to recognise the characteristics of the two chronic diseases. Therefore, this work aims to build a dataset with images of Crohnâ€™s disease and ulcerative colitis (collected from the public datasets LIMUC, HyperKvasir and CrohnIPI) and train deep learning models (five CNNs and six ViTs) to develop a tool capable of helping doctors to distinguish the type of inflammatory bowel disease. In addition, as these architectures will be too heavy to work in a hospital context, in this work, we are looking to use knowledge distillation to create lighter and simpler architectures with the same precision as the pre-trained architectures used in this study. During this process, it is important to evaluate and interpret the pre-trained architectures before the distillation process, and the architectures resulting from knowledge distillation to ensure that we can maintain performance and that the information learnt by both architectures are similar. It is concluded that is possible to reduce 25x the number of parameters while maintaining good performance and reducing the inference time by 5.32 s. Allied with this, through the interpretability of the models was concluded that both before and after the knowledge distillation are possible to identify ulcers, bleeding situations, and lesions caused by the inflammation of the disease.",crohn   s disease and ulcerative colitis are two chronic diseases that cause inflammation in the tissues of the entire gastrointestinal tract and are described by the term inflammatory bowel disease  gastroenterologists find it difficult to evaluate endoscopic images to recognise the characteristics of the two chronic diseases  therefore  this work aims to build a dataset with images of crohn   s disease and ulcerative colitis  collected from the public datasets limuc  hyperkvasir and crohnipi  and train deep learning models  five cnns and six vits  to develop a tool capable of helping doctors to distinguish the type of inflammatory bowel disease  in addition  as these architectures will be too heavy to work in a hospital context  in this work  we are looking to use knowledge distillation to create lighter and simpler architectures with the same precision as the pre trained architectures used in this study  during this process  it is important to evaluate and interpret the pre trained architectures before the distillation process  and the architectures resulting from knowledge distillation to ensure that we can maintain performance and that the information learnt by both architectures are similar  it is concluded that is possible to reduce   x the number of parameters while maintaining good performance and reducing the inference time by      s  allied with this  through the interpretability of the models was concluded that both before and after the knowledge distillation are possible to identify ulcers  bleeding situations  and lesions caused by the inflammation of the disease ,4.8852644,4.060981,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
A Model-Driven Approach for Systematic Reproducibility and Replicability of Data Science Projects,"In the last few years, there has been an important increase in the number of tools and approaches to define pipelines that allow the development of data science projects. They allow not only the pipeline definition but also the code generation needed to execute the project providing an easy way to carry out the projects even for non-expert users. However, there are still some challenges that these tools do not address yet, e.g. the possibility of executing pipelines defined by using different tools or execute them in different environments (reproducibility and replicability) or models validation and verification by identifying inconsistent operations (intentionality). In order to alleviate these problems, this paper presents a Model-Driven framework for the definition of data science pipelines independent of the particular execution platform and tools. The framework relies on the separation of the pipeline definition into two different modelling layers: conceptual, where the data scientist may specify all the data and models operations to be carried out by the pipeline; operational, where the data engineer may describe the execution environment details where the operations (defined in the conceptual part) will be implemented. Based on this abstract definition and layers separation, the approach allows: the usage of different tools improving, thus, process replicability; the automation of the process execution, enhancing process reproducibility; and the definition of model verification rules, providing intentionality restrictions.
 Keywords
 Reproducibility
 Replicability
 Process
 Data science
 Model-driven engineering",in the last few years  there has been an important increase in the number of tools and approaches to define pipelines that allow the development of data science projects  they allow not only the pipeline definition but also the code generation needed to execute the project providing an easy way to carry out the projects even for non expert users  however  there are still some challenges that these tools do not address yet  e g  the possibility of executing pipelines defined by using different tools or execute them in different environments  reproducibility and replicability  or models validation and verification by identifying inconsistent operations  intentionality   in order to alleviate these problems  this paper presents a model driven framework for the definition of data science pipelines independent of the particular execution platform and tools  the framework relies on the separation of the pipeline definition into two different modelling layers  conceptual  where the data scientist may specify all the data and models operations to be carried out by the pipeline  operational  where the data engineer may describe the execution environment details where the operations  defined in the conceptual part  will be implemented  based on this abstract definition and layers separation  the approach allows  the usage of different tools improving  thus  process replicability  the automation of the process execution  enhancing process reproducibility  and the definition of model verification rules  providing intentionality restrictions   keywords  reproducibility  replicability  process  data science  model driven engineering,9.4300375,5.7679105,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Security of AI Hardware Systems,"Artificial intelligence (AI) systems are changing our lives. Coming with the benefits, challenges on AI security raise concerns as AI systems are not only accessing personal and sensitive data, they are also to be deployed on systems related to life safety (e.g., autonomous vehicles and medical systems) and critical infrastructures. In this chapter, we will start from a brief introduction to modern AI systems, review reported AI security issues, and discuss possible countermeasures.",artificial intelligence  ai  systems are changing our lives  coming with the benefits  challenges on ai security raise concerns as ai systems are not only accessing personal and sensitive data  they are also to be deployed on systems related to life safety  e g   autonomous vehicles and medical systems  and critical infrastructures  in this chapter  we will start from a brief introduction to modern ai systems  review reported ai security issues  and discuss possible countermeasures ,11.827881,6.2896323,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
"An Advanced Encryption Standard in Memory (AESIM) Efficient, High Performance S-box Based AES Encryption and Decryption Architecture on VLSI","This paper investigates the reconstruction of Van Goghâ€™s drawings which have been degraded in the course of time due to aging problems, like ink fading and discoloration. Learning to predict the past and original appearances of degraded drawings can help to envisage how the artistâ€™s work may have looked at the time of creation. In this paper, we use reproductions as reference information for the past appearances of drawings and consider the reconstruction of drawings as a pixel-wise prediction problem. We present an approach to automatically predict the past appearances of drawings. This approach brings together methods from multi-resolution image analysis and deep convolutional neural networks (CNNs) for addressing the task of pixel-wise prediction. Our experiments first investigate how scale affects prediction performance of the proposed multi-scale CNN framework and then demonstrate the reconstruction capability of the multi-scale CNN framework. The results demonstrate that the predictive reconstruction of degraded images is a feasible endeavor.",this paper investigates the reconstruction of van gogh   s drawings which have been degraded in the course of time due to aging problems  like ink fading and discoloration  learning to predict the past and original appearances of degraded drawings can help to envisage how the artist   s work may have looked at the time of creation  in this paper  we use reproductions as reference information for the past appearances of drawings and consider the reconstruction of drawings as a pixel wise prediction problem  we present an approach to automatically predict the past appearances of drawings  this approach brings together methods from multi resolution image analysis and deep convolutional neural networks  cnns  for addressing the task of pixel wise prediction  our experiments first investigate how scale affects prediction performance of the proposed multi scale cnn framework and then demonstrate the reconstruction capability of the multi scale cnn framework  the results demonstrate that the predictive reconstruction of degraded images is a feasible endeavor ,5.238742,4.392614,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Privacy preserving data publishing based on sensitivity in context of Big Data using Hive,"As CMOS(Complementary Metal Oxide Semiconductor) technology reaches its scaling threshold, evolving non-volatile memory approaches are becoming a hopeful substitutes to Dynamic RAM (i.e.) DRAM because of the low leakage power and improved scalability. Nonetheless, a new security flaw concerns the non-volatile central memory system. An intruder can easily access confidential memory records, as the non-volatility causeâ€™s knowledge to be stored even after the electricity is off for a long time. While memory encryption in real-time is an efficient way for dealing with this vulnerability in memory accesses along with an exclusive Advanced Encryption Standard (AES) engine, runtime performance and overhead energy are involved. The proposed work is to combine the AES key and the ECC key alternately for encryption and decryption and hence, a quick and efficient application of AES in memory (AESIM) was proposed in the paper to encrypt the either a part of the memory or the entire only if it is needed. Instead of counting additional processing elements to the cost-sensitive memory, the intrinsic logic operating capability of NVM was utilized to employ the proposed AESIM technique. We take advantage of the assistances provided by the in-memory storage design (huge internal bandwidth and dramatic reduction in movement of data) to overcome the complexities of the bandwidth concentrated encryption method. S-box is utilized along with AESIM methodology for performing the encryption process and then the counter action of decryption is performed by the inverse S-box which is employed with the AESIM. By embracing the memory's massive parallelism, AESIM outperforms current methods with higher performance yet lower consumption of energy. The efficiency of the proposed AESIM technique is calculated for both encryption and decryption process by measuring the minimum time used, the minimum time taken for the time before clock delivery, the average time required for operation after clock, the latency and the amount of logic separately for the proposed AESIM encryption and decryption technique.",as cmos complementary metal oxide semiconductor  technology reaches its scaling threshold  evolving non volatile memory approaches are becoming a hopeful substitutes to dynamic ram  i e   dram because of the low leakage power and improved scalability  nonetheless  a new security flaw concerns the non volatile central memory system  an intruder can easily access confidential memory records  as the non volatility cause   s knowledge to be stored even after the electricity is off for a long time  while memory encryption in real time is an efficient way for dealing with this vulnerability in memory accesses along with an exclusive advanced encryption standard  aes  engine  runtime performance and overhead energy are involved  the proposed work is to combine the aes key and the ecc key alternately for encryption and decryption and hence  a quick and efficient application of aes in memory  aesim  was proposed in the paper to encrypt the either a part of the memory or the entire only if it is needed  instead of counting additional processing elements to the cost sensitive memory  the intrinsic logic operating capability of nvm was utilized to employ the proposed aesim technique  we take advantage of the assistances provided by the in memory storage design  huge internal bandwidth and dramatic reduction in movement of data  to overcome the complexities of the bandwidth concentrated encryption method  s box is utilized along with aesim methodology for performing the encryption process and then the counter action of decryption is performed by the inverse s box which is employed with the aesim  by embracing the memory s massive parallelism  aesim outperforms current methods with higher performance yet lower consumption of energy  the efficiency of the proposed aesim technique is calculated for both encryption and decryption process by measuring the minimum time used  the minimum time taken for the time before clock delivery  the average time required for operation after clock  the latency and the amount of logic separately for the proposed aesim encryption and decryption technique ,5.610399,7.8273544,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
The survey on ARM processors for HPC,"Privacy preserving data publication is the main concern in present days, because the data being published through internet has been increasing day by day. This huge amount of data was named as Big Data by its size. This project deals with the privacy preservation in context of big data using a data warehousing solution called hive. We implemented nearest similarity based clustering (NSB) with Bottom-up generalization to achieve (v,l)-anonymity which deals with the sensitivity vulnerabilities and ensures the individual privacy. We also calculate the sensitivity levels by simple comparison method using the index values, by classifying the different levels of sensitivity. The experiments were carried out on the hive environment to verify the efficiency of algorithms with big data. This framework also supports the execution of existing algorithms without any changes. The model in the article outperforms than existing models.",privacy preserving data publication is the main concern in present days  because the data being published through internet has been increasing day by day  this huge amount of data was named as big data by its size  this project deals with the privacy preservation in context of big data using a data warehousing solution called hive  we implemented nearest similarity based clustering  nsb  with bottom up generalization to achieve  v l  anonymity which deals with the sensitivity vulnerabilities and ensures the individual privacy  we also calculate the sensitivity levels by simple comparison method using the index values  by classifying the different levels of sensitivity  the experiments were carried out on the hive environment to verify the efficiency of algorithms with big data  this framework also supports the execution of existing algorithms without any changes  the model in the article outperforms than existing models ,6.795121,7.28894,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Lithium-film ceramics for solid-state lithionic devices,"It is critical to evaluate an individual's capabilities in order to assess their capabilities. Exams have a vital part in the testing process and, as a result, the questions that must be tested. Framing questions may be a tiresome endeavor at times, necessitating the use of automated question generating. Natural language processing may be used to produce questions that are accurate, answered, and efficient (NLP). We can structure questions by accepting and processing information using NLP and different question creation methods. MCQs, fill in the blanks, Wh-questions, crosswords, and a quick synopsis of the supplied material are among the questions created. Before being sent to the AQG, the data is preprocessed. Depending on the supplied content, the questions are verified for contextual relevance and answerability. Automated question generation can be beneficial in self-analysis, self-guidance, and other areas.
 Keywords
 Natural language processing
 Data preprocessing
 Machine learning
 T5 transformer
 Naive Bayes
 Prediction",it is critical to evaluate an individual s capabilities in order to assess their capabilities  exams have a vital part in the testing process and  as a result  the questions that must be tested  framing questions may be a tiresome endeavor at times  necessitating the use of automated question generating  natural language processing may be used to produce questions that are accurate  answered  and efficient  nlp   we can structure questions by accepting and processing information using nlp and different question creation methods  mcqs  fill in the blanks  wh questions  crosswords  and a quick synopsis of the supplied material are among the questions created  before being sent to the aqg  the data is preprocessed  depending on the supplied content  the questions are verified for contextual relevance and answerability  automated question generation can be beneficial in self analysis  self guidance  and other areas   keywords  natural language processing  data preprocessing  machine learning  t  transformer  naive bayes  prediction,6.087314,5.35301,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Programming the Criminologist: Developing Cyber Skills to Investigate Cybercrime,"The search for alternatives to traditional Li-ion batteries has sparked interest in the chemistry and manufacturing of solid-state Li-ion conductors. Li-ion conductors are traditionally processed as millimetre-sized pellets using conventional ceramic-processing routes. However, in thin-film form, Li-ion conductors offer applications beyond energy storage, including artificial intelligence, in-memory computing and smart sensing. In this Review, we examine the chemistry and thin-film processing of Li oxides and discuss challenges and opportunities for the integration of Li-oxide films in microbatteries for energy storage, neuromorphic computation mimicking human-brain operations and sensors for toxins and greenhouse gases. Li oxides in thin-film form provide fast Li-ion movement and connected electronic-state changes, which improve energy and information density and increase cycle speed and endurance of Li-conductor-based devices. Finally, we provide a future vision of lithionic devices integrating Li-based ceramics for the design of microdevices beyond batteries.",the search for alternatives to traditional li ion batteries has sparked interest in the chemistry and manufacturing of solid state li ion conductors  li ion conductors are traditionally processed as millimetre sized pellets using conventional ceramic processing routes  however  in thin film form  li ion conductors offer applications beyond energy storage  including artificial intelligence  in memory computing and smart sensing  in this review  we examine the chemistry and thin film processing of li oxides and discuss challenges and opportunities for the integration of li oxide films in microbatteries for energy storage  neuromorphic computation mimicking human brain operations and sensors for toxins and greenhouse gases  li oxides in thin film form provide fast li ion movement and connected electronic state changes  which improve energy and information density and increase cycle speed and endurance of li conductor based devices  finally  we provide a future vision of lithionic devices integrating li based ceramics for the design of microdevices beyond batteries ,5.0052357,8.632112,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Data and Analytics,"The expansion of the internet from the late 1990s with advancements in speed, capacity, and availability has revolutionized the lives of many people throughout the world. However, this same technology is also exploited as a ubiquitous crime site by cybercriminals. A consequence of this has been the emergence of a new investigative resource for criminological researchers to examine cybercrime. Just as criminals have developed their technical expertise, it is important that criminological researchers develop new digital skills and methodological approaches to better understand criminal behavior in cyberspace and implement evidence-based prevention measures. There are many open-source programming languages, libraries, and tools to help the modern criminologist process large volumes of data efficiently, accurately, and repeatably. This chapter will discuss how using techniques exploited in other fields, such as software engineering and data science, digital criminologists can quickly test ideas, process large data sets, and share ideas, techniques, and data.",the expansion of the internet from the late     s with advancements in speed  capacity  and availability has revolutionized the lives of many people throughout the world  however  this same technology is also exploited as a ubiquitous crime site by cybercriminals  a consequence of this has been the emergence of a new investigative resource for criminological researchers to examine cybercrime  just as criminals have developed their technical expertise  it is important that criminological researchers develop new digital skills and methodological approaches to better understand criminal behavior in cyberspace and implement evidence based prevention measures  there are many open source programming languages  libraries  and tools to help the modern criminologist process large volumes of data efficiently  accurately  and repeatably  this chapter will discuss how using techniques exploited in other fields  such as software engineering and data science  digital criminologists can quickly test ideas  process large data sets  and share ideas  techniques  and data ,6.103934,4.627683,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Experimental Comparison of Stochastic Optimizers in Deep Learning,"This chapter considers the use of data and analytics in Australian campaigning. It discusses how political parties in Australia collect data, where the data comes from, and how they analyse and use data to target voters. I demonstrate that despite what is often assumed, sophisticated data and analytics practices are extremely uneven. As I outline, data and analytics practices may place parties in a strong position to deal with changes in the macro-political environment, but the efficacy of these practices is debatable, especially in a country that uses a mixed electoral system, where elections are multi-party contests, and where compulsory voting prevails. One effect of data and analytics operations, however, is that it changes how parties perceive the electorate and can affect who political parties engage with and through which channel.",this chapter considers the use of data and analytics in australian campaigning  it discusses how political parties in australia collect data  where the data comes from  and how they analyse and use data to target voters  i demonstrate that despite what is often assumed  sophisticated data and analytics practices are extremely uneven  as i outline  data and analytics practices may place parties in a strong position to deal with changes in the macro political environment  but the efficacy of these practices is debatable  especially in a country that uses a mixed electoral system  where elections are multi party contests  and where compulsory voting prevails  one effect of data and analytics operations  however  is that it changes how parties perceive the electorate and can affect who political parties engage with and through which channel ,7.423506,6.4837728,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Radiologistsâ€™ Usage of Diagnostic AI Systems The Role of Diagnostic Self-Efficacy for Sensemaking from Confirmation and Disconfirmation,"The stochastic optimization problem in deep learning involves finding optimal values of loss function and neural network parameters using a meta-heuristic search algorithm. The fact that these values cannot be reasonably obtained by using a deterministic optimization technique underscores the need for an iterative method that randomly picks data segments, arbitrarily determines initial values of optimization (network) parameters and steadily computes series of error functions until a tolerable error is attained. The typical stochastic optimization algorithm for training deep neural networks as a non-convex optimization problem is gradient descent. It has existing extensions like Stochastic Gradient Descent, Adagrad, Adadelta, RMSProp and Adam. In terms of accuracy, convergence rate and training time, each of these stochastic optimizers represents an improvement. However, there is room for further improvement. This paper presents outcomes of series of experiments conducted with a view to providing empirical evidences of successes made so far. We used Python deep learning libaries (Tensorflow and Keras API) for our experiments. Each algorithm is executed, results collated, and a case made for further research in deep learning to improve training time and convergence rate of deep neural network, as well as accuracy of outcomes. This is in response to the growing demands for deep learning in mission-critical and highly sophisticated decision making processes across industry verticals.
 Keywords
 Deep learning
 Deep neural networks
 Error function
 Neural network parameters
 Stochastic optimization",the stochastic optimization problem in deep learning involves finding optimal values of loss function and neural network parameters using a meta heuristic search algorithm  the fact that these values cannot be reasonably obtained by using a deterministic optimization technique underscores the need for an iterative method that randomly picks data segments  arbitrarily determines initial values of optimization  network  parameters and steadily computes series of error functions until a tolerable error is attained  the typical stochastic optimization algorithm for training deep neural networks as a non convex optimization problem is gradient descent  it has existing extensions like stochastic gradient descent  adagrad  adadelta  rmsprop and adam  in terms of accuracy  convergence rate and training time  each of these stochastic optimizers represents an improvement  however  there is room for further improvement  this paper presents outcomes of series of experiments conducted with a view to providing empirical evidences of successes made so far  we used python deep learning libaries  tensorflow and keras api  for our experiments  each algorithm is executed  results collated  and a case made for further research in deep learning to improve training time and convergence rate of deep neural network  as well as accuracy of outcomes  this is in response to the growing demands for deep learning in mission critical and highly sophisticated decision making processes across industry verticals   keywords  deep learning  deep neural networks  error function  neural network parameters  stochastic optimization,2.888272,7.2793546,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Benchmarking Data Lakes Featuring Structured and Unstructured Data with DLBench,"While diagnostic AI systems are implemented in medical practice, it is still unclear how physicians embed them in diagnostic decision making. This study examines how radiologists come to use diagnostic AI systems in different ways and what role AI assessments play in this process if they confirm or disconfirm radiologistsâ€™ own judgment. The study draws on rich qualitative data from a revelatory case study of an AI system for stroke diagnosis at a University Hospital to elaborate how three sensemaking processes revolve around confirming and disconfirming AI assessments. Through context-specific sensedemanding, sensegiving, and sensebreaking, radiologists develop distinct usage patterns of AI systems. The study reveals that diagnostic self-efficacy influences which of the three sensemaking processes radiologists engage in. In deriving six propositions, the account of sensemaking and usage of diagnostic AI systems in medical practice paves the way for future research.",while diagnostic ai systems are implemented in medical practice  it is still unclear how physicians embed them in diagnostic decision making  this study examines how radiologists come to use diagnostic ai systems in different ways and what role ai assessments play in this process if they confirm or disconfirm radiologists    own judgment  the study draws on rich qualitative data from a revelatory case study of an ai system for stroke diagnosis at a university hospital to elaborate how three sensemaking processes revolve around confirming and disconfirming ai assessments  through context specific sensedemanding  sensegiving  and sensebreaking  radiologists develop distinct usage patterns of ai systems  the study reveals that diagnostic self efficacy influences which of the three sensemaking processes radiologists engage in  in deriving six propositions  the account of sensemaking and usage of diagnostic ai systems in medical practice paves the way for future research ,11.107448,6.923745,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
On Topological Data Analysis for SHM: An Introduction to Persistent Homology,"In the last few years, the concept of data lake has become trendy for data storage and analysis. Thus, several approaches have been proposed to build data lake systems. However, these proposals are difficult to evaluate as there are no commonly shared criteria for comparing data lake systems. Thus, we introduce DLBench, a benchmark to evaluate and compare data lake implementations that support textual and/or tabular contents. More concretely, we propose a data model made of both textual and CSV documents, a workload model composed of a set of various tasks, as well as a set of performance-based metrics, all relevant to the context of data lakes. As a proof of concept, we use DLBench to evaluate an open source data lake system we previously developed.
 Keywords
 Data lakes
 Benchmarking
 Textual documents
 Tabular data",in the last few years  the concept of data lake has become trendy for data storage and analysis  thus  several approaches have been proposed to build data lake systems  however  these proposals are difficult to evaluate as there are no commonly shared criteria for comparing data lake systems  thus  we introduce dlbench  a benchmark to evaluate and compare data lake implementations that support textual and or tabular contents  more concretely  we propose a data model made of both textual and csv documents  a workload model composed of a set of various tasks  as well as a set of performance based metrics  all relevant to the context of data lakes  as a proof of concept  we use dlbench to evaluate an open source data lake system we previously developed   keywords  data lakes  benchmarking  textual documents  tabular data,4.559613,4.6731095,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Building footprint extraction and counting on very high-resolution satellite imagery using object detection deep learning framework,"This chapter aims to discuss a method of quantifying the â€˜shapeâ€™ of data, via a methodology called topological data analysis. The main tool within topological data analysis is persistent homology; this is a means of measuring the shape of data, from the homology of a simplicial complex, calculated over a range of values. The required background theory and a method of computing persistent homology are presented here, with applications specific to structural health monitoring. These results allow for topological inference and the ability to deduce features in higher-dimensional data that might otherwise be overlooked.
 A simplicial complex is constructed for data for a given distance parameter. This complex encodes information about the local proximity of data points. A singular homology value can be calculated from this simplicial complex. Extending this idea, the distance parameter is given for a range of values, and the homology is calculated over this range. The persistent homology is a representation of how the homological features of the data persist over this interval. The result is characteristic to the data. A method that allows for the comparison of the persistent homology for different data sets is also discussed.
 Keywords
 Topological data analysis
 Persistent homology
 Simplicial complex",this chapter aims to discuss a method of quantifying the    shape    of data  via a methodology called topological data analysis  the main tool within topological data analysis is persistent homology  this is a means of measuring the shape of data  from the homology of a simplicial complex  calculated over a range of values  the required background theory and a method of computing persistent homology are presented here  with applications specific to structural health monitoring  these results allow for topological inference and the ability to deduce features in higher dimensional data that might otherwise be overlooked   a simplicial complex is constructed for data for a given distance parameter  this complex encodes information about the local proximity of data points  a singular homology value can be calculated from this simplicial complex  extending this idea  the distance parameter is given for a range of values  and the homology is calculated over this range  the persistent homology is a representation of how the homological features of the data persist over this interval  the result is characteristic to the data  a method that allows for the comparison of the persistent homology for different data sets is also discussed   keywords  topological data analysis  persistent homology  simplicial complex,3.7030096,3.2230248,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Decomposition Methods for Large-Scale Semidefinite Programs with Chordal Aggregate Sparsity and Partial Orthogonality,"Building footprints are the most visible features in urban areas. Detecting building footprint has a substantial position in decision-making problems such as city planning and development, urban mapping and management, population estimation, etc. In this paper, we aim to automatically detect and count building footprints by leveraging deep learning techniques and the potential availability of remote sensing datasets at high spatial resolutions. We build object detection deep learning models by integrating the partitioning segmentation and convolutional neural networks (CNN) architecture using the WorldView-3 very high-resolution optical satellite imagery data. Our detection model is implemented on data from the Paris, France, and Khartoum, Sudan regions. These regions were chosen because it has very different characteristics and large data variation, making it challenging to extract building features from satellite imagery. This challenge is even greater because one area is taken perpendicularly and the other area is taken at an angle of several degrees which causes more noise, one of which is the shadow of the building. The detection models can detect and count the building footprints and have promising performance on large variable data with an Average Precision (AP) of 64.19%. Paris was detected better by 74.66% compared to Khartoum by 56.19%. The partitioning segmentation technique is used to tune the anchor boxes of CNN input images. Our result offers a potential practical implementation for rapid yet accurate estimation of urban monitoring and city planning, particularly in metropolitan regions.",building footprints are the most visible features in urban areas  detecting building footprint has a substantial position in decision making problems such as city planning and development  urban mapping and management  population estimation  etc  in this paper  we aim to automatically detect and count building footprints by leveraging deep learning techniques and the potential availability of remote sensing datasets at high spatial resolutions  we build object detection deep learning models by integrating the partitioning segmentation and convolutional neural networks  cnn  architecture using the worldview   very high resolution optical satellite imagery data  our detection model is implemented on data from the paris  france  and khartoum  sudan regions  these regions were chosen because it has very different characteristics and large data variation  making it challenging to extract building features from satellite imagery  this challenge is even greater because one area is taken perpendicularly and the other area is taken at an angle of several degrees which causes more noise  one of which is the shadow of the building  the detection models can detect and count the building footprints and have promising performance on large variable data with an average precision  ap  of         paris was detected better by        compared to khartoum by         the partitioning segmentation technique is used to tune the anchor boxes of cnn input images  our result offers a potential practical implementation for rapid yet accurate estimation of urban monitoring and city planning  particularly in metropolitan regions ,4.62026,5.51508,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Dynamics of phosphorus fractions and potential bioavailability along soil profiles from seasonal-flooding wetlands in a Chinese estuary,"Many semidefinite programs (SDPs) arising in practical applications have useful structural properties that can be exploited at the algorithmic level. In this chapter, we review two decomposition frameworks for large-scale SDPs characterized by either chordal aggregate sparsity or partial orthogonality. Chordal aggregate sparsity allows one to decompose the positive semidefinite matrix variable in the SDP, while partial orthogonality enables the decomposition of the affine constraints. The decomposition frameworks are particularly suitable for the application of first-order algorithms. We describe how the decomposition strategies enable one to speed up the iterations of a first-order algorithm, based on the alternating direction method of multipliers, for the solution of the homogeneous self-dual embedding of a primal-dual pair of SDPs. Precisely, we give an overview of two structure-exploiting algorithms for semidefinite programming, which have been implemented in the open-source MATLAB solver CDCS. Numerical experiments on a range of large-scale SDPs demonstrate that the decomposition methods described in this chapter promise significant computational gains.
 Keywords
 Large-scale semidefinite programs
 Chordal decomposition
 Partial orthogonality
 Operator-splitting algorithms
 Decomposition methods
 AMS Subject Classifications
 90C06
 90C25
 49M27",many semidefinite programs  sdps  arising in practical applications have useful structural properties that can be exploited at the algorithmic level  in this chapter  we review two decomposition frameworks for large scale sdps characterized by either chordal aggregate sparsity or partial orthogonality  chordal aggregate sparsity allows one to decompose the positive semidefinite matrix variable in the sdp  while partial orthogonality enables the decomposition of the affine constraints  the decomposition frameworks are particularly suitable for the application of first order algorithms  we describe how the decomposition strategies enable one to speed up the iterations of a first order algorithm  based on the alternating direction method of multipliers  for the solution of the homogeneous self dual embedding of a primal dual pair of sdps  precisely  we give an overview of two structure exploiting algorithms for semidefinite programming  which have been implemented in the open source matlab solver cdcs  numerical experiments on a range of large scale sdps demonstrate that the decomposition methods described in this chapter promise significant computational gains   keywords  large scale semidefinite programs  chordal decomposition  partial orthogonality  operator splitting algorithms  decomposition methods  ams subject classifications    c      c      m  ,3.1269312,8.033846,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
"Seasonal variation characteristics and release potential of phosphorus in sediments: a case study of the Qiuxi River, a typical diffuse source pollution river in southwestern China","Soil phosphorus fractions in wetland ecosystems have received increasing attention due to its high eutrophication risks. Soil samples were collected to 40 cm depth in three sampling seasons to investigate the seasonal dynamics of organic and inorganic phosphorus fractions, bioavailability, and relationship between those and soil properties in a seasonal-flooding wetland in the Yellow River Estuary. The results showed that inorganic phosphorus (IP) and organic phosphorus (OP) contents exhibited much higher levels in the top 10 cm soils, and declined along soil profiles in spring. IP kept constant along soil profiles in fall, while OP decreased in summer and fall. They were greatly affected by water content (WC), pH, Clâˆ’/SO42âˆ’, soil organic matter (SOM), and electrical conductivity (EC). Middle labile organic phosphorus (MLOP) and non-labile organic phosphorus (NLOP) accounted for higher percentages of total OP in summer and fall respectively than labile organic phosphorus (LOP) in spring. MLOP and NLOP levels showed a decrease along soil profiles in spring and in spring/fall, respectively, while NLOP significantly increased with depth in summer. Ca-P was the dominant IP fraction in all soils in three sampling seasons, declined with depth in spring/fall and increased in summer. Comparatively, soluble/loosely-P(S/L-P) generally decreased with depth along soil profiles in three sampling seasons. And residual P (Res-P) kept little change with depth in spring. Fe/Al-P levels decreased firstly and then increased with depth in spring and summer. Available phosphorus and potential bioavailable phosphorus contents decreased with depth in spring and summer not in fall, and had a strong significant positive correlation with WC and SOM. Alkaline phosphatase not acid phosphatase was the key factor influencing soil MLOP levels. Generally, the fractions and bioavailability of phosphorus as well as phosphatase in this region were affected by soil depth, sampling seasons, and soil properties (e.g., WC, pH, Clâˆ’/SO42âˆ’, SOM, and EC).",soil phosphorus fractions in wetland ecosystems have received increasing attention due to its high eutrophication risks  soil samples were collected to    cm depth in three sampling seasons to investigate the seasonal dynamics of organic and inorganic phosphorus fractions  bioavailability  and relationship between those and soil properties in a seasonal flooding wetland in the yellow river estuary  the results showed that inorganic phosphorus  ip  and organic phosphorus  op  contents exhibited much higher levels in the top    cm soils  and declined along soil profiles in spring  ip kept constant along soil profiles in fall  while op decreased in summer and fall  they were greatly affected by water content  wc   ph  cl    so       soil organic matter  som   and electrical conductivity  ec   middle labile organic phosphorus  mlop  and non labile organic phosphorus  nlop  accounted for higher percentages of total op in summer and fall respectively than labile organic phosphorus  lop  in spring  mlop and nlop levels showed a decrease along soil profiles in spring and in spring fall  respectively  while nlop significantly increased with depth in summer  ca p was the dominant ip fraction in all soils in three sampling seasons  declined with depth in spring fall and increased in summer  comparatively  soluble loosely p s l p  generally decreased with depth along soil profiles in three sampling seasons  and residual p  res p  kept little change with depth in spring  fe al p levels decreased firstly and then increased with depth in spring and summer  available phosphorus and potential bioavailable phosphorus contents decreased with depth in spring and summer not in fall  and had a strong significant positive correlation with wc and som  alkaline phosphatase not acid phosphatase was the key factor influencing soil mlop levels  generally  the fractions and bioavailability of phosphorus as well as phosphatase in this region were affected by soil depth  sampling seasons  and soil properties  e g   wc  ph  cl    so       som  and ec  ,4.564051,1.8312414,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Local extreme complete trio pattern for multimedia image retrieval system,"Purpose
 To better control and manage phosphorus (P) in the aquatic environment of the Qiuxi River, a typical river severely influenced by anthropogenic activities in southwest China, the morphological characteristics and the release potential of P in sediments during different water seasons were determined.
 Materials and methods
 The overlying water and sediment samples were collected from the Qiuxi River in the normal-water season (NWS), low-water season (LWS), and high-water season (HWS), and physicochemical properties were quantified. Total phosphorus (TP) in sediment and the inorganic phosphorus (Pi) fraction were analyzed using the standard measures technology (SMT) procedure, and organic phosphorus (Po) was further determined to be labile Po (LOP), moderately labile Po (MLOP), or non-labile Po (NLOP). The release potential of P from the sediments was studied by experiments under simulated conditions.
 Results and discussion
 The results showed that P pollution in the Qiuxi River was the most serious during the LWS, with mean TP concentrations in the sediment of 854.6 mg kgâˆ’1, and the release risk of the sediment P was also highest during this water season. The variation in P concentration was significantly influenced by the discharge of domestic sewage, agricultural diffusion, flow rate, and OM. The concentrations of P fractions varied with water season, but Pi was constantly higher than Po. HCl-extractable Pi (HCl-Pi) accounted for most of the P in the sediments, which was related to its characteristics and the geographical location of the Qiuxi River. The maximum P release (Rmax) was 25.9 mg kgâˆ’1 in the LWS and 15.3 mg kgâˆ’1 in the HWS, which were positively correlated with the TP (r2â€‰=â€‰0.848, pâ€‰<â€‰0.01) and OM (r2â€‰=â€‰0.847, pâ€‰<â€‰0.01) concentrations in the sediments and explained why the release risk of the sediment P in the LWS was higher than that in the HWS.
 Conclusions
 Phosphorus pollution and the P release potential in the sediments of the Qiuxi River were most severe in the LWS, so more effective measures to restrain the release of P should be taken during the LWS. Moreover, OM in sediments should be given more attention owing to its significantly positive correlation with the risk of P release.",purpose  to better control and manage phosphorus  p  in the aquatic environment of the qiuxi river  a typical river severely influenced by anthropogenic activities in southwest china  the morphological characteristics and the release potential of p in sediments during different water seasons were determined   materials and methods  the overlying water and sediment samples were collected from the qiuxi river in the normal water season  nws   low water season  lws   and high water season  hws   and physicochemical properties were quantified  total phosphorus  tp  in sediment and the inorganic phosphorus  pi  fraction were analyzed using the standard measures technology  smt  procedure  and organic phosphorus  po  was further determined to be labile po  lop   moderately labile po  mlop   or non labile po  nlop   the release potential of p from the sediments was studied by experiments under simulated conditions   results and discussion  the results showed that p pollution in the qiuxi river was the most serious during the lws  with mean tp concentrations in the sediment of       mg kg      and the release risk of the sediment p was also highest during this water season  the variation in p concentration was significantly influenced by the discharge of domestic sewage  agricultural diffusion  flow rate  and om  the concentrations of p fractions varied with water season  but pi was constantly higher than po  hcl extractable pi  hcl pi  accounted for most of the p in the sediments  which was related to its characteristics and the geographical location of the qiuxi river  the maximum p release  rmax  was      mg kg     in the lws and      mg kg     in the hws  which were positively correlated with the tp  r               p             and om  r               p             concentrations in the sediments and explained why the release risk of the sediment p in the lws was higher than that in the hws   conclusions  phosphorus pollution and the p release potential in the sediments of the qiuxi river were most severe in the lws  so more effective measures to restrain the release of p should be taken during the lws  moreover  om in sediments should be given more attention owing to its significantly positive correlation with the risk of p release ,3.6810024,2.1127605,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Effects of fine bubble aeration at the sedimentâ€’water interface on distributions of organic phosphorus fractions and related microbial activity in a heavily urban river,"This paper presents a new feature descriptor, namely local extreme complete trio pattern (LECTP) for image retrieval application. The LECTP extracts complete extreme to minimal edge information in all possible directions using trio values. The LECTP integrates the local extreme sign trio patterns (LESTP) with magnitude local operator (MLOP) for image retrieval. The performance of the LECTP is tested by conducting three experiments on Corel-5 000, Corel-10 000 and MIT-VisTex color databases, respectively. The results after investigation show a significant improvement in terms of average retrieval precision (ARP) and average retrieval rate (ARR) as compared to the other state-of-the art techniques in content based image retrieval (CBIR).",this paper presents a new feature descriptor  namely local extreme complete trio pattern  lectp  for image retrieval application  the lectp extracts complete extreme to minimal edge information in all possible directions using trio values  the lectp integrates the local extreme sign trio patterns  lestp  with magnitude local operator  mlop  for image retrieval  the performance of the lectp is tested by conducting three experiments on corel        corel        and mit vistex color databases  respectively  the results after investigation show a significant improvement in terms of average retrieval precision  arp  and average retrieval rate  arr  as compared to the other state of the art techniques in content based image retrieval  cbir  ,4.055728,6.134531,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Digital Eye Care and Teleophthalmology A Practical Guide to Applications,"Purpose
 Effects of aeration on distribution and release potential of organic phosphorus in sediments are of great significance. The aim of this study was to investigate effects of fine bubble aeration at the sedimentâ€’water interface on species distributions of organic phosphorus and related microbial activities in the sediments from Nanfei River, a seriously polluted urban river in Hefei City, Anhui Province, China.
 Materials and methods
 A simulation experiment with a precision oxygen distribution system with fine bubble was applied and the sediments in system were taken out at intervals to test various indicators, mainly including the contents of phosphorus, species distribution of organic phosphorus, microbial biomass (MBC), and alkaline phosphatase activity (APA), as well as the number of phosphate solubilizing bacteria.
 Results
 The results showed that the content of dissolved organic carbon (DOC) increased in the sediments, along with the decrease of pH and the significant increase of oxidationâ€“reduction potential (ORP). The content of total phosphorus and inorganic phosphorus in the surface sediments generally presented a downward trend when the content of organic phosphorus increased first and then decreased during aeration. The variation trends of liable organic phosphorus and moderately labile organic phosphorus were similar to organic phosphorus, while the content of non-labile organic phosphorus was slightly decreased. In addition, the MBC and APA increased. The number of organic phosphorus mineralizing bacteria (OPB) increased while that of inorganic phosphorus solubilizing bacteria (IPB) decreased, and the number of OPB was significantly correlated to APA, which corresponds to the mineralization mechanism of organic phosphorus.
 Conclusions
 There were two stages of phosphorus transformation in the surface sediments during the aeration treatment: the stabilization of inorganic phosphorus in the early stage and the mineralization of organic phosphorus latterly, which means an increased risk of phosphorus release into the water in the late stage. Therefore, the fine bubble aeration treatment at the sedimentâ€’water interface applied to controlling the internal pollution of water bodies should be considered, especially focusing on the strict control of the aeration time. Overall, the present study can provide scientific guidance for in situ remediation of heavily polluted sediments.",purpose  effects of aeration on distribution and release potential of organic phosphorus in sediments are of great significance  the aim of this study was to investigate effects of fine bubble aeration at the sediment   water interface on species distributions of organic phosphorus and related microbial activities in the sediments from nanfei river  a seriously polluted urban river in hefei city  anhui province  china   materials and methods  a simulation experiment with a precision oxygen distribution system with fine bubble was applied and the sediments in system were taken out at intervals to test various indicators  mainly including the contents of phosphorus  species distribution of organic phosphorus  microbial biomass  mbc   and alkaline phosphatase activity  apa   as well as the number of phosphate solubilizing bacteria   results  the results showed that the content of dissolved organic carbon  doc  increased in the sediments  along with the decrease of ph and the significant increase of oxidation   reduction potential  orp   the content of total phosphorus and inorganic phosphorus in the surface sediments generally presented a downward trend when the content of organic phosphorus increased first and then decreased during aeration  the variation trends of liable organic phosphorus and moderately labile organic phosphorus were similar to organic phosphorus  while the content of non labile organic phosphorus was slightly decreased  in addition  the mbc and apa increased  the number of organic phosphorus mineralizing bacteria  opb  increased while that of inorganic phosphorus solubilizing bacteria  ipb  decreased  and the number of opb was significantly correlated to apa  which corresponds to the mineralization mechanism of organic phosphorus   conclusions  there were two stages of phosphorus transformation in the surface sediments during the aeration treatment  the stabilization of inorganic phosphorus in the early stage and the mineralization of organic phosphorus latterly  which means an increased risk of phosphorus release into the water in the late stage  therefore  the fine bubble aeration treatment at the sediment   water interface applied to controlling the internal pollution of water bodies should be considered  especially focusing on the strict control of the aeration time  overall  the present study can provide scientific guidance for in situ remediation of heavily polluted sediments ,3.860816,2.0565813,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
AI Best Practice and DataOps,"We ran through in the first chapter the key themes for productionizing AI today. Before we proceed into an exhaustive look at data ingestion and techniques and tools for building an AI application, it's important to establish a framework for success.",we ran through in the first chapter the key themes for productionizing ai today  before we proceed into an exhaustive look at data ingestion and techniques and tools for building an ai application  it s important to establish a framework for success ,11.334868,6.251115,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
"Intelligent Computing Proceedings of the 2021 Computing Conference, Volume 2","Brain tumors are created when unusual cells develop within the brain. These tumors can be divided into four groups, and some can be surgically removed while others gradually spread to neighboring tissues. In this study, we explore the classification of brain tumors using a convolutional neural network (CNN) and the concept of transfer learning. We also attempted to deploy the proposed model on a web application.
 Keywords
 Brain tumor
 Magnetic resonance imaging
 Convolutional neural network
 Machine learning",brain tumors are created when unusual cells develop within the brain  these tumors can be divided into four groups  and some can be surgically removed while others gradually spread to neighboring tissues  in this study  we explore the classification of brain tumors using a convolutional neural network  cnn  and the concept of transfer learning  we also attempted to deploy the proposed model on a web application   keywords  brain tumor  magnetic resonance imaging  convolutional neural network  machine learning,3.8690693,4.8155804,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
An Exploratory Study to Classify Brain Tumor Using Convolutional Neural Networks,"Technology is the muscle-mass of AI solutions, providing the computing infrastructure and software capabilities to use and deploy AI methods. Acquiring and building new technology takes time. New software and hardware are necessary at times, but leaders must decide when these are truly needed and then guide the entire process from advocacy to approval to operate. Enterprise solutions like Army Vantage, OSD Advana, and Air Force Platform One play important roles, but technology solutions for the vast number of individual systems of record in national security will remain prominent. Over the coming years data must remain a central focusâ€”data access, aggregation, management, securityâ€”and will continue to require innovations in technology and processes to provide the fuel for AI work and solutions.",technology is the muscle mass of ai solutions  providing the computing infrastructure and software capabilities to use and deploy ai methods  acquiring and building new technology takes time  new software and hardware are necessary at times  but leaders must decide when these are truly needed and then guide the entire process from advocacy to approval to operate  enterprise solutions like army vantage  osd advana  and air force platform one play important roles  but technology solutions for the vast number of individual systems of record in national security will remain prominent  over the coming years data must remain a central focus   data access  aggregation  management  security   and will continue to require innovations in technology and processes to provide the fuel for ai work and solutions ,11.120702,7.2211914,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Leading the Technology,"Phosphorus reuse by application of biochar is a recent concept that needs to be supported by long-term field data. To monitor biocharâ€™s long-term effects on P turnover, one-off biochar was applied in 2013 with mineral NPK fertilizers being applied every year since then. Biochar application rates included 0 t haâˆ’1 (CK), 15.75 t haâˆ’1 (BC1), 31.5 t haâˆ’1 (BC2), and 47.25 t haâˆ’1 (BC3). Over the 5 yearsâ€™ field experiment, P distribution in soil profile, inorganic and organic P fractions in bulk, and rhizosphere soil and maize P uptake were determined. The results showed that biochar reduced the inorganic P fractions (Ca2-P, Ca8-P, Al-P, Fe-P and O-P by 4.8â€“33.7%, 8.8â€“59.0%, 13.7â€“28.6%, 8.4â€“17.6%, and 3.3â€“25.5%, respectively), and increased organic P fractions (MLOP and HROP by 67.2â€“11.6% and 18.8â€“87.7%, respectively) in bulk soil, while in rhizosphere soil, Fe-P and MLOP were decreased by 13.4â€“34.5% and 67.2â€“111.6%, respectively, in 2017. After the application of biochar for 5 years, moderately labile organic phosphorus (MLOP), moderately resistant organic phosphorus (MROP), and highly resistant organic phosphorus (HROP) with different biochar treatments were enhanced by 12.8â€“42.7%, 20.1â€“48.0%, and 5.5â€“66.6%, respectively, but Ca8-P, Al-P, O-P, and Ca10-P were all decreased by 18.6â€“24.9%, 16.4â€“21.4%, and 3.3â€“23.48%, respectively. Total P storage in 0â€“100 cm was declined by biochar. Increases in maize P uptake in the stover (38.6â€“71.3%) and grain (20.9â€“25.5%) were occurred after 31.5 t haâˆ’1 and 47.25 t haâˆ’1 biochar addition. To sum up, biochar is found to regulate the distribution, storage, and transformation of soil P, which lead to increase in maize P uptake.",phosphorus reuse by application of biochar is a recent concept that needs to be supported by long term field data  to monitor biochar   s long term effects on p turnover  one off biochar was applied in      with mineral npk fertilizers being applied every year since then  biochar application rates included   t ha      ck         t ha      bc         t ha      bc    and       t ha      bc    over the   years    field experiment  p distribution in soil profile  inorganic and organic p fractions in bulk  and rhizosphere soil and maize p uptake were determined  the results showed that biochar reduced the inorganic p fractions  ca  p  ca  p  al p  fe p and o p by                                                      and              respectively   and increased organic p fractions  mlop and hrop by              and               respectively  in bulk soil  while in rhizosphere soil  fe p and mlop were decreased by              and                respectively  in       after the application of biochar for   years  moderately labile organic phosphorus  mlop   moderately resistant organic phosphorus  mrop   and highly resistant organic phosphorus  hrop  with different biochar treatments were enhanced by                             and              respectively  but ca  p  al p  o p  and ca   p were all decreased by                             and               respectively  total p storage in         cm was declined by biochar  increases in maize p uptake in the stover                and grain                were occurred after      t ha     and       t ha     biochar addition  to sum up  biochar is found to regulate the distribution  storage  and transformation of soil p  which lead to increase in maize p uptake ,4.419877,1.4964222,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Spatio-temporal variabilities of soil phosphorus pool and phosphorus uptake with maize stover biochar amendment for 5 years of maize,"Clinical AI applications, particularly medical imaging, are increasingly being adopted in healthcare systems worldwide. However, a crucial question remains: what happens after the AI model is put into production? We present our novel multi-modal model drift framework capable of tracking drift without contemporaneous ground truth using only readily available inputs, namely DICOM metadata, image appearance representation from a variational autoencoder (VAE), and model output probabilities. CheXStray was developed and tested using CheXpert, PadChest and Pediatric Pneumonia Chest X-ray datasets and we demonstrate that our framework generates a strong proxy for ground truth performance. In this work, we offer new insights into the challenges and solutions for observing deployed medical imaging AI and make three key contributions to real-time medical imaging AI monitoring: (1) proof-of-concept for medical imaging drift detection including use of VAE and domain specific statistical methods (2) a multi-modal methodology for measuring and unifying drift metrics (3) new insights into the challenges and solutions for observing deployed medical imaging AI. Our framework is released as open-source tools so that others may easily run their own workflows and build upon our work. Code available at: https://github.com/microsoft/MedImaging-ModelDriftMonitoring
 Keywords
 Medical imaging
 Model drift
 AI monitoring",clinical ai applications  particularly medical imaging  are increasingly being adopted in healthcare systems worldwide  however  a crucial question remains  what happens after the ai model is put into production  we present our novel multi modal model drift framework capable of tracking drift without contemporaneous ground truth using only readily available inputs  namely dicom metadata  image appearance representation from a variational autoencoder  vae   and model output probabilities  chexstray was developed and tested using chexpert  padchest and pediatric pneumonia chest x ray datasets and we demonstrate that our framework generates a strong proxy for ground truth performance  in this work  we offer new insights into the challenges and solutions for observing deployed medical imaging ai and make three key contributions to real time medical imaging ai monitoring      proof of concept for medical imaging drift detection including use of vae and domain specific statistical methods     a multi modal methodology for measuring and unifying drift metrics     new insights into the challenges and solutions for observing deployed medical imaging ai  our framework is released as open source tools so that others may easily run their own workflows and build upon our work  code available at  https   github com microsoft medimaging modeldriftmonitoring  keywords  medical imaging  model drift  ai monitoring,6.559528,3.9637961,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Responses of organic and inorganic phosphorus fractions in brown earth to successive maize stover and biochar application: a 5-year field experiment in Northeast China,"Purpose
 To compare the effects of maize stover and its biochar on soil P fractions and investigate the effects of different stover incorporation practices (direct return or pyrolysis) on the transformation of soil P fractions after a long-term field experiment.
 Materials and methods
 Total P, Olsen-P, inorganic P fractions, and organic P fractions were analyzed via a 5-year field experiment growing maize. The treatments were as follows: CK0 (no fertilizer application or amendment), CK (application of mineral NPK fertilizer), ST (application of maize stover at 7.5 t haâˆ’1 along with mineral NPK fertilizer), and BC (application of biochar at 2.63 t haâˆ’1, a rate approximately equivalent to a maize stover biomass of 7.5 t haâˆ’1; the biochar was charred according to a 35% output ratio in the factory). All treatments received N mineral fertilizer at 120 kg N haâˆ’1, P mineral fertilizer at 26 kg P haâˆ’1, and K mineral fertilizer at 50 kg K haâˆ’1 annually.
 Results and discussion
 Relative to the initial fractions in 2013, biochar generally increased the inorganic P fractions (Ca8-P, Ca10-P, Al-P, and Fe-P), and maize stover generally increased the organic P fractions (MLOP, MROP, and HROP), while both maize stover and its biochar significantly decreased O-P in the soil. After 5 years (in 2017), relative to CK treatment, amendment with maize stover and its biochar increased total P and decreased Olsen-P. The total inorganic P, Ca8-P, and Fe-P were significantly increased by biochar. Ca2-P and O-P were significantly decreased by maize stover and its biochar. Total organic P was increased with maize stover and biochar amendment. LOP and HROP were significantly increased under biochar application, and all organic P fractions were significantly increased under maize stover amendment.
 Conclusions
 The application of maize stover and its biochar affected both organic and inorganic phosphorus fractions; biochar had a more advantageous effect on the soil inorganic P fractions, while stover had a greater effect on the content of organic P fractions.",purpose  to compare the effects of maize stover and its biochar on soil p fractions and investigate the effects of different stover incorporation practices  direct return or pyrolysis  on the transformation of soil p fractions after a long term field experiment   materials and methods  total p  olsen p  inorganic p fractions  and organic p fractions were analyzed via a   year field experiment growing maize  the treatments were as follows  ck   no fertilizer application or amendment   ck  application of mineral npk fertilizer   st  application of maize stover at     t ha     along with mineral npk fertilizer   and bc  application of biochar at      t ha      a rate approximately equivalent to a maize stover biomass of     t ha      the biochar was charred according to a     output ratio in the factory   all treatments received n mineral fertilizer at     kg n ha      p mineral fertilizer at    kg p ha      and k mineral fertilizer at    kg k ha     annually   results and discussion  relative to the initial fractions in       biochar generally increased the inorganic p fractions  ca  p  ca   p  al p  and fe p   and maize stover generally increased the organic p fractions  mlop  mrop  and hrop   while both maize stover and its biochar significantly decreased o p in the soil  after   years  in        relative to ck treatment  amendment with maize stover and its biochar increased total p and decreased olsen p  the total inorganic p  ca  p  and fe p were significantly increased by biochar  ca  p and o p were significantly decreased by maize stover and its biochar  total organic p was increased with maize stover and biochar amendment  lop and hrop were significantly increased under biochar application  and all organic p fractions were significantly increased under maize stover amendment   conclusions  the application of maize stover and its biochar affected both organic and inorganic phosphorus fractions  biochar had a more advantageous effect on the soil inorganic p fractions  while stover had a greater effect on the content of organic p fractions ,4.4371223,1.7864802,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
"Comments on: Data science, big data and statistics","The paper under discussion offers an accurate panoramic view about the effects that the emergence of big data and data science in the last decade is having on statistics. I congratulate the authors for such a well-written and stimulating piece of work, including an excellent bibliography review. I agree with them that statistics has been able to adapt to the new scenarios (abundance and heterogeneity of data, impressive computing capacity, other disciplines sharing the same objectives, among other), and I trust that the discipline will take advantage of the new challenges it will face in the future.
 The authorsâ€™ belief on the need for convergence of different disciplines (statistics, machine learning, operation research, mathematics) is a position that I share completely. Specifically, they foresee that statistical ideas will be used to decompose and understand the forecasting rules created in other areas, [and] to identify the importance of the more relevant variables. The rest of the discussion elaborates on this idea.",the paper under discussion offers an accurate panoramic view about the effects that the emergence of big data and data science in the last decade is having on statistics  i congratulate the authors for such a well written and stimulating piece of work  including an excellent bibliography review  i agree with them that statistics has been able to adapt to the new scenarios  abundance and heterogeneity of data  impressive computing capacity  other disciplines sharing the same objectives  among other   and i trust that the discipline will take advantage of the new challenges it will face in the future   the authors    belief on the need for convergence of different disciplines  statistics  machine learning  operation research  mathematics  is a position that i share completely  specifically  they foresee that statistical ideas will be used to decompose and understand the forecasting rules created in other areas   and  to identify the importance of the more relevant variables  the rest of the discussion elaborates on this idea ,9.488961,6.4241304,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Predictive and Prescriptive Analytics in Big-data Era,"The notion of data analytics and its real-time application is important in the Big-data era owing to the voluminous data generation. Predictive and prescriptive analytics provide the future trends from the available data effectively. This will help to decide the usability of the data and thereby its retention for future applications. The paper reports the predictive and prescriptive analysis notion in Big-data regime, various platforms for its analysis and the future research directions.",the notion of data analytics and its real time application is important in the big data era owing to the voluminous data generation  predictive and prescriptive analytics provide the future trends from the available data effectively  this will help to decide the usability of the data and thereby its retention for future applications  the paper reports the predictive and prescriptive analysis notion in big data regime  various platforms for its analysis and the future research directions ,8.590304,5.9844775,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
A Strongly Polynomial Method for Solving Integer Max-Linear Optimization Problems in a Generic Case,"We study the existence of integer solutions to max-linear optimization problems. Specifically, we show that, in a generic case, the integer max-linear optimization problem can be solved in strongly polynomial time. This extends results from our previous papers where polynomial methods for this generic case were given.",we study the existence of integer solutions to max linear optimization problems  specifically  we show that  in a generic case  the integer max linear optimization problem can be solved in strongly polynomial time  this extends results from our previous papers where polynomial methods for this generic case were given ,3.0421724,8.105692,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Database Adaptiveness and Integration,"In most of existing multiobjective estimation of distribution algorithms (MEDAs), there exist drawbacks: incorrect treatment of population outliers; the loss of population diversity; and too much computational effort being spent on finding an optimal population model. To ease the drawbacks, this paper designs a novel clustering-based multivariate Gaussian sampling strategy and proposes an adaptive MEDA called AMEDA. A clustering analysis approach is utilized in AMEDA to discover the distribution structure of the population. Based on the distribution information, with a certain probability, a local or a global multivariate Gaussian model (MGM) is built for each solution to sample a new solution. A covariance sharing strategy is designed in AMEDA to reduce the complexity of building MGMs, and an adaptive update strategy of the probability that controls the contributions of the two types of MGMs is developed to dynamically balance exploration and exploitation. AMEDA is compared with four representative MOEAs on a number of test instances with complex Pareto fronts and variable linkages. Experimental results suggest that AMEDA outperforms the comparison algorithms on dealing with the test instances. The effectiveness of the clustering-based multivariate Gaussian sampling strategy and the adaptive probability update strategy is also experimentally verified.",in most of existing multiobjective estimation of distribution algorithms  medas   there exist drawbacks  incorrect treatment of population outliers  the loss of population diversity  and too much computational effort being spent on finding an optimal population model  to ease the drawbacks  this paper designs a novel clustering based multivariate gaussian sampling strategy and proposes an adaptive meda called ameda  a clustering analysis approach is utilized in ameda to discover the distribution structure of the population  based on the distribution information  with a certain probability  a local or a global multivariate gaussian model  mgm  is built for each solution to sample a new solution  a covariance sharing strategy is designed in ameda to reduce the complexity of building mgms  and an adaptive update strategy of the probability that controls the contributions of the two types of mgms is developed to dynamically balance exploration and exploitation  ameda is compared with four representative moeas on a number of test instances with complex pareto fronts and variable linkages  experimental results suggest that ameda outperforms the comparison algorithms on dealing with the test instances  the effectiveness of the clustering based multivariate gaussian sampling strategy and the adaptive probability update strategy is also experimentally verified ,3.9156733,7.677832,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Swarm Simulation Modeling Using the Hadamard Product,What Database Adaptiveness is.,what database adaptiveness is ,9.084799,6.8293633,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
No dimension-free deterministic algorithm computes approximate stationarities of Lipschitzians,"Abstract
 Using a large number of drones poses the challenge of correct, transparent, and high-performance modeling of their co-operation as a swarm. The authors develop and present an example of transitioning from a description of the control system of a single drone to the behavior of a swarm of identical drones based on the Hadamard algebra (product). It is shown that this approach increases model performance tenfold and allows the modeling of swarm systems with a very large number of units.",abstract  using a large number of drones poses the challenge of correct  transparent  and high performance modeling of their co operation as a swarm  the authors develop and present an example of transitioning from a description of the control system of a single drone to the behavior of a swarm of identical drones based on the hadamard algebra  product   it is shown that this approach increases model performance tenfold and allows the modeling of swarm systems with a very large number of units ,7.0112085,4.7057953,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Obtaining Approximately Optimal and Diverse Solutions via Dispersion,"We consider the oracle complexity of computing an approximate stationary point of a Lipschitz function. When the function is smooth, it is well known that the simple deterministic gradient method has finite dimension-free oracle complexity. However, when the function can be nonsmooth, it is only recently that a randomized algorithm with finite dimension-free oracle complexity has been developed. In this paper, we show that no deterministic algorithm can do the same. Moreover, even without the dimension-free requirement, we show that any finite-time deterministic method cannot be general zero-respecting. In particular, this implies that a natural derandomization of the aforementioned randomized algorithm cannot have finite-time complexity. Our results reveal a fundamental hurdle in modern large-scale nonconvex nonsmooth optimization.",we consider the oracle complexity of computing an approximate stationary point of a lipschitz function  when the function is smooth  it is well known that the simple deterministic gradient method has finite dimension free oracle complexity  however  when the function can be nonsmooth  it is only recently that a randomized algorithm with finite dimension free oracle complexity has been developed  in this paper  we show that no deterministic algorithm can do the same  moreover  even without the dimension free requirement  we show that any finite time deterministic method cannot be general zero respecting  in particular  this implies that a natural derandomization of the aforementioned randomized algorithm cannot have finite time complexity  our results reveal a fundamental hurdle in modern large scale nonconvex nonsmooth optimization ,3.7515888,7.580723,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
In-memory computing with resistive switching devices,"There has been a long-standing interest in computing diverse solutions to optimization problems. In 1995 J. Krarup [28] posed the problem of finding k-edge disjoint Hamiltonian Circuits of minimum total weight, called the peripatetic salesman problem (PSP). Since then researchers have investigated the complexity of finding diverse solutions to spanning trees, paths, vertex covers, matchings, and more. Unlike the PSP that has a constraint on the total weight of the solutions, recent work has involved finding diverse solutions that are all optimal.
 However, sometimes the space of exact solutions may be too small to achieve sufficient diversity. Motivated by this, we initiate the study of obtaining sufficiently-diverse, yet approximately-optimal solutions to optimization problems. Formally, given an integer k, an approximation factor c, and an instance I of an optimization problem, we aim to obtain a set of k solutions to I that a) are all c approximately-optimal for I and b) maximize the diversity of the k solutions. Finding such solutions, therefore, requires a better understanding of the global landscape of the optimization function.
 Given a metric on the space of solutions, and the diversity measure as the sum of pairwise distances between solutions, we first provide a general reduction to an associated budget-constrained optimization (BCO) problem, where one objective function is to optimized subject to a bound on the second objective function. We then prove that bi-approximations to the BCO can be used to give bi-approximations to the diverse approximately optimal solutions problem.
 As applications of our result, we present polynomial time approximation algorithms for several problems such as diverse c-approximate maximum matchings, \(s-t\) shortest paths, global min-cut, and minimum weight bases of a matroid. The last result gives us diverse c-approximate minimum spanning trees, advancing a step towards achieving diverse c-approximate TSP tours.
 We also explore the connection to the field of multiobjective optimization and show that the class of problems to which our result applies includes those for which the associated DUALRESTRICT problem defined by Papadimitriou and Yannakakis [35], and recently explored by Herzel et al. [26] can be solved in polynomial time.
 Keywords
 Diversity
 Minimum spanning tree
 Maximum matching
 Shortest path
 Travelling salesman problem
 Dispersion problem",there has been a long standing interest in computing diverse solutions to optimization problems  in      j  krarup      posed the problem of finding k edge disjoint hamiltonian circuits of minimum total weight  called the peripatetic salesman problem  psp   since then researchers have investigated the complexity of finding diverse solutions to spanning trees  paths  vertex covers  matchings  and more  unlike the psp that has a constraint on the total weight of the solutions  recent work has involved finding diverse solutions that are all optimal   however  sometimes the space of exact solutions may be too small to achieve sufficient diversity  motivated by this  we initiate the study of obtaining sufficiently diverse  yet approximately optimal solutions to optimization problems  formally  given an integer k  an approximation factor c  and an instance i of an optimization problem  we aim to obtain a set of k solutions to i that a  are all c approximately optimal for i and b  maximize the diversity of the k solutions  finding such solutions  therefore  requires a better understanding of the global landscape of the optimization function   given a metric on the space of solutions  and the diversity measure as the sum of pairwise distances between solutions  we first provide a general reduction to an associated budget constrained optimization  bco  problem  where one objective function is to optimized subject to a bound on the second objective function  we then prove that bi approximations to the bco can be used to give bi approximations to the diverse approximately optimal solutions problem   as applications of our result  we present polynomial time approximation algorithms for several problems such as diverse c approximate maximum matchings    s t   shortest paths  global min cut  and minimum weight bases of a matroid  the last result gives us diverse c approximate minimum spanning trees  advancing a step towards achieving diverse c approximate tsp tours   we also explore the connection to the field of multiobjective optimization and show that the class of problems to which our result applies includes those for which the associated dualrestrict problem defined by papadimitriou and yannakakis       and recently explored by herzel et al       can be solved in polynomial time   keywords  diversity  minimum spanning tree  maximum matching  shortest path  travelling salesman problem  dispersion problem,2.5480824,7.9125695,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
In-memory computing with resistive switching devices,"Modern computers are based on the von Neumann architecture in which computation and storage are physically separated: data are fetched from the memory unit, shuttled to the processing unit (where computation takes place) and then shuttled back to the memory unit to be stored. The rate at which data can be transferred between the processing unit and the memory unit represents a fundamental limitation of modern computers, known as the memory wall. In-memory computing is an approach that attempts to address this issue by designing systems that compute within the memory, thus eliminating the energy-intensive and time-consuming data movement that plagues current designs. Here we review the development of in-memory computing using resistive switching devices, where the two-terminal structure of the devices, their resistive switching properties, and direct data processing in the memory can enable area- and energy-efficient computation. We examine the different digital, analogue, and stochastic computing schemes that have been proposed, and explore the microscopic physical mechanisms involved. Finally, we discuss the challenges in-memory computing faces, including the required scaling characteristics, in delivering next-generation computing.",modern computers are based on the von neumann architecture in which computation and storage are physically separated  data are fetched from the memory unit  shuttled to the processing unit  where computation takes place  and then shuttled back to the memory unit to be stored  the rate at which data can be transferred between the processing unit and the memory unit represents a fundamental limitation of modern computers  known as the memory wall  in memory computing is an approach that attempts to address this issue by designing systems that compute within the memory  thus eliminating the energy intensive and time consuming data movement that plagues current designs  here we review the development of in memory computing using resistive switching devices  where the two terminal structure of the devices  their resistive switching properties  and direct data processing in the memory can enable area  and energy efficient computation  we examine the different digital  analogue  and stochastic computing schemes that have been proposed  and explore the microscopic physical mechanisms involved  finally  we discuss the challenges in memory computing faces  including the required scaling characteristics  in delivering next generation computing ,5.0300417,8.623294,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
A novel hybrid optimization algorithm: Dynamic hybrid optimization algorithm,"Nowadays, many algorithms are invented with different strengths and weaknesses, none of which is the best for all cases. Herein, a hybrid optimization algorithm entitled the dynamic hybrid optimization algorithm (DHOA) is presented. We cover the weaknesses of one algorithm with the strengths of another algorithm using a new method of combination. There are two methods for combining algorithms: parallel and sequential. We adopted the parallel method and optimized the algorithmâ€™s performance. In this method, unlike other parallel methods, the population size of the better algorithm is enhanced. Three algorithms were selected due to their relatively different performance in the optimization, so that the results could be more accurately examined. We aimed to achieve better and more accurate results in a shorter time by using the exploitation ability of PSO, HHO, and the crossover of GA. Twenty-three well-known examples were provided to determine the fitness of the proposed method and to compare it with these three algorithms. A group of 10 modern benchmark test functions of Congress on Evolutionary Computation (CEC) was used as an extra evaluation for DHOA. Three well-known engineering examples (10-bar truss, welded beam, and pressure vessel designs) were also examined to evaluate the performance of the proposed method. The three algorithms were the Genetic Algorithm (GA), particle swarm optimization (PSO), and Harris Hawks algorithm (HHO). According to the findings, the proposed method has a faster convergence and better performance than the other algorithms. It also yields better results than its basic algorithms. The Friedman mean rank of the proposed dynamic hybrid optimization was one of the top three algorithms among 23 well-known functions and CEC2019 examples. As for the three famous engineering examples (10-bar truss, welded beam, and pressure vessel designs), it was one of the top three algorithms.",nowadays  many algorithms are invented with different strengths and weaknesses  none of which is the best for all cases  herein  a hybrid optimization algorithm entitled the dynamic hybrid optimization algorithm  dhoa  is presented  we cover the weaknesses of one algorithm with the strengths of another algorithm using a new method of combination  there are two methods for combining algorithms  parallel and sequential  we adopted the parallel method and optimized the algorithm   s performance  in this method  unlike other parallel methods  the population size of the better algorithm is enhanced  three algorithms were selected due to their relatively different performance in the optimization  so that the results could be more accurately examined  we aimed to achieve better and more accurate results in a shorter time by using the exploitation ability of pso  hho  and the crossover of ga  twenty three well known examples were provided to determine the fitness of the proposed method and to compare it with these three algorithms  a group of    modern benchmark test functions of congress on evolutionary computation  cec  was used as an extra evaluation for dhoa  three well known engineering examples     bar truss  welded beam  and pressure vessel designs  were also examined to evaluate the performance of the proposed method  the three algorithms were the genetic algorithm  ga   particle swarm optimization  pso   and harris hawks algorithm  hho   according to the findings  the proposed method has a faster convergence and better performance than the other algorithms  it also yields better results than its basic algorithms  the friedman mean rank of the proposed dynamic hybrid optimization was one of the top three algorithms among    well known functions and cec     examples  as for the three famous engineering examples     bar truss  welded beam  and pressure vessel designs   it was one of the top three algorithms ,2.5188859,7.6548424,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Multivariate multifractal texture DCGAN synthesis: How well does it work ? How does one know ?,"In a recent past, Deep Learning emerged as a standard tool in Image Processing, commonly involved in numerous and various tasks. Notably, Deep Learning has become increasingly popular for the synthesis of images in several applications different in nature. However, research efforts have been massively focused on designing new and increasingly complex architectures to achieve yet better performance, often at the price of overlooking the uneasy question of the assessment of the quality of the synthesized images. Focusing on the specific context of pure textures, i.e., of images with no geometrical contents, the present work aims to propose a methodology that permits to quantify the quality of Deep Learning synthesized images. It makes use of Deep Convolutional Generative Adversarial Networks, a specific class of trained neural networks, commonly used for image synthesis. Because they provide versatile and well-documented texture models, multivariate multifractal fields, with rich multiscale cross-statistics (scale-free and multifractal textures), are used. A posteriori synthesis quality indices are defined from the statistics of multiscale (wavelet) representations computed on deep learning generated multivariate textures and compared to those associated with the models. These comparisons permit to objectively quantify the quality of deep learning texture synthesis as well as the reproducibility of the training and learning procedures, an approach that departs from reporting only the training yielding best performance. This methodology further permits to quantify objectively the variation in the quality of deep learning generated multivariate textures with respect to the complexity of deep learning architectures. Moreover, a priori indices, constructed directly on loss functions, hence much easier to compute, are also proposed and shown to correlate significantly with the a posteriori and costly multiscale representation synthesis quality indices.",in a recent past  deep learning emerged as a standard tool in image processing  commonly involved in numerous and various tasks  notably  deep learning has become increasingly popular for the synthesis of images in several applications different in nature  however  research efforts have been massively focused on designing new and increasingly complex architectures to achieve yet better performance  often at the price of overlooking the uneasy question of the assessment of the quality of the synthesized images  focusing on the specific context of pure textures  i e   of images with no geometrical contents  the present work aims to propose a methodology that permits to quantify the quality of deep learning synthesized images  it makes use of deep convolutional generative adversarial networks  a specific class of trained neural networks  commonly used for image synthesis  because they provide versatile and well documented texture models  multivariate multifractal fields  with rich multiscale cross statistics  scale free and multifractal textures   are used  a posteriori synthesis quality indices are defined from the statistics of multiscale  wavelet  representations computed on deep learning generated multivariate textures and compared to those associated with the models  these comparisons permit to objectively quantify the quality of deep learning texture synthesis as well as the reproducibility of the training and learning procedures  an approach that departs from reporting only the training yielding best performance  this methodology further permits to quantify objectively the variation in the quality of deep learning generated multivariate textures with respect to the complexity of deep learning architectures  moreover  a priori indices  constructed directly on loss functions  hence much easier to compute  are also proposed and shown to correlate significantly with the a posteriori and costly multiscale representation synthesis quality indices ,3.6290364,6.826056,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Analysis of Web Usage Patterns to Identify Most Frequently Accessed Web Page by Multiple Users,"All Data related to web sites that we access is stored in web logs. Increase in browsing these days has led to increase in size of these web log files. Web Mining is one technique that can be applied to these log files to mine navigational patterns. There are various types of web mining depending upon data mined Content, Usage or Structure. In this paper we focus on Mining of usage patterns: Web Usage Mining to discover most frequently accessed web page by multiple users after preprocessing of log file.
 Keywords
 Web
 Usage
 Patterns
 Navigation
 Log file
 Web Usage Mining",all data related to web sites that we access is stored in web logs  increase in browsing these days has led to increase in size of these web log files  web mining is one technique that can be applied to these log files to mine navigational patterns  there are various types of web mining depending upon data mined content  usage or structure  in this paper we focus on mining of usage patterns  web usage mining to discover most frequently accessed web page by multiple users after preprocessing of log file   keywords  web  usage  patterns  navigation  log file  web usage mining,5.1408286,7.4880624,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Motivators and Inhibitors for Business Analytics Adoption from the Cross-Cultural Perspectives: A Data Mining Approach,"In the increasingly knowledge-based world economy, the multinational firmâ€™s success often hinges on its business intelligence capability nurtured by business analytics (BA). Despite the growing recognition of BA's role in enhancing the firmâ€™s intellectual capital and subsequent competitiveness, it is still unknown what truly motivates and inhibits BA adoption. This study aims to identify key influencing factors for BA adoption such as organizational characteristics, information security/privacy, and information technology maturity (knowledge level). In so doing, this study employed data mining and data visualization techniques to develop specific patterns of BA adoption practices based on a combined sample of 224 Korean firms and 106 U.S. firms representing various industry sectors. This study is one of the first attempts to develop practical guidelines for the successful implementation of BA based on the cross-national study of BA practices among both Korean and U.S. firms.",in the increasingly knowledge based world economy  the multinational firm   s success often hinges on its business intelligence capability nurtured by business analytics  ba   despite the growing recognition of ba s role in enhancing the firm   s intellectual capital and subsequent competitiveness  it is still unknown what truly motivates and inhibits ba adoption  this study aims to identify key influencing factors for ba adoption such as organizational characteristics  information security privacy  and information technology maturity  knowledge level   in so doing  this study employed data mining and data visualization techniques to develop specific patterns of ba adoption practices based on a combined sample of     korean firms and     u s  firms representing various industry sectors  this study is one of the first attempts to develop practical guidelines for the successful implementation of ba based on the cross national study of ba practices among both korean and u s  firms ,9.052254,6.9549193,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
A Comprehensive Review on Bacteria Foraging Optimization Technique,"Intelligent applications using evolutionary algorithms are becoming famous because of their ability to handle any real time complex and uncertain situations. Swarm intelligence, now-a-days has become a research focus which studies the collective behavior existing among the natural species which lives in group. Bacteria Foraging Optimization (BFO) is an optimization algorithm based on the social intelligence behavior of E.coli bacteria. Literature has witnessed the applications of BFO algorithm and the results reported are promising with regard to its convergence and accuracy. Several studies based on distributed control and optimization also suggested that algorithm based on BFO can be treated as global optimization technique. In this chapter, we have focused on the behavior of biological bacterial colony followed by the optimization algorithm based on bacterial colony foraging. We have also explored variations in the components of BFO algorithm (Revised BFO), hybridization of BFO with other Evolutionary Algorithms (Hybrid BFO) and multi-objective BFO. Finally, we have analyzed some applications of BFO algorithm in various domains.
 Keywords
 Bacteria foraging
 Evolutionary computing
 Hybrid BFO
 Multi-objective optimization
 Optimization
 Revised BFO
 Swarm intelligence",intelligent applications using evolutionary algorithms are becoming famous because of their ability to handle any real time complex and uncertain situations  swarm intelligence  now a days has become a research focus which studies the collective behavior existing among the natural species which lives in group  bacteria foraging optimization  bfo  is an optimization algorithm based on the social intelligence behavior of e coli bacteria  literature has witnessed the applications of bfo algorithm and the results reported are promising with regard to its convergence and accuracy  several studies based on distributed control and optimization also suggested that algorithm based on bfo can be treated as global optimization technique  in this chapter  we have focused on the behavior of biological bacterial colony followed by the optimization algorithm based on bacterial colony foraging  we have also explored variations in the components of bfo algorithm  revised bfo   hybridization of bfo with other evolutionary algorithms  hybrid bfo  and multi objective bfo  finally  we have analyzed some applications of bfo algorithm in various domains   keywords  bacteria foraging  evolutionary computing  hybrid bfo  multi objective optimization  optimization  revised bfo  swarm intelligence,3.1528358,7.955727,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
An Approach to Benchmarking Industrial Big Data Applications,"Through the increasing use of interconnected sensors, instrumentation, and smart machines, and the proliferation of social media and other open data, industrial operations and physical systems are generating ever increasing volumes of data of many different types. At the same time, advances in computing, storage, communication, and big data technologies are making it possible to collect, store, process, analyze and visualize enormous volumes of data at scale and at speed. The convergence of Operations Technology (OT) and Information Technology (IT), powered by innovative data analytics, holds the promise of using insights derived from these rich types of data to better manage our systems, resources, environment, health, social infrastructure, and industrial operations. Opportunities to apply innovative analytics abound in many industries (e.g., manufacturing, power distribution, oil and gas exploration and production, telecommunication, healthcare, agriculture, mining) and similarly in government (e.g., homeland security, smart cities, public transportation, accountable care). In developing several such applications over the years, we have come to realize that existing benchmarks for decision support, streaming data, event processing, or distributed processing are not adequate for industrial big data applications. One primary reason being that these benchmarks individually address narrow range of data and analytics processing needs of industrial big data applications. In this paper, we outline an approach we are taking to defining a benchmark that is motivated by typical industrial operations scenarios. We describe the main issues we are considering for the benchmark, including the typical data and processing requirements; representative queries and analytics operations over streaming and stored, structured and unstructured data; and the proposed simulator data architecture.
 Keywords
 Smart City
 Operation Technology
 Streaming Data
 Query Type
 Business Data
 These keywords were added by machine and not by the authors. This process is experimental and the keywords may be updated as the learning algorithm improves.",through the increasing use of interconnected sensors  instrumentation  and smart machines  and the proliferation of social media and other open data  industrial operations and physical systems are generating ever increasing volumes of data of many different types  at the same time  advances in computing  storage  communication  and big data technologies are making it possible to collect  store  process  analyze and visualize enormous volumes of data at scale and at speed  the convergence of operations technology  ot  and information technology  it   powered by innovative data analytics  holds the promise of using insights derived from these rich types of data to better manage our systems  resources  environment  health  social infrastructure  and industrial operations  opportunities to apply innovative analytics abound in many industries  e g   manufacturing  power distribution  oil and gas exploration and production  telecommunication  healthcare  agriculture  mining  and similarly in government  e g   homeland security  smart cities  public transportation  accountable care   in developing several such applications over the years  we have come to realize that existing benchmarks for decision support  streaming data  event processing  or distributed processing are not adequate for industrial big data applications  one primary reason being that these benchmarks individually address narrow range of data and analytics processing needs of industrial big data applications  in this paper  we outline an approach we are taking to defining a benchmark that is motivated by typical industrial operations scenarios  we describe the main issues we are considering for the benchmark  including the typical data and processing requirements  representative queries and analytics operations over streaming and stored  structured and unstructured data  and the proposed simulator data architecture   keywords  smart city  operation technology  streaming data  query type  business data  these keywords were added by machine and not by the authors  this process is experimental and the keywords may be updated as the learning algorithm improves ,7.106907,6.55956,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Geovisualisation Generation from Semantic Models: A State of the Art,"Geovisualisation is a first-choice approach when it comes to support a userâ€™s reasoning process to explore geographical information or solve a spatial problem. More and more data relevant for geovisual analysis is published in the Web, sometimes even directly described using the RDF formalism and made available through SPARQL endpoints. Beyond exploiting Semantic Web data, we claim that Semantic Web-based Geovisualisation is a field that also offers an opportunity to make methods, techniques and tools of geovisualisation evolve so they fully exploit the possibilities offered by the Semantic Web technologies stack. In this paper we review some works of the literature that have addressed the issues of cartography and geovisualisation of data formalised or published using Semantic Web technologies, ranging from domain knowledge representation only to frameworks supporting knowledge-based process for geovisualisation generation. As a contribution to this field, and based on lessons learned from the state of the art, we introduce the CoViKoa framework we have designed and implemented. Then, taking stock of our experience, we introduce some challenges we still envision in the field of Semantic Web-based Geovisualisation. We present some of them as open questions, but also draw some guidelines, for future works in the field.
 Keywords
 Geovisualisation
 Semantic Web
 generation process
 state of the art",geovisualisation is a first choice approach when it comes to support a user   s reasoning process to explore geographical information or solve a spatial problem  more and more data relevant for geovisual analysis is published in the web  sometimes even directly described using the rdf formalism and made available through sparql endpoints  beyond exploiting semantic web data  we claim that semantic web based geovisualisation is a field that also offers an opportunity to make methods  techniques and tools of geovisualisation evolve so they fully exploit the possibilities offered by the semantic web technologies stack  in this paper we review some works of the literature that have addressed the issues of cartography and geovisualisation of data formalised or published using semantic web technologies  ranging from domain knowledge representation only to frameworks supporting knowledge based process for geovisualisation generation  as a contribution to this field  and based on lessons learned from the state of the art  we introduce the covikoa framework we have designed and implemented  then  taking stock of our experience  we introduce some challenges we still envision in the field of semantic web based geovisualisation  we present some of them as open questions  but also draw some guidelines  for future works in the field   keywords  geovisualisation  semantic web  generation process  state of the art,6.927362,5.8794866,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Training for Research Careers in Biomedical Informatics and Data Science Supported by the National Library of Medicine,"The National Library of Medicine (NLM) has been the primary funder for university-based biomedical informatics training programs in the U.S. since the early 1970s. NLM has provided institutional training grants as well as informatics research opportunities for individual fellows. The programs supported by NLM have changed over time as the competencies needed for informatics research training have evolved. Over the years, the focus of the program has broadened to address a wide range of informatics needs, including the incorporation of bioinformatics and public health informatics training into programs that had earlier been focused almost exclusively on clinical informatics, and most recently incorporating biomedical data science as a fundamental component of the training. NLM also provides and supports training for biomedical research librarians. This chapter describes the evolution of grant-supported informatics training, identifies basic elements of informatics and data science curricula designed to produce interdisciplinary researchers, highlights new directions, and discusses data science training programs for librarians.
 Keywords
 Biomedical informatics
 Translational bioinformatics
 Informatics training
 National Institutes of Health
 National Library of Medicine
 Public health informatics
 Biomedical data science",the national library of medicine  nlm  has been the primary funder for university based biomedical informatics training programs in the u s  since the early     s  nlm has provided institutional training grants as well as informatics research opportunities for individual fellows  the programs supported by nlm have changed over time as the competencies needed for informatics research training have evolved  over the years  the focus of the program has broadened to address a wide range of informatics needs  including the incorporation of bioinformatics and public health informatics training into programs that had earlier been focused almost exclusively on clinical informatics  and most recently incorporating biomedical data science as a fundamental component of the training  nlm also provides and supports training for biomedical research librarians  this chapter describes the evolution of grant supported informatics training  identifies basic elements of informatics and data science curricula designed to produce interdisciplinary researchers  highlights new directions  and discusses data science training programs for librarians   keywords  biomedical informatics  translational bioinformatics  informatics training  national institutes of health  national library of medicine  public health informatics  biomedical data science,10.261578,6.1301208,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Task offloading in mmWave based 5G vehicular cloud computing,"Vehicular cloud computing (VCC) is a promising paradigm for efficiently utilizing and sharing computing and storage resources on vehicles. However, the network topology and the available computing resources change rapidly due to vehicular mobility. In this paper, we study the task offloading problem in the vehicular cloud (VC), in which computing missions that are exclusively divided into interdependent tasks can be offloaded from the edge cloud and executed on vehicles in the VC to minimize the overall response time. A mobility-aware model based on vehiclesâ€™ stay time is adopted by considering the instability of computing resources caused by the high vehicular mobility. We formulate an NP-hard optimization problem for task offloading that considers the heterogeneity of vehicular computing capabilities and the interdependency of computing tasks. For this, a Mobility-Aware Vehicular Cloud task Offloading (MAVCO) scheme is designed for low complexity that provides the optimal solution. We also consider the fifth-generation new-radio vehicle-to-everything communication model, i.e., cellular link and millimeter wave, to augment the system performance. The simulation findings demonstrate that the proposed algorithm can efficiently minimize the tasksâ€™ response time while releasing the edge cloud burden by comparing it with benchmark approaches.",vehicular cloud computing  vcc  is a promising paradigm for efficiently utilizing and sharing computing and storage resources on vehicles  however  the network topology and the available computing resources change rapidly due to vehicular mobility  in this paper  we study the task offloading problem in the vehicular cloud  vc   in which computing missions that are exclusively divided into interdependent tasks can be offloaded from the edge cloud and executed on vehicles in the vc to minimize the overall response time  a mobility aware model based on vehicles    stay time is adopted by considering the instability of computing resources caused by the high vehicular mobility  we formulate an np hard optimization problem for task offloading that considers the heterogeneity of vehicular computing capabilities and the interdependency of computing tasks  for this  a mobility aware vehicular cloud task offloading  mavco  scheme is designed for low complexity that provides the optimal solution  we also consider the fifth generation new radio vehicle to everything communication model  i e   cellular link and millimeter wave  to augment the system performance  the simulation findings demonstrate that the proposed algorithm can efficiently minimize the tasks    response time while releasing the edge cloud burden by comparing it with benchmark approaches ,6.6042156,7.427333,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Performance Analysis of DE over K-Means Proposed Model of Soft Computing,"In real-world data increased periodically, huge amount of data is called Big data. It is a well-known term used to define the exponential growth of data, both in structured and unstructured format. Data analysis is a method of cleaning, altering, learning valuable statistics, decision-making, and advising assumption with the help of many algorithms and procedures such as classification and clustering. In this paper we discuss about big data analysis using soft computing technique and propose how to pair two different approaches like evolutionary algorithm and machine learning approach also try to find better cause.
 Keywords
 Big data
 K-means algorithm
 DE (differential evolution)
 Data clustering",in real world data increased periodically  huge amount of data is called big data  it is a well known term used to define the exponential growth of data  both in structured and unstructured format  data analysis is a method of cleaning  altering  learning valuable statistics  decision making  and advising assumption with the help of many algorithms and procedures such as classification and clustering  in this paper we discuss about big data analysis using soft computing technique and propose how to pair two different approaches like evolutionary algorithm and machine learning approach also try to find better cause   keywords  big data  k means algorithm  de  differential evolution   data clustering,4.475112,7.1622653,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Deep Belief Neural Network for 5G Diabetes Monitoring in Big Data on Edge IoT,"The diabetes is a critical disease from the small children to old age people. Due to improper diet and physical activities of the living population, obesity becomes prevalent in young generation. If we analyze self care of individual life, no man or women ready to spend their time for health care. It leads to problem like diabetes, blood pressure etc. Today is a busy world were robots and artificial machines ready to take care of human personal needs. Automatic systems help humans to manage their busy schedule. It motivates us to develop a diabetes motoring system for patients using IoT device in their body which monitors their blood sugar level, blood pressure, sport activities, diet plan, oxygen level, ECG data. The data are processed using feature selection algorithm called as particle swarm optimization and transmitted to nearest edge node for processing in 5G networks. Secondly, data are processed using DBN Layer. Thirdly, we share the diagnosed data output through the wireless communication such as LTE/5G to the patients connected through the edge nodes for further medical assistance. The patient wearable devices are connected to the social network. The Result of our proposed system is evaluated with some existing system. Time and Performance outperform than other techniques.",the diabetes is a critical disease from the small children to old age people  due to improper diet and physical activities of the living population  obesity becomes prevalent in young generation  if we analyze self care of individual life  no man or women ready to spend their time for health care  it leads to problem like diabetes  blood pressure etc  today is a busy world were robots and artificial machines ready to take care of human personal needs  automatic systems help humans to manage their busy schedule  it motivates us to develop a diabetes motoring system for patients using iot device in their body which monitors their blood sugar level  blood pressure  sport activities  diet plan  oxygen level  ecg data  the data are processed using feature selection algorithm called as particle swarm optimization and transmitted to nearest edge node for processing in  g networks  secondly  data are processed using dbn layer  thirdly  we share the diagnosed data output through the wireless communication such as lte  g to the patients connected through the edge nodes for further medical assistance  the patient wearable devices are connected to the social network  the result of our proposed system is evaluated with some existing system  time and performance outperform than other techniques ,4.8545866,5.3208327,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Evaluation of two semi-supervised learning methods and their combination for automatic classification of bone marrow cells,"Differential bone marrow (BM) cell counting is an important test for the diagnosis of various hematological diseases. However, it is difficult to accurately classify BM cells due to non-uniformity and the lack of reproducibility of differential counting. Therefore, automatic classification systems have been developed in which deep learning is used. These systems requires large and accurately labeled datasets for training. To overcome this, we used semi-supervised learning (SSL), in which learning proceeds while labeling. We used three methods: self-training (ST), active learning (AL), and a combination of these methods, and attempted to automatically classify 16 types of BM cell images. ST involves data verification, as in AL, before adding them to the training dataset (confirmed self-training: CST). After 25 rounds of CST, AL, and CSTâ€‰+â€‰AL, the initial number of training data increased from 425 to 40,518; 3682; and 47,843, respectively. Accuracies for the test data of 50 images for each cell type were 0.944, 0.941, and 0.976, respectively. Data added with CST or AL showed some imbalances between classes, while CSTâ€‰+â€‰AL exhibited fewer imbalances. We suggest that CSTâ€‰+â€‰AL, when combined with two SSL methods, is efficient in increasing training data for the development of automatic BM cells classification systems.",differential bone marrow  bm  cell counting is an important test for the diagnosis of various hematological diseases  however  it is difficult to accurately classify bm cells due to non uniformity and the lack of reproducibility of differential counting  therefore  automatic classification systems have been developed in which deep learning is used  these systems requires large and accurately labeled datasets for training  to overcome this  we used semi supervised learning  ssl   in which learning proceeds while labeling  we used three methods  self training  st   active learning  al   and a combination of these methods  and attempted to automatically classify    types of bm cell images  st involves data verification  as in al  before adding them to the training dataset  confirmed self training  cst   after    rounds of cst  al  and cst       al  the initial number of training data increased from     to               and         respectively  accuracies for the test data of    images for each cell type were               and        respectively  data added with cst or al showed some imbalances between classes  while cst       al exhibited fewer imbalances  we suggest that cst       al  when combined with two ssl methods  is efficient in increasing training data for the development of automatic bm cells classification systems ,3.6261349,4.7794952,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Efficient learning approach using new combined fuzzy-M5P model tree: experimental investigation of active power filters,"This paper deals with the complete design and real-time implementation of a novel mixed control based on the pruned model tree (M5P) and collected datasets of a fuzzy logic controller. This combination aims to benefit from both the decision tree rapidity and the fuzzy logic advantages. In harmonic mitigation systems with an active power filter, a strategy for identifying harmonic currents has a considerable influence on the quality and capacity of compensation. The proposed fuzzy-M5P model tree is assessed in the indirect current control identification algorithm along with an effective comparison using the artificial neural network approach. The two learning methods are described and contrasted in an organized manner to evaluate their respective advantages in both steady state and dynamic state operating conditions. In compliance with IEEE std 519â€“1992 harmonic limits, an experimental setup was realized using dSPACE 1103 hardware to verify the excellent behavior of the system and to confirm the effectiveness of the proposed M5P based control in terms of an almost unity power factor of 0.99, a low total harmonic distortion value of 3.07%, and satisfactory dynamic performances characterized by a fast response time of 100 ms.",this paper deals with the complete design and real time implementation of a novel mixed control based on the pruned model tree  m p  and collected datasets of a fuzzy logic controller  this combination aims to benefit from both the decision tree rapidity and the fuzzy logic advantages  in harmonic mitigation systems with an active power filter  a strategy for identifying harmonic currents has a considerable influence on the quality and capacity of compensation  the proposed fuzzy m p model tree is assessed in the indirect current control identification algorithm along with an effective comparison using the artificial neural network approach  the two learning methods are described and contrasted in an organized manner to evaluate their respective advantages in both steady state and dynamic state operating conditions  in compliance with ieee std            harmonic limits  an experimental setup was realized using dspace      hardware to verify the excellent behavior of the system and to confirm the effectiveness of the proposed m p based control in terms of an almost unity power factor of       a low total harmonic distortion value of        and satisfactory dynamic performances characterized by a fast response time of     ms ,4.1703277,1.7977306,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
An Introduction to Data Science and Its Applications,"Data science has become a fundamental discipline, both in the field of basic research and in the resolution of applied problems, where statistics and computer science intersect. Thus, from the perspective of the data itself, machine learning, operation research, methods and algorithms, and data mining techniques are aligned to address new challenges characterised by the complexity, volume and heterogeneous nature of data.",data science has become a fundamental discipline  both in the field of basic research and in the resolution of applied problems  where statistics and computer science intersect  thus  from the perspective of the data itself  machine learning  operation research  methods and algorithms  and data mining techniques are aligned to address new challenges characterised by the complexity  volume and heterogeneous nature of data ,6.8850675,4.250998,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Deploying and Hosting Machine Learning Models,"This is one of the most important chapters in the book as more machine learning models transition from research labs into real-world applications. Ultimately, of course, after you have finished experimenting, you will need to consider a more production-friendly environment than your laptop. With the widespread industrial support and investment, this has been made easier through a variety of different frameworks. Tech giants such as Google, Facebook and Microsoft provide access to compressive frameworks for free. In line with industrial automation, many businesses are looking towards the use of algorithms to solve complex and repetitive problems while streamlining existing processes [1]. This has led to the widespread utilisation of machine learning algorithms that are already integrated into many distinct aspects of our lives. This is apparent in many services such as social media, home entertainment, online shopping and even our healthcare. The advanced machine learning algorithms we see today are relatively new and consequently how we deploy these algorithms has not fully matured. Until recently this was only undertaken by large tech giants but as you will see in this chapter anyone can now deploy and utilise the machine learning algorithms they develop to solve many challenges they currently face. Figure 13.1 shows the overlap between development (training) and model deployment (inferencing).",this is one of the most important chapters in the book as more machine learning models transition from research labs into real world applications  ultimately  of course  after you have finished experimenting  you will need to consider a more production friendly environment than your laptop  with the widespread industrial support and investment  this has been made easier through a variety of different frameworks  tech giants such as google  facebook and microsoft provide access to compressive frameworks for free  in line with industrial automation  many businesses are looking towards the use of algorithms to solve complex and repetitive problems while streamlining existing processes      this has led to the widespread utilisation of machine learning algorithms that are already integrated into many distinct aspects of our lives  this is apparent in many services such as social media  home entertainment  online shopping and even our healthcare  the advanced machine learning algorithms we see today are relatively new and consequently how we deploy these algorithms has not fully matured  until recently this was only undertaken by large tech giants but as you will see in this chapter anyone can now deploy and utilise the machine learning algorithms they develop to solve many challenges they currently face  figure      shows the overlap between development  training  and model deployment  inferencing  ,8.920503,6.820093,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Managing the Machine Learning Life Cycle,"As companies leverage AI and machine learning to transform their business, they soon realize developing and deploying ML applications is not a small task. In Chapter 8, you learned the machine learning development process is a highly iterative and scientific process that needs an engineering culture and practice that is slightly different from the traditional software development process. As the machine learning development community, including data scientist, *ML engineers and software engineers, gains more experience with developing machine learning applications and taking them to production, an apparent theme emerges and has been formalized into a discipline called MLOps.",as companies leverage ai and machine learning to transform their business  they soon realize developing and deploying ml applications is not a small task  in chapter    you learned the machine learning development process is a highly iterative and scientific process that needs an engineering culture and practice that is slightly different from the traditional software development process  as the machine learning development community  including data scientist   ml engineers and software engineers  gains more experience with developing machine learning applications and taking them to production  an apparent theme emerges and has been formalized into a discipline called mlops ,9.203608,6.3365216,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Research and Application of Spark Platform on Big Data Processing in Intelligent Agriculture of Jilin Province,"Aiming at the demand of real-time massive data processing of Intelligent Agriculture in Jilin Province, this paper studies the big data processing of Intelligent Agriculture in Jilin Province based on Spark platform by acquiring real-time data through monitoring platform. This study first conducted the performance comparison experiment of Hadoop and Spark data processing platform, then used the Spark distributed cluster computing platform, real-time processing the big data of monitoring area. The experimental results show that the Spark platform speeds up 11.4 times faster than the Hadoop platform in the case of 100 million data sizes; and based on the Spark platform for real-time processing of big data intelligent agricultural monitoring network, not only provides memory calculations to reduce IO overhead, but also the results are faster and more accurate. The research results provide strong support for the implementation of precision agriculture technology in intelligent agriculture.
 Keywords
 Spark
 Big data processing
 MapReduce
 Intelligent Agriculture in Jilin Province",aiming at the demand of real time massive data processing of intelligent agriculture in jilin province  this paper studies the big data processing of intelligent agriculture in jilin province based on spark platform by acquiring real time data through monitoring platform  this study first conducted the performance comparison experiment of hadoop and spark data processing platform  then used the spark distributed cluster computing platform  real time processing the big data of monitoring area  the experimental results show that the spark platform speeds up      times faster than the hadoop platform in the case of     million data sizes  and based on the spark platform for real time processing of big data intelligent agricultural monitoring network  not only provides memory calculations to reduce io overhead  but also the results are faster and more accurate  the research results provide strong support for the implementation of precision agriculture technology in intelligent agriculture   keywords  spark  big data processing  mapreduce  intelligent agriculture in jilin province,6.6797585,6.954323,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
An Anomaly Detection Method Based on Normalized Mutual Information Feature Selection and Quantum Wavelet Neural Network,"This paper presents an anomaly detection model based on normalized mutual information feature selection (NMIFS) and quantum wavelet neural network (QWNN). The goal of the proposed model is to address the problem of determining the feature subset used to detect an anomaly in a machine learning task. In order to achieve an effective reduction for high-dimensional feature data, the NMIFS method is used to select the best feature combination from a given set of sample features. Then, the best combination of feature vectors are sent to the QWNN classifier for learning and training in the training phase, and the anomaly detection model is obtained. At the detection stage, the data is fed into the detection model and ultimately generates accurate detection results. The learning algorithm of structural risk minimization extreme learning machine is employed by the QWNN classifier to account for empirical and confidence risk. The experimental results on real abnormal data demonstrate that the NMIFSâ€“QWNN method has higher detection accuracy and a lower false negative rate than the existing common anomaly detection methods. Furthermore, the complexity of the algorithm is low and the detection accuracy can reach up to 95.8%.",this paper presents an anomaly detection model based on normalized mutual information feature selection  nmifs  and quantum wavelet neural network  qwnn   the goal of the proposed model is to address the problem of determining the feature subset used to detect an anomaly in a machine learning task  in order to achieve an effective reduction for high dimensional feature data  the nmifs method is used to select the best feature combination from a given set of sample features  then  the best combination of feature vectors are sent to the qwnn classifier for learning and training in the training phase  and the anomaly detection model is obtained  at the detection stage  the data is fed into the detection model and ultimately generates accurate detection results  the learning algorithm of structural risk minimization extreme learning machine is employed by the qwnn classifier to account for empirical and confidence risk  the experimental results on real abnormal data demonstrate that the nmifs   qwnn method has higher detection accuracy and a lower false negative rate than the existing common anomaly detection methods  furthermore  the complexity of the algorithm is low and the detection accuracy can reach up to       ,3.420114,6.1010127,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Leading the People,"Leading AI teams means that you are leading practitioners from multiple disciplines including data science, software engineering, computer science, and IT. Data scientists are essential to the development of AI models, but it takes a multi-disciplinary team to deploy and maintain the models in operation at scale. In addition to leadership fundamentalsâ€”which are not always executed wellâ€”you must lead the talent lifecycle with an understanding of what data scientists need and value in their development. The demand for data scientists dwarfs the availability of experienced data scientists, thus they have tremendous leverage in deciding where they work and whom they follow. Given the unavoidable attrition, leaders must ensure that AI knowledge is instantiated in reusable code. The government will acquire most large-scale AI capabilities from industry; thus, competency in leading a government-industry partnership is essential.",leading ai teams means that you are leading practitioners from multiple disciplines including data science  software engineering  computer science  and it  data scientists are essential to the development of ai models  but it takes a multi disciplinary team to deploy and maintain the models in operation at scale  in addition to leadership fundamentals   which are not always executed well   you must lead the talent lifecycle with an understanding of what data scientists need and value in their development  the demand for data scientists dwarfs the availability of experienced data scientists  thus they have tremendous leverage in deciding where they work and whom they follow  given the unavoidable attrition  leaders must ensure that ai knowledge is instantiated in reusable code  the government will acquire most large scale ai capabilities from industry  thus  competency in leading a government industry partnership is essential ,10.203391,6.6325793,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
"Explainable Artificial Intelligence in Healthcare: Opportunities, Gaps and Challenges and a Novel Way to Look at the Problem Space","Explainable Artificial Intelligence (XAI) is rapidly becoming an emerging and fast-growing research field; however, its adoption in healthcare is still at the early stage despite the potential that XAI can bring to the application of AI in this industry. Many challenges remain to be solved, including setting standards for explanations, the degree of interaction between different stakeholders and the models, the implementation of quality and performance metrics, the agreement on standards for safety and accountability, its integration into clinical workflows, and IT infrastructure. This paper has two objectives. The first one is to present summarized outcomes of a literature survey and highlight the state-of-the-art for explainability including gaps, challenges, and opportunities for XAI in healthcare industry. For easier comprehension and onboarding to this research field we suggest a synthesized taxonomy for categorizing explainability methods. The second objective is to ask the question if applying a novel way of looking at explainability problem space, through a specific problem/domain lens, and automating that approach in an AutoML similar fashion, would help mitigate the challenges mentioned above. In the literature there is a tendency to look at the explainability of AI from model-first lens, which puts concrete problems and domains aside. For example, the explainability of a patient's survival model is treated the same as explaining a hospital cost procedure calculation. With a well-identified problem/domain that XAI should be applied to, the scope is clear and well-defined, enabling us to (semi-) automatically find suitable models, optimize their parameters and their explanations, metrics, stakeholders, safety/accountability level, and suggest means of their integration into clinical workflow .
 Keywords
 Artificial intelligence
 Machine learning
 Interpretability
 Explainability
 Explainable AI
 XAI
 AI in Healthcare",explainable artificial intelligence  xai  is rapidly becoming an emerging and fast growing research field  however  its adoption in healthcare is still at the early stage despite the potential that xai can bring to the application of ai in this industry  many challenges remain to be solved  including setting standards for explanations  the degree of interaction between different stakeholders and the models  the implementation of quality and performance metrics  the agreement on standards for safety and accountability  its integration into clinical workflows  and it infrastructure  this paper has two objectives  the first one is to present summarized outcomes of a literature survey and highlight the state of the art for explainability including gaps  challenges  and opportunities for xai in healthcare industry  for easier comprehension and onboarding to this research field we suggest a synthesized taxonomy for categorizing explainability methods  the second objective is to ask the question if applying a novel way of looking at explainability problem space  through a specific problem domain lens  and automating that approach in an automl similar fashion  would help mitigate the challenges mentioned above  in the literature there is a tendency to look at the explainability of ai from model first lens  which puts concrete problems and domains aside  for example  the explainability of a patient s survival model is treated the same as explaining a hospital cost procedure calculation  with a well identified problem domain that xai should be applied to  the scope is clear and well defined  enabling us to  semi   automatically find suitable models  optimize their parameters and their explanations  metrics  stakeholders  safety accountability level  and suggest means of their integration into clinical workflow    keywords  artificial intelligence  machine learning  interpretability  explainability  explainable ai  xai  ai in healthcare,12.016918,6.349215,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
"Intelligent Data Engineering and Automated Learning â€“ IDEAL 2021 22nd International Conference, IDEAL 2021, Manchester, UK, November 25â€“27, 2021, Proceedings","The process of generating a caption for a given image using the techniques of computer vision and natural language processing is called image caption generation. During recent times, many deep learning models have been used to increase the performance of the caption generating models. But the drawback of these models is that they lack proper focus on the pertinent part of the image while generating the caption which leads to a vague caption generation. To get the better of these drawbacks, we are proposing a model, which gives a caption by selecting pertinent objects in a particular image and providing a perceivable explanation using them.
 Keywords
 Attention model
 Encoderâ€“decoder architecture
 Transfer learning
 Interpretability enhancement model",the process of generating a caption for a given image using the techniques of computer vision and natural language processing is called image caption generation  during recent times  many deep learning models have been used to increase the performance of the caption generating models  but the drawback of these models is that they lack proper focus on the pertinent part of the image while generating the caption which leads to a vague caption generation  to get the better of these drawbacks  we are proposing a model  which gives a caption by selecting pertinent objects in a particular image and providing a perceivable explanation using them   keywords  attention model  encoder   decoder architecture  transfer learning  interpretability enhancement model,5.4597707,6.302126,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Image Caption Generation Using Attention Model,"Model-Based System and Software Engineering (MBSE) technology such as simulation has been adopted for decades by the space industry. During the lifecycle of a space mission a number of models are developed to support simulation and other analysis capabilities addressing needs specific for the different project phases. Typical concerns are: feasibility assessment, design optimization and validation, system performance and safety assessments, detail design verification and on-board software validation. In this context, symbolic and data-driven AI techniques can provide advanced capabilities to support the online operations of space missions. One of the main challenges to enable AI in the virtual flight segment is the problem of combining heterogeneous models in a common framework. The ROBDT project aims at developing a Robotic Digital Twin framework that combines data-driven models, physics-based and symbolic models and uses online data and data analytics to adapt the models at runtime. The digital twin will support the robotic asset operations by providing timing and reliable prediction and by supporting what-if analysis to assess multiple scenarios. In this paper, we present the architecture of the ROBDT framework and the preliminary achievements.
 Keywords
 Digital twins
 Space domain
 Planning and scheduling
 Diagnosis
 Monitoring",model based system and software engineering  mbse  technology such as simulation has been adopted for decades by the space industry  during the lifecycle of a space mission a number of models are developed to support simulation and other analysis capabilities addressing needs specific for the different project phases  typical concerns are  feasibility assessment  design optimization and validation  system performance and safety assessments  detail design verification and on board software validation  in this context  symbolic and data driven ai techniques can provide advanced capabilities to support the online operations of space missions  one of the main challenges to enable ai in the virtual flight segment is the problem of combining heterogeneous models in a common framework  the robdt project aims at developing a robotic digital twin framework that combines data driven models  physics based and symbolic models and uses online data and data analytics to adapt the models at runtime  the digital twin will support the robotic asset operations by providing timing and reliable prediction and by supporting what if analysis to assess multiple scenarios  in this paper  we present the architecture of the robdt framework and the preliminary achievements   keywords  digital twins  space domain  planning and scheduling  diagnosis  monitoring,8.229562,5.6898255,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
The regime and P availability of omitting P fertilizer application for rice in rice/wheat rotation in the Taihu Lake Region of southern China,"Purpose
 In the Taihu Lake Region (TLR) of China, farmersâ€™ injudicious and excessive use of phosphorus (P) fertilizer has led to a dramatic spike in P accumulation. In view of that, the water flooding practice can increase soil P release and enhance P availability in rice season, compared with the strong P fixation in wheat season; it seems possible to save P fertilizer in rice season with the aim of reducing P loads without any crop yield declines.
 Materials and methods
 To validate this possibility, a 4-year pot experiment encompassing eight rice/wheat seasons and using four paddy soils with varying Olsen-P contents (6.16 to 40.95 mg kgâˆ’1) was conducted to compare rice/wheat yield, inorganic and organic P accumulation under four different P regimes, P fertilization for both rice and wheat (PRâ€‰+â€‰W; conventional practice), P fertilization only for wheat (PW), P fertilization only for rice (PR), and no P fertilization for both seasons (Pzero).
 Results and discussion
 Compared with conventional PRâ€‰+â€‰W treatment, PR treatment significantly decreased wheat yields, especially in medium- and low-P soils, with an Olsen-P concentrate decline of 34.4â€“62.8 %. In contrast, PW treatment showed no significant difference in the rice/wheat yields over 4 years irrespective of high-, medium-, and low-P-concentrated soils, despite the soil Olsen-P concentration declining by 34.9â€“64.4 %. This highlights the feasibility of omitting P fertilizer application to flooded rice for at least 4 years in rice/wheat cropping paddy fields while maintaining crop yields and reducing environmental risk. In four paddy soils, available inorganic P was the dominant effective P source and increased with the concentration of Olsen-P. Without P fertilization over time, the concentration of soil inorganic P fractions declined and organic P remained relatively constant.
 Conclusions
 According to the P supply capacity of different soils under the regime of omitting P fertilization for rice, how to utilize the bioavailability of P in different P supply capacity soils when P fertilization is omitted for rice crops will be required in future work.",purpose  in the taihu lake region  tlr  of china  farmers    injudicious and excessive use of phosphorus  p  fertilizer has led to a dramatic spike in p accumulation  in view of that  the water flooding practice can increase soil p release and enhance p availability in rice season  compared with the strong p fixation in wheat season  it seems possible to save p fertilizer in rice season with the aim of reducing p loads without any crop yield declines   materials and methods  to validate this possibility  a   year pot experiment encompassing eight rice wheat seasons and using four paddy soils with varying olsen p contents       to       mg kg      was conducted to compare rice wheat yield  inorganic and organic p accumulation under four different p regimes  p fertilization for both rice and wheat  pr       w  conventional practice   p fertilization only for wheat  pw   p fertilization only for rice  pr   and no p fertilization for both seasons  pzero    results and discussion  compared with conventional pr       w treatment  pr treatment significantly decreased wheat yields  especially in medium  and low p soils  with an olsen p concentrate decline of                in contrast  pw treatment showed no significant difference in the rice wheat yields over   years irrespective of high   medium   and low p concentrated soils  despite the soil olsen p concentration declining by                this highlights the feasibility of omitting p fertilizer application to flooded rice for at least   years in rice wheat cropping paddy fields while maintaining crop yields and reducing environmental risk  in four paddy soils  available inorganic p was the dominant effective p source and increased with the concentration of olsen p  without p fertilization over time  the concentration of soil inorganic p fractions declined and organic p remained relatively constant   conclusions  according to the p supply capacity of different soils under the regime of omitting p fertilization for rice  how to utilize the bioavailability of p in different p supply capacity soils when p fertilization is omitted for rice crops will be required in future work ,4.3636355,1.577632,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Phosphorus content as a function of soil aggregate size and paddy cultivation in highly weathered soils,"Red soils are the major land resource in subtropical and tropical areas and are characterized by low phosphorus (P) availability. To assess the availability of P for plants and the potential stability of P in soil, two pairs of subtropical red soil samples from a paddy field and an adjacent uncultivated upland were collected from Hunan Province, China. Analysis of total P and Olsen P and sequential extraction was used to determine the inorganic and organic P fractions in different aggregate size classes. Our results showed that the soil under paddy cultivation had lower proportions of small aggregates and higher proportions of large aggregates than those from the uncultivated upland soil. The portion of >2-mm-sized aggregates increased by 31 and 20 % at Taoyuan and Guiyang, respectively. The total P and Olsen P contents were 50â€“150 and 50â€“300 % higher, respectively, in the paddy soil than those in the upland soil. Higher inorganic and organic P fractions tended to be enriched in both the smallest and largest aggregate size classes compared to the middle size class (0.02â€“0.2 mm). Furthermore, the proportion of P fractions was higher in smaller aggregate sizes (<2 mm) than in the higher aggregate sizes (>2 mm). In conclusion, soils under paddy cultivation displayed improved soil aggregate structure, altered distribution patterns of P fractions in different aggregate size classes, and to some extent had enhanced labile P pools.",red soils are the major land resource in subtropical and tropical areas and are characterized by low phosphorus  p  availability  to assess the availability of p for plants and the potential stability of p in soil  two pairs of subtropical red soil samples from a paddy field and an adjacent uncultivated upland were collected from hunan province  china  analysis of total p and olsen p and sequential extraction was used to determine the inorganic and organic p fractions in different aggregate size classes  our results showed that the soil under paddy cultivation had lower proportions of small aggregates and higher proportions of large aggregates than those from the uncultivated upland soil  the portion of    mm sized aggregates increased by    and      at taoyuan and guiyang  respectively  the total p and olsen p contents were          and            higher  respectively  in the paddy soil than those in the upland soil  higher inorganic and organic p fractions tended to be enriched in both the smallest and largest aggregate size classes compared to the middle size class             mm   furthermore  the proportion of p fractions was higher in smaller aggregate sizes     mm  than in the higher aggregate sizes     mm   in conclusion  soils under paddy cultivation displayed improved soil aggregate structure  altered distribution patterns of p fractions in different aggregate size classes  and to some extent had enhanced labile p pools ,4.726645,1.7767289,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Continuous design control for machine learning in certified medical systems,"Continuous software engineering has become commonplace in numerous fields. However, in regulating intensive sectors, where additional concerns need to be taken into account, it is often considered difficult to apply continuous development approaches, such as devops. In this paper, we present an approach for using pull requests as design controls, and apply this approach to machine learning in certified medical systems leveraging model cards, a novel technique developed to add explainability to machine learning systems, as a regulatory audit trail. The approach is demonstrated with an industrial system that we have used previously to show how medical systems can be developed in a continuous fashion.",continuous software engineering has become commonplace in numerous fields  however  in regulating intensive sectors  where additional concerns need to be taken into account  it is often considered difficult to apply continuous development approaches  such as devops  in this paper  we present an approach for using pull requests as design controls  and apply this approach to machine learning in certified medical systems leveraging model cards  a novel technique developed to add explainability to machine learning systems  as a regulatory audit trail  the approach is demonstrated with an industrial system that we have used previously to show how medical systems can be developed in a continuous fashion ,7.2452607,4.658432,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
"An IoT Beehive Network for Monitoring Urban Biodiversity: Vision, Method, and Architecture","Environmental sustainability issues have received global attention in recent decades, both at scientific and administrative levels. Despite the scrupulous studies and initiatives around such issues, they remain largely unresolved, and sometimes even unknown. A complete understanding of the quality of our living environment that surrounds us, especially urban places, where we spend most of our lives would help improve living conditions for both humans and other species present. The concept of Intelligent Beehives for urban biodiversity encapsulates and leverages biotic elements such as bio-indicators (e.g. bees), and pollination, with technologies like AI and IoT instrumentation. Together they comprise a smart service that shapes the backbone of a real-time, AI-enabled environmental dashboard. In this vision paper, we outline and discuss our solution architecture and prototypization for such servified intelligent beehives. We focus our discussion on the hivesâ€™ predictive modelling abilities that enable Machine-Learning service operations â€“ or MLOps â€“ for increasing the sustainability of urban biodiversity.
 Keywords
 IoT beehive
 Urban biodiversity
 MLOps
 Data architecture",environmental sustainability issues have received global attention in recent decades  both at scientific and administrative levels  despite the scrupulous studies and initiatives around such issues  they remain largely unresolved  and sometimes even unknown  a complete understanding of the quality of our living environment that surrounds us  especially urban places  where we spend most of our lives would help improve living conditions for both humans and other species present  the concept of intelligent beehives for urban biodiversity encapsulates and leverages biotic elements such as bio indicators  e g  bees   and pollination  with technologies like ai and iot instrumentation  together they comprise a smart service that shapes the backbone of a real time  ai enabled environmental dashboard  in this vision paper  we outline and discuss our solution architecture and prototypization for such servified intelligent beehives  we focus our discussion on the hives    predictive modelling abilities that enable machine learning service operations     or mlops     for increasing the sustainability of urban biodiversity   keywords  iot beehive  urban biodiversity  mlops  data architecture,11.474583,6.215134,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Chapter 1: Introduction and Overview,"Internet of Things (IoT) systems connect the physical world to the Internet. Basically, IoT works by attaching real-world interfaces to the Internet, such as sensors that provide data and actuators that act upon their surroundings. In effect, IoT systems provide the technology and means to instrument, quantify, and actuate the physical world.",internet of things  iot  systems connect the physical world to the internet  basically  iot works by attaching real world interfaces to the internet  such as sensors that provide data and actuators that act upon their surroundings  in effect  iot systems provide the technology and means to instrument  quantify  and actuate the physical world ,4.761232,5.128301,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Evaluation of human melanoma and normal formalin paraffin-fixed samples using Raman and LIBS fused data,"In this research, we developed a novel method of quantitative analysis to increase the detection potential for screening and classification of skin cancer (melanoma). We fused two distinct optical approaches, an atomic spectroscopic detection technique laser-induced breakdown spectroscopy (LIBS) and a vibrational molecular spectroscopic technique known as Raman spectroscopy. Melanoma is a kind of skin cancer, also known as malignant melanoma, that developed in melanocytes cells, which produced melanin. Classification of melanoma cancerous tissues is a fundamental problem in biomedicine. For early melanoma cancer diagnosis and treatment, precise and accurate categorizing is critically essential. Laser-based spectroscopic approaches can be used as an operating instrument for simultaneous tissue ablation and ablated tissue elemental and molecular analysis. For this purpose, melanoma and normal paraffin-embedded tissues are used as a sample for LIBS and Raman measurement. We studied the data provided by laser-based spectroscopic methods using different machine learning classification techniques of extreme learning machine (ELM), partial least square discriminant analysis (PLS-DA), and K nearest neighbors (kNN). For visualization of melanoma and normal data, principal component analysis (PCA) is also used. Three different ways are used to process the data, LIBS measurement, Raman measurement, and combine data measurement (merged/fused data), and then compared the results. ELM classification model achieved the highest accuracy (100%) for combined data as well as for Raman and LIBS data, respectively. According to the experimental results, we can assume that Raman spectroscopy and LIBS combine can significantly improve the identification and classification accuracy of melanoma and normal specimens.",in this research  we developed a novel method of quantitative analysis to increase the detection potential for screening and classification of skin cancer  melanoma   we fused two distinct optical approaches  an atomic spectroscopic detection technique laser induced breakdown spectroscopy  libs  and a vibrational molecular spectroscopic technique known as raman spectroscopy  melanoma is a kind of skin cancer  also known as malignant melanoma  that developed in melanocytes cells  which produced melanin  classification of melanoma cancerous tissues is a fundamental problem in biomedicine  for early melanoma cancer diagnosis and treatment  precise and accurate categorizing is critically essential  laser based spectroscopic approaches can be used as an operating instrument for simultaneous tissue ablation and ablated tissue elemental and molecular analysis  for this purpose  melanoma and normal paraffin embedded tissues are used as a sample for libs and raman measurement  we studied the data provided by laser based spectroscopic methods using different machine learning classification techniques of extreme learning machine  elm   partial least square discriminant analysis  pls da   and k nearest neighbors  knn   for visualization of melanoma and normal data  principal component analysis  pca  is also used  three different ways are used to process the data  libs measurement  raman measurement  and combine data measurement  merged fused data   and then compared the results  elm classification model achieved the highest accuracy        for combined data as well as for raman and libs data  respectively  according to the experimental results  we can assume that raman spectroscopy and libs combine can significantly improve the identification and classification accuracy of melanoma and normal specimens ,3.713721,3.0494864,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Poly Logarithmic Naive Bayes Intrusion Detection System Using Linear Stable PCA Feature Extraction,"Software defined network is smart and centralized architecture which increases the network performance and it is efficiently programmed to support different framework of big data and cloud computing virtualization. Several network categorical traffic attacks attributes are many issues which numerous of conventional IDS-Intrusion Detection System with lesser efficiency in terms of recognition, augmented rate of false positive, and bad generalization capacity. Thus, it is necessary to propose a method redresses all of the mentioned issues. In this paper, we propose the IDS methodology to recognize the maliciousness in the Software defined network (SDN) with the novel linearly stable PCA to extract the features. Afterwards, the extracted features will be classified with the novel poly logarithmic function based Naive Bayes classification methodology to diagnose between the normal and abnormal nodes. Finally, we carry out the performance evaluation in terms of accuracy, recall, FPR, TPR, and many performance by using the datasets of KDD TEST^{ - 21} and KDD TEST plus for validating the proposed IDS performance.",software defined network is smart and centralized architecture which increases the network performance and it is efficiently programmed to support different framework of big data and cloud computing virtualization  several network categorical traffic attacks attributes are many issues which numerous of conventional ids intrusion detection system with lesser efficiency in terms of recognition  augmented rate of false positive  and bad generalization capacity  thus  it is necessary to propose a method redresses all of the mentioned issues  in this paper  we propose the ids methodology to recognize the maliciousness in the software defined network  sdn  with the novel linearly stable pca to extract the features  afterwards  the extracted features will be classified with the novel poly logarithmic function based naive bayes classification methodology to diagnose between the normal and abnormal nodes  finally  we carry out the performance evaluation in terms of accuracy  recall  fpr  tpr  and many performance by using the datasets of kdd test         and kdd test plus for validating the proposed ids performance ,3.262614,5.4001513,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Writer Identification System for Indic and Non-Indic Scripts: State-of-the-Art Survey,"Writer identification is a challenging move in the field of pattern recognition and reflects advanced perceptions into the handwriting research. It is the process of determining the author or writer of the text by matching it with the training database. It is an exigent task because the writing style of an individual is distinct from other because of unique intrinsic characteristics and is different even if the same writer writes that text with the same pen next time. It is concerned with the writing styles, feelings, perception, behavior and the brain of an individual and it is one of the neoteric applications of biometric identification. Biometric identification is the branch of computer science that deals with identification of an individual from a group using unique identifiers such as fingerprints, retina, handwriting and signatures. It is a term used for the body measurements and calculations. This paper presents a comprehensive and transparent panorama on the work done for the writer identification system on different Indic and non-Indic scripts and a widespread view towards this peculiar research area. The structure of the paper comprises introduction, motivation for the work, background, sources of information, schemes, process, reported works, synthesis analysis, study of features and classifiers for writer identification, and finally the conclusion and future directions. The main focus of this paper is to present in a systematic way, the reported works on writer identification systems on Indic scripts such as Bengali, Gujarati, Gurumukhi, Kannada, Malayalam, Oriya, Tamil and Telugu and Non-Indic scripts such as Arabic, Chinese, French, Persian, Roman and finally exposes the synthesis analysis based on the findings. This study gives the cognizance and beneficial assistance to the novice researchers in this field by providing in a nut shell the studies of various feature extraction methods and classification techniques required for writer identification on both Indic and non-Indic scripts. It is observed that work done on the writer identification systems with good accuracy rates in Indic scripts is limited as compared to non-Indic scripts and truly presents a future direction.",writer identification is a challenging move in the field of pattern recognition and reflects advanced perceptions into the handwriting research  it is the process of determining the author or writer of the text by matching it with the training database  it is an exigent task because the writing style of an individual is distinct from other because of unique intrinsic characteristics and is different even if the same writer writes that text with the same pen next time  it is concerned with the writing styles  feelings  perception  behavior and the brain of an individual and it is one of the neoteric applications of biometric identification  biometric identification is the branch of computer science that deals with identification of an individual from a group using unique identifiers such as fingerprints  retina  handwriting and signatures  it is a term used for the body measurements and calculations  this paper presents a comprehensive and transparent panorama on the work done for the writer identification system on different indic and non indic scripts and a widespread view towards this peculiar research area  the structure of the paper comprises introduction  motivation for the work  background  sources of information  schemes  process  reported works  synthesis analysis  study of features and classifiers for writer identification  and finally the conclusion and future directions  the main focus of this paper is to present in a systematic way  the reported works on writer identification systems on indic scripts such as bengali  gujarati  gurumukhi  kannada  malayalam  oriya  tamil and telugu and non indic scripts such as arabic  chinese  french  persian  roman and finally exposes the synthesis analysis based on the findings  this study gives the cognizance and beneficial assistance to the novice researchers in this field by providing in a nut shell the studies of various feature extraction methods and classification techniques required for writer identification on both indic and non indic scripts  it is observed that work done on the writer identification systems with good accuracy rates in indic scripts is limited as compared to non indic scripts and truly presents a future direction ,5.8444147,4.645224,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Intelligent Decision Support System (iDSS) for Manufacturing Data Corpus,"People in industries like manufacturing require, use, and produce knowledge on a daily basis. Tremendous quantity of data with difference in formats, structures and linkages need to be cautiously explored. However, the most valuable knowledge is not easy to identify or share because it is deep within the minds of experts. In manufacturing, it is very common to see dashboards on business performance, however, very few literatures available on technical knowledge management. Technical knowledge of an expert can be effectively managed and transferred by having an interface or dashboard that provides adequate information for the learners. Hence, this project aims to establish intelligent Decision Support System (iDSS) that can strategically manage, transfer, and share valuable knowledge of experts within the manufacturing organization based on machine learning and deep learning models. This study used English text data that is properly phrased to build a deep learning model in Natural Language Processing (NLP) for maintenance factory reports. As a result, interactive visualizations are presented to aid decision-makers in making knowledgeable decisions that includes the display of failure diagnostic and Named Entity Recognition (NER). These findings may provide troubleshooting insights as an assistance to new employees and deliver a precise management of decisions in looking back in history and preparing ahead. The investigation of this study will be further explored for complex numeric parameters from sensors data, integration of predictive maintenance in the dashboard, and utilizing a more sophisticated training model for better predictions.
 Keywords
 Manufacturing
 Interface
 Knowledge Management",people in industries like manufacturing require  use  and produce knowledge on a daily basis  tremendous quantity of data with difference in formats  structures and linkages need to be cautiously explored  however  the most valuable knowledge is not easy to identify or share because it is deep within the minds of experts  in manufacturing  it is very common to see dashboards on business performance  however  very few literatures available on technical knowledge management  technical knowledge of an expert can be effectively managed and transferred by having an interface or dashboard that provides adequate information for the learners  hence  this project aims to establish intelligent decision support system  idss  that can strategically manage  transfer  and share valuable knowledge of experts within the manufacturing organization based on machine learning and deep learning models  this study used english text data that is properly phrased to build a deep learning model in natural language processing  nlp  for maintenance factory reports  as a result  interactive visualizations are presented to aid decision makers in making knowledgeable decisions that includes the display of failure diagnostic and named entity recognition  ner   these findings may provide troubleshooting insights as an assistance to new employees and deliver a precise management of decisions in looking back in history and preparing ahead  the investigation of this study will be further explored for complex numeric parameters from sensors data  integration of predictive maintenance in the dashboard  and utilizing a more sophisticated training model for better predictions   keywords  manufacturing  interface  knowledge management,5.6129456,5.2214513,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Conditional Anomaly Detection for Quality and Productivity Improvement of Electronics Manufacturing Systems,"Today the integration of Artificial Intelligence (AI) solutions is part of the strategy in the industrial environment. We focus on anomaly detection in the framework of manufacturing electronic cards manufacturing under mass production conditions (24/7). Early anomaly detection is critical to avoid defects. Researches and applications of anomaly detection techniques in the industry have been published but when they face production constraints success is not guaranteed. Todayâ€™s manufacturing systems are complex and involve different behaviors. We propose and evaluate a new realistic methodology for detecting conditional anomalies that could be successfully implemented in production. The proposed solution is based on Variational Autoencoders (VAEs) which provide interesting scores under the near real-time constraints of the production environment. The results have been thoroughly evaluated and validated with the support of expert process engineers.
 Keywords
 Smart factory
 Electronic circuit manufacturing
 Artificial Intelligence
 Deep conditional anomaly detection",today the integration of artificial intelligence  ai  solutions is part of the strategy in the industrial environment  we focus on anomaly detection in the framework of manufacturing electronic cards manufacturing under mass production conditions         early anomaly detection is critical to avoid defects  researches and applications of anomaly detection techniques in the industry have been published but when they face production constraints success is not guaranteed  today   s manufacturing systems are complex and involve different behaviors  we propose and evaluate a new realistic methodology for detecting conditional anomalies that could be successfully implemented in production  the proposed solution is based on variational autoencoders  vaes  which provide interesting scores under the near real time constraints of the production environment  the results have been thoroughly evaluated and validated with the support of expert process engineers   keywords  smart factory  electronic circuit manufacturing  artificial intelligence  deep conditional anomaly detection,8.665174,4.2669277,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Reusability Quality Metrics for Agent-Based Robot Systems,"Programming for robots is generally problem specific and components are not easily reused. Recently there has been push for robotics programming to integrate software engineering principles into the design and development to improve the reusability, however currently no metrics have been proposed to measure this quality in robotics. This paper proposes the use of reusability metrics from Component-Based Software Engineering (CBSE) and Service-Oriented Architecture (SOA) to measure reusability metrics, and finds that they are applicable to modular, agent-based robotics systems through a case study of an example system.
 Keywords
 Reusability Quality
 Component-based Software Engineering (CBSE)
 Reusability Metric
 Service-Oriented Device Architecture (SODA)
 Agent-based Control System
 These keywords were added by machine and not by the authors. This process is experimental and the keywords may be updated as the learning algorithm improves.",programming for robots is generally problem specific and components are not easily reused  recently there has been push for robotics programming to integrate software engineering principles into the design and development to improve the reusability  however currently no metrics have been proposed to measure this quality in robotics  this paper proposes the use of reusability metrics from component based software engineering  cbse  and service oriented architecture  soa  to measure reusability metrics  and finds that they are applicable to modular  agent based robotics systems through a case study of an example system   keywords  reusability quality  component based software engineering  cbse   reusability metric  service oriented device architecture  soda   agent based control system  these keywords were added by machine and not by the authors  this process is experimental and the keywords may be updated as the learning algorithm improves ,9.355584,7.035347,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Plans and Functional Safety Management,"What This Chapter Is About
 Safety plans
 Functional safety management
 Software quality assurance plans",what this chapter is about  safety plans  functional safety management  software quality assurance plans,9.700411,6.943209,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Expanding and Optimizing Human Resources for Eye Care,"Innovative approaches in the delivery of eye care require a resilient eye health workforce. The challenges facing the global healthcare workforce overall are found within the field of eye care. These include most notably the challenges of accurate planning and having processes to attract, train, retain, and provide career opportunities for eye health professionals. Success in the provision of quality, sustainable, community-oriented services requires a well-prepared eye care team. The need for increased services and the insufficient numbers of eye care professionals to provide them are well documented and can be daunting. These needs and the HR gap are cited as strategies including setting targets, defining roles, task shifting, team building, and ensuring contributions of mid-level personnel and managers. The diversity of the workforce including the importance of including women is noted. Importantly, these efforts are being undertaken on a global, regional, and national basis with an increasing level of inter-coordination. Addressed are the benefits of enhancing the effectiveness of current human resources in eye health (HReH), the growing array of training strategies and resources, and priorities for moving forward.
 Keywords
 Training
 Human resource
 Develop",innovative approaches in the delivery of eye care require a resilient eye health workforce  the challenges facing the global healthcare workforce overall are found within the field of eye care  these include most notably the challenges of accurate planning and having processes to attract  train  retain  and provide career opportunities for eye health professionals  success in the provision of quality  sustainable  community oriented services requires a well prepared eye care team  the need for increased services and the insufficient numbers of eye care professionals to provide them are well documented and can be daunting  these needs and the hr gap are cited as strategies including setting targets  defining roles  task shifting  team building  and ensuring contributions of mid level personnel and managers  the diversity of the workforce including the importance of including women is noted  importantly  these efforts are being undertaken on a global  regional  and national basis with an increasing level of inter coordination  addressed are the benefits of enhancing the effectiveness of current human resources in eye health  hreh   the growing array of training strategies and resources  and priorities for moving forward   keywords  training  human resource  develop,10.35914,7.6566668,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Establishment of an Appropriate Data Analytic Platform for Developing a Wisdom Manufacturing System Using Decision Techniques,"In todayâ€™s global business context, data has played a critical role in ensuring accurate and appropriate decision making in manufacturing organisations. Despite the huge pool of information (i.e. data) generated by consumers, repair or maintenance shops, manufacturing job shop, scientific society on various products, which could be deployed by manufacturers in eliciting vital information towards achieving sustainable product design and development, only few manufacturers are making use of this data to generate wisdom required for sustainable manufacturing. This act is caused by lack of appropriate systems capable of integrating the available data and make wise inferences that will result in a competitive advantage of a specific organisation over its competitors. In light of this, the aim of this study is to establish a suitable data analytic platform that could be used to sort, classify and integrate data required to generate wisdom vital for sustainable manufacturing. In order to achieve this, Analytical Hierarchy Process (AHP) was deployed to appraise various alternative data analytical platforms such as Python, Apache Spark, Qlik View, Power BI, Tableau, KNIME, Excel, Talend, Rapid Miner and Statistical Analysis System (SAS) using various criteria such as Data Format, Availability, Interface, Programming Intensity, Data Science Knowledge Intensity and Capabilities. The result of this decision analysis and selection exercise, revealed that KNIME data analytic platform, with the most important decision criterion; data science knowledge intensity, and a cumulative assessment score of 80.80 is the appropriate data analytic platform that manufacturers should use to generate a knowledge advisor vital for sustainable manufacturing and product development.
 Keywords
 Wisdom Manufacturing
 Data Analytics
 Analytical Hierarchy Process
 Decision Analysis",in today   s global business context  data has played a critical role in ensuring accurate and appropriate decision making in manufacturing organisations  despite the huge pool of information  i e  data  generated by consumers  repair or maintenance shops  manufacturing job shop  scientific society on various products  which could be deployed by manufacturers in eliciting vital information towards achieving sustainable product design and development  only few manufacturers are making use of this data to generate wisdom required for sustainable manufacturing  this act is caused by lack of appropriate systems capable of integrating the available data and make wise inferences that will result in a competitive advantage of a specific organisation over its competitors  in light of this  the aim of this study is to establish a suitable data analytic platform that could be used to sort  classify and integrate data required to generate wisdom vital for sustainable manufacturing  in order to achieve this  analytical hierarchy process  ahp  was deployed to appraise various alternative data analytical platforms such as python  apache spark  qlik view  power bi  tableau  knime  excel  talend  rapid miner and statistical analysis system  sas  using various criteria such as data format  availability  interface  programming intensity  data science knowledge intensity and capabilities  the result of this decision analysis and selection exercise  revealed that knime data analytic platform  with the most important decision criterion  data science knowledge intensity  and a cumulative assessment score of       is the appropriate data analytic platform that manufacturers should use to generate a knowledge advisor vital for sustainable manufacturing and product development   keywords  wisdom manufacturing  data analytics  analytical hierarchy process  decision analysis,5.7760262,5.1089187,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Schedule-Based Cooperative Multi-agent Reinforcement Learning for Multi-channel Communication in Wireless Sensor Networks,"Wireless sensor networks (WSNs) have become an important component in the Internet of things (IoT) field. In WSNs, multi-channel protocols have been developed to overcome some limitations related to the throughput and delivery rate which have become necessary for many IoT applications that require sufficient bandwidth to transmit a large amount of data. However, the requirement of frequent negotiation for channel assignment in distributed multi-channel protocols incurs an extra-large communication overhead which results in a reduction of the network lifetime. To deal with this requirement in an energy-efficient way is a challenging task. Hence, the Reinforcement Learning (RL) approach for channel assignment is used to overcome this problem. Nevertheless, the use of the RL approach requires a number of iterations to obtain the best solution which in turn creates a communication overhead and time-wasting. In this paper, a Self-schedule based Cooperative multi-agent Reinforcement Learning for Channel Assignment (SCRL CA) approach is proposed to improve the network lifetime and performance. The proposal addresses both regular traffic scheduling and assignment of the available orthogonal channels in an energy-efficient way. We solve the cooperation between the RL agents problem by using the self-schedule method to accelerate the RL iterations, reduce the communication overhead and balance the energy consumption in the route selection process. Therefore, two algorithms are proposed, the first one is for the Static channel assignment (SSCRL CA) while the second one is for the Dynamic channel assignment (DSCRL CA). The results of extensive simulation experiments show the effectiveness of our approach in improving the network lifetime and performance through the two algorithms.",wireless sensor networks  wsns  have become an important component in the internet of things  iot  field  in wsns  multi channel protocols have been developed to overcome some limitations related to the throughput and delivery rate which have become necessary for many iot applications that require sufficient bandwidth to transmit a large amount of data  however  the requirement of frequent negotiation for channel assignment in distributed multi channel protocols incurs an extra large communication overhead which results in a reduction of the network lifetime  to deal with this requirement in an energy efficient way is a challenging task  hence  the reinforcement learning  rl  approach for channel assignment is used to overcome this problem  nevertheless  the use of the rl approach requires a number of iterations to obtain the best solution which in turn creates a communication overhead and time wasting  in this paper  a self schedule based cooperative multi agent reinforcement learning for channel assignment  scrl ca  approach is proposed to improve the network lifetime and performance  the proposal addresses both regular traffic scheduling and assignment of the available orthogonal channels in an energy efficient way  we solve the cooperation between the rl agents problem by using the self schedule method to accelerate the rl iterations  reduce the communication overhead and balance the energy consumption in the route selection process  therefore  two algorithms are proposed  the first one is for the static channel assignment  sscrl ca  while the second one is for the dynamic channel assignment  dscrl ca   the results of extensive simulation experiments show the effectiveness of our approach in improving the network lifetime and performance through the two algorithms ,4.1400795,7.935458,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Automated Multiple Face Recognition Using Deep Learning for Security and Surveillance Applications,"Face recognition is some of the difficult processes due to a large number of wild datasets. Deep learning is the research concentrate on the latest years. Beacause of its best implementation, it is widely used in the area of pattern recognition initiated deep learning structure is collected of a set of complicated designed CNN. Deep learning gave valid resolution in the matter of recognition execution. In our present paper, our purpose is to consider deep learning established face recognition below atmosphere like disparate aspects of head positions, difficult clarification, faulty exterior characteristic localization, and precision using deep learning. We are using OpenCV, Haar cascade for detecting faces, eyes, and smile. LBPH face recognizer is used for training data recognition of faces. Convolution neural network (CNN) is used for facial extractions without any flaws and with more accuracy.
 Keywords
 CNN
 Face recognition
 Deep learning
 LBPH
 OpenCV
 Haar cascade",face recognition is some of the difficult processes due to a large number of wild datasets  deep learning is the research concentrate on the latest years  beacause of its best implementation  it is widely used in the area of pattern recognition initiated deep learning structure is collected of a set of complicated designed cnn  deep learning gave valid resolution in the matter of recognition execution  in our present paper  our purpose is to consider deep learning established face recognition below atmosphere like disparate aspects of head positions  difficult clarification  faulty exterior characteristic localization  and precision using deep learning  we are using opencv  haar cascade for detecting faces  eyes  and smile  lbph face recognizer is used for training data recognition of faces  convolution neural network  cnn  is used for facial extractions without any flaws and with more accuracy   keywords  cnn  face recognition  deep learning  lbph  opencv  haar cascade,3.8885171,5.3253875,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Long-term agronomic practices alter the composition of asymbiotic diazotrophic bacterial community and their nitrogen fixation genes in an acidic red soil,"The panopticon is a design that originated with the English philosopher and social theorist Jeremy Bentham in the eighteenth century. The device would allow prisoners to be observed by a single security guard, without the prisoners knowing they were being watched. Today, the panopticon is used as a metaphor to highlight the threat to privacy and personal autonomy that comes with the collection, processing, and analysis of big data and shows the need to protect personal information in the face of increasing technological advancement. For example, multinational businesses face increasing scrutiny over how to store, process, and transfer private user data across geographic boundaries.",the panopticon is a design that originated with the english philosopher and social theorist jeremy bentham in the eighteenth century  the device would allow prisoners to be observed by a single security guard  without the prisoners knowing they were being watched  today  the panopticon is used as a metaphor to highlight the threat to privacy and personal autonomy that comes with the collection  processing  and analysis of big data and shows the need to protect personal information in the face of increasing technological advancement  for example  multinational businesses face increasing scrutiny over how to store  process  and transfer private user data across geographic boundaries ,10.730982,8.148579,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Influence of algal blooms on the efficacy of La/Al-based phoslock in the control of phosphorus release from sediment in shallow lakes: a microcosm study,"Environmental sustainability is a key element of modern society. It has received global attention in recent years, both at scientific and administrative levels. Despite the scrupulous studies addressing this theme, many issues remain largely unresolved. A (big) data and AI approach is a promising alternative for tackling societal or environmental problems that are hard to grasp. We apply this approach to assess urban biodiversity. More specifically, the concept of intelligent beehives is introduced. This concept encapsulates and leverages biotic elements, such as harnessing bees as biomonitoring agents, with technologies like IoT instrumentation and AI. Together they comprise the data-driven services that shape the backbone of a real-time environmental dashboard. In this vision paper, our solution architecture and prototypization for such service-enabled beehives are sketched and discussed. We focus on the role of the IoT beehive network and open data for predictive modelling of biodiversity and argue how MLOps practices support a transformative process for creating awareness and maintaining or even increasing urban biodiversity.
 Keywords
 Urban biodiversity
 IoT Beehive
 Open data
 MLOps and Stratified Architecture",environmental sustainability is a key element of modern society  it has received global attention in recent years  both at scientific and administrative levels  despite the scrupulous studies addressing this theme  many issues remain largely unresolved  a  big  data and ai approach is a promising alternative for tackling societal or environmental problems that are hard to grasp  we apply this approach to assess urban biodiversity  more specifically  the concept of intelligent beehives is introduced  this concept encapsulates and leverages biotic elements  such as harnessing bees as biomonitoring agents  with technologies like iot instrumentation and ai  together they comprise the data driven services that shape the backbone of a real time environmental dashboard  in this vision paper  our solution architecture and prototypization for such service enabled beehives are sketched and discussed  we focus on the role of the iot beehive network and open data for predictive modelling of biodiversity and argue how mlops practices support a transformative process for creating awareness and maintaining or even increasing urban biodiversity   keywords  urban biodiversity  iot beehive  open data  mlops and stratified architecture,11.520746,6.040683,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Phosphatase phoD gene community changes organic phosphorus in sediment from Caohai plateau wetland,"With the gradual expansion of microservice architecture-based applications, the complexity of system operation and maintenance is also growing significantly. With the advent of AIOps, it is now possible to automatically detect the state of the system, allocate resources, warn, and detect anomalies using machine learning models. Given the dynamic nature of online workloads, the running state of a microservice system in production is constantly in flux. Therefore, it is necessary to continuously train, encapsulate, and deploy models based on the current system status for the AIOps model to dynamically adapt to the system environment. This paper proposes a model update and management pipeline framework for AIOps models in microservices systems in order to accomplish the aforementioned objectives and simplify the process. In addition, a prototype system based on Kubernetes and Gitlab is designed to provide preliminary framework implementation and validation. The system consists of three components: model training, model packaging, and model deploying. Parallelization and parameter search are incorporated into the model training procedure in order to facilitate rapid training of multiple models and automated model hyperparameter tuning. We automate the packaging and deployment process using technology for continuous integration. Experiments are conducted to validate the prototype system, and the results demonstrate the feasibility of the proposed framework. This work serves as a useful resource for constructing an integrated and streamlined AIOps model management system.",with the gradual expansion of microservice architecture based applications  the complexity of system operation and maintenance is also growing significantly  with the advent of aiops  it is now possible to automatically detect the state of the system  allocate resources  warn  and detect anomalies using machine learning models  given the dynamic nature of online workloads  the running state of a microservice system in production is constantly in flux  therefore  it is necessary to continuously train  encapsulate  and deploy models based on the current system status for the aiops model to dynamically adapt to the system environment  this paper proposes a model update and management pipeline framework for aiops models in microservices systems in order to accomplish the aforementioned objectives and simplify the process  in addition  a prototype system based on kubernetes and gitlab is designed to provide preliminary framework implementation and validation  the system consists of three components  model training  model packaging  and model deploying  parallelization and parameter search are incorporated into the model training procedure in order to facilitate rapid training of multiple models and automated model hyperparameter tuning  we automate the packaging and deployment process using technology for continuous integration  experiments are conducted to validate the prototype system  and the results demonstrate the feasibility of the proposed framework  this work serves as a useful resource for constructing an integrated and streamlined aiops model management system ,8.211744,3.998767,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Integrated Soil-Crop System Management Increases Phosphorus Concentrations and Bioavailability in a Primosol,"This chapter walks through several use cases for implementing a Data Fabric and Data Mesh that also represent business-relevant entry points. Data governance and privacy initiatives are ongoing in almost every organization, enabling access to enterprise data and AI artefacts across platforms to the people who have a business need. Other use cases are driven by hybrid cloud data integration; the need for a comprehensive view on customers, vendors, and other parties for better business outcome; and development and integration of trustworthy AI into business processes.",this chapter walks through several use cases for implementing a data fabric and data mesh that also represent business relevant entry points  data governance and privacy initiatives are ongoing in almost every organization  enabling access to enterprise data and ai artefacts across platforms to the people who have a business need  other use cases are driven by hybrid cloud data integration  the need for a comprehensive view on customers  vendors  and other parties for better business outcome  and development and integration of trustworthy ai into business processes ,9.826707,5.0927687,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Data Ethics,"Going data intensive requires much effort not only in the design, but also in system/infrastructure configuration and deployment; most of these activities still happen via heavy manual fine-tuning and often costly trial-and-error experimentation.
 This book chapter introduces the field of data engineering; sets out to list the key desiderata of modern-day, data-intensive applications and AI/ML analytics software; and argues the necessity of novel methods and techniques, including MLOps. All topics will be further elaborated in the remaining chapters of this first module on data engineering.
 Keywords
 Big data engineering
 Data-intensive applications
 Data lakes
 Data pipelines
 Data engineering challenges",going data intensive requires much effort not only in the design  but also in system infrastructure configuration and deployment  most of these activities still happen via heavy manual fine tuning and often costly trial and error experimentation   this book chapter introduces the field of data engineering  sets out to list the key desiderata of modern day  data intensive applications and ai ml analytics software  and argues the necessity of novel methods and techniques  including mlops  all topics will be further elaborated in the remaining chapters of this first module on data engineering   keywords  big data engineering  data intensive applications  data lakes  data pipelines  data engineering challenges,7.8905625,5.5036244,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
IoT Beehives and Open Data to Gauge Urban Biodiversity,"In this chapter, we will cover how you can use MLFlow and Google Cloud to operationalize your models even without MLFlow providing explicit deployment support for Google Cloud.",in this chapter  we will cover how you can use mlflow and google cloud to operationalize your models even without mlflow providing explicit deployment support for google cloud ,8.417333,7.3661847,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
An automatic model management system and its implementation for AIOps on microservice platforms,"The asymbiotic diazotrophic bacteria are important for nitrogen (N) input to soil. Here, we investigated asymbiotic diazotrophic bacteria in an acidic red soil from functional, phylogenetic, and ecological perspectives. We firstly confirmed that phosphorus (P) availability determines the overall asymbiotic N fixation potential in the red soil. Then, we analyzed the soil bacterial community and N fixing (nifH) gene composition. Long-term different fertilizations significantly affected the composition of soil bacterial community. In addition, long-term organic cultivations increased most of the asymbiotic diazotrophic bacteria and the corresponding nifH gene abundances. Few asymbiotic diazotrophic bacteria, belonging to Chloroflexaceae, Methylocystaceae, Enterobacteriaceae, and Pseudomonadaceae, and their corresponding nifH genes were more abundant in N and P co-limited than in not co-limited soils, suggesting that some bacterial taxa from these families might be activated under nutrient limited conditions. Our findings provided new information for the distribution of asymbiotic diazotrophic bacteria in red soil and gave insights into the ecology of diazotrophic bacteria.",the asymbiotic diazotrophic bacteria are important for nitrogen  n  input to soil  here  we investigated asymbiotic diazotrophic bacteria in an acidic red soil from functional  phylogenetic  and ecological perspectives  we firstly confirmed that phosphorus  p  availability determines the overall asymbiotic n fixation potential in the red soil  then  we analyzed the soil bacterial community and n fixing  nifh  gene composition  long term different fertilizations significantly affected the composition of soil bacterial community  in addition  long term organic cultivations increased most of the asymbiotic diazotrophic bacteria and the corresponding nifh gene abundances  few asymbiotic diazotrophic bacteria  belonging to chloroflexaceae  methylocystaceae  enterobacteriaceae  and pseudomonadaceae  and their corresponding nifh genes were more abundant in n and p co limited than in not co limited soils  suggesting that some bacterial taxa from these families might be activated under nutrient limited conditions  our findings provided new information for the distribution of asymbiotic diazotrophic bacteria in red soil and gave insights into the ecology of diazotrophic bacteria ,4.8841286,1.8314984,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Data Fabric and Data Mesh Use Case Scenarios,"Purpose
 One of the most significant problems in eutrophic lakes is the presence of algal blooms, which may affect phosphorus (P) inactivation agents (PIAs) in the control of P release from sediment. Therefore, in this study, lanthanum/aluminium co-modified thermally treated calcium-rich attapulgite (LA@TCAP) is used to analyse the influence and mechanisms of algal blooms on P inactivation effect to provide technical support for the application of PIAs.
 Materials and methods
 In August 2020, lake water, sediments, and algae were collected from Zhushan Bay in Lake Taihu and LA@TCAP was prepared in the laboratory. These samples were used to establish three groups of microscopic simulation experiments. Through sequential extraction and 31P nuclear magnetic resonance, the mobile forms of P (Mobile-P) of sediment in each experimental group were measured and analysed, and the influence of algal blooms on the inactivation effect of the P immobilisation of LA@TCAP was determined. Physical and chemical properties of overlying water (DO, pH, algae organic matter (AOM), etc) and microbial community structure of capping layers were used to understand the influence mechanisms of algal blooms on the inactivation effect of PIAs.
 Results and discussion
 The concentration of dissolved oxygen (DO) concentration in the overlying water was reduced due to the decomposition of algal blooms, which increased the relative abundance of P-solubilising bacteria, and transformed more inert forms of P (Inert-P) into Mobile-P in the capping layer. Simultaneously, the algal blooms released OP, which passed through the capping layer and increased the OP content in the sediment. Under this dual effect, the Mobile-P content in the sediment increased, making LA@TCAP unable to inactivate the increased mobile-P, which was bound to affect the inactivation effect of LA@TCAP. Besides, the AOM released from the algal blooms combined with the metal ions in LA@TCAP, resulting in the reduction of adsorption sites of LA@TCAP for P.
 Conclusions
 The algal blooms significantly decreased the DO concentration in the overlying water, thereby affecting the microbial community and transforming more Inert-P into Mobile-P. In addition, the adsorption performance of LA@TCAP for P also reduced owing to AOM competed with P for the metal ions in the LA@TCAP. Thus, algal blooms reduced the ability of LA@TCAP to control the P release from sediment.",purpose  one of the most significant problems in eutrophic lakes is the presence of algal blooms  which may affect phosphorus  p  inactivation agents  pias  in the control of p release from sediment  therefore  in this study  lanthanum aluminium co modified thermally treated calcium rich attapulgite  la tcap  is used to analyse the influence and mechanisms of algal blooms on p inactivation effect to provide technical support for the application of pias   materials and methods  in august       lake water  sediments  and algae were collected from zhushan bay in lake taihu and la tcap was prepared in the laboratory  these samples were used to establish three groups of microscopic simulation experiments  through sequential extraction and   p nuclear magnetic resonance  the mobile forms of p  mobile p  of sediment in each experimental group were measured and analysed  and the influence of algal blooms on the inactivation effect of the p immobilisation of la tcap was determined  physical and chemical properties of overlying water  do  ph  algae organic matter  aom   etc  and microbial community structure of capping layers were used to understand the influence mechanisms of algal blooms on the inactivation effect of pias   results and discussion  the concentration of dissolved oxygen  do  concentration in the overlying water was reduced due to the decomposition of algal blooms  which increased the relative abundance of p solubilising bacteria  and transformed more inert forms of p  inert p  into mobile p in the capping layer  simultaneously  the algal blooms released op  which passed through the capping layer and increased the op content in the sediment  under this dual effect  the mobile p content in the sediment increased  making la tcap unable to inactivate the increased mobile p  which was bound to affect the inactivation effect of la tcap  besides  the aom released from the algal blooms combined with the metal ions in la tcap  resulting in the reduction of adsorption sites of la tcap for p   conclusions  the algal blooms significantly decreased the do concentration in the overlying water  thereby affecting the microbial community and transforming more inert p into mobile p  in addition  the adsorption performance of la tcap for p also reduced owing to aom competed with p for the metal ions in the la tcap  thus  algal blooms reduced the ability of la tcap to control the p release from sediment ,3.6866133,2.2294192,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Big Data Engineering,"Purpose
 The objective of this study was to investigate the characteristics of sediment organic phosphorus (Po) driven by the microbial community during the ecological restoration of a plateau wetland.
 Materials and methods
 Twenty surface sediment samples were collected from the Caohai wetland, China. A series of analysis methods were used, including Ivanoff extraction, enzymatic hydrolysis, solution 31P nuclear magnetic resonance (31P-NMR), and high-throughput sequencing technology.
 Results
 The concentrations of the total Po were in the range 564.66 to 751.30 mg kgâˆ’1, among which Ful-Po was the dominant component with a proportion of 38.67â€“45.37%. In the enzymatically hydrolyzable Po, phosphomonoester was the main fraction accounting for 19.58â€“67.87%, while it made up 52.91â€“68.98% of the Po determined by 31P-NMR. The biogeochemical feature of Po indicated the high releasing risk of bioavailable Po from the sediment to the overlying water in the Caohai plateau wetland. Anthropogenic input was the dominant source of Po in the sediments, followed by the internal biological processes. Two thousand sixty-six OTUs were clustered in the phoD gene-harboring communities and were dominated by the Proteobacteria phylum and Rubrobacter genus. The redundancy analysis (RDA), correlation network analysis, and structural equation modeling (SEM) suggested the direct and/or indirect (coupling the C and N cycles) contribution of phoD gene communities to P fractions.
 Conclusion
 This study established the influence of microbes on P fractions and provided a valuable understanding of the biogeochemical cycling of P in sediment from an ecologically restored wetland.",purpose  the objective of this study was to investigate the characteristics of sediment organic phosphorus  po  driven by the microbial community during the ecological restoration of a plateau wetland   materials and methods  twenty surface sediment samples were collected from the caohai wetland  china  a series of analysis methods were used  including ivanoff extraction  enzymatic hydrolysis  solution   p nuclear magnetic resonance    p nmr   and high throughput sequencing technology   results  the concentrations of the total po were in the range        to        mg kg      among which ful po was the dominant component with a proportion of                 in the enzymatically hydrolyzable po  phosphomonoester was the main fraction accounting for                 while it made up                of the po determined by   p nmr  the biogeochemical feature of po indicated the high releasing risk of bioavailable po from the sediment to the overlying water in the caohai plateau wetland  anthropogenic input was the dominant source of po in the sediments  followed by the internal biological processes  two thousand sixty six otus were clustered in the phod gene harboring communities and were dominated by the proteobacteria phylum and rubrobacter genus  the redundancy analysis  rda   correlation network analysis  and structural equation modeling  sem  suggested the direct and or indirect  coupling the c and n cycles  contribution of phod gene communities to p fractions   conclusion  this study established the influence of microbes on p fractions and provided a valuable understanding of the biogeochemical cycling of p in sediment from an ecologically restored wetland ,3.6098065,2.3495786,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Deploying in Google,"In recent years, integrated soil-crop system management (ISSM), i.e., using crop modeling and advanced nutrient management to redesign the cropping system, has been successfully used to improve crop yield and nutrient-use efficiency in China. However, the effects of ISSM on the properties of soils are not yet clear. Based on a seven-year (2009â€“2016) field plot trial with continuous corn monoculture, this study compared the effects of ISSM with improved practice (IP), high-yield practice (HY), and current farming practice (FP) on phosphorus (P) forms in an Alluvic Primosol of Northeast China by using chemical and spectroscopic (31P NMR) analyses. The concentrations of total P and Olsen P were in the order FP < IP < HY < ISSM; the order for inorganic and organic P fractions obtained by chemical analysis was also the same except for Ca10-P that showed an opposite order. 31P NMR spectroscopy showed that inorganic orthophosphate, pyrophosphate, orthophosphate monoesters, and orthophosphate diesters were all higher in the surface soil in ISSM treatment than in HY, IP, and FP treatments. Our results suggest that ISSM has a positive effect on the availability of P in soil.",in recent years  integrated soil crop system management  issm   i e   using crop modeling and advanced nutrient management to redesign the cropping system  has been successfully used to improve crop yield and nutrient use efficiency in china  however  the effects of issm on the properties of soils are not yet clear  based on a seven year               field plot trial with continuous corn monoculture  this study compared the effects of issm with improved practice  ip   high yield practice  hy   and current farming practice  fp  on phosphorus  p  forms in an alluvic primosol of northeast china by using chemical and spectroscopic    p nmr  analyses  the concentrations of total p and olsen p were in the order fp   ip   hy   issm  the order for inorganic and organic p fractions obtained by chemical analysis was also the same except for ca   p that showed an opposite order    p nmr spectroscopy showed that inorganic orthophosphate  pyrophosphate  orthophosphate monoesters  and orthophosphate diesters were all higher in the surface soil in issm treatment than in hy  ip  and fp treatments  our results suggest that issm has a positive effect on the availability of p in soil ,4.292084,1.9141967,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
In Summary and Onward,"Reaching the end of the book, it must have become obvious that both a Data Fabric architecture and Data Mesh solution are inevitably associated with applying AI, intelligent knowledge, and automation. Indeed, infusing AI is required to enable intelligent cataloging, to generate active metadata, to build semantic knowledge graphs, and to gain necessary and holistic insight to improve, optimize, and automate tasks and to enable self-service generation of data products that are ready for consumption. These capabilities are enabled via a knowledge catalog that stores active metadata and data product specifications as well.",reaching the end of the book  it must have become obvious that both a data fabric architecture and data mesh solution are inevitably associated with applying ai  intelligent knowledge  and automation  indeed  infusing ai is required to enable intelligent cataloging  to generate active metadata  to build semantic knowledge graphs  and to gain necessary and holistic insight to improve  optimize  and automate tasks and to enable self service generation of data products that are ready for consumption  these capabilities are enabled via a knowledge catalog that stores active metadata and data product specifications as well ,10.185383,6.5499763,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Delivery and Automation Pipeline in Machine Learning,"Growing volumes of available data, cheaper and powerful computational processing, and more affordable data storage continue to accelerate and fuel the integration of business applications and machine learning (ML) models. ML models power more and more applications in production. The following are some well-known model-driven applications.",growing volumes of available data  cheaper and powerful computational processing  and more affordable data storage continue to accelerate and fuel the integration of business applications and machine learning  ml  models  ml models power more and more applications in production  the following are some well known model driven applications ,8.962529,5.8893127,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Automated Machine Learning Deployment Using Open-Source CI/CD Tool,"This paper proposes the practice of applying the culture of DevOps with machine learning to build and deploy the model rapidly and seamlessly. Without leveraging the power of DevOps and without adopting it, no industry could think of surviving today. Today, industries are dependent on old data and fetching the important data out of it, making models, and training it that help them grow their companies. That practice we call it today is ML. So, there is no possibility of surviving without being quick and ML; however, ML models take time to be developed, so to overcome that issue of time, MLOps plays a vital role today in the industries. Now, they could build it fast and grow fast. The machine learning processes initially seem easy, but if not carefully handled and designed, then creating and deploying such models may lead to huge time loss and resources. Hence, the overall performance of the system would be degraded, as well as the efficiency. This paper presents an applicable model of continuous open-source integration (CI) and continuous delivery (CD) principles and tools to minimize time wastage during system resourcing. Throughout our methodological results, we observed that the model improves the time efficiency, reduces the efforts of data scientists and cost-cutting after avoiding using heavily paid MLOps tools.
 Keywords
 MLOps
 DevOps
 Jenkins
 CI/CD
 Machine learning
 Automation",this paper proposes the practice of applying the culture of devops with machine learning to build and deploy the model rapidly and seamlessly  without leveraging the power of devops and without adopting it  no industry could think of surviving today  today  industries are dependent on old data and fetching the important data out of it  making models  and training it that help them grow their companies  that practice we call it today is ml  so  there is no possibility of surviving without being quick and ml  however  ml models take time to be developed  so to overcome that issue of time  mlops plays a vital role today in the industries  now  they could build it fast and grow fast  the machine learning processes initially seem easy  but if not carefully handled and designed  then creating and deploying such models may lead to huge time loss and resources  hence  the overall performance of the system would be degraded  as well as the efficiency  this paper presents an applicable model of continuous open source integration  ci  and continuous delivery  cd  principles and tools to minimize time wastage during system resourcing  throughout our methodological results  we observed that the model improves the time efficiency  reduces the efforts of data scientists and cost cutting after avoiding using heavily paid mlops tools   keywords  mlops  devops  jenkins  ci cd  machine learning  automation,7.6273766,7.3876395,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Wrapping It Up,"You underwent a long and arduous journey over the course of the last 12 chapters. As you begin the last phase of this book, letâ€™s summarize the key takeaways and salient points of those chapters. This is important because one of the main things that I will focus on in this chapter is the topic of what was not covered. Naturally, you will appreciate the treatment of what was not by examining and recollecting what was covered.",you underwent a long and arduous journey over the course of the last    chapters  as you begin the last phase of this book  let   s summarize the key takeaways and salient points of those chapters  this is important because one of the main things that i will focus on in this chapter is the topic of what was not covered  naturally  you will appreciate the treatment of what was not by examining and recollecting what was covered ,9.787342,6.753647,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Deploying in Azure,"In this chapter, we will cover how you can use Microsoft Azure to operationalize your MLFlow models. In particular, we will look at how you can also utilize Azureâ€™s built-in functionality to deploy a model to a development branch and to a production branch, along with how you can query the models once deployed.",in this chapter  we will cover how you can use microsoft azure to operationalize your mlflow models  in particular  we will look at how you can also utilize azure   s built in functionality to deploy a model to a development branch and to a production branch  along with how you can query the models once deployed ,7.92637,7.7916327,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
The Data Lakehouse Paradigm,"In this chapter, you will learn about the Lakehouse architectural best practices, patterns, and Apache Spark capabilities in the Lakehouse. You will also learn about the many Azure-centric technologies that support Spark for ELT, advanced analytics, storage, compute, and reporting to form the modern Data Lakehouse architecture.",in this chapter  you will learn about the lakehouse architectural best practices  patterns  and apache spark capabilities in the lakehouse  you will also learn about the many azure centric technologies that support spark for elt  advanced analytics  storage  compute  and reporting to form the modern data lakehouse architecture ,8.96694,7.720557,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Deploying in AWS,"In this chapter, we will cover how you can operationalize your MLFlow models using AWS SageMaker. We will cover how you can upload your runs to S3 storage, how you can build and push an MLFlow Docker container image to AWS, and how you can deploy your model, query it, update the model once it is deployed, and remove a deployed model.",in this chapter  we will cover how you can operationalize your mlflow models using aws sagemaker  we will cover how you can upload your runs to s  storage  how you can build and push an mlflow docker container image to aws  and how you can deploy your model  query it  update the model once it is deployed  and remove a deployed model ,8.032911,7.719267,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
"AIoT 101: What, Why, How, Who","AIoT combines two of the most important technology paradigms of the 2020s: Artificial Intelligence (AI) and the Internet of Things (IoT). To best understand AIoT from all relevant perspectives, we will start by looking at the why, what, who and how perspectives, inspired by the work of Simon Sinek [1] as well as the St. Gallen IoT Lab [2] (Fig. 1.1):While Simon Sinek suggests to Start with Why, we will first look at the what to provide some context, before discussing why you should consider it.",aiot combines two of the most important technology paradigms of the     s  artificial intelligence  ai  and the internet of things  iot   to best understand aiot from all relevant perspectives  we will start by looking at the why  what  who and how perspectives  inspired by the work of simon sinek     as well as the st  gallen iot lab      fig       while simon sinek suggests to start with why  we will first look at the what to provide some context  before discussing why you should consider it ,10.634888,6.318541,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
MaReIA: a cloud MapReduce based high performance whole slide image analysis framework,"Recent advancements in systematic analysis of high resolution whole slide images have increase efficiency of diagnosis, prognosis and prediction of cancer and important diseases. Due to the enormous sizes and dimensions of whole slide images, the analysis requires extensive computing resources which are not commonly available. Images have to be tiled for processing due to computer memory limitations, which lead to inaccurate results due to the ignorance of boundary crossing objects. Thus, we propose a generic and highly scalable cloud-based image analysis framework for whole slide images. The framework enables parallelized integration of image analysis steps, such as segmentation and aggregation of micro-structures in a single pipeline, and generation of final objects manageable by databases. The core concept relies on the abstraction of objects in whole slide images as different classes of spatial geometries, which in turn can be handled as text based records in MapReduce. The framework applies an overlapping partitioning scheme on images, and provides parallelization of tiling and image segmentation based on MapReduce architecture. It further provides robust object normalization, graceful handling of boundary objects with an efficient spatial indexing based matching method to generate accurate results. Our experiments on Amazon EMR show that MaReIA is highly scalable, generic and extremely cost effective by benchmark tests.",recent advancements in systematic analysis of high resolution whole slide images have increase efficiency of diagnosis  prognosis and prediction of cancer and important diseases  due to the enormous sizes and dimensions of whole slide images  the analysis requires extensive computing resources which are not commonly available  images have to be tiled for processing due to computer memory limitations  which lead to inaccurate results due to the ignorance of boundary crossing objects  thus  we propose a generic and highly scalable cloud based image analysis framework for whole slide images  the framework enables parallelized integration of image analysis steps  such as segmentation and aggregation of micro structures in a single pipeline  and generation of final objects manageable by databases  the core concept relies on the abstraction of objects in whole slide images as different classes of spatial geometries  which in turn can be handled as text based records in mapreduce  the framework applies an overlapping partitioning scheme on images  and provides parallelization of tiling and image segmentation based on mapreduce architecture  it further provides robust object normalization  graceful handling of boundary objects with an efficient spatial indexing based matching method to generate accurate results  our experiments on amazon emr show that mareia is highly scalable  generic and extremely cost effective by benchmark tests ,4.4509063,4.6775703,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Missing data imputation by K nearest neighbours based on grey relational structure and mutual information,"Treatment of missing data has become increasingly significant in scientific research and engineering applications. The classic imputation strategy based on the K nearest neighbours (KNN) has been widely used to solve the plague problem. However, former studies do not give much attention to feature relevance, which has a significant impact on the selection of nearest neighbours. As a result, biased results may appear in similarity measurements. In this paper, we propose a novel method to impute missing data, named feature weighted grey KNN (FWGKNN) imputation algorithm. This approach employs mutual information (MI) to measure feature relevance. We present an experimental evaluation for five UCI datasets in three missingness mechanisms with various missing rates. Experimental results show that feature relevance has a non-ignorable influence on missing data estimation based on grey theory, and our method is considered superior to the other four estimation strategies. Moreover, the classification bias can be significantly reduced by using our approach in classification tasks.",treatment of missing data has become increasingly significant in scientific research and engineering applications  the classic imputation strategy based on the k nearest neighbours  knn  has been widely used to solve the plague problem  however  former studies do not give much attention to feature relevance  which has a significant impact on the selection of nearest neighbours  as a result  biased results may appear in similarity measurements  in this paper  we propose a novel method to impute missing data  named feature weighted grey knn  fwgknn  imputation algorithm  this approach employs mutual information  mi  to measure feature relevance  we present an experimental evaluation for five uci datasets in three missingness mechanisms with various missing rates  experimental results show that feature relevance has a non ignorable influence on missing data estimation based on grey theory  and our method is considered superior to the other four estimation strategies  moreover  the classification bias can be significantly reduced by using our approach in classification tasks ,4.5365086,7.0639477,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
iFlow: Powering Lightweight Cross-Platform Data Pipelines,"With the advent of ML applications cutting across sectors, data preprocessing for the training and proper functioning of ML models has seen a rise in importance. This research paper represents a similar attempt by proposing iFlow, a software tool for the easy creation of cross-platform data flow pipelines based on the Python programming language. The tool leverages the default file system of the user's operating system, enabling faster and real-time inflow and outflow of data for easier and more convenient data processing. The project plan emphasizes modularity and extensibility, with a focus on the automation of data pipelines, as well as the development of associated UI components for a better user experience. The paper highlights the potential applications of iFlow in the field of machine learning pipelines, positioning it as a lightweight and open-source MLOps framework for the future.
 Keywords
 iFlow
 Data pipelines
 Data processing
 Cross-platform
 Lightweight",with the advent of ml applications cutting across sectors  data preprocessing for the training and proper functioning of ml models has seen a rise in importance  this research paper represents a similar attempt by proposing iflow  a software tool for the easy creation of cross platform data flow pipelines based on the python programming language  the tool leverages the default file system of the user s operating system  enabling faster and real time inflow and outflow of data for easier and more convenient data processing  the project plan emphasizes modularity and extensibility  with a focus on the automation of data pipelines  as well as the development of associated ui components for a better user experience  the paper highlights the potential applications of iflow in the field of machine learning pipelines  positioning it as a lightweight and open source mlops framework for the future   keywords  iflow  data pipelines  data processing  cross platform  lightweight,9.651233,5.4162955,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
The AIQ Meta-Testbed: Pragmatically Bridging Academic AI Testing and Industrial Q Needs,"AI solutions seem to appear in any and all application domains. As AI becomes more pervasive, the importance of quality assurance increases. Unfortunately, there is no consensus on what artificial intelligence means and interpretations range from simple statistical analysis to sentient humanoid robots. On top of that, quality is a notoriously hard concept to pinpoint. What does this mean for AI quality? In this paper, we share our working definition and a pragmatic approach to address the corresponding quality assurance with a focus on testing. Finally, we present our ongoing work on establishing the AIQ Meta-Testbed.
 Keywords
 Artificial intelligence
 Machine learning
 Quality assurance
 Software testing
 Testbed",ai solutions seem to appear in any and all application domains  as ai becomes more pervasive  the importance of quality assurance increases  unfortunately  there is no consensus on what artificial intelligence means and interpretations range from simple statistical analysis to sentient humanoid robots  on top of that  quality is a notoriously hard concept to pinpoint  what does this mean for ai quality  in this paper  we share our working definition and a pragmatic approach to address the corresponding quality assurance with a focus on testing  finally  we present our ongoing work on establishing the aiq meta testbed   keywords  artificial intelligence  machine learning  quality assurance  software testing  testbed,9.566814,6.977531,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Introduction to MLFlow,"In this chapter, we will cover what MLFlow is, what it does, and how you can implement MLOps setups into your existing projects. More specifically, we will cover how you can integrate MLFlow with scikit-learn, TensorFlow 2.0+/Keras, PyTorch, and PySpark. We will go over experiment creation; metric, parameter, and artifact logging; model logging; and how you can deploy models on a local server and query them for predictions.",in this chapter  we will cover what mlflow is  what it does  and how you can implement mlops setups into your existing projects  more specifically  we will cover how you can integrate mlflow with scikit learn  tensorflow      keras  pytorch  and pyspark  we will go over experiment creation  metric  parameter  and artifact logging  model logging  and how you can deploy models on a local server and query them for predictions ,8.212696,7.6263456,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Fairness-aware machine learning engineering: how far are we?,"Machine learning is part of the daily life of people and companies worldwide. Unfortunately, bias in machine learning algorithms risks unfairly influencing the decision-making process and reiterating possible discrimination. While the interest of the software engineering community in software fairness is rapidly increasing, there is still a lack of understanding of various aspects connected to fair machine learning engineering, i.e., the software engineering process involved in developing fairness-critical machine learning systems. Questions connected to the practitionersâ€™ awareness and maturity about fairness, the skills required to deal with the matter, and the best development phase(s) where fairness should be faced more are just some examples of the knowledge gaps currently open. In this paper, we provide insights into how fairness is perceived and managed in practice, to shed light on the instruments and approaches that practitioners might employ to properly handle fairness. We conducted a survey with 117 professionals who shared their knowledge and experience highlighting the relevance of fairness in practice, and the skills and tools required to handle it. The key results of our study show that fairness is still considered a second-class quality aspect in the development of artificial intelligence systems. The building of specific methods and development environments, other than automated validation tools, might help developers to treat fairness throughout the software lifecycle and revert this trend.",machine learning is part of the daily life of people and companies worldwide  unfortunately  bias in machine learning algorithms risks unfairly influencing the decision making process and reiterating possible discrimination  while the interest of the software engineering community in software fairness is rapidly increasing  there is still a lack of understanding of various aspects connected to fair machine learning engineering  i e   the software engineering process involved in developing fairness critical machine learning systems  questions connected to the practitioners    awareness and maturity about fairness  the skills required to deal with the matter  and the best development phase s  where fairness should be faced more are just some examples of the knowledge gaps currently open  in this paper  we provide insights into how fairness is perceived and managed in practice  to shed light on the instruments and approaches that practitioners might employ to properly handle fairness  we conducted a survey with     professionals who shared their knowledge and experience highlighting the relevance of fairness in practice  and the skills and tools required to handle it  the key results of our study show that fairness is still considered a second class quality aspect in the development of artificial intelligence systems  the building of specific methods and development environments  other than automated validation tools  might help developers to treat fairness throughout the software lifecycle and revert this trend ,10.302949,4.58344,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Parallelizing Automatic Model Management System for AIOps on Microservice Platforms,"With the gradual increase in the scale of applications based on microservice architecture, the complexity of system operation and maintenance is also significantly increasing. The emergence of AIOps makes it possible to automatically detect the state, allocate the resources, warn and detect the anomaly of the system through some machine learning models. Given dynamic online workloads, the running state of a production microservice system is constantly in flux. Therefore, it is necessary to continuously train, encapsulate and deploy models based on the current system status, so that the AIOps model can dynamically adapt to the system environment. To address this problem, this paper proposes a model management pipeline framework for AIOps on microservice platforms, and implements a prototype system based on Kubernetes to verify the framework. The system consists of three components: model training, model packaging and model deploying. Parallelization and parameter search are introduced in the model training process to support rapid training of multiple models and automated model hyperparameter tuning. Rapid deployment of models is supported by the model packaging and deploying components. Experiments were performed to verify the prototype system, and the experimental results illustrate the feasibility of the proposed framework. This work provides a valuable reference for the construction of an integrated and streamlined AIOps model management system.
 Keywords
 Model management pipeline
 AIOps
 Parallel model training
 Microservice
 MLOps",with the gradual increase in the scale of applications based on microservice architecture  the complexity of system operation and maintenance is also significantly increasing  the emergence of aiops makes it possible to automatically detect the state  allocate the resources  warn and detect the anomaly of the system through some machine learning models  given dynamic online workloads  the running state of a production microservice system is constantly in flux  therefore  it is necessary to continuously train  encapsulate and deploy models based on the current system status  so that the aiops model can dynamically adapt to the system environment  to address this problem  this paper proposes a model management pipeline framework for aiops on microservice platforms  and implements a prototype system based on kubernetes to verify the framework  the system consists of three components  model training  model packaging and model deploying  parallelization and parameter search are introduced in the model training process to support rapid training of multiple models and automated model hyperparameter tuning  rapid deployment of models is supported by the model packaging and deploying components  experiments were performed to verify the prototype system  and the experimental results illustrate the feasibility of the proposed framework  this work provides a valuable reference for the construction of an integrated and streamlined aiops model management system   keywords  model management pipeline  aiops  parallel model training  microservice  mlops,8.330714,4.0009694,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Datafication Engineering,"Datafication engineering is designing, developing, and deploying artificial intelligence (AI) and machine learning (ML) systems. It involves a range of tasks, including data collection and preparation, model selection, deployment, hyperparameter tuning, model training and evaluation, and deployment and monitoring of the models.",datafication engineering is designing  developing  and deploying artificial intelligence  ai  and machine learning  ml  systems  it involves a range of tasks  including data collection and preparation  model selection  deployment  hyperparameter tuning  model training and evaluation  and deployment and monitoring of the models ,8.248593,5.484105,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Pulsed Neural Network Plus Parallel Multi-core Approach to Solve Efficiently Big Shortest Path Problems,"A Third Generation Artificial Neural Network plus a Parallel Multi-Core approach is presented. This approach is capable of efficiently tackle the problem of finding the shortest path between two nodes, for big cases with thousands of nodes. The efficient solution of the shortest path problem has applications in such important and current areas as robotics, telecommunications, operation research, game theory, computer networks, internet, industrial design, transport phenomena, design of electronic circuits and others, so it is a subject of great interest in the area of combinatorial optimization. Due to the parallel design of the Pulsed Neuronal Network presented here, it is possible speed up the solution using parallel multi-processors; this solution approach can be highly competitive, as observed from the good results obtained, even in cases with thousands of nodes.
 Keywords
 Shortest path problems
 Pulsed Neural Network
 Parallel multi-core",a third generation artificial neural network plus a parallel multi core approach is presented  this approach is capable of efficiently tackle the problem of finding the shortest path between two nodes  for big cases with thousands of nodes  the efficient solution of the shortest path problem has applications in such important and current areas as robotics  telecommunications  operation research  game theory  computer networks  internet  industrial design  transport phenomena  design of electronic circuits and others  so it is a subject of great interest in the area of combinatorial optimization  due to the parallel design of the pulsed neuronal network presented here  it is possible speed up the solution using parallel multi processors  this solution approach can be highly competitive  as observed from the good results obtained  even in cases with thousands of nodes   keywords  shortest path problems  pulsed neural network  parallel multi core,2.5539508,7.6059637,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
MXT: A New Variant of Pyramid Vision Transformer for Multi-label Chest X-ray Image Classification,"Nowadays, the global COVID-19 situation is still serious, and the new mutant virus Delta has already spread all over the world. The chest X-ray is one of the most common radiological examinations for screening catheters and diagnosis of many lung diseases, which plays an important role in assisting clinical diagnosis during the outbreak. This study considers the problem of multi-label catheters and thorax disease classification on chest X-ray images based on computer vision. Therefore, we propose a new variant of pyramid vision Transformer for multi-label chest X-ray image classification, named MXT, which can capture both short and long-range visual information through self-attention. Especially, downsampling spatial reduction attention can reduce the resource consumption of using Transformer. Meanwhile, multi-layer overlap patch (MLOP) embedding is used to tokenize images and dynamic position feed forward with zero paddings can encode position instead of adding a positional mask. Furthermore, class token Transformer block and multi-label attention (MLA) are utilized to offer more effective processing of multi-label classification. We evaluate our MXT on Chest X-ray14 dataset which has 14 disease pathologies and Catheter dataset containing 11 types of catheter placement. Each image is labeled one or more categories. Compared with some state-of-the-art baselines, our MXT can yield the highest mean AUC score of 83.0% on the Chest X-ray14 dataset and 94.6% on the Catheter dataset. According to the ablation study, we can obtain the following results: (1) The proposed MLOP embedding has a better performance than overlap patch (OP) embedding layer and non-overlap patch (N-OP) embedding layer that the mean AUC score is improved 0.6% and 0.4%, respectively. (2) Our demonstrate dynamic position feed forward can replace the traditional position mask which can learn the position information, and the mean AUC increased by 0.6%. (3) The mean AUC score by the designed MLA is more 0.2% and 0.6% than using the class token and calculating the mean scores of all tokens. The comprehensive experiments on two datasets demonstrate the effectiveness of the proposed method for multi-label chest X-ray image classification. Hence, our MXT can assist radiologists in diagnoses of lung diseases and check the placement of catheters, which can reduce the work pressure of medical staff.",nowadays  the global covid    situation is still serious  and the new mutant virus delta has already spread all over the world  the chest x ray is one of the most common radiological examinations for screening catheters and diagnosis of many lung diseases  which plays an important role in assisting clinical diagnosis during the outbreak  this study considers the problem of multi label catheters and thorax disease classification on chest x ray images based on computer vision  therefore  we propose a new variant of pyramid vision transformer for multi label chest x ray image classification  named mxt  which can capture both short and long range visual information through self attention  especially  downsampling spatial reduction attention can reduce the resource consumption of using transformer  meanwhile  multi layer overlap patch  mlop  embedding is used to tokenize images and dynamic position feed forward with zero paddings can encode position instead of adding a positional mask  furthermore  class token transformer block and multi label attention  mla  are utilized to offer more effective processing of multi label classification  we evaluate our mxt on chest x ray   dataset which has    disease pathologies and catheter dataset containing    types of catheter placement  each image is labeled one or more categories  compared with some state of the art baselines  our mxt can yield the highest mean auc score of       on the chest x ray   dataset and       on the catheter dataset  according to the ablation study  we can obtain the following results      the proposed mlop embedding has a better performance than overlap patch  op  embedding layer and non overlap patch  n op  embedding layer that the mean auc score is improved      and       respectively      our demonstrate dynamic position feed forward can replace the traditional position mask which can learn the position information  and the mean auc increased by           the mean auc score by the designed mla is more      and      than using the class token and calculating the mean scores of all tokens  the comprehensive experiments on two datasets demonstrate the effectiveness of the proposed method for multi label chest x ray image classification  hence  our mxt can assist radiologists in diagnoses of lung diseases and check the placement of catheters  which can reduce the work pressure of medical staff ,3.6327322,5.4032073,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Long-term application of fertilizer and manures affect P fractions in Mollisol,"Application of phosphorus (P), a major plant nutrient, as fertilizer is critical to maintain P level for crop production and yield in most cultivated soils. While, it may impact the dynamics, limited studies have examined the long-term effects of fertilization on P fractions in a soil profile in Mollisol. A long-term field experiment was conducted at the State Key Experimental Station of Agroecology of the Chinese Academy of Sciences in Hailun county, Heilongjiang Province, China. A sequential fractionation procedure was used to determine the effect of fertilizer (types) treatments including no fertilizer (CK), chemical fertilizer (NPK), chemical fertilizer plus straw (NPKâ€‰+â€‰S) and pig manure (OM) on fractions of P and their distribution within 0â€“100 cm soil profiles. Unlike CK treatment, the long-term application of fertilizers increased the concentration and accumulation of total and available P in 0â€“20 and 0â€“40 cm soil depths than deeper soils, respectively. The phosphorus activity coefficient (PAC) ranged from 1.5 to 13.8% within 0â€“100 cm soil depth. The largest PAC value was observed under OM treatment at 0â€“40 cm soil depth and under NPKâ€‰+â€‰S treatment at 40â€“100 cm soil depth. The Ca2-P and Ca8-P concentrations increased significantly by 0.5â€“7.5 times and 0.5â€“10.4 times, respectively in OM treatment with the largest value in 0â€“40 cm soil depth over CK treatment. The Al-P concentration under NPKâ€‰+â€‰S and OM treatments increased throughout the soil profile. The OM treatment increased all Po concentrations in the 0â€“40 cm soil depth, while NPK and NPKâ€‰+â€‰S treatments increased labile organic P, moderately labile organic P, and highly stable organic P in the 0â€“20 cm soil depth. Thus, the application of fertilizer and straw, or organic manure may enhance inorganic and organic P pool in a Mollisol in Northeast China. Thus, organic manure application in the subsoil as a potential P source and their impact should be considered in developing management practices and policies regarding nutrient management.",application of phosphorus  p   a major plant nutrient  as fertilizer is critical to maintain p level for crop production and yield in most cultivated soils  while  it may impact the dynamics  limited studies have examined the long term effects of fertilization on p fractions in a soil profile in mollisol  a long term field experiment was conducted at the state key experimental station of agroecology of the chinese academy of sciences in hailun county  heilongjiang province  china  a sequential fractionation procedure was used to determine the effect of fertilizer  types  treatments including no fertilizer  ck   chemical fertilizer  npk   chemical fertilizer plus straw  npk       s  and pig manure  om  on fractions of p and their distribution within         cm soil profiles  unlike ck treatment  the long term application of fertilizers increased the concentration and accumulation of total and available p in        and        cm soil depths than deeper soils  respectively  the phosphorus activity coefficient  pac  ranged from     to       within         cm soil depth  the largest pac value was observed under om treatment at        cm soil depth and under npk       s treatment at          cm soil depth  the ca  p and ca  p concentrations increased significantly by           times and            times  respectively in om treatment with the largest value in        cm soil depth over ck treatment  the al p concentration under npk       s and om treatments increased throughout the soil profile  the om treatment increased all po concentrations in the        cm soil depth  while npk and npk       s treatments increased labile organic p  moderately labile organic p  and highly stable organic p in the        cm soil depth  thus  the application of fertilizer and straw  or organic manure may enhance inorganic and organic p pool in a mollisol in northeast china  thus  organic manure application in the subsoil as a potential p source and their impact should be considered in developing management practices and policies regarding nutrient management ,4.3752885,1.6745131,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
A Distributed Data Storage Strategy Based on LOPs,"Distributed data management requires data partitioning and deployment at the data storage level, and data querying requires the configuration and integration of query subresults at each site. The data partitioning strategy is closely related to the overhead of the distributed system. It is necessary to determine the appropriate data partitioning strategy and update strategy according to the application. This paper proposes a widely distributed storage and processing scheme for a distributed linear order partition (DLOP) based on time stamps. This scheme proposes two kinds of partition strategy based on the characteristics of an ""equivalent division"" of a linear order partition (LOP), namely, partitioning based on time interval equilibrium and partitioning based on query expectation. Each site in the distributed system is uniformly configured with an index-based data query mechanism to complete the distributed management of data. The corresponding experiments verify the practicability and efficiency of the proposed storage strategy and show that the proposed method is effective for the self-scalability of the data scale and reduces the cluster hardware configuration requirements.",distributed data management requires data partitioning and deployment at the data storage level  and data querying requires the configuration and integration of query subresults at each site  the data partitioning strategy is closely related to the overhead of the distributed system  it is necessary to determine the appropriate data partitioning strategy and update strategy according to the application  this paper proposes a widely distributed storage and processing scheme for a distributed linear order partition  dlop  based on time stamps  this scheme proposes two kinds of partition strategy based on the characteristics of an  equivalent division  of a linear order partition  lop   namely  partitioning based on time interval equilibrium and partitioning based on query expectation  each site in the distributed system is uniformly configured with an index based data query mechanism to complete the distributed management of data  the corresponding experiments verify the practicability and efficiency of the proposed storage strategy and show that the proposed method is effective for the self scalability of the data scale and reduces the cluster hardware configuration requirements ,3.705811,7.721468,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Rapid Delivery of Software: The Effect of Alignment on Time to Market,"In Scrum, teams working collaboratively on interdependent pieces of software face alignment issues as they need to coordinate their work. Organisations aim to minimise time to market of their products, which makes it relevant to identify how alignment issues affect time to market. Currently, empirical evidence of the effect of implementing alignment activities on delivering software is scarce. This research aims to identify those alignment activities that shorten the time to market of backlog items. First, examination of key concepts led to a grounded choice of alignment activities taken into account. Use of alignment activities in development of features was identified by sending feature owners a close-ended questionnaire on the alignment of their collaborating Scrum teams. The cycle times of backlog items were measured by using the application programmable interface of the agile tool used for tracking backlog items. Results show that when user stories were developed using a shared Definition of Ready, process and lead time decreased significantly. Process and lead time also differed between user stories implementing a different number of shared feedback sessions, where using two shared feedback sessions per sprint resulted in the lowest process and lead time.
 Keywords
 Agile
 Agile tools
 Alignment
 Scrum
 Scrum collaboration
 Time to market",in scrum  teams working collaboratively on interdependent pieces of software face alignment issues as they need to coordinate their work  organisations aim to minimise time to market of their products  which makes it relevant to identify how alignment issues affect time to market  currently  empirical evidence of the effect of implementing alignment activities on delivering software is scarce  this research aims to identify those alignment activities that shorten the time to market of backlog items  first  examination of key concepts led to a grounded choice of alignment activities taken into account  use of alignment activities in development of features was identified by sending feature owners a close ended questionnaire on the alignment of their collaborating scrum teams  the cycle times of backlog items were measured by using the application programmable interface of the agile tool used for tracking backlog items  results show that when user stories were developed using a shared definition of ready  process and lead time decreased significantly  process and lead time also differed between user stories implementing a different number of shared feedback sessions  where using two shared feedback sessions per sprint resulted in the lowest process and lead time   keywords  agile  agile tools  alignment  scrum  scrum collaboration  time to market,9.577241,4.772795,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
RelOps â€“ A Whole-of-Organisation Approach for Reliability Analytics,"Reliability analysis on in-service assets uses well-established methods to, for example, determine mean-time-between-failure (MTBF) estimates or identify failure modes. However, the data inputs to these calculations depend on how the raw data from maintenance repair records have been processed. Furthermore, processes to extract and clean raw maintenance data are often ad hoc and performed differently by each engineer. As a result, calculations for asset reliability measures and identification of historical events and failure modes are difficult to replicate. Currently, the process is manual, time-consuming and not scalable. As a solution we present RelOps, a process to achieve standardised, scalable, and efficient end-to-end data handling and processing for organisation-wide reliability analysis. The process is illustrated with a case study showing current practice in MTBF estimation and the opportunities for technical language processing (TLP) to infer MTBF from maintenance work orders raised against a slurry pump.RelOps draws on DevOps and MLOps practices widely used in the software engineering and machine learning communities. The aim of RelOps is to shorten the reliability analysis development lifecycle and provide continuous delivery of quality outputs using a standardised and repeatable process.",reliability analysis on in service assets uses well established methods to  for example  determine mean time between failure  mtbf  estimates or identify failure modes  however  the data inputs to these calculations depend on how the raw data from maintenance repair records have been processed  furthermore  processes to extract and clean raw maintenance data are often ad hoc and performed differently by each engineer  as a result  calculations for asset reliability measures and identification of historical events and failure modes are difficult to replicate  currently  the process is manual  time consuming and not scalable  as a solution we present relops  a process to achieve standardised  scalable  and efficient end to end data handling and processing for organisation wide reliability analysis  the process is illustrated with a case study showing current practice in mtbf estimation and the opportunities for technical language processing  tlp  to infer mtbf from maintenance work orders raised against a slurry pump relops draws on devops and mlops practices widely used in the software engineering and machine learning communities  the aim of relops is to shorten the reliability analysis development lifecycle and provide continuous delivery of quality outputs using a standardised and repeatable process ,6.008604,4.6483684,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Searching for the Right Algorithms,"In the last few decades, data from different sources have become more accessible and consumable, and companies have started looking for ways to use machine learning (ML) techniques to optimize business metrics, pursue new opportunities, and grow revenues (Lazzeri 2019). Not only has data become more available, but there has also been an explosion of machine learning and artificial intelligence applications that enable companies to build sophisticated, intelligent, and data-driven solutions. Machine learning, a term that encompasses a range of algorithmic approaches from statistical methods such as regressions to neural networks, has rapidly advanced to the forefront of analytics (Tambe 2012).",in the last few decades  data from different sources have become more accessible and consumable  and companies have started looking for ways to use machine learning  ml  techniques to optimize business metrics  pursue new opportunities  and grow revenues  lazzeri        not only has data become more available  but there has also been an explosion of machine learning and artificial intelligence applications that enable companies to build sophisticated  intelligent  and data driven solutions  machine learning  a term that encompasses a range of algorithmic approaches from statistical methods such as regressions to neural networks  has rapidly advanced to the forefront of analytics  tambe       ,8.838626,5.9711013,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Democratizing Enterprise AI Success Factors and Challenges: A Systematic Literature Review and a Proposed Framework,"To democratize or not to democratize, this is not the problem anymore for the enterprises that consider democratizing their enterprise AI practice; the problem that these enterprises face nowadays, is how to successfully democratize their enterprise AI. In this paper we conduct a systematic literature review to provide an in-depth analysis of the success factors and the challenges of democratizing the artificial intelligence practices in the enterprises, we also build on this review and propose a framework for the enterprise AI democratization that suggests a set of the success factors and challenges. The research design of this paper is to conduct a systematic literature review by including 41 papers as an initial set of studies for review; we screen the papers and implement inclusion and quality checks on these studies, and we qualify 15 papers for the final review. The key findings of this paper, from the systematic literature review, list a set of success factors and challenges that enterprises should consider to strengthen or to avoid. We propose these factors in a form of proposed framework suggesting four categories: strategy, enterprise architecture, data, and trust. Because of the publication specification and limitation, we limited the scope of our primary studies to a limited set to match the constraints and limitations. The paper includes implications for the academic literature review and the extraction of factors that can impact the process of the enterprise artificial intelligence democratization, and the need to increase the awareness of the enterprise AI practices in order to overcome the challenges that might prevent enterprises from having a successful enterprise AI. While there are some efforts to assess and review the success factors and challenges of the AI practices in general, one of the major findings of the literature review conducted is that there is evident research gap in the literature on the perception and associated factors of artificial intelligence. This paper seeks to fill this gap.
 Keywords
 Enterprise
 Emerging technologies
 Artificial intelligence
 Enterprise architecture
 Intelligent enterprise",to democratize or not to democratize  this is not the problem anymore for the enterprises that consider democratizing their enterprise ai practice  the problem that these enterprises face nowadays  is how to successfully democratize their enterprise ai  in this paper we conduct a systematic literature review to provide an in depth analysis of the success factors and the challenges of democratizing the artificial intelligence practices in the enterprises  we also build on this review and propose a framework for the enterprise ai democratization that suggests a set of the success factors and challenges  the research design of this paper is to conduct a systematic literature review by including    papers as an initial set of studies for review  we screen the papers and implement inclusion and quality checks on these studies  and we qualify    papers for the final review  the key findings of this paper  from the systematic literature review  list a set of success factors and challenges that enterprises should consider to strengthen or to avoid  we propose these factors in a form of proposed framework suggesting four categories  strategy  enterprise architecture  data  and trust  because of the publication specification and limitation  we limited the scope of our primary studies to a limited set to match the constraints and limitations  the paper includes implications for the academic literature review and the extraction of factors that can impact the process of the enterprise artificial intelligence democratization  and the need to increase the awareness of the enterprise ai practices in order to overcome the challenges that might prevent enterprises from having a successful enterprise ai  while there are some efforts to assess and review the success factors and challenges of the ai practices in general  one of the major findings of the literature review conducted is that there is evident research gap in the literature on the perception and associated factors of artificial intelligence  this paper seeks to fill this gap   keywords  enterprise  emerging technologies  artificial intelligence  enterprise architecture  intelligent enterprise,11.712405,6.149622,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
DevOps for DataOps,"Creating trust in data and trust in users of data minimizes risks. Trust safeguards regulatory compliance, reduces commercial risk, and protects the reputation of the organization. Trust in data also ensures the integrity of data and makes it easier for users to identify and safely consume it. Leandro DalleMule and Thomas Davenport describe this aspect of data strategy as data defense in their famous Harvard Business Review article.1 Data defense is vital, but so too is data offense for a balanced data strategy. Data offense centers on data use to make decisions that increase organizational efficiency, enhance customer experience, and improve product creation.",creating trust in data and trust in users of data minimizes risks  trust safeguards regulatory compliance  reduces commercial risk  and protects the reputation of the organization  trust in data also ensures the integrity of data and makes it easier for users to identify and safely consume it  leandro dallemule and thomas davenport describe this aspect of data strategy as data defense in their famous harvard business review article   data defense is vital  but so too is data offense for a balanced data strategy  data offense centers on data use to make decisions that increase organizational efficiency  enhance customer experience  and improve product creation ,10.311204,7.5762787,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
A Data-Driven Methodology for Guiding the Selection of Preprocessing Techniques in a Machine Learning Pipeline,"The performance of a Machine Learning (ML) model greatly depends on the previous preprocessing of the data. Unfortunately, the decision on which preprocessing techniques should be applied relies on the expertise of data scientists and/or ML practitioners. Since the correct application of some techniques depend on the characteristics of the data whereas others depend on the particular ML model to be trained, this leads to an error-prone process that requires the data scientist to be knowledgeable in all the combinations that may arise. To tackle this problem, we propose a methodology that guides the selection of the most appropriated preprocessing techniques that are highly required or strongly recommended taking into account both the ML model as well as the data characteristics, so that the developer is able to freely experiment with different models while ensuring that no needed preprocessing techniques are overlooked. According to the ML model and the data at hand, the methodology will (i) obtain the characteristics of the model (ii) check whether these characteristics are met by the data or not and (iii) show to the developer which variables require preprocessing and which techniques should be applied so that a proper decision can be made. To the best of our knowledge, this is the only work that tries to gather the most common ML models together with its most adequate preprocessing techniques and encode this information into a methodology that guides this process in a systematic way.
 Keywords
 Data-driven
 Preprocessing
 Methodology
 Data Science",the performance of a machine learning  ml  model greatly depends on the previous preprocessing of the data  unfortunately  the decision on which preprocessing techniques should be applied relies on the expertise of data scientists and or ml practitioners  since the correct application of some techniques depend on the characteristics of the data whereas others depend on the particular ml model to be trained  this leads to an error prone process that requires the data scientist to be knowledgeable in all the combinations that may arise  to tackle this problem  we propose a methodology that guides the selection of the most appropriated preprocessing techniques that are highly required or strongly recommended taking into account both the ml model as well as the data characteristics  so that the developer is able to freely experiment with different models while ensuring that no needed preprocessing techniques are overlooked  according to the ml model and the data at hand  the methodology will  i  obtain the characteristics of the model  ii  check whether these characteristics are met by the data or not and  iii  show to the developer which variables require preprocessing and which techniques should be applied so that a proper decision can be made  to the best of our knowledge  this is the only work that tries to gather the most common ml models together with its most adequate preprocessing techniques and encode this information into a methodology that guides this process in a systematic way   keywords  data driven  preprocessing  methodology  data science,6.3333826,5.5197487,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
"Development Efforts for Reproducible Research: Platform, Library and Editorial Investment","Reproducible research in pattern recognition can be viewed from a number of angles, including code execution, platforms that promote reproducibility, code sharing, or the release of libraries providing access to relevant algorithms in the corresponding disciplines. In this work, after recalling the motivation and classic definitions of reproducible research, we propose an updated overview of the main platforms that might be used for reproducible research. We then review the different libraries that are commonly used by the pattern recognition, computer vision, imaging and geometry processing communities, and we share our experience of developing a research library. In the third part, new advanced editorial investments will be presented, such as the IPOL journal or other IPOL-inspired new initiatives like OVD-SaaS.",reproducible research in pattern recognition can be viewed from a number of angles  including code execution  platforms that promote reproducibility  code sharing  or the release of libraries providing access to relevant algorithms in the corresponding disciplines  in this work  after recalling the motivation and classic definitions of reproducible research  we propose an updated overview of the main platforms that might be used for reproducible research  we then review the different libraries that are commonly used by the pattern recognition  computer vision  imaging and geometry processing communities  and we share our experience of developing a research library  in the third part  new advanced editorial investments will be presented  such as the ipol journal or other ipol inspired new initiatives like ovd saas ,8.808496,4.641508,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
From AI ethics principles to data science practice: a reflection and a gap analysis based on recent frameworks and practical experience,"In the field of AI ethics, after the introduction of ethical frameworks and the evaluation thereof, we seem to have arrived at a third wave in which the operationalisation of ethics is central. Operationalisation is required, since ethics frameworks are often not suited to be used by data scientists in the development of AI-based services or products. Therefore, in this paper, we aim to contribute to this third wave by mapping AI ethical principles onto the lifecycle of an AI-based digital service or product and combining it with an explicit governance model to clarify responsibilities in operationalisation. We then discuss practical, conceptual, and political implications of this analysis to end with key challenges around operationalising AI ethics.",in the field of ai ethics  after the introduction of ethical frameworks and the evaluation thereof  we seem to have arrived at a third wave in which the operationalisation of ethics is central  operationalisation is required  since ethics frameworks are often not suited to be used by data scientists in the development of ai based services or products  therefore  in this paper  we aim to contribute to this third wave by mapping ai ethical principles onto the lifecycle of an ai based digital service or product and combining it with an explicit governance model to clarify responsibilities in operationalisation  we then discuss practical  conceptual  and political implications of this analysis to end with key challenges around operationalising ai ethics ,11.9221525,5.7369943,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Resource efficient aortic distensibility calculation by end to end spatiotemporal learning of aortic lumen from multicentre multivendor multidisease CMR images,"Aortic distensibility (AD) is important for the prognosis of multiple cardiovascular diseases. We propose a novel resource-efficient deep learning (DL) model, inspired by the bi-directional ConvLSTM U-Net with densely connected convolutions, to perform end-to-end hierarchical learning of the aorta from cine cardiovascular MRI towards streamlining AD quantification. Unlike current DL aortic segmentation approaches, our pipeline: (i) performs simultaneous spatio-temporal learning of the video input, (ii) combines the feature maps from the encoder and decoder using non-linear functions, and (iii) takes into account the high class imbalance. By using multi-centre multi-vendor data from a highly heterogeneous patient cohort, we demonstrate that the proposed method outperforms the state-of-the-art method in terms of accuracy and at the same time it consumes \(\sim\) 3.9 times less fuel and generates \(\sim\) 2.8 less carbon emissions. Our model could provide a valuable tool for exploring genome-wide associations of the AD with the cognitive performance in large-scale biomedical databases. By making energy usage and carbon emissions explicit, the presented work aligns with efforts to keep DLâ€™s energy requirements and carbon cost in check. The improved resource efficiency of our pipeline might open up the more systematic DL-powered evaluation of the MRI-derived aortic stiffness.",aortic distensibility  ad  is important for the prognosis of multiple cardiovascular diseases  we propose a novel resource efficient deep learning  dl  model  inspired by the bi directional convlstm u net with densely connected convolutions  to perform end to end hierarchical learning of the aorta from cine cardiovascular mri towards streamlining ad quantification  unlike current dl aortic segmentation approaches  our pipeline   i  performs simultaneous spatio temporal learning of the video input   ii  combines the feature maps from the encoder and decoder using non linear functions  and  iii  takes into account the high class imbalance  by using multi centre multi vendor data from a highly heterogeneous patient cohort  we demonstrate that the proposed method outperforms the state of the art method in terms of accuracy and at the same time it consumes    sim       times less fuel and generates    sim       less carbon emissions  our model could provide a valuable tool for exploring genome wide associations of the ad with the cognitive performance in large scale biomedical databases  by making energy usage and carbon emissions explicit  the presented work aligns with efforts to keep dl   s energy requirements and carbon cost in check  the improved resource efficiency of our pipeline might open up the more systematic dl powered evaluation of the mri derived aortic stiffness ,6.0308094,5.934674,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Introduction: The Data Science Process,"June 1918. A subcommittee consisting of Prof. Eddington, Sir Dyson, and others made arrangements for expeditions to Sobral in North Brazil and to the island of Principe. The goal of these two expeditions? To collect some data during the eclipse that was to occur on May 29, 1919â€¦",june       a subcommittee consisting of prof  eddington  sir dyson  and others made arrangements for expeditions to sobral in north brazil and to the island of principe  the goal of these two expeditions  to collect some data during the eclipse that was to occur on may            ,3.9377584,4.8399615,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
How do programmers fix bugs as workarounds? An empirical study on Apache projects,"In software development, issue tracker systems are widely used to manage bug reports. In such a system, a bug report can be filed, diagnosed, assigned, and fixed. In the standard process, a bug can be resolved as fixed, invalid, duplicated, or wonâ€™t fix. Although the above resolutions are well-defined and easy to understand, a bug report can end with a less -known resolution, i.e., a workaround. Compared with other resolutions, the definition of workarounds is more ambiguous. Besides the problem that is reported in a bug report, the resolution of a workaround raises more questions. Some questions are important for users, especially those programmers who build their projects upon others (e.g., libraries). Although some early studies have been conducted to analyze API workarounds, many research questions on workarounds are still open. For example, which bugs are resolved as workarounds? Why is a bug report resolved as a workaround? What are the repairs and impacts of workarounds? In this paper, we conduct the first empirical study to explore the above research questions. In particular, we analyzed 200 real workarounds that were collected from 81 Apache projects. Our results lead to eight findings and answers to all the above questions. For example, if bug reports are resolved as workarounds, their problems often either arise in external projects (40%) or reside in programming environments (23.5%). Although the problems of some workarounds (38.5%) reside in the project where they are reported, it is difficult to fix them fully and perfectly. Our findings are useful to understand workarounds, and to improve software projects and issue trackers.",in software development  issue tracker systems are widely used to manage bug reports  in such a system  a bug report can be filed  diagnosed  assigned  and fixed  in the standard process  a bug can be resolved as fixed  invalid  duplicated  or won   t fix  although the above resolutions are well defined and easy to understand  a bug report can end with a less  known resolution  i e   a workaround  compared with other resolutions  the definition of workarounds is more ambiguous  besides the problem that is reported in a bug report  the resolution of a workaround raises more questions  some questions are important for users  especially those programmers who build their projects upon others  e g   libraries   although some early studies have been conducted to analyze api workarounds  many research questions on workarounds are still open  for example  which bugs are resolved as workarounds  why is a bug report resolved as a workaround  what are the repairs and impacts of workarounds  in this paper  we conduct the first empirical study to explore the above research questions  in particular  we analyzed     real workarounds that were collected from    apache projects  our results lead to eight findings and answers to all the above questions  for example  if bug reports are resolved as workarounds  their problems often either arise in external projects       or reside in programming environments          although the problems of some workarounds         reside in the project where they are reported  it is difficult to fix them fully and perfectly  our findings are useful to understand workarounds  and to improve software projects and issue trackers ,9.573464,7.3054047,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
How Leaders Should Think and Talk About AI,"When you consider the tremendous range of national security missions, the existing systems in operation, and the global footprint of Americaâ€™s national security interests, AI leaders will need to make wise choices about the problems on which they will focus resources. This requires a dialogue between AI leaders and their customers. This dialogue should not begin with or revolve around AI models or some framework that seeks to explain AI in a single conceptual graphic. These conversations need to focus on customersâ€™ mission problems and the potential impact of AI. From this central focus, the four types of AI projectsâ€”all of which share the same technical DNAâ€”will keep the dialogue practical and accessible to all. AI technology has transformational potential, but only if it is used to fundamentally change and improve the operations that drive mission outcomes. That is the central focusâ€”not algorithms, not tech, but mission outcomes.",when you consider the tremendous range of national security missions  the existing systems in operation  and the global footprint of america   s national security interests  ai leaders will need to make wise choices about the problems on which they will focus resources  this requires a dialogue between ai leaders and their customers  this dialogue should not begin with or revolve around ai models or some framework that seeks to explain ai in a single conceptual graphic  these conversations need to focus on customers    mission problems and the potential impact of ai  from this central focus  the four types of ai projects   all of which share the same technical dna   will keep the dialogue practical and accessible to all  ai technology has transformational potential  but only if it is used to fundamentally change and improve the operations that drive mission outcomes  that is the central focus   not algorithms  not tech  but mission outcomes ,11.304682,6.138798,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Data Science Projects,"We began this book with an introduction to the data science process in Part 1. Then in Part 2, we saw the various classes of problems that could be relevant to your business and how the data science process is applied in each of those cases. In Part 3, we looked at the various techniques and technologies that go into executing each step of the data science process, culminating in a reference architecture that can be tailored to your specific team. And in the last couple of chapters, we have seen the various roles that go into forming an interdisciplinary team that executes the data science process end-end.",we began this book with an introduction to the data science process in part    then in part    we saw the various classes of problems that could be relevant to your business and how the data science process is applied in each of those cases  in part    we looked at the various techniques and technologies that go into executing each step of the data science process  culminating in a reference architecture that can be tailored to your specific team  and in the last couple of chapters  we have seen the various roles that go into forming an interdisciplinary team that executes the data science process end end ,9.409664,6.2920074,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
In-situ quality assurance for electron-based additive manufacturing by electron optical observation,"Well-established non-destructive testing methods in aero engine industry are time-consuming and expensive with a negative impact on economic viability, especially for parts from additive manufacturing. To improve the economics of electron beam powder bed fusion (PBF-EB), the detection and evaluation of backscattered electrons (BSEs) during the PBF-EB process is a highly promising approach. Electron optical (ELO) images are obtained using the electron beam in a way comparable with scanning electron microscopy. The method is capable of detecting defects (e.g., pores) and the part contour for each layer, thus providing information about the quality of the resulting component. The estimation of dimensional and geometrical accuracy is obtained from the comparison of design data (target geometry) with ELO data (actual geometry). The purpose of our investigation is the utilization of backscattered electron detection as a non-destructive in-situ testing method for additively manufactured aero engine parts of the second component class which includes turbine blades, fuel nozzles and casings.",well established non destructive testing methods in aero engine industry are time consuming and expensive with a negative impact on economic viability  especially for parts from additive manufacturing  to improve the economics of electron beam powder bed fusion  pbf eb   the detection and evaluation of backscattered electrons  bses  during the pbf eb process is a highly promising approach  electron optical  elo  images are obtained using the electron beam in a way comparable with scanning electron microscopy  the method is capable of detecting defects  e g   pores  and the part contour for each layer  thus providing information about the quality of the resulting component  the estimation of dimensional and geometrical accuracy is obtained from the comparison of design data  target geometry  with elo data  actual geometry   the purpose of our investigation is the utilization of backscattered electron detection as a non destructive in situ testing method for additively manufactured aero engine parts of the second component class which includes turbine blades  fuel nozzles and casings ,3.1465285,4.8840184,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Distinct classes and subclasses of antibodies to hemolysin co-regulated protein 1 and O-polysaccharide and correlation with clinical characteristics of melioidosis patients,"Melioidosis is a tropical infectious disease caused by Burkholderia pseudomallei that results in high mortality. Hemolysin co-regulated protein 1 (Hcp1) and O-polysaccharide (OPS) are vaccine candidates and potential diagnostic antigens. The correlation of classes/subclasses of antibodies against these antigens with clinical characteristics of melioidosis patients is unknown. Antibodies in plasma samples from melioidosis patients and healthy donors were quantified by ELISA and compared with clinical features. In melioidosis patients, Hcp1 induced high IgG levels. OPS induced high IgG and IgA levels. The area under receiver operating characteristic curve (AUROCC) to discriminate melioidosis cases from healthy donors was highest for anti-Hcp1 IgG (0.92) compared to anti-Hcp1 IgA or IgM. In contrast, AUROCC for anti-OPS for IgG (0.91) and IgA (0.92) were comparable. Anti-Hcp1 IgG1 and anti-OPS IgG2 had the greatest AUROCCs (0.87 and 0.95, respectively) compared to other IgG subclasses for each antigen. Survivors had significantly higher anti-Hcp1 IgG3 levels than non-survivors. Male melioidosis patients with diabetes had higher anti-OPS IgA levels than males without diabetes. Thus, diverse and specific antibody responses are associated with distinct clinical characteristics in melioidosis, confirming the diagnostic utility of these responses and providing new insights into immune mechanisms.",melioidosis is a tropical infectious disease caused by burkholderia pseudomallei that results in high mortality  hemolysin co regulated protein    hcp   and o polysaccharide  ops  are vaccine candidates and potential diagnostic antigens  the correlation of classes subclasses of antibodies against these antigens with clinical characteristics of melioidosis patients is unknown  antibodies in plasma samples from melioidosis patients and healthy donors were quantified by elisa and compared with clinical features  in melioidosis patients  hcp  induced high igg levels  ops induced high igg and iga levels  the area under receiver operating characteristic curve  aurocc  to discriminate melioidosis cases from healthy donors was highest for anti hcp  igg        compared to anti hcp  iga or igm  in contrast  aurocc for anti ops for igg        and iga        were comparable  anti hcp  igg  and anti ops igg  had the greatest auroccs       and       respectively  compared to other igg subclasses for each antigen  survivors had significantly higher anti hcp  igg  levels than non survivors  male melioidosis patients with diabetes had higher anti ops iga levels than males without diabetes  thus  diverse and specific antibody responses are associated with distinct clinical characteristics in melioidosis  confirming the diagnostic utility of these responses and providing new insights into immune mechanisms ,4.7772408,2.9192052,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
ML Tools for the Web: A Way for Rapid Prototyping and HCI Research,"Machine learning (ML) has become a powerful tool with the potential to enable new interactions and user experiences. Although the use of ML in HCI research is growing, the process of prototyping and deploying ML remains challenging. We claim that ML tools designed to be used on the Web are suitable for fast prototyping and HCI research. In this chapter, we review literature, current technologies, and use cases of ML tools for the Web. We also provide a case study, using TensorFlow.jsâ€”a major Web ML library, to demonstrate how to prototype with Web ML tools in different prototyping scenarios. At the end, we discuss challenges and future directions of designing tools for fast prototyping and research.",machine learning  ml  has become a powerful tool with the potential to enable new interactions and user experiences  although the use of ml in hci research is growing  the process of prototyping and deploying ml remains challenging  we claim that ml tools designed to be used on the web are suitable for fast prototyping and hci research  in this chapter  we review literature  current technologies  and use cases of ml tools for the web  we also provide a case study  using tensorflow js   a major web ml library  to demonstrate how to prototype with web ml tools in different prototyping scenarios  at the end  we discuss challenges and future directions of designing tools for fast prototyping and research ,8.626334,7.735076,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Human-Centered AI for Manufacturing â€“ Design Principles for Industrial AI-Based Services,"AI-based services are becoming more and more common in manufacturing; however, the development, implementation, and operation of these services are associated with challenges. The design of Human-Centered AI (HCAI) is one approach to address these challenges. Design guidelines and principles are provided to assist AI developers in the design of HCAI. However, these principles are currently defined for AI in general and not for specific application contexts. The aim of this work is to analyze whether existing design principles for HCAI are transferable to IAI-based services in manufacturing and how they can be integrated into the development process. In an explorative-qualitative research design, the design pattern of the Peopleâ€‰+â€‰AI Guidebook by the PAIR from Google were analyzed regarding their applicability in manufacturing environments. The finding show that a transfer of the design principles is generally possible. According to the experts, 15 of the design patterns have a direct influence on the perception of Industrial AI-based services by end-users or management and can thus increase the acceptance of them. Finally, the design patterns were assessed in terms of their application relevance and complexity in manufacturing.
 Keywords
 Industrial AI
 Human-Centered AI
 Design Principles",ai based services are becoming more and more common in manufacturing  however  the development  implementation  and operation of these services are associated with challenges  the design of human centered ai  hcai  is one approach to address these challenges  design guidelines and principles are provided to assist ai developers in the design of hcai  however  these principles are currently defined for ai in general and not for specific application contexts  the aim of this work is to analyze whether existing design principles for hcai are transferable to iai based services in manufacturing and how they can be integrated into the development process  in an explorative qualitative research design  the design pattern of the people       ai guidebook by the pair from google were analyzed regarding their applicability in manufacturing environments  the finding show that a transfer of the design principles is generally possible  according to the experts     of the design patterns have a direct influence on the perception of industrial ai based services by end users or management and can thus increase the acceptance of them  finally  the design patterns were assessed in terms of their application relevance and complexity in manufacturing   keywords  industrial ai  human centered ai  design principles,11.226206,7.510183,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Impact of the acceleration voltage on the processing of Î³-TiAl via electron beam powder bed fusion,"Electron beam powder bed fusion (PBF-EB) is an additive manufacturing (AM) technology that is maturing toward broader industrial applications. However, conventional PBF-EB machines are still limited to 60 kV acceleration voltage (Ub). Therefore, this work presents the first results of a novel prototype PBF-EB machine capable of acceleration voltages up to 150 kV. In general, a higher acceleration voltage enables larger beam powers, which shortens the pre-heating time and makes a larger pre-heating area available. Moreover, a lower beam current is required for the same power during pre-heating, enabling the processing of a gamma titanium aluminide (Î³-TiAl) alloy without any process gas. Î³-TiAl cuboids are built in a vacuum atmosphere (2Ã—10â€“5 mbar) with 60 , 125 , and 150 kV acceleration voltage. Additionally, the deeper penetration of higher acceleration voltage should be beneficial for melting as well. Cuboids are examined for defects and aluminum content to show the influence of the acceleration voltage on the process window, melt pool formation, gas porosity, and aluminum evaporation. In short, this work aims to investigate the impact of a higher acceleration voltage on the whole PBF-EB process.",electron beam powder bed fusion  pbf eb  is an additive manufacturing  am  technology that is maturing toward broader industrial applications  however  conventional pbf eb machines are still limited to    kv acceleration voltage  ub   therefore  this work presents the first results of a novel prototype pbf eb machine capable of acceleration voltages up to     kv  in general  a higher acceleration voltage enables larger beam powers  which shortens the pre heating time and makes a larger pre heating area available  moreover  a lower beam current is required for the same power during pre heating  enabling the processing of a gamma titanium aluminide     tial  alloy without any process gas     tial cuboids are built in a vacuum atmosphere            mbar  with            and     kv acceleration voltage  additionally  the deeper penetration of higher acceleration voltage should be beneficial for melting as well  cuboids are examined for defects and aluminum content to show the influence of the acceleration voltage on the process window  melt pool formation  gas porosity  and aluminum evaporation  in short  this work aims to investigate the impact of a higher acceleration voltage on the whole pbf eb process ,3.1518612,4.6454115,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
A Proximal Point Algorithm with Quasi-distance in Multi-objective Optimization,"In this paper, we present a generalized vector-valued proximal point algorithm for convex and unconstrained multi-objective optimization problems. Our main contribution is the introduction of quasi-distance mappings in the regularized subproblems, which has important applications in the computer theory and economics, among others. By considering a certain class of quasi-distances, that are Lipschitz continuous and coercive in any of their arguments, we show that any sequence generated by our algorithm is bounded and its accumulation points are weak Pareto solutions.",in this paper  we present a generalized vector valued proximal point algorithm for convex and unconstrained multi objective optimization problems  our main contribution is the introduction of quasi distance mappings in the regularized subproblems  which has important applications in the computer theory and economics  among others  by considering a certain class of quasi distances  that are lipschitz continuous and coercive in any of their arguments  we show that any sequence generated by our algorithm is bounded and its accumulation points are weak pareto solutions ,3.2582376,7.9687104,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
DevOps Basics and Variations,"Software development processes and the release requirements can change over time in order to continue bringing value to customers and gaining market adoption. To scale up and get some early feedback, many organizations have adopted a frequent release methodology for new features or defect fixes. These releases are deployed to the production system as often as once a week, and sometimes they are even once a day, once an hour, or even every ten seconds. To maintain this edge in the market or gain this quick feedback cycle, companies are adopting DevOps practices such as continuous delivery and continuous deployment. In this chapter, you will get an introduction to DevOps concepts and practices.",software development processes and the release requirements can change over time in order to continue bringing value to customers and gaining market adoption  to scale up and get some early feedback  many organizations have adopted a frequent release methodology for new features or defect fixes  these releases are deployed to the production system as often as once a week  and sometimes they are even once a day  once an hour  or even every ten seconds  to maintain this edge in the market or gain this quick feedback cycle  companies are adopting devops practices such as continuous delivery and continuous deployment  in this chapter  you will get an introduction to devops concepts and practices ,9.466236,6.654872,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Building Models,"In this chapter, we will go over how to build a simple logistic regression model in both scikit-learn and PySpark. We will also go over the process of k-fold cross validation to tune a hyperparameter in scikit-learn.",in this chapter  we will go over how to build a simple logistic regression model in both scikit learn and pyspark  we will also go over the process of k fold cross validation to tune a hyperparameter in scikit learn ,7.7239995,7.69822,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
A novel botnet attack detection for IoT networks based on communication graphs,"Abstract
 Intrusion detection systems have been proposed for the detection of botnet attacks. Various types of centralized or distributed cloud-based machine learning and deep learning models have been suggested. However, the emergence of the Internet of Things (IoT) has brought about a huge increase in connected devices, necessitating a different approach. In this paper, we propose to perform detection on IoT-edge devices. The suggested architecture includes an anomaly intrusion detection system in the application layer of IoT-edge devices, arranged in software-defined networks. IoT-edge devices request information from the software-defined networks controller about their own behaviour in the network. This behaviour is represented by communication graphs and is novel for IoT networks. This representation better characterizes the behaviour of the device than the traditional analysis of network traffic, with a lower volume of information. Botnet attack scenarios are simulated with the IoT-23 dataset. Experimental results show that attacks are detected with high accuracy using a deep learning model with low device memory requirements and significant storage reduction for training.
 Graphical abstract",abstract  intrusion detection systems have been proposed for the detection of botnet attacks  various types of centralized or distributed cloud based machine learning and deep learning models have been suggested  however  the emergence of the internet of things  iot  has brought about a huge increase in connected devices  necessitating a different approach  in this paper  we propose to perform detection on iot edge devices  the suggested architecture includes an anomaly intrusion detection system in the application layer of iot edge devices  arranged in software defined networks  iot edge devices request information from the software defined networks controller about their own behaviour in the network  this behaviour is represented by communication graphs and is novel for iot networks  this representation better characterizes the behaviour of the device than the traditional analysis of network traffic  with a lower volume of information  botnet attack scenarios are simulated with the iot    dataset  experimental results show that attacks are detected with high accuracy using a deep learning model with low device memory requirements and significant storage reduction for training   graphical abstract,3.244709,5.472592,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Multi-metric Approach for Decomposition of Microservice-Based Data Science Workflows,"To support fast development cycles in data science, microservice architectures are becoming increasingly important. However, while the design and identification of microservices in transaction-oriented applications are already widely studied, software architects lack support for data science workflows. The identification of microservices for data science workflows differs due to high volume and velocity characteristics.
 With this work, we aim to present a multi-metric approach for decomposition of microservice-based data science workflows. First, we select different metrics and evaluate their impact on workflow execution under different workload and data conditions. Within the approach, we provide a software architecture that enables microservice architectures to be deployed concurrently in cloud environments considering microservice design patterns such as orchestration of choreography. This architecture can be used to run real-world experiments, aggregate logs and analyze them in an automated way with respect to our chosen metrics. We evaluated our approach using a real-world data science workflow for automated startup assessments.
 Our work has both practical, theoretical and economic implications. Practically, it can support software architects and data scientists in architecting microservices. In this context, it also has implications for MLOps, as microservices can be used to train and deploy ML models. Theoretically, our software architecture can be used for other research comparing microservice architectures. Economically, we also achieve business impact by looking at the cost of microservice architectures based on service activation time.
 Keywords
 Data Science Workflow
 Microservice Architecture
 Microservice Decomposition
 Data Science Use Case",to support fast development cycles in data science  microservice architectures are becoming increasingly important  however  while the design and identification of microservices in transaction oriented applications are already widely studied  software architects lack support for data science workflows  the identification of microservices for data science workflows differs due to high volume and velocity characteristics   with this work  we aim to present a multi metric approach for decomposition of microservice based data science workflows  first  we select different metrics and evaluate their impact on workflow execution under different workload and data conditions  within the approach  we provide a software architecture that enables microservice architectures to be deployed concurrently in cloud environments considering microservice design patterns such as orchestration of choreography  this architecture can be used to run real world experiments  aggregate logs and analyze them in an automated way with respect to our chosen metrics  we evaluated our approach using a real world data science workflow for automated startup assessments   our work has both practical  theoretical and economic implications  practically  it can support software architects and data scientists in architecting microservices  in this context  it also has implications for mlops  as microservices can be used to train and deploy ml models  theoretically  our software architecture can be used for other research comparing microservice architectures  economically  we also achieve business impact by looking at the cost of microservice architectures based on service activation time   keywords  data science workflow  microservice architecture  microservice decomposition  data science use case,9.415776,3.683283,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Getting Started: Data Analysis,"In this chapter, we will go over the premise of the problem we are attempting to solve with the machine learning solution we want to operationalize. We will also begin data analysis and feature engineering of our data set.",in this chapter  we will go over the premise of the problem we are attempting to solve with the machine learning solution we want to operationalize  we will also begin data analysis and feature engineering of our data set ,8.768179,7.169276,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
"End to End Agile and Automated Machine Learning Framework for Trustworthy, Reliable and Sustainable Artificial Intelligence","Artificial Intelligence is playing pivotal role in automation of processes that were considered hard problems previously, but trustworthiness of these systems is still under question as many of these systems fail to meet expectations. Trustworthiness of artificial intelligence based systems depend on many factors. This paper analyzes human trust lifecycle and proposes an end to end agile and automated machine learning framework for automation of development, deployment, monitoring, and enhancements of AI/ML processes. Further this paper presents results of initial deployments of proposed framework and compares them with benchmark results.
 Keywords
 Agile development and deployment
 AI/ML
 Automated machine learning
 Trustworthy artificial intelligence",artificial intelligence is playing pivotal role in automation of processes that were considered hard problems previously  but trustworthiness of these systems is still under question as many of these systems fail to meet expectations  trustworthiness of artificial intelligence based systems depend on many factors  this paper analyzes human trust lifecycle and proposes an end to end agile and automated machine learning framework for automation of development  deployment  monitoring  and enhancements of ai ml processes  further this paper presents results of initial deployments of proposed framework and compares them with benchmark results   keywords  agile development and deployment  ai ml  automated machine learning  trustworthy artificial intelligence,9.860934,4.9294553,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
From Source Code to Model Service: A Frameworkâ€™s Perspective,"In the current IT world, machine learning has become a powerful driving force for the development of computer science. The entire life cycle of machine learning includes data processing, code development, model training, model release, and other processes. Although there are currently mature machine learning development frameworks such as TensorFlow and PyTorch, help algorithm engineers develop quickly. However, data import, code deployment, model release and other links in the machine learning process still need to be done manually. These engineering problems distract the energy of algorithm engineering and reduce the iterative efficiency of the model. At the same time, cloud-native has become the development direction of current software systems. If machine learning can be based on cloud-native technology, it will significantly liberate productivity. Therefore, there is an urgent need to develop a one-stop machine learning platform based on cloud-native technologies.
 Keywords
 Machine learning
 CI/CD
 Workflow
 Model deploy",in the current it world  machine learning has become a powerful driving force for the development of computer science  the entire life cycle of machine learning includes data processing  code development  model training  model release  and other processes  although there are currently mature machine learning development frameworks such as tensorflow and pytorch  help algorithm engineers develop quickly  however  data import  code deployment  model release and other links in the machine learning process still need to be done manually  these engineering problems distract the energy of algorithm engineering and reduce the iterative efficiency of the model  at the same time  cloud native has become the development direction of current software systems  if machine learning can be based on cloud native technology  it will significantly liberate productivity  therefore  there is an urgent need to develop a one stop machine learning platform based on cloud native technologies   keywords  machine learning  ci cd  workflow  model deploy,7.9323907,6.8589993,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
AIoT.exe,"The starting point of the discussion on technical execution following will be a deep dive into our topics from the AIoT 101 section, namely, AI, Data, Digital Twin, IoT, and Hardware: the key ingredients of many AIoT products and solutions. Each topic will be specifically looked at from the execution perspective (hence the play with â€œ*.exeâ€), with a focus on both technology and organization. For each topic, we will also discuss how the technical pipeline and pipeline organization should be addressed and how it can all be integrated (mainly through the IoT perspective) (Fig. 24.1).",the starting point of the discussion on technical execution following will be a deep dive into our topics from the aiot     section  namely  ai  data  digital twin  iot  and hardware  the key ingredients of many aiot products and solutions  each topic will be specifically looked at from the execution perspective  hence the play with      exe      with a focus on both technology and organization  for each topic  we will also discuss how the technical pipeline and pipeline organization should be addressed and how it can all be integrated  mainly through the iot perspective   fig        ,10.795262,5.9598203,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Analysis: Flawed Datasets of Monkeypox Skin Images,"The self-proclaimed first publicly available dataset of Monkeypox skin images consists of medically irrelevant images extracted from Google and photography repositories through a process denominated web-scrapping. Yet, this did not stop other researchers from employing it to build Machine Learning (ML) solutions aimed at computer-aided diagnosis of Monkeypox and other viral infections presenting skin lesions. Neither did it stop the reviewers or editors from publishing these subsequent works in peer-reviewed journals. Several of these works claimed extraordinary performance in the classification of Monkeypox, Chickenpox and Measles, employing ML and the aforementioned dataset. In this work, we analyse the initiator work that has catalysed the development of several ML solutions, and whose popularity is continuing to grow. Further, we provide a rebuttal experiment that showcases the risks of such methodologies, proving that the ML solutions do not necessarily obtain their performance from the features relevant to the diseases at issue.",the self proclaimed first publicly available dataset of monkeypox skin images consists of medically irrelevant images extracted from google and photography repositories through a process denominated web scrapping  yet  this did not stop other researchers from employing it to build machine learning  ml  solutions aimed at computer aided diagnosis of monkeypox and other viral infections presenting skin lesions  neither did it stop the reviewers or editors from publishing these subsequent works in peer reviewed journals  several of these works claimed extraordinary performance in the classification of monkeypox  chickenpox and measles  employing ml and the aforementioned dataset  in this work  we analyse the initiator work that has catalysed the development of several ml solutions  and whose popularity is continuing to grow  further  we provide a rebuttal experiment that showcases the risks of such methodologies  proving that the ml solutions do not necessarily obtain their performance from the features relevant to the diseases at issue ,8.400706,7.261601,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Deploying an AI Solution (Productionizing and Containerization),"Productionizing an AI model is not easy. Many AI projects get stuck at Proof of Concept (PoC) phase, with Gartner suggesting 50% of IT leaders will struggle to move their AI projects past demo/prototype and into production. There is often organizational confusion between the two aims of creating a POC and a production-grade Enterprise AI solution, partly from the lack of expertise from the rest of the business. There is no point, after all, in productionizing if the rest of the workforce isnâ€™t, at least at a basic level, upskilled on AI, how to use it and its benefits and importantly, how to interface or engage with it or how to use it.",productionizing an ai model is not easy  many ai projects get stuck at proof of concept  poc  phase  with gartner suggesting     of it leaders will struggle to move their ai projects past demo prototype and into production  there is often organizational confusion between the two aims of creating a poc and a production grade enterprise ai solution  partly from the lack of expertise from the rest of the business  there is no point  after all  in productionizing if the rest of the workforce isn   t  at least at a basic level  upskilled on ai  how to use it and its benefits and importantly  how to interface or engage with it or how to use it ,11.4406,6.95668,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Carbon and Cataracts: How to Make Your Service Sustainable,"Environmental considerations and other resource constraints make it impossible for the current cataract surgical practices of high-income countries to be continued far into the future. The evidence to support the need for change and the opportunities for change are presented. Individual ophthalmologists can adapt their practice to make it more sustainable, but systemic shifts in attitudes and practices will be needed nationally and internationally to transform our cataract services into those which can be continued in perpetuity. In particular, policies that are ostensibly designed to promote safety, end up putting patients at risk as they increase the per-case carbon footprint of one of the earthâ€™s most frequently undertaken surgical procedure.
 Keywords
 Cataract
 Sustainability
 Triple bottom line
 Environment
 Carbon
 Patient safety
 Life cycle assessment
 Sustainable healthcare",environmental considerations and other resource constraints make it impossible for the current cataract surgical practices of high income countries to be continued far into the future  the evidence to support the need for change and the opportunities for change are presented  individual ophthalmologists can adapt their practice to make it more sustainable  but systemic shifts in attitudes and practices will be needed nationally and internationally to transform our cataract services into those which can be continued in perpetuity  in particular  policies that are ostensibly designed to promote safety  end up putting patients at risk as they increase the per case carbon footprint of one of the earth   s most frequently undertaken surgical procedure   keywords  cataract  sustainability  triple bottom line  environment  carbon  patient safety  life cycle assessment  sustainable healthcare,10.940013,5.531282,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Verifiable Machine Learning Models in Industrial IoT via Blockchain,"Imitation Learning from observation describes policy learning in a similar way to human learning. An agentâ€™s policy is trained by observing an expert performing a task. Although many state-only imitation learning approaches are based on adversarial imitation learning, one main drawback is that adversarial training is often unstable and lacks a reliable convergence estimator. If the true environment reward is unknown and cannot be used to select the best-performing model, this can result in bad real-world policy performance. We propose a non-adversarial learning-from-observations approach, together with an interpretable convergence and performance metric. Our training objective minimizes the Kulback-Leibler divergence (KLD) between the policy and expert state transition trajectories which can be optimized in a non-adversarial fashion. Such methods demonstrate improved robustness when learned density models guide the optimization. We further improve the sample efficiency by rewriting the KLD minimization as the Soft Actor Critic objective based on a modified reward using additional density models that estimate the environmentâ€™s forward and backward dynamics. Finally, we evaluate the effectiveness of our approach on well-known continuous control environments and show state-of-the-art performance while having a reliable performance estimator compared to several recent learning-from-observation methods.",imitation learning from observation describes policy learning in a similar way to human learning  an agent   s policy is trained by observing an expert performing a task  although many state only imitation learning approaches are based on adversarial imitation learning  one main drawback is that adversarial training is often unstable and lacks a reliable convergence estimator  if the true environment reward is unknown and cannot be used to select the best performing model  this can result in bad real world policy performance  we propose a non adversarial learning from observations approach  together with an interpretable convergence and performance metric  our training objective minimizes the kulback leibler divergence  kld  between the policy and expert state transition trajectories which can be optimized in a non adversarial fashion  such methods demonstrate improved robustness when learned density models guide the optimization  we further improve the sample efficiency by rewriting the kld minimization as the soft actor critic objective based on a modified reward using additional density models that estimate the environment   s forward and backward dynamics  finally  we evaluate the effectiveness of our approach on well known continuous control environments and show state of the art performance while having a reliable performance estimator compared to several recent learning from observation methods ,3.847634,7.2440534,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Imitation learning by state-only distribution matching,"The importance of machine learning (ML) has been increasing dramatically for years. From assistance systems to production optimisation to healthcare support, almost every area of daily life and industry is coming into contact with machine learning. Besides all the benefits ML brings, the lack of transparency and difficulty in creating traceability pose major risks. While solutions exist to make the training of machine learning models more transparent, traceability is still a major challenge. Ensuring the identity of a model is another challenge, as unnoticed modification of a model is also a danger when using ML. This paper proposes to create an ML Birth Certificate and ML Family Tree secured by blockchain technology. Important information about training and changes to the model through retraining can be stored in a blockchain and accessed by any user to create more security and traceability about an ML model.
 Keywords
 Machine learning
 Verifiability
 Blockchain
 Poisoning
 Cybersecurity",the importance of machine learning  ml  has been increasing dramatically for years  from assistance systems to production optimisation to healthcare support  almost every area of daily life and industry is coming into contact with machine learning  besides all the benefits ml brings  the lack of transparency and difficulty in creating traceability pose major risks  while solutions exist to make the training of machine learning models more transparent  traceability is still a major challenge  ensuring the identity of a model is another challenge  as unnoticed modification of a model is also a danger when using ml  this paper proposes to create an ml birth certificate and ml family tree secured by blockchain technology  important information about training and changes to the model through retraining can be stored in a blockchain and accessed by any user to create more security and traceability about an ml model   keywords  machine learning  verifiability  blockchain  poisoning  cybersecurity,5.274472,5.490661,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Miscellaneous,I want to ensure that my experience can add value to your own journey. This last chapter will present some best practices and lessons learned from my experience.,i want to ensure that my experience can add value to your own journey  this last chapter will present some best practices and lessons learned from my experience ,9.084199,6.690687,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
AI model transferability in healthcare: a sociotechnical perspective,"To deliver value in healthcare, artificial intelligence and machine learning models must be integrated not only into technology platforms but also into local human and organizational ecosystems and workflows. To realize the promised benefits of applying these models at scale, a roadmap of the challenges and potential solutions to sociotechnical transferability is needed.",to deliver value in healthcare  artificial intelligence and machine learning models must be integrated not only into technology platforms but also into local human and organizational ecosystems and workflows  to realize the promised benefits of applying these models at scale  a roadmap of the challenges and potential solutions to sociotechnical transferability is needed ,10.274434,7.4183702,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
The DataOps Factory,"Data science and analytics are in a broken state. A 2016 Klynveld Peat Marwick Goerdeler (KPMG) study of 2000 global data analytics decision-makers revealed that only 10% believe they excel in data quality, tools, and methodologies, and 60% say they are not very confident in their analytical insights.1 For every organization that finds measurable success from data science and analytics, several others struggle with data quality, the ability to get work into production, and generate meaningful ROI on investments in people or technology. DataOps is a cure for many of the problems facing data science and analytics today. By adopting DataOps, organizations can deliver data products in a consistent, reliable, fast, scalable, and repeatable process just like a factory.",data science and analytics are in a broken state  a      klynveld peat marwick goerdeler  kpmg  study of      global data analytics decision makers revealed that only     believe they excel in data quality  tools  and methodologies  and     say they are not very confident in their analytical insights   for every organization that finds measurable success from data science and analytics  several others struggle with data quality  the ability to get work into production  and generate meaningful roi on investments in people or technology  dataops is a cure for many of the problems facing data science and analytics today  by adopting dataops  organizations can deliver data products in a consistent  reliable  fast  scalable  and repeatable process just like a factory ,6.094467,4.6655188,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
"AutoML, AutoAI, and the Rise of NoLo UIs","In what is still so far a relatively short space of time, growth in machine and deep learning implementations in organizations across the world has been extraordinary. However, this hasnâ€™t always translated into commercial success, with disappointingly low adoption rates in the retail sector (11.5% in the UK) and just over 50% of prototypes ending up in production across all industries. Historically many solutions have been operationally siloed with PhD-level statisticians left to explain code-heavy technical models.",in what is still so far a relatively short space of time  growth in machine and deep learning implementations in organizations across the world has been extraordinary  however  this hasn   t always translated into commercial success  with disappointingly low adoption rates in the retail sector        in the uk  and just over     of prototypes ending up in production across all industries  historically many solutions have been operationally siloed with phd level statisticians left to explain code heavy technical models ,10.473073,7.1681895,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
AI and Data Management Architectures,"The AI capability in an IT landscape is more than just the icing on the cake. It is a core capability for forward-thinking, data-driven, innovative companies. While not just the icing, it is also not the whole cake. An AI organization has to integrate its components into the overall corporate application landscape â€“ and its own system landscape typically consists of more than just a few Jupyter notebooks. In other words: This chapter looks at the big architectural questions any AI organization faces that is more than just a one-man show.",the ai capability in an it landscape is more than just the icing on the cake  it is a core capability for forward thinking  data driven  innovative companies  while not just the icing  it is also not the whole cake  an ai organization has to integrate its components into the overall corporate application landscape     and its own system landscape typically consists of more than just a few jupyter notebooks  in other words  this chapter looks at the big architectural questions any ai organization faces that is more than just a one man show ,9.517946,3.80369,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Enterprise Machine Learning Serving,"In the previous chapter, we discussed the hosting of trained models and how we can use frameworks such as Flask to input and receive information that can be used in a business pipeline. Access to these models can be direct or through model servers to support enterprise solutions. In the previous chapter, we also discussed how models can be accessed directly through library imports. In this chapter, we will discuss component-based MLOps and how models can be packaged using Docker and distributed at scale using Kubernetes. The chapter will focus on enterprise-level solutions that containerise TensorFlow Serving for scalable model serving. Typically, to access GPUs through Docker using this configuration a Linux distribution is required. However, with new advances from Microsoft, the Linux Kernel can be embedded and accessed as a component directly within the OS using Windows Subsystem for Linux (WSL2). This overcomes the limitation of accessing GPUs with NVidia Docker runtime which is covered in this chapter. Currently, the only way to access the NVidia Docker runtime and GPU in Windows is to run WSL2.",in the previous chapter  we discussed the hosting of trained models and how we can use frameworks such as flask to input and receive information that can be used in a business pipeline  access to these models can be direct or through model servers to support enterprise solutions  in the previous chapter  we also discussed how models can be accessed directly through library imports  in this chapter  we will discuss component based mlops and how models can be packaged using docker and distributed at scale using kubernetes  the chapter will focus on enterprise level solutions that containerise tensorflow serving for scalable model serving  typically  to access gpus through docker using this configuration a linux distribution is required  however  with new advances from microsoft  the linux kernel can be embedded and accessed as a component directly within the os using windows subsystem for linux  wsl    this overcomes the limitation of accessing gpus with nvidia docker runtime which is covered in this chapter  currently  the only way to access the nvidia docker runtime and gpu in windows is to run wsl  ,7.7762556,7.581091,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Surgical Tool Datasets for Machine Learning Research: A Survey,"This paper is a comprehensive survey of datasets for surgical tool detection and related surgical data science and machine learning techniques and algorithms. The survey offers a high level perspective of current research in this area, analyses the taxonomy of approaches adopted by researchers using surgical tool datasets, and addresses key areas of research, such as the datasets used, evaluation metrics applied and deep learning techniques utilised. Our presentation and taxonomy provides a framework that facilitates greater understanding of current work, and highlights the challenges and opportunities for further innovative and useful research.",this paper is a comprehensive survey of datasets for surgical tool detection and related surgical data science and machine learning techniques and algorithms  the survey offers a high level perspective of current research in this area  analyses the taxonomy of approaches adopted by researchers using surgical tool datasets  and addresses key areas of research  such as the datasets used  evaluation metrics applied and deep learning techniques utilised  our presentation and taxonomy provides a framework that facilitates greater understanding of current work  and highlights the challenges and opportunities for further innovative and useful research ,6.8762712,4.2255907,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
AI Startup Landscape,"In the previous chapter, we built a conceptual understanding of the fundamental of AI techniques and their applications, the foundation of AI startups, and how AI helps enterprises become AI-first companies.",in the previous chapter  we built a conceptual understanding of the fundamental of ai techniques and their applications  the foundation of ai startups  and how ai helps enterprises become ai first companies ,11.287919,6.34361,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Developing Responsible AI Business Model,"In the age of mobile apps, Internet of things, or connected devices, we are in the process of creating more data by 2025, than the data generated cumulatively during 2011â€“2020. Data is one of the precious resources in todayâ€™s time and cannot be undermined (Antonio Neri, March 2020). Building and developing data and artificial intelligence & machine learning businesses that are based on Responsible Artificial Intelligence (AI) business models are critical to not just enable better sustainable businesses, but also be valued by stakeholders at large. This chapter will cover the approach towards Responsible AI business models.",in the age of mobile apps  internet of things  or connected devices  we are in the process of creating more data by       than the data generated cumulatively during              data is one of the precious resources in today   s time and cannot be undermined  antonio neri  march        building and developing data and artificial intelligence   machine learning businesses that are based on responsible artificial intelligence  ai  business models are critical to not just enable better sustainable businesses  but also be valued by stakeholders at large  this chapter will cover the approach towards responsible ai business models ,10.173457,7.5614157,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Analysis of heavy metal concentrations in soil using Kriging technique using remote sensing data,"The study addresses the challenging task of estimating toxic concentration in soils, focusing on Tirupur District, Tamilnadu, India, utilizing Landsat 8 imagery. Acknowledging the potential environmental repercussions, the research emphasizes the increase in pollutionâ€”air, water, and soilâ€”due to toxic concentrations, particularly heavy metals resulting from industrial activities. Soil pollution, a consequence of rapid industrial development near water sources, is a key concern, exacerbated by improper waste disposal. Utilizing Landsat 8 OLI images and relevant soil standards, the study employs Kriging and regression analysis for mapping heavy metal concentrations in the soil, both through remote sensing and field data. The correlation between remote sensing and in-situ data enhances result reliability. The findings categorize soil samples from 17 locations in Tirupur District based on pollution levels, distinguishing regions as highly polluted, not polluted, or moderately polluted. This research contributes valuable insights into the spatial distribution of heavy metal pollution, offering a foundation for targeted environmental management strategies in the identified regions.",the study addresses the challenging task of estimating toxic concentration in soils  focusing on tirupur district  tamilnadu  india  utilizing landsat   imagery  acknowledging the potential environmental repercussions  the research emphasizes the increase in pollution   air  water  and soil   due to toxic concentrations  particularly heavy metals resulting from industrial activities  soil pollution  a consequence of rapid industrial development near water sources  is a key concern  exacerbated by improper waste disposal  utilizing landsat   oli images and relevant soil standards  the study employs kriging and regression analysis for mapping heavy metal concentrations in the soil  both through remote sensing and field data  the correlation between remote sensing and in situ data enhances result reliability  the findings categorize soil samples from    locations in tirupur district based on pollution levels  distinguishing regions as highly polluted  not polluted  or moderately polluted  this research contributes valuable insights into the spatial distribution of heavy metal pollution  offering a foundation for targeted environmental management strategies in the identified regions ,4.5590677,2.159444,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Integrative molecular analyses define correlates of high B7-H3 expression in metastatic castrate-resistant prostate cancer,"B7-H3 (CD276) is an immune checkpoint overexpressed in prostate cancer with minimal expression in normal tissues and associated with poor prognosis, making it an excellent therapy target. We interrogated B7-H3 expression and its regulation in metastatic castration-resistant prostate cancer (mCRPC). We found greater expression of B7-H3 transcript relative to other immunotherapy targets (CTLA-4, PD-L1/2), including in tumors that lacked expression of prostate-specific membrane antigen (PSMA). Enzalutamide-resistant mCRPC cells demonstrated increased amounts of B7-H3, and this was associated with resistance signaling pathways. Using a machine-learning algorithm, the gene network of B7-H3 was strongly correlated with androgen receptor (AR) and AR co-factor (HOXB13, FOXA1) networks. In mCRPC samples, the B7-H3 promoter and distal enhancer regions exhibited enhanced transcriptional activity and were directly bound by AR and its co-factors. Altogether, our study characterizes molecular profiles and epigenetic regulation of B7-H3-expressing mCRPC tumors, which informs optimal precision-oncology approaches for mCRPC patients.",b  h   cd     is an immune checkpoint overexpressed in prostate cancer with minimal expression in normal tissues and associated with poor prognosis  making it an excellent therapy target  we interrogated b  h  expression and its regulation in metastatic castration resistant prostate cancer  mcrpc   we found greater expression of b  h  transcript relative to other immunotherapy targets  ctla    pd l      including in tumors that lacked expression of prostate specific membrane antigen  psma   enzalutamide resistant mcrpc cells demonstrated increased amounts of b  h   and this was associated with resistance signaling pathways  using a machine learning algorithm  the gene network of b  h  was strongly correlated with androgen receptor  ar  and ar co factor  hoxb    foxa   networks  in mcrpc samples  the b  h  promoter and distal enhancer regions exhibited enhanced transcriptional activity and were directly bound by ar and its co factors  altogether  our study characterizes molecular profiles and epigenetic regulation of b  h  expressing mcrpc tumors  which informs optimal precision oncology approaches for mcrpc patients ,3.8756585,2.915928,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Integrating reinforcement-learning-based vehicle dispatch algorithm into agent-based modeling of autonomous taxis,"While increasing number of studies are using agent-based models to study the potential environmental, economic, and social impacts of shared autonomous vehicles, the idle vehicle dispatching in these models is often simplified to heuristic rules. Because the system performance of an autonomous taxi fleet can be significantly affected by the vehicle dispatching algorithm, refining the vehicle dispatching can help us better evaluate the potential benefits and impacts of shared autonomous vehicle systems. The recent development of reinforcement-learning-based vehicle dispatching algorithms provides opportunities to improve autonomous vehicle system modeling with efficient and scalable vehicle dispatching. This study integrates a reinforcement learning algorithm into to an agent-based simulation model of a ride hailing system. Using an autonomous taxi fleet in New York City as a case study, we compared the system performance of using the proposed Deep Q-Network (DQN) method for dispatching decision with common rule-based and heuristic dispatch algorithms from relevant literatures. The results show that (1) DQN dispatches vehicles more conservatively (with less dispatching activities and distances) but achieved similar (slightly lower) rider service level with proactive dispatch methods; and (2) DQN outperformed all other dispatch methods evaluated in this study with significantly higher dispatch efficiency, as measured by the ratio of the number of extra riders served due to dispatching to the extra fleet dispatch distance.",while increasing number of studies are using agent based models to study the potential environmental  economic  and social impacts of shared autonomous vehicles  the idle vehicle dispatching in these models is often simplified to heuristic rules  because the system performance of an autonomous taxi fleet can be significantly affected by the vehicle dispatching algorithm  refining the vehicle dispatching can help us better evaluate the potential benefits and impacts of shared autonomous vehicle systems  the recent development of reinforcement learning based vehicle dispatching algorithms provides opportunities to improve autonomous vehicle system modeling with efficient and scalable vehicle dispatching  this study integrates a reinforcement learning algorithm into to an agent based simulation model of a ride hailing system  using an autonomous taxi fleet in new york city as a case study  we compared the system performance of using the proposed deep q network  dqn  method for dispatching decision with common rule based and heuristic dispatch algorithms from relevant literatures  the results show that     dqn dispatches vehicles more conservatively  with less dispatching activities and distances  but achieved similar  slightly lower  rider service level with proactive dispatch methods  and     dqn outperformed all other dispatch methods evaluated in this study with significantly higher dispatch efficiency  as measured by the ratio of the number of extra riders served due to dispatching to the extra fleet dispatch distance ,3.5751705,7.4034953,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
A Graph-Theoretic Approach to Multiobjective Permutation-Based Optimization,"A Generalized Coordinate Method (GCM) for linear permutation-based optimization is presented as a generalization of the Modified Coordinate Localization Method and Modified Coordinate Method is presented, and its applications to multiobjective linear optimization on permutations are outlined. The method is based on properties of linear function on a transposition graph, a decomposition of the graph, and extracting from it a multidimensional grid graph, where a directed search of an optimal solution is performed. Depending on the search parameters, GCM yields an exact or approximate solution to the original problem. An illustrative example is given for the method.
 Keywords
 Permutation-based optimization
 Vertex located set
 Convex extension
 Permutation set
 Permutohedron
 Transposition graph
 Skeleton graph
 Configuration graph
 Structural graph",a generalized coordinate method  gcm  for linear permutation based optimization is presented as a generalization of the modified coordinate localization method and modified coordinate method is presented  and its applications to multiobjective linear optimization on permutations are outlined  the method is based on properties of linear function on a transposition graph  a decomposition of the graph  and extracting from it a multidimensional grid graph  where a directed search of an optimal solution is performed  depending on the search parameters  gcm yields an exact or approximate solution to the original problem  an illustrative example is given for the method   keywords  permutation based optimization  vertex located set  convex extension  permutation set  permutohedron  transposition graph  skeleton graph  configuration graph  structural graph,3.074423,8.133665,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Machine learning in production,"Now that you hopefully feel more comfortable experimenting with machine learning and building applications using different models and inputs, letâ€™s talk about the different aspects of putting machine learning models and systems into production.",now that you hopefully feel more comfortable experimenting with machine learning and building applications using different models and inputs  let   s talk about the different aspects of putting machine learning models and systems into production ,9.024423,6.641575,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Model Deployment and Challenges,"You got a refresher on machine learning concepts in the previous chapter, so it is now logical to move to the next stage. What is machine learning deployment, and what are some of the common challenges when doing it?",you got a refresher on machine learning concepts in the previous chapter  so it is now logical to move to the next stage  what is machine learning deployment  and what are some of the common challenges when doing it ,8.774268,6.908279,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
AI in the Automotive Industry,"The transition to alternative powertrain systems and the increasing complexity of automotive software poses great challenges for the automotive industry. This is especially true when novel development paradigms profoundly change the previous tradition in terms of product development. AI is such a driver of change, which we will illuminate in this chapter with regard to its influence on the technical development of future vehicle platforms and mobility products. We will address both the product and the development process as well as the company side.",the transition to alternative powertrain systems and the increasing complexity of automotive software poses great challenges for the automotive industry  this is especially true when novel development paradigms profoundly change the previous tradition in terms of product development  ai is such a driver of change  which we will illuminate in this chapter with regard to its influence on the technical development of future vehicle platforms and mobility products  we will address both the product and the development process as well as the company side ,11.141139,6.3833113,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Cybersecurity Assessment Construction of Artificial Intelligence,"The development of artificial intelligence (AI) in the automotive sector is a major contributor to the increasing number of intelligent transportation systems. Especially, with the rapid emergence and evolution of machine learning and artificial intelligence (AI) capabilities the number of Al models used in the automotive industry has been developed. Within this context; as an automotive company; we have provided efficient and secure AI models that can be used in the autonomous driving industry, and we have regularly investigated and provided the necessary security attributes to ensure that the Al models used in the autonomous driving industry are equipped with the necessary security attributes. From this perspective, the aim of this paper is to provide an overview of the various aspects of the intellectual property eco-system, including the current status of standardization and academic perspectives, also highlights the potential of this area. For this purpose we have performed a D-patching attack on the Yolo v3 model (Mujahid, 2021) to compromise its integrity. The results show that these methods are effective in protecting the model, but they require additional costs to be considered. Finally, To prevent this attack, we proposed a set of countermeasures that can be used to detect the input testing dataset.
 Keywords
 Artificial Intelligence
 Cyber Security
 Artificial Neural Networks",the development of artificial intelligence  ai  in the automotive sector is a major contributor to the increasing number of intelligent transportation systems  especially  with the rapid emergence and evolution of machine learning and artificial intelligence  ai  capabilities the number of al models used in the automotive industry has been developed  within this context  as an automotive company  we have provided efficient and secure ai models that can be used in the autonomous driving industry  and we have regularly investigated and provided the necessary security attributes to ensure that the al models used in the autonomous driving industry are equipped with the necessary security attributes  from this perspective  the aim of this paper is to provide an overview of the various aspects of the intellectual property eco system  including the current status of standardization and academic perspectives  also highlights the potential of this area  for this purpose we have performed a d patching attack on the yolo v  model  mujahid        to compromise its integrity  the results show that these methods are effective in protecting the model  but they require additional costs to be considered  finally  to prevent this attack  we proposed a set of countermeasures that can be used to detect the input testing dataset   keywords  artificial intelligence  cyber security  artificial neural networks,5.1860504,4.0601225,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
A Reference Architecture Model for Big Data Systems in the Finance Sector,"In recent years there is a surge in the amount of digital data that are generated by financial organizations, which is driving the development and deployment of novel Big Data and Artificial Intelligence (AI) applications in the finance sector. Nevertheless, there is still no easy and standardized way for developing, deploying and operating data-intensive systems for digital finance. This chapter introduces a standards-based reference architecture model for architecting, implementing and deploying big data and AI systems in digital finance. The model introduces the main building blocks that comprise machine learning and data science pipelines for digital finance applications, while providing structuring principles for their integration in applications. Complementary viewpoints of the model are presented, including a logical view and considerations for developing and deploying applications compliant to the reference architecture. The chapter ends up presenting a few practical examples of the use of the reference model for developing data science pipelines for digital finance.
 Keywords
 Big data
 Machine learning
 Architecture
 Artificial intelligence
 Finance
 Insurance",in recent years there is a surge in the amount of digital data that are generated by financial organizations  which is driving the development and deployment of novel big data and artificial intelligence  ai  applications in the finance sector  nevertheless  there is still no easy and standardized way for developing  deploying and operating data intensive systems for digital finance  this chapter introduces a standards based reference architecture model for architecting  implementing and deploying big data and ai systems in digital finance  the model introduces the main building blocks that comprise machine learning and data science pipelines for digital finance applications  while providing structuring principles for their integration in applications  complementary viewpoints of the model are presented  including a logical view and considerations for developing and deploying applications compliant to the reference architecture  the chapter ends up presenting a few practical examples of the use of the reference model for developing data science pipelines for digital finance   keywords  big data  machine learning  architecture  artificial intelligence  finance  insurance,9.318254,5.5328,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Banking AI as a Service,"AI helps to process a large volume of data, process unstructured data, simulate human-like communication both as voice and textual, automate decision making, and automate complete banking processes. The existing technology is constrained by extremely limited capabilities in processing large volumes of unstructured data and automating decision making beyond rule engines. Therefore, AI can help to complete the automation of a business process and build a machine interface for customers, partners, and employees.",ai helps to process a large volume of data  process unstructured data  simulate human like communication both as voice and textual  automate decision making  and automate complete banking processes  the existing technology is constrained by extremely limited capabilities in processing large volumes of unstructured data and automating decision making beyond rule engines  therefore  ai can help to complete the automation of a business process and build a machine interface for customers  partners  and employees ,10.662365,6.312465,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Data Analytics in Action,"The previous chapters provided gentle introductions to various important topics in the area of data analytics. In this chapter, we present three real-life case studies that illustrate how the methods and approaches outlined in the previous chapters can be put into practice. The first case study shows how the Dutch company BagsID uses data analytics to improve the efficiency of luggage handling at airports. The second case study analyzes email communication between employees of a multinational service company to assess the efficacy of interventions aimed at stimulating the employeesâ€™ openness to innovation. The third case study considers how vehicle sensor data can be leveraged for Pay-How-You-Drive insurance policies. Together, the three case studies give a glimpse into the vast world of applied data analytics.
 Keywords
 Baggage handling
 BagsID
 Reidentification learning
 Software and AI engineering
 Information flows in service organizations
 Longitudinal social network analysis
 Relational event model
 CAN bus
 Pay-How-You-Drive insurance",the previous chapters provided gentle introductions to various important topics in the area of data analytics  in this chapter  we present three real life case studies that illustrate how the methods and approaches outlined in the previous chapters can be put into practice  the first case study shows how the dutch company bagsid uses data analytics to improve the efficiency of luggage handling at airports  the second case study analyzes email communication between employees of a multinational service company to assess the efficacy of interventions aimed at stimulating the employees    openness to innovation  the third case study considers how vehicle sensor data can be leveraged for pay how you drive insurance policies  together  the three case studies give a glimpse into the vast world of applied data analytics   keywords  baggage handling  bagsid  reidentification learning  software and ai engineering  information flows in service organizations  longitudinal social network analysis  relational event model  can bus  pay how you drive insurance,10.065348,5.773646,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Moving towards vertically integrated artificial intelligence development,"Substantial interest and investment in clinical artificial intelligence (AI) research has not resulted in widespread translation to deployed AI solutions. Current attention has focused on bias and explainability in AI algorithm development, external validity and model generalisability, and lack of equity and representation in existing data. While of great importance, these considerations also reflect a model-centric approach seen in published clinical AI research, which focuses on optimising architecture and performance of an AI model on best available datasets. However, even robustly built models using state-of-the-art algorithms may fail once tested in realistic environments due to unpredictability of real-world conditions, out-of-dataset scenarios, characteristics of deployment infrastructure, and lack of added value to clinical workflows relative to cost and potential clinical risks. In this perspective, we define a vertically integrated approach to AI development that incorporates early, cross-disciplinary, consideration of impact evaluation, data lifecycles, and AI production, and explore its implementation in two contrasting AI development pipelines: a scalable â€œAI factoryâ€ (Mayo Clinic, Rochester, United States), and an end-to-end cervical cancer screening platform for resource poor settings (Paps AI, Mbarara, Uganda). We provide practical recommendations for implementers, and discuss future challenges and novel approaches (including a decentralised federated architecture being developed in the NHS (AI4VBH, London, UK)). Growth in global clinical AI research continues unabated, and introduction of vertically integrated teams and development practices can increase the translational potential of future clinical AI projects.",substantial interest and investment in clinical artificial intelligence  ai  research has not resulted in widespread translation to deployed ai solutions  current attention has focused on bias and explainability in ai algorithm development  external validity and model generalisability  and lack of equity and representation in existing data  while of great importance  these considerations also reflect a model centric approach seen in published clinical ai research  which focuses on optimising architecture and performance of an ai model on best available datasets  however  even robustly built models using state of the art algorithms may fail once tested in realistic environments due to unpredictability of real world conditions  out of dataset scenarios  characteristics of deployment infrastructure  and lack of added value to clinical workflows relative to cost and potential clinical risks  in this perspective  we define a vertically integrated approach to ai development that incorporates early  cross disciplinary  consideration of impact evaluation  data lifecycles  and ai production  and explore its implementation in two contrasting ai development pipelines  a scalable    ai factory     mayo clinic  rochester  united states   and an end to end cervical cancer screening platform for resource poor settings  paps ai  mbarara  uganda   we provide practical recommendations for implementers  and discuss future challenges and novel approaches  including a decentralised federated architecture being developed in the nhs  ai vbh  london  uk    growth in global clinical ai research continues unabated  and introduction of vertically integrated teams and development practices can increase the translational potential of future clinical ai projects ,6.7990255,3.7764356,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Nonhypothesis-Driven Research: Data Mining and Knowledge Discovery,"Clinical information, stored over time and increasingly linked to other types of information such as environmental and social determinants of health and healthcare claims, is a potentially rich data source for clinical research. Knowledge discovery in databases (KDD) is a process for pattern discovery and predictive modeling in large databases. KDD encompasses and makes extensive use of data-mining methodsâ€”automated processes and algorithms that enable pattern recognition and classification. Characteristically, KDD involves the use of machine learning methods developed in the domain of artificial intelligence and information retrieval. These methods, which include both structure learning and parameter learning, have been applied to healthcare and biomedical data for various purposes with good success and potential or realized clinical translation. We introduce the Fayyad model of knowledge discovery in databases and describe the steps of the process, providing select examples from clinical research informatics. These steps range from initial data selection and preparation to interpretation and evaluation. Commonly used data-mining methods are surveyed: artificial neural networks, decision-tree induction, support vector machines (kernel methods), association-rule induction, k-nearest neighbor, and probabilistic methods such as Bayesian networks. We link methods for evaluating the models that result from the KDD process to methods used in diagnostic medicine, spotlighting measures derived from a confusion matrix and receiver operating characteristic curve analysis and, more recently, uncertainty quantification and conformal prediction. Throughout the chapter, we discuss salient aspects of biomedical data management and use, including applications, the use of FAIR principles, pipelines and infrastructure for KDD, and future directions.
 Keywords
 Knowledge discovery in databases
 Data mining
 Artificial neural networks
 Support vector machines
 Decision trees
 k-Nearest neighbor classification
 Clinical data repositories
 Machine learning",clinical information  stored over time and increasingly linked to other types of information such as environmental and social determinants of health and healthcare claims  is a potentially rich data source for clinical research  knowledge discovery in databases  kdd  is a process for pattern discovery and predictive modeling in large databases  kdd encompasses and makes extensive use of data mining methods   automated processes and algorithms that enable pattern recognition and classification  characteristically  kdd involves the use of machine learning methods developed in the domain of artificial intelligence and information retrieval  these methods  which include both structure learning and parameter learning  have been applied to healthcare and biomedical data for various purposes with good success and potential or realized clinical translation  we introduce the fayyad model of knowledge discovery in databases and describe the steps of the process  providing select examples from clinical research informatics  these steps range from initial data selection and preparation to interpretation and evaluation  commonly used data mining methods are surveyed  artificial neural networks  decision tree induction  support vector machines  kernel methods   association rule induction  k nearest neighbor  and probabilistic methods such as bayesian networks  we link methods for evaluating the models that result from the kdd process to methods used in diagnostic medicine  spotlighting measures derived from a confusion matrix and receiver operating characteristic curve analysis and  more recently  uncertainty quantification and conformal prediction  throughout the chapter  we discuss salient aspects of biomedical data management and use  including applications  the use of fair principles  pipelines and infrastructure for kdd  and future directions   keywords  knowledge discovery in databases  data mining  artificial neural networks  support vector machines  decision trees  k nearest neighbor classification  clinical data repositories  machine learning,6.4491873,3.9944537,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Positive feedback loops lead to concept drift in machine learning systems,"We have derived conditions when unintended feedback loops occur in supervised machine learning systems. In this paper, we study an important problem of discovering and measuring hidden feedback loops. Such feedback loops occur in web search, recommender systems, healthcare, predictive public policing and other systems. As a possible cause of echo chambers and filter bubbles, these feedback loops tend to produce concept drifts in user behavior. We study systems in their context of use, because both learning algorithms and user interactions are important. Then we decompose the automation bias from the use of the system into users adherence to predictions and their usage rate to derive conditions for a feedback loop to occur. We also provide estimates for the size of a concept drift caused by the loop. A series of controlled simulation experiments with real-world and synthetic data support our findings. This paper builds on our prior results and elaborates the analytical model of feedback loops, extends the experiments, and provides practical application guidelines.",we have derived conditions when unintended feedback loops occur in supervised machine learning systems  in this paper  we study an important problem of discovering and measuring hidden feedback loops  such feedback loops occur in web search  recommender systems  healthcare  predictive public policing and other systems  as a possible cause of echo chambers and filter bubbles  these feedback loops tend to produce concept drifts in user behavior  we study systems in their context of use  because both learning algorithms and user interactions are important  then we decompose the automation bias from the use of the system into users adherence to predictions and their usage rate to derive conditions for a feedback loop to occur  we also provide estimates for the size of a concept drift caused by the loop  a series of controlled simulation experiments with real world and synthetic data support our findings  this paper builds on our prior results and elaborates the analytical model of feedback loops  extends the experiments  and provides practical application guidelines ,5.0817156,5.0617347,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Introduction to Data Science and Data Analytics,"This initial chapter, â€œIntroduction to Data Science and Data Analyticsâ€, presents the main concepts related to the subject of the book. As happened in the first book of the series, â€œIntroduction to the Data Science Framework: A View from the EDISON Projectâ€, the chapter uses the common word about to start all the sections that present the introduction to what is Data Analytics in the framework of Data Science. The chapter presents a brief introduction to Data Science that can be amplified by reading the previous book, an introduction to EDISON, the European Union (EU)-funded project under which the framework for Data Science, and specifically, the Data Analytics body of knowledge treated in this book, was developed. The chapter also presents an introduction to Data Analytics from the four different perspectives developed in the EDISON project, that is, the Data Analytics competences, its body of knowledge, its curriculum, and its related professional profiles. Finally, the chapter ends with a last about, in this case, about the book itself, in which the contents and structure of the book will be introduced.",this initial chapter     introduction to data science and data analytics     presents the main concepts related to the subject of the book  as happened in the first book of the series     introduction to the data science framework  a view from the edison project     the chapter uses the common word about to start all the sections that present the introduction to what is data analytics in the framework of data science  the chapter presents a brief introduction to data science that can be amplified by reading the previous book  an introduction to edison  the european union  eu  funded project under which the framework for data science  and specifically  the data analytics body of knowledge treated in this book  was developed  the chapter also presents an introduction to data analytics from the four different perspectives developed in the edison project  that is  the data analytics competences  its body of knowledge  its curriculum  and its related professional profiles  finally  the chapter ends with a last about  in this case  about the book itself  in which the contents and structure of the book will be introduced ,9.657273,6.512021,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Defining Platform Research Infrastructure as a Service (PRIaaS) for Future Scientific Data Infrastructure,"Modern science increasingly works with large amount of data, which are heterogeneous, are distributed, and require special infrastructure for data collection, storage, processing, and visualization. Science digitalization, likewise industry digitalization, is facilitated by the explosive development of digital technologies and cloud-based infrastructure technologies and services. This paper attempts to understand impact and new requirements to the future Scientific Data Infrastructure imposed by growing science digitalization. The paper presents two lines of analysis: one is a retrospective analysis related to the European Research Infrastructure (RI) development stages and timeline from centralized to distributed and current Federated Interoperable; another line provided analysis of digital technology trends and identified what technologies will impact the future Scientific Data Infrastructure (SDI). Based on this analysis, the paper proposes a vision for the future RI Platform as a Service (PRIaaS) that incorporates recent digital technologies and enables platform and ecosystem model for future science. Notably the proposed PRIaaS adopts TMForum Digital Platform Reference Architecture (DPRA) that will simplify building and federating domain-specific RIs while focusing on the domain-specific data value chain with data protection and policy-based management by design.",modern science increasingly works with large amount of data  which are heterogeneous  are distributed  and require special infrastructure for data collection  storage  processing  and visualization  science digitalization  likewise industry digitalization  is facilitated by the explosive development of digital technologies and cloud based infrastructure technologies and services  this paper attempts to understand impact and new requirements to the future scientific data infrastructure imposed by growing science digitalization  the paper presents two lines of analysis  one is a retrospective analysis related to the european research infrastructure  ri  development stages and timeline from centralized to distributed and current federated interoperable  another line provided analysis of digital technology trends and identified what technologies will impact the future scientific data infrastructure  sdi   based on this analysis  the paper proposes a vision for the future ri platform as a service  priaas  that incorporates recent digital technologies and enables platform and ecosystem model for future science  notably the proposed priaas adopts tmforum digital platform reference architecture  dpra  that will simplify building and federating domain specific ris while focusing on the domain specific data value chain with data protection and policy based management by design ,9.802336,7.314409,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Architecting AI: When to Be Cloud Native,"The rapid evolution of technology and the increasing demand for scalable, resilient, and flexible systems have made cloud-native architecture a critical consideration for businesses looking to grow and succeed with AI. Cloud-native applications harness the full potential of the cloud, providing a robust foundation for AI-driven innovation and growth. In this chapter, we will explore the core principles and components of cloud-native architecture and discuss common patterns for designing and implementing AI apps that are primed for success in the cloud.",the rapid evolution of technology and the increasing demand for scalable  resilient  and flexible systems have made cloud native architecture a critical consideration for businesses looking to grow and succeed with ai  cloud native applications harness the full potential of the cloud  providing a robust foundation for ai driven innovation and growth  in this chapter  we will explore the core principles and components of cloud native architecture and discuss common patterns for designing and implementing ai apps that are primed for success in the cloud ,10.321562,5.4061007,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Machine learning and deep learning based predictive quality in manufacturing: a systematic review,"With the ongoing digitization of the manufacturing industry and the ability to bring together data from manufacturing processes and quality measurements, there is enormous potential to use machine learning and deep learning techniques for quality assurance. In this context, predictive quality enables manufacturing companies to make data-driven estimations about the product quality based on process data. In the current state of research, numerous approaches to predictive quality exist in a wide variety of use cases and domains. Their applications range from quality predictions during production using sensor data to automated quality inspection in the field based on measurement data. However, there is currently a lack of an overall view of where predictive quality research stands as a whole, what approaches are currently being investigated, and what challenges currently exist. This paper addresses these issues by conducting a comprehensive and systematic review of scientific publications between 2012 and 2021 dealing with predictive quality in manufacturing. The publications are categorized according to the manufacturing processes they address as well as the data bases and machine learning models they use. In this process, key insights into the scope of this field are collected along with gaps and similarities in the solution approaches. Finally, open challenges for predictive quality are derived from the results and an outlook on future research directions to solve them is provided.",with the ongoing digitization of the manufacturing industry and the ability to bring together data from manufacturing processes and quality measurements  there is enormous potential to use machine learning and deep learning techniques for quality assurance  in this context  predictive quality enables manufacturing companies to make data driven estimations about the product quality based on process data  in the current state of research  numerous approaches to predictive quality exist in a wide variety of use cases and domains  their applications range from quality predictions during production using sensor data to automated quality inspection in the field based on measurement data  however  there is currently a lack of an overall view of where predictive quality research stands as a whole  what approaches are currently being investigated  and what challenges currently exist  this paper addresses these issues by conducting a comprehensive and systematic review of scientific publications between      and      dealing with predictive quality in manufacturing  the publications are categorized according to the manufacturing processes they address as well as the data bases and machine learning models they use  in this process  key insights into the scope of this field are collected along with gaps and similarities in the solution approaches  finally  open challenges for predictive quality are derived from the results and an outlook on future research directions to solve them is provided ,6.0137196,4.694414,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Towards Systematically Engineering Autonomous Systems Using Reinforcement Learning and Planning,Autonomous systems need to be able dynamically adapt to changing requirements and environmental conditions without redeployment and without interruption of the systems functionality. The EU project ASCENS has developed a comprehensive suite of foundational theories and methods for building autonomic systems. In this paper we specialise the EDLC process model of ASCENS to deal with planning and reinforcement learning techniques. We present the â€œAIDLâ€ life cycle and illustrate it with two case studies: simulation-based online planning and the PSyCo reinforcement learning approach for synthesizing agent policies from hard and soft requirements. Related work and potential avenues for future research are discussed.,autonomous systems need to be able dynamically adapt to changing requirements and environmental conditions without redeployment and without interruption of the systems functionality  the eu project ascens has developed a comprehensive suite of foundational theories and methods for building autonomic systems  in this paper we specialise the edlc process model of ascens to deal with planning and reinforcement learning techniques  we present the    aidl    life cycle and illustrate it with two case studies  simulation based online planning and the psyco reinforcement learning approach for synthesizing agent policies from hard and soft requirements  related work and potential avenues for future research are discussed ,7.1195855,4.2753716,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Biquality learning: a framework to design algorithms dealing with closed-set distribution shifts,"Training machine learning models from data with weak supervision and dataset shifts is still challenging. Designing algorithms when these two situations arise has not been explored much, and existing algorithms cannot always handle the most complex distributional shifts. We think the biquality data setup is a suitable framework for designing such algorithms. Biquality Learning assumes that two datasets are available at training time: a trusted dataset sampled from the distribution of interest and the untrusted dataset with dataset shifts and weaknesses of supervision (aka distribution shifts). The trusted and untrusted datasets available at training time make designing algorithms dealing with any distribution shifts possible. We propose two methods, one inspired by the label noise literature and another by the covariate shift literature for biquality learning. We experiment with two novel methods to synthetically introduce concept drift and class-conditional shifts in real-world datasets across many of them. We opened some discussions and assessed that developing biquality learning algorithms robust to distributional changes remains an interesting problem for future research.",training machine learning models from data with weak supervision and dataset shifts is still challenging  designing algorithms when these two situations arise has not been explored much  and existing algorithms cannot always handle the most complex distributional shifts  we think the biquality data setup is a suitable framework for designing such algorithms  biquality learning assumes that two datasets are available at training time  a trusted dataset sampled from the distribution of interest and the untrusted dataset with dataset shifts and weaknesses of supervision  aka distribution shifts   the trusted and untrusted datasets available at training time make designing algorithms dealing with any distribution shifts possible  we propose two methods  one inspired by the label noise literature and another by the covariate shift literature for biquality learning  we experiment with two novel methods to synthetically introduce concept drift and class conditional shifts in real world datasets across many of them  we opened some discussions and assessed that developing biquality learning algorithms robust to distributional changes remains an interesting problem for future research ,3.4955256,7.184732,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Approximation of matrix-valued functions via statistical convergence with respect to power series methods,"In this paper, we deal with an approximation problem for matrix-valued positive linear operators via statistical convergence with respect to the power series method which is a new statistical type convergence. Then, we present an application that shows our theorem is more applicable than the classical one. We also compute the rates of P-statistical convergence of these operators.",in this paper  we deal with an approximation problem for matrix valued positive linear operators via statistical convergence with respect to the power series method which is a new statistical type convergence  then  we present an application that shows our theorem is more applicable than the classical one  we also compute the rates of p statistical convergence of these operators ,4.176051,7.259608,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Cloud Native Operations,"Congratulations! If you are reading this chapter and have completed all the previous ones, including the practical exercises, you have crossed the proverbial migration finish line. You provisioned cost-efficient, reliable, secure, and observable operational environments on the cloud provider infrastructure and deployed application code and data via an automated pipeline within the comprehensive DevSecOps ecosystem!",congratulations  if you are reading this chapter and have completed all the previous ones  including the practical exercises  you have crossed the proverbial migration finish line  you provisioned cost efficient  reliable  secure  and observable operational environments on the cloud provider infrastructure and deployed application code and data via an automated pipeline within the comprehensive devsecops ecosystem ,8.554776,7.3917904,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
The Pragmatics of the Data Acquisition and Assessment,"In this chapter, we will look in a more detail at the ways in which data were acquired and processed in the framework of the project in question. We will do so against the background of observations and examples already provided in the preceding section, starting with the first section of the present chapter.",in this chapter  we will look in a more detail at the ways in which data were acquired and processed in the framework of the project in question  we will do so against the background of observations and examples already provided in the preceding section  starting with the first section of the present chapter ,8.994005,7.6655035,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Machine Learning Deployment Using Docker,"Over the last few years, Docker has changed the way applications are deployed in production. Application architectures have moved from monolithic to microservices, with more control of continuous (ongoing) deployments that donâ€™t impact a large of part of the running applications. Docker has proved to be instrumental in allowing applications to run at scale and to be available all the time. Though itâ€™s been more than seven years since Docker was released, itâ€™s gotten a lot of attention from the developer community recently (especially by DevOps and MLOps teams). Companies large and small are using Docker in applications.",over the last few years  docker has changed the way applications are deployed in production  application architectures have moved from monolithic to microservices  with more control of continuous  ongoing  deployments that don   t impact a large of part of the running applications  docker has proved to be instrumental in allowing applications to run at scale and to be available all the time  though it   s been more than seven years since docker was released  it   s gotten a lot of attention from the developer community recently  especially by devops and mlops teams   companies large and small are using docker in applications ,8.285374,3.5231032,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Overcoming Challenges to ML Adoption,"Organizations have many data and ML challenges. Overcoming the data challenge with a solid data strategy, and creating a data culture, is an important step toward applying and adopting ML in your organization. ML adoption will take hold in your organization if it can solve problems that can help your organization grow. While changing an organization's culture is never easy or quick, showing tangible ML value that can be related to cost decreases or revenue increases will drive more ML adoption.",organizations have many data and ml challenges  overcoming the data challenge with a solid data strategy  and creating a data culture  is an important step toward applying and adopting ml in your organization  ml adoption will take hold in your organization if it can solve problems that can help your organization grow  while changing an organization s culture is never easy or quick  showing tangible ml value that can be related to cost decreases or revenue increases will drive more ml adoption ,10.627487,7.476201,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
The Data Lake Setup,"This is the most technical part of the project. This is where we design and deliver the working solution that provides the business value. Once we have established the key processes, personas, roles, and responsibilities and have divided the areas of work into a proper cadence, this is the phase where we start building things and delivering value to our customers. This is the part where things start to take shape.",this is the most technical part of the project  this is where we design and deliver the working solution that provides the business value  once we have established the key processes  personas  roles  and responsibilities and have divided the areas of work into a proper cadence  this is the phase where we start building things and delivering value to our customers  this is the part where things start to take shape ,10.155247,7.0126023,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Self-learning Data Foundation for Scientific AI,"The â€œSelf-Learning Data Foundation for AIâ€ is an open-source platform to manage Machine Learning (ML) metadata in complex end-to-end pipelines, and includes the intelligence to optimize data gradation, pipeline configuration, and compute performance. The work addresses several challenges: prioritizing data to reduce movement, tracking lineage to optimize complex ML pipelines, and enabling reproducibility and portability of data selection and ML model development. Off-the-shelf AI metadata management frameworks (such as MLflow or Weights & Biases) focus on fine-grain stage-level metadata, and only track parts of the pipeline, and lineage. Our proposed software layer sits between ML workflows and pipelines and storage/data access. The first implementation of the Data Foundation is the Common Metadata Framework (CMF), which captures metadata and tracks them automatically alongside references to data artifacts and application code. Its git-like nature allows parallel model development by different teams and is well suited for federated environments. It includes intelligence to optimize pipelines and storage, can learn the access patterns from pipeline execution to inform optimizations such as prestaging and caching. It also learns from model inference metrics to build iteratively more robust models. Through a data shaping use case for I/O optimization and an active learning use case to reduce labelling (on DeepCam AI model training on climate data running on NERSC Cori), we show the versatility of the data foundation layer, the potential benefits (4x reduction in training time and 2x reduction in labelling effort), and its central role in complex ML pipelines.
 Keywords
 AI metadata
 Trustworthy AI
 MLOps",the    self learning data foundation for ai    is an open source platform to manage machine learning  ml  metadata in complex end to end pipelines  and includes the intelligence to optimize data gradation  pipeline configuration  and compute performance  the work addresses several challenges  prioritizing data to reduce movement  tracking lineage to optimize complex ml pipelines  and enabling reproducibility and portability of data selection and ml model development  off the shelf ai metadata management frameworks  such as mlflow or weights   biases  focus on fine grain stage level metadata  and only track parts of the pipeline  and lineage  our proposed software layer sits between ml workflows and pipelines and storage data access  the first implementation of the data foundation is the common metadata framework  cmf   which captures metadata and tracks them automatically alongside references to data artifacts and application code  its git like nature allows parallel model development by different teams and is well suited for federated environments  it includes intelligence to optimize pipelines and storage  can learn the access patterns from pipeline execution to inform optimizations such as prestaging and caching  it also learns from model inference metrics to build iteratively more robust models  through a data shaping use case for i o optimization and an active learning use case to reduce labelling  on deepcam ai model training on climate data running on nersc cori   we show the versatility of the data foundation layer  the potential benefits   x reduction in training time and  x reduction in labelling effort   and its central role in complex ml pipelines   keywords  ai metadata  trustworthy ai  mlops,7.790074,5.840428,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Human-in-the-loop machine learning: a state of the art,"Researchers are defining new types of interactions between humans and machine learning algorithms generically called human-in-the-loop machine learning. Depending on who is in control of the learning process, we can identify: active learning, in which the system remains in control; interactive machine learning, in which there is a closer interaction between users and learning systems; and machine teaching, where human domain experts have control over the learning process. Aside from control, humans can also be involved in the learning process in other ways. In curriculum learning human domain experts try to impose some structure on the examples presented to improve the learning; in explainable AI the focus is on the ability of the model to explain to humans why a given solution was chosen. This collaboration between AI models and humans should not be limited only to the learning process; if we go further, we can see other terms that arise such as Usable and Useful AI. In this paper we review the state of the art of the techniques involved in the new forms of relationship between humans and ML algorithms. Our contribution is not merely listing the different approaches, but to provide definitions clarifying confusing, varied and sometimes contradictory terms; to elucidate and determine the boundaries between the different methods; and to correlate all the techniques searching for the connections and influences between them.",researchers are defining new types of interactions between humans and machine learning algorithms generically called human in the loop machine learning  depending on who is in control of the learning process  we can identify  active learning  in which the system remains in control  interactive machine learning  in which there is a closer interaction between users and learning systems  and machine teaching  where human domain experts have control over the learning process  aside from control  humans can also be involved in the learning process in other ways  in curriculum learning human domain experts try to impose some structure on the examples presented to improve the learning  in explainable ai the focus is on the ability of the model to explain to humans why a given solution was chosen  this collaboration between ai models and humans should not be limited only to the learning process  if we go further  we can see other terms that arise such as usable and useful ai  in this paper we review the state of the art of the techniques involved in the new forms of relationship between humans and ml algorithms  our contribution is not merely listing the different approaches  but to provide definitions clarifying confusing  varied and sometimes contradictory terms  to elucidate and determine the boundaries between the different methods  and to correlate all the techniques searching for the connections and influences between them ,9.375121,7.3743534,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
A knowledge-driven approach for designing data analytics platforms,"Big data analytics technologies are rapidly expanding across all industry sectors as organisations try to make analytics an integral part of their everyday decision-making. Although there are many software tools and libraries to assist analysts and software engineers in developing solutions, organisations are looking for flexible analytics platforms that can address their specific objectives and requirements. To minimise costs, such platforms also need to co-exist with existing IT infrastructures and reuse knowledge and resources already accumulated within the organisation. To address such needs, this paper proposes the Data Analytics Solution Engineering (DASE) frameworkâ€”a knowledge-driven approach supported by semantic web technologies for requirements engineering, design and development of new data analytics platforms. It includes a meta-model that captures data analytics platform requirements via a Knowledge Base, a set of guidelines that organisations can follow in engineering data analytics platforms and a reference architecture that demonstrates how to use these guidelines. We evaluate the DASE framework through two case studies and demonstrate how it can facilitate knowledge-based and requirements-driven data analytics platform engineering. The resulting data analytics platforms are observed to be user friendly, easy to maintain and flexible in handling changes to requirements. This work contributes to the body of knowledge in knowledge-driven requirements engineering, and data analytics platform engineering by providing a meta-model and a reference architecture that can be tailored to different analytics application domains.",big data analytics technologies are rapidly expanding across all industry sectors as organisations try to make analytics an integral part of their everyday decision making  although there are many software tools and libraries to assist analysts and software engineers in developing solutions  organisations are looking for flexible analytics platforms that can address their specific objectives and requirements  to minimise costs  such platforms also need to co exist with existing it infrastructures and reuse knowledge and resources already accumulated within the organisation  to address such needs  this paper proposes the data analytics solution engineering  dase  framework   a knowledge driven approach supported by semantic web technologies for requirements engineering  design and development of new data analytics platforms  it includes a meta model that captures data analytics platform requirements via a knowledge base  a set of guidelines that organisations can follow in engineering data analytics platforms and a reference architecture that demonstrates how to use these guidelines  we evaluate the dase framework through two case studies and demonstrate how it can facilitate knowledge based and requirements driven data analytics platform engineering  the resulting data analytics platforms are observed to be user friendly  easy to maintain and flexible in handling changes to requirements  this work contributes to the body of knowledge in knowledge driven requirements engineering  and data analytics platform engineering by providing a meta model and a reference architecture that can be tailored to different analytics application domains ,8.858679,4.373338,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
DataOps Technology,"Technology is deliberately left until the final chapter because while it is essential, it is less critical than people, culture, and processes. If tools were all it took to be successful, then Silicon Valley giants would not open-source their crown jewels such as Kubernetes, TensorFlow, Apache Kafka, and Apache Airflow.",technology is deliberately left until the final chapter because while it is essential  it is less critical than people  culture  and processes  if tools were all it took to be successful  then silicon valley giants would not open source their crown jewels such as kubernetes  tensorflow  apache kafka  and apache airflow ,9.529796,6.971287,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Cloud Migration Fundamentals,"Chapter 1 presented an in-depth introduction to cloud computing, including its essential characteristics, service delivery models, and deployment models. This chapter continues to build on those concepts and includes the following objectives:",chapter   presented an in depth introduction to cloud computing  including its essential characteristics  service delivery models  and deployment models  this chapter continues to build on those concepts and includes the following objectives ,8.669024,7.7545886,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Terminology: Data Fabric and Data Mesh,"This chapter explains the key terms that will be used throughout this book, the terms Data Fabric and Data Mesh, and how these two terms relate to each other. We introduce the term data-as-a-product or shopping-for-data and provide a high-level introduction into AI-infused Data Fabric capabilities. The chapter concludes with a description of a data product as a key concept of a Data Mesh.",this chapter explains the key terms that will be used throughout this book  the terms data fabric and data mesh  and how these two terms relate to each other  we introduce the term data as a product or shopping for data and provide a high level introduction into ai infused data fabric capabilities  the chapter concludes with a description of a data product as a key concept of a data mesh ,10.216498,7.486549,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Data Fabric Architecture Patterns,"A specific Data Fabric architecture is determined by its business and IT context and intent, meaning that not every implementation is identical. A Data Fabric could for instance serve different data consumption patterns, such as real-time transactional inference of AI-based insights, trustworthy AI scenarios, or AI governance purposes. A specific implementation of a Data Fabric also depends on concrete solution requirements, such as the ones associated with a Data Mesh solution (e.g., data-as-a-product) and whether the Data Fabric should serve certain technologies, such as IoT, edge computing, or 5G. Finally, intelligent information integration can be underpinned with different and complementary methods, such as data virtualization, replication, streaming, etc., which has an impact on the underlying Data Fabric architecture. Integration challenges within a hybrid cloud landscape leveraging public cloud services may differ from integration needs within a private cloud and on-premises landscape.",a specific data fabric architecture is determined by its business and it context and intent  meaning that not every implementation is identical  a data fabric could for instance serve different data consumption patterns  such as real time transactional inference of ai based insights  trustworthy ai scenarios  or ai governance purposes  a specific implementation of a data fabric also depends on concrete solution requirements  such as the ones associated with a data mesh solution  e g   data as a product  and whether the data fabric should serve certain technologies  such as iot  edge computing  or  g  finally  intelligent information integration can be underpinned with different and complementary methods  such as data virtualization  replication  streaming  etc   which has an impact on the underlying data fabric architecture  integration challenges within a hybrid cloud landscape leveraging public cloud services may differ from integration needs within a private cloud and on premises landscape ,9.598016,4.006084,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Product-Market Validation for AI as a Service (AIaaS),"The previous chapter taught us how to validate AI-first SaaS with the business user as the target market. In this chapter, we will learn more about AI as a Service (AIaaS), which targets the developers' market, and how to validate its market.",the previous chapter taught us how to validate ai first saas with the business user as the target market  in this chapter  we will learn more about ai as a service  aiaas   which targets the developers  market  and how to validate its market ,11.269831,6.8351493,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Understanding DevOps Critical Success Factors: Insights from Professionals,"This paper explores the factors that contribute to the success of software development undertaken with DevOps practices. DevOps is a set of practices that aims to increase software development process efficiency by reducing barriers between operation and development teams. Despite the wealth of information available on DevOps practices, adoption, and the respective challenges, there is a dearth of research focusing specifically on the DevOps critical success factors. This paper seeks to fill this gap by analyzing and discussing the key factors that are essential for success in software development with DevOps. To this end, we have conducted an open-ended survey among 72 DevOps professionals. By employing the Gioia method, we elaborate on the professionalsâ€™ perspectives on the DevOps success factors identified and connect them to the prior literature. These success factors encompass intra-organizational collaboration, organizational hierarchy, strategic planning, team dynamics, cultural shift, performance engineering, integration, build and test automation, infrastructure, and DevOps as a service. We propose five DevOps implementation advice that could benefit companies while implementing DevOps practices. Those include management support, investment in DevOps tools, sharing knowledge within teams, sharing responsibility in teams, being willing to explore and experiment with the practices, and being agile are crucial for DevOps performance and organizational success.
 Keywords
 DevOps
 Critical success factors
 Continuous delivery
 Continuous development
 DevOps survey
 Software development
 Success factors validation
 Gioia method
 Qualitative research",this paper explores the factors that contribute to the success of software development undertaken with devops practices  devops is a set of practices that aims to increase software development process efficiency by reducing barriers between operation and development teams  despite the wealth of information available on devops practices  adoption  and the respective challenges  there is a dearth of research focusing specifically on the devops critical success factors  this paper seeks to fill this gap by analyzing and discussing the key factors that are essential for success in software development with devops  to this end  we have conducted an open ended survey among    devops professionals  by employing the gioia method  we elaborate on the professionals    perspectives on the devops success factors identified and connect them to the prior literature  these success factors encompass intra organizational collaboration  organizational hierarchy  strategic planning  team dynamics  cultural shift  performance engineering  integration  build and test automation  infrastructure  and devops as a service  we propose five devops implementation advice that could benefit companies while implementing devops practices  those include management support  investment in devops tools  sharing knowledge within teams  sharing responsibility in teams  being willing to explore and experiment with the practices  and being agile are crucial for devops performance and organizational success   keywords  devops  critical success factors  continuous delivery  continuous development  devops survey  software development  success factors validation  gioia method  qualitative research,10.137632,5.760167,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Introduction to the AI Engineering Theme,The term artificial intelligence (AI) triggers many things in terms of its inherent meaning and potential. The notion of a machine with the same level of intellect as a human or even far exceeding it is enthralling and scary at the same time. Several science fiction movies build on the HAL 9000 or Terminator theme of artificial intelligence bent on controlling or even exterminating humankind.,the term artificial intelligence  ai  triggers many things in terms of its inherent meaning and potential  the notion of a machine with the same level of intellect as a human or even far exceeding it is enthralling and scary at the same time  several science fiction movies build on the hal      or terminator theme of artificial intelligence bent on controlling or even exterminating humankind ,10.033332,7.357193,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Systems for ML Lifecycle Tasks,"In the previous chapters, we focused on the specification, execution, and optimization of ML algorithms in various settings. However, the process of running ML algorithms to train ML models is only one step, albeit a major one, in the end-to-end lifecycle of ML applications, as depicted in Figure 1.1 in Chapter 1. This lifecycle also involves the processes of sourcing and preparing data for ML, model selection and model management, and deployment of ML models into production. Tackling these challenges requires ideas and techniques that combine not just ML and data management, but also other fields of computing, including human-computer interaction and operating and distributed systems. We now dive into these auxiliary steps in the ML lifecycle in depth.",in the previous chapters  we focused on the specification  execution  and optimization of ml algorithms in various settings  however  the process of running ml algorithms to train ml models is only one step  albeit a major one  in the end to end lifecycle of ml applications  as depicted in figure     in chapter    this lifecycle also involves the processes of sourcing and preparing data for ml  model selection and model management  and deployment of ml models into production  tackling these challenges requires ideas and techniques that combine not just ml and data management  but also other fields of computing  including human computer interaction and operating and distributed systems  we now dive into these auxiliary steps in the ml lifecycle in depth ,7.8368883,5.953377,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Quality Engineering in AI Services,"This short paper discusses some of the challenges in testing AI systems, proposes some good practices and advocates a shift to a customer-driven approach, driven by problems customers need to solve rather than problems engineers can solve.",this short paper discusses some of the challenges in testing ai systems  proposes some good practices and advocates a shift to a customer driven approach  driven by problems customers need to solve rather than problems engineers can solve ,9.520809,5.9953976,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Towards Cognitive Ports of the Future,"In modern societies, the rampant growth of data management technologiesâ€”that have access to data sources from a plethora of heterogeneous systemsâ€”enables data analysts to leverage their advantages to new areas and critical infrastructures. However, there is no global reference standard for data platform technology. Data platforms scenarios are characterized by a high degree of heterogeneity at all levels (middleware, application service, data/semantics, scalability, and governance), preventing deployment, federation, and interoperability of existing solutions. Although many initiatives are dealing with developing data platform architectures in diversified application domains, not many projects have addressed integration in port environments with the possibility of including cognitive services. Unlike other cases, port environment is a complex system that consists of multiple heterogeneous critical infrastructures, which are connected and dependent on each other. The key pillar is to define the design of a secure interoperable system facilitating the exchange of data through standardized data models, based on common semantics, and offering advanced interconnection capabilities leading to cooperation between different IT/IoT/Objects platforms. This contribution deals with scalability, interoperability, and standardization features of data platforms from a business point of view in a smart and cognitive port case study. The main goal is to design an innovative platform, named DataPorts, which will overcome these obstacles and provide an ecosystem where port authorities, external data platforms, transportation, and logistics companies can cooperate and create the basis to offer cognitive services. The chapter relates to knowledge and learning as well as to systems, methodologies, hardware, and tools cross-sectorial technology enablers of the AI, Data and Robotics Strategic Research, Innovation & Deployment Agenda (Milano et al., Strategic research, innovation and deployment agenda - AI, data and robotics partnership. Third release. Big Data Value Association, 2020).
 Keywords
 Industry 4.0
 Data for AI
 Port authorities",in modern societies  the rampant growth of data management technologies   that have access to data sources from a plethora of heterogeneous systems   enables data analysts to leverage their advantages to new areas and critical infrastructures  however  there is no global reference standard for data platform technology  data platforms scenarios are characterized by a high degree of heterogeneity at all levels  middleware  application service  data semantics  scalability  and governance   preventing deployment  federation  and interoperability of existing solutions  although many initiatives are dealing with developing data platform architectures in diversified application domains  not many projects have addressed integration in port environments with the possibility of including cognitive services  unlike other cases  port environment is a complex system that consists of multiple heterogeneous critical infrastructures  which are connected and dependent on each other  the key pillar is to define the design of a secure interoperable system facilitating the exchange of data through standardized data models  based on common semantics  and offering advanced interconnection capabilities leading to cooperation between different it iot objects platforms  this contribution deals with scalability  interoperability  and standardization features of data platforms from a business point of view in a smart and cognitive port case study  the main goal is to design an innovative platform  named dataports  which will overcome these obstacles and provide an ecosystem where port authorities  external data platforms  transportation  and logistics companies can cooperate and create the basis to offer cognitive services  the chapter relates to knowledge and learning as well as to systems  methodologies  hardware  and tools cross sectorial technology enablers of the ai  data and robotics strategic research  innovation   deployment agenda  milano et al   strategic research  innovation and deployment agenda   ai  data and robotics partnership  third release  big data value association          keywords  industry      data for ai  port authorities,8.038467,6.0321465,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
The Azure Portal for Cognitive Services,"This chapter will explore how you can get started with Cognitive Services on the Azure portal, and it includes an exploration of the common features. Next, the chapter will take you inside the Azure Marketplace for Bot Service, Cognitive Services, and Machine Learning.",this chapter will explore how you can get started with cognitive services on the azure portal  and it includes an exploration of the common features  next  the chapter will take you inside the azure marketplace for bot service  cognitive services  and machine learning ,8.521897,7.7440124,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Introduction to Azure Machine Learning,"In this chapter, we will study Azure ML platform and learn its capabilities, benefits, components, and advantages. In Chapter 5, we will do hands-on using Azure ML SDK and will understand how to build end-to-end machine learning solutions.",in this chapter  we will study azure ml platform and learn its capabilities  benefits  components  and advantages  in chapter    we will do hands on using azure ml sdk and will understand how to build end to end machine learning solutions ,8.421327,7.8145466,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Data or Business First?â€”Manufacturersâ€™ Transformation Toward Data-driven Business Models,"Driven by digital technologies, manufacturers aim to tap into data-driven business models, in which value is generated from data as a complement to physical products. However, this transformation can be complex, as different archetypes of data-driven business models require substantially different business and technical capabilities. While there are manifold contributions to research on technical capability development, an integrated and aligned perspective on both business and technology capabilities for distinct data-driven business model archetypes is needed. This perspective promises to enhance researchâ€™s understanding of this transformation and offers guidance for practitioners. As maturity models have proven to be valuable tools in capability development, we follow a design science approach to develop a maturity model for the transformation toward archetypal data-driven business models. To provide an integrated perspective on business and technology capabilities, the maturity model leverages a layered enterprise architecture model. By applying and evaluating in use at two manufacturers, we find two different transformation approaches, namely â€˜data firstâ€™ and â€˜business firstâ€™. The resulting insights highlight the modelâ€™s integrative perspectiveâ€™s value for research to improve the understanding of this transformation. For practitioners, the maturity model allows a status quo assessment and derives fields of action to develop the capabilities required for the aspired data-driven business model.",driven by digital technologies  manufacturers aim to tap into data driven business models  in which value is generated from data as a complement to physical products  however  this transformation can be complex  as different archetypes of data driven business models require substantially different business and technical capabilities  while there are manifold contributions to research on technical capability development  an integrated and aligned perspective on both business and technology capabilities for distinct data driven business model archetypes is needed  this perspective promises to enhance research   s understanding of this transformation and offers guidance for practitioners  as maturity models have proven to be valuable tools in capability development  we follow a design science approach to develop a maturity model for the transformation toward archetypal data driven business models  to provide an integrated perspective on business and technology capabilities  the maturity model leverages a layered enterprise architecture model  by applying and evaluating in use at two manufacturers  we find two different transformation approaches  namely    data first    and    business first     the resulting insights highlight the model   s integrative perspective   s value for research to improve the understanding of this transformation  for practitioners  the maturity model allows a status quo assessment and derives fields of action to develop the capabilities required for the aspired data driven business model ,9.9251585,6.445373,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
AITA: AI trustworthiness assessment AAAI spring symposium 2023,"The accelerated developments in the field of Artificial Intelligence (AI) hint at the need for considering â€œTrustâ€ as a design principle rather than an option. Moreover, the design of AI-based critical systems, such as in avionics, mobility, defense, healthcare, finance, critical infrastructures, etc., requires proving their trustworthiness. Thus, AI-based critical systems must be assessed across many dimensions by different parties (regulators, developers, customers, reinsurance companies, and end-users) for different reasons. We can call it AI validation, monitoring, assessing, or auditing, but the fundamental concept in all cases is to make sure that the AI is performing well within its operational design domain. Such assessment begins from the early stages of development, including the definition of the specification requirements for the system, the analysis, the design, etc. Trust and trustworthiness assessment have to be considered at every phase of the system lifecycle, including sale and deployment, updates, maintenance, or int. It is expected that full trustworthiness in AI systems can only be established if the technical measures to establish trustworthiness are flanked by specifications for the governance and processes of organizations that use and develop AI. Application of Social Sciences and Humanities (SSH) methods and principles to handle humanâ€“AI interaction, and aid in the operationalisation of (ethical) values in the design and assessment, with important information provided on their actual impact on trust and trustworthiness is a key issue.",the accelerated developments in the field of artificial intelligence  ai  hint at the need for considering    trust    as a design principle rather than an option  moreover  the design of ai based critical systems  such as in avionics  mobility  defense  healthcare  finance  critical infrastructures  etc   requires proving their trustworthiness  thus  ai based critical systems must be assessed across many dimensions by different parties  regulators  developers  customers  reinsurance companies  and end users  for different reasons  we can call it ai validation  monitoring  assessing  or auditing  but the fundamental concept in all cases is to make sure that the ai is performing well within its operational design domain  such assessment begins from the early stages of development  including the definition of the specification requirements for the system  the analysis  the design  etc  trust and trustworthiness assessment have to be considered at every phase of the system lifecycle  including sale and deployment  updates  maintenance  or int  it is expected that full trustworthiness in ai systems can only be established if the technical measures to establish trustworthiness are flanked by specifications for the governance and processes of organizations that use and develop ai  application of social sciences and humanities  ssh  methods and principles to handle human   ai interaction  and aid in the operationalisation of  ethical  values in the design and assessment  with important information provided on their actual impact on trust and trustworthiness is a key issue ,12.215566,6.011359,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
"The Good, The Bad, and The Average: Benchmarking of Reconstruction Based Multivariate Time Series Anomaly Detection","Reconstruction-based algorithms offer state-of-the-art performance in multivariate time series anomaly detection. But as always: there is no single best algorithm. To find the optimal solution, one has to compare different methods and tune their hyperparameters. This paper introduces a lightweight modular benchmarking framework for data scientists and researchers in the field. The framework can be easily set up and automatically create a visual summary of the relevant performance indicators and automatically selected examples to give insight into the behavior of the model and aid during the development.
 Keywords
 Anomaly Detection
 Multivariate Time Series
 Reconstruction-based Models
 Autoencoder
 Benchmark
 Experiment tracking
 MLOps
 Visualisation",reconstruction based algorithms offer state of the art performance in multivariate time series anomaly detection  but as always  there is no single best algorithm  to find the optimal solution  one has to compare different methods and tune their hyperparameters  this paper introduces a lightweight modular benchmarking framework for data scientists and researchers in the field  the framework can be easily set up and automatically create a visual summary of the relevant performance indicators and automatically selected examples to give insight into the behavior of the model and aid during the development   keywords  anomaly detection  multivariate time series  reconstruction based models  autoencoder  benchmark  experiment tracking  mlops  visualisation,6.3763113,4.777305,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Cloud Computing Continuum Research Topics and Challenges. A Multi-source Analysis,"While the emergence of COVID-19 [1] has put major cloud service providers around the world to the test, the pandemic has also provided a strong impetus for the adoption and deployment of cloud computing: the transition to a remote workforce, entertainment, e-commerce, and especially remote education have affected the cloud industry and how providers are responding to the sudden and significant increase in demand for cloud solutions and services. Obviously, while highlighting the robustness of the public cloud, the pandemic-induced situation also highlights several important research challenges that need to be addressed.
 This paper presents a multi-source based analysis for the identification of cloud computing research challenges as part of the road mapping methodology followed in the HUB4CLOUD project. The analysis consists of an in-depth study of several sources including analysis of the international context, analysis of academic venues, interviews with relevant stakeholders and existing funded projects.
 The paper also provides an overview of the main research topics identified and proposes next steps for the utilization of these finding in the development of a Cloud Computing research roadmap.
 Keywords
 Cloud computing
 Research topics
 Multi-source analysis
 Cloud continuum",while the emergence of covid        has put major cloud service providers around the world to the test  the pandemic has also provided a strong impetus for the adoption and deployment of cloud computing  the transition to a remote workforce  entertainment  e commerce  and especially remote education have affected the cloud industry and how providers are responding to the sudden and significant increase in demand for cloud solutions and services  obviously  while highlighting the robustness of the public cloud  the pandemic induced situation also highlights several important research challenges that need to be addressed   this paper presents a multi source based analysis for the identification of cloud computing research challenges as part of the road mapping methodology followed in the hub cloud project  the analysis consists of an in depth study of several sources including analysis of the international context  analysis of academic venues  interviews with relevant stakeholders and existing funded projects   the paper also provides an overview of the main research topics identified and proposes next steps for the utilization of these finding in the development of a cloud computing research roadmap   keywords  cloud computing  research topics  multi source analysis  cloud continuum,10.2506695,6.1198545,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
AIoT Pipelines,"Pipelines have become an important concept in many development organizations, especially from a DevOps perspective. This chapter introduces the concept of AIoT pipelines and discusses pipeline aggregations.",pipelines have become an important concept in many development organizations  especially from a devops perspective  this chapter introduces the concept of aiot pipelines and discusses pipeline aggregations ,9.788732,5.538925,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Holistic AIoT DevOps,"The introduction of DevOps â€” together with Continuous Integration/Continuous Delivery (CI/CD) â€” has fundamentally changed the way software is developed, integrated, tested, and deployed. DevOps and CI/CD are key enablers of agile development. However, todayâ€™s DevOps practices predominantly focus on cloud and enterprise application development. For successful AIoT products, DevOps will need to be extended to include AI and IoT (Fig. 27.1).",the introduction of devops     together with continuous integration continuous delivery  ci cd      has fundamentally changed the way software is developed  integrated  tested  and deployed  devops and ci cd are key enablers of agile development  however  today   s devops practices predominantly focus on cloud and enterprise application development  for successful aiot products  devops will need to be extended to include ai and iot  fig        ,9.818029,4.2883244,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Macaroni: Crawling and Enriching Metadata from Public Model Zoos,"Machine learning (ML) researchers and practitioners are building repositories of pre-trained models, called model zoos. These model zoos contain metadata that detail various properties of the ML models and datasets, which are useful for reporting, auditing, reproducibility, and interpretability. Unfortunately, the existing metadata representations come with limited expressivity and lack of standardization. Meanwhile, an interoperable method to store and query model zoo metadata is missing. These two gaps hinder model search, reuse, comparison, and composition. In this demo paper, we advocate for standardized ML model metadata representation, proposing Macaroni, a metadata search engine with toolkits that support practitioners to obtain and enrich that metadata.
 Keywords
 Machine Learning
 Model Zoo
 Metadata Representation",machine learning  ml  researchers and practitioners are building repositories of pre trained models  called model zoos  these model zoos contain metadata that detail various properties of the ml models and datasets  which are useful for reporting  auditing  reproducibility  and interpretability  unfortunately  the existing metadata representations come with limited expressivity and lack of standardization  meanwhile  an interoperable method to store and query model zoo metadata is missing  these two gaps hinder model search  reuse  comparison  and composition  in this demo paper  we advocate for standardized ml model metadata representation  proposing macaroni  a metadata search engine with toolkits that support practitioners to obtain and enrich that metadata   keywords  machine learning  model zoo  metadata representation,6.361701,5.8628306,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Editorial,"Social media has many benefits: from staying in contact with close and not-so-close friends, over exercising the right to voice oneâ€™s opinion, to communicating with many like-minded people all over the world and providing an additional channel for information exchange.
 Unfortunately, social media has also been abused and misused ever since its inception. Hate speech is prevalent on many sites alienating trusting users and hindering fruitful discussions. Fake news are distributed through social media platforms with dangerous effects. But even without malicious intention, social media can be misleading due to various biases in the system.
 In this special issue of Datenbank-Spektrum, we will explore and present current trends in the field of automatically detecting and managing hate speech, fake news, bias and other toxic content in the context of social media. We solicited novel research contributions and received eight submissions in total. Each submission was reviewed by two independent reviewers and then discussed among the editors. Four papers were finally accepted covering a broad range of topics.
 The first article entitled Automated multilingual detection of Pro-Kremlin propaganda in newspapers and Telegram posts by Veronika Solopova, Oana-Juliana Popescu, Christoph BenzmÃ¼ller and Tim Landgraf explores the specific natural language processing problem of propaganda detection and looks at it both with a quantitative as well as a qualitative angle. Transformer-based and linguistically motivated approaches are investigated and compared. This leads to some surprising findings including the use of some seemingly neutral lexical items that turn out to be strong indicators of propaganda in this context. The authors hope to make a contribution towards understanding patterns of fake news or propaganda detection and in particular offering some steps towards addressing the problem in less resourced languages.
 The next contribution, Generalizability of Abusive Language Detection Models on Homogeneous German Datasets by Nina Seemann, Yeong Su Lee, Julian HÃ¶llig and Michaela Geierhos compares the compatibility of different German datasets for abusive language detection from the GermEval and HASOC evaluation campaigns. The authors find that a combination of different datasets is not always beneficial. Its effectiveness not only depends on the similarity of annotation schemes but also on the source from which the respective text samples have been drawn. The authors take into consideration different types of learning methods. An error analysis of the output of the strongest classifier provides more insights into the properties of the different datasets.
 The third article Moving Beyond Benchmarks and Competitions: Towards Addressing Social Media Challenges in an Educational Context by Dimitri Ognibene, Gregor Donabauer, Emily Theophilou, Sathya Bursic, Francesco Lomonaco, Rodrigo Wilkens, Davinia Hernandez-Leo, and Udo Kruschwitz emphasizes the importance of not just chasing state-of-the-art performance measures when tackling fake news, filter bubbles, or cyberbullying. Instead they argue that such social media threats should be addressed by educating users with a focus on teenagers. Hence, the efforts developed as part of the COURAGE project are twofold: building multi-modal threat detectors and content analyzers on the one hand and educating users in dealing with social media threats and the output of machine learning methods active on social media sites.
 The final article of this special issue Avoiding Bias when Capturing Illegal Hate Speech by Johannes SchÃ¤fer exemplifies the creation of a dataset sampled from Twitter for hate speech detection with a fine-grained class inventory bearing in mind the definitions of German law code (â€œStrafgesetzbuch (StGB)â€). The annotation scheme distinguishes between 4 subclasses of hate speech: malicious gossip/defamation, incitement to commit offenses, incitement of masses, and insults. In their classification experiments, the authors also focus on the role of identity terms. While such terms are often biased towards specific classes (â€œidentity term biasâ€), the authors also argue that the removal of such terms, which can be regarded as â€œbrute-forceâ€ bias mitigation, omits essential information for a classifier to make a correct prediction.
 We would like to thank the authors of all submissions for their contribution. In addition to that, we are particularly grateful to the reviewers who had to work towards a particularly tight schedule, namely Josef Ruppenhofer (IDS, Mannheim), Thomas Mandl (University of Hildesheim), Melanie Siegel (Hochschule Darmstadt), Julia Maria StruÃŸ (FH Potsdam), Supriyo Mandal (ZBW Kiel), Gregor Donabauer (University of Regensburg), Marco Viviani (University of Milan-Bicocca), Andrew MacFarlane (City University), Sean MacAvaney (University of Glasgow), Maik FrÃ¶be (University of Jena), Elisabeth Eder (Alpen-Adria-UniversitÃ¤t Klagenfurt), Michael Granitzer (University of Passau), Seid Muhie Yimam (UniversitÃ¤t Hamburg), Julian Risch (deepset.ai), and Betty van Aken (BHT Berlin).",social media has many benefits  from staying in contact with close and not so close friends  over exercising the right to voice one   s opinion  to communicating with many like minded people all over the world and providing an additional channel for information exchange   unfortunately  social media has also been abused and misused ever since its inception  hate speech is prevalent on many sites alienating trusting users and hindering fruitful discussions  fake news are distributed through social media platforms with dangerous effects  but even without malicious intention  social media can be misleading due to various biases in the system   in this special issue of datenbank spektrum  we will explore and present current trends in the field of automatically detecting and managing hate speech  fake news  bias and other toxic content in the context of social media  we solicited novel research contributions and received eight submissions in total  each submission was reviewed by two independent reviewers and then discussed among the editors  four papers were finally accepted covering a broad range of topics   the first article entitled automated multilingual detection of pro kremlin propaganda in newspapers and telegram posts by veronika solopova  oana juliana popescu  christoph benzm  ller and tim landgraf explores the specific natural language processing problem of propaganda detection and looks at it both with a quantitative as well as a qualitative angle  transformer based and linguistically motivated approaches are investigated and compared  this leads to some surprising findings including the use of some seemingly neutral lexical items that turn out to be strong indicators of propaganda in this context  the authors hope to make a contribution towards understanding patterns of fake news or propaganda detection and in particular offering some steps towards addressing the problem in less resourced languages   the next contribution  generalizability of abusive language detection models on homogeneous german datasets by nina seemann  yeong su lee  julian h  llig and michaela geierhos compares the compatibility of different german datasets for abusive language detection from the germeval and hasoc evaluation campaigns  the authors find that a combination of different datasets is not always beneficial  its effectiveness not only depends on the similarity of annotation schemes but also on the source from which the respective text samples have been drawn  the authors take into consideration different types of learning methods  an error analysis of the output of the strongest classifier provides more insights into the properties of the different datasets   the third article moving beyond benchmarks and competitions  towards addressing social media challenges in an educational context by dimitri ognibene  gregor donabauer  emily theophilou  sathya bursic  francesco lomonaco  rodrigo wilkens  davinia hernandez leo  and udo kruschwitz emphasizes the importance of not just chasing state of the art performance measures when tackling fake news  filter bubbles  or cyberbullying  instead they argue that such social media threats should be addressed by educating users with a focus on teenagers  hence  the efforts developed as part of the courage project are twofold  building multi modal threat detectors and content analyzers on the one hand and educating users in dealing with social media threats and the output of machine learning methods active on social media sites   the final article of this special issue avoiding bias when capturing illegal hate speech by johannes sch  fer exemplifies the creation of a dataset sampled from twitter for hate speech detection with a fine grained class inventory bearing in mind the definitions of german law code     strafgesetzbuch  stgb       the annotation scheme distinguishes between   subclasses of hate speech  malicious gossip defamation  incitement to commit offenses  incitement of masses  and insults  in their classification experiments  the authors also focus on the role of identity terms  while such terms are often biased towards specific classes     identity term bias      the authors also argue that the removal of such terms  which can be regarded as    brute force    bias mitigation  omits essential information for a classifier to make a correct prediction   we would like to thank the authors of all submissions for their contribution  in addition to that  we are particularly grateful to the reviewers who had to work towards a particularly tight schedule  namely josef ruppenhofer  ids  mannheim   thomas mandl  university of hildesheim   melanie siegel  hochschule darmstadt   julia maria stru    fh potsdam   supriyo mandal  zbw kiel   gregor donabauer  university of regensburg   marco viviani  university of milan bicocca   andrew macfarlane  city university   sean macavaney  university of glasgow   maik fr  be  university of jena   elisabeth eder  alpen adria universit  t klagenfurt   michael granitzer  university of passau   seid muhie yimam  universit  t hamburg   julian risch  deepset ai   and betty van aken  bht berlin  ,7.1942077,6.23783,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Hands-on with Azure Machine Learning,"In the previous chapter, we discussed Azure Machine Learning service tools, functionality, and assets. This chapter focuses on providing hands-on experience to users and develop end-to-end machine learning project life cycle using Azure ML SDK. As mentioned in the previous chapter, Azure ML offers Python SDK, R SDK, and low-code or zero-code Azure ML designer approaches to develop, train, and deploy ML models; we will use Python SDK for our hands-on labs in this chapter. For the purposes of hands-on lab in this chapter, we will assume users are familiar with Python and getting started with implementing data science solutions on cloud.",in the previous chapter  we discussed azure machine learning service tools  functionality  and assets  this chapter focuses on providing hands on experience to users and develop end to end machine learning project life cycle using azure ml sdk  as mentioned in the previous chapter  azure ml offers python sdk  r sdk  and low code or zero code azure ml designer approaches to develop  train  and deploy ml models  we will use python sdk for our hands on labs in this chapter  for the purposes of hands on lab in this chapter  we will assume users are familiar with python and getting started with implementing data science solutions on cloud ,8.672706,7.759708,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Hands-on with Azure Databricks,"In Chapter 6, we explored the concepts of Spark and Azure Databricksâ€™ implementation of the platform. In this chapter, we will be doing a hands-on exploration of these concepts in Azure Databricks.",in chapter    we explored the concepts of spark and azure databricks    implementation of the platform  in this chapter  we will be doing a hands on exploration of these concepts in azure databricks ,8.633753,7.6025596,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
"Editorial issue 3â€¯+â€‰4, 2023","This special issue of AStA Wirtschafts- und Sozialstatistisches Archiv with two volumes aims to offer an overview of some relevant quality aspects of machine learning methods, especially but not only when applied to official statistics.",this special issue of asta wirtschafts  und sozialstatistisches archiv with two volumes aims to offer an overview of some relevant quality aspects of machine learning methods  especially but not only when applied to official statistics ,8.042465,6.2751484,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
A Framework for Privacy-Preserved Collaborative Learning in Smart Factory Environment,"Integration of artificial intelligence (AI) in a work environment is the key factor of the industry 4.0 revolution. Vertical and horizontal integration among different parties become relevant but privacy could be the issues. Federated learning (FL) has been widely used as a decentralized mechanism to cope with privacy preserving problems. However, the initial setup for FL in the real-world application is difficult and requires a lot of human involvement in daily operation. In addition, project key performance indicator which is important to assess enterprise collaboration accomplishment among partners has been rarely addressed. In this work, we develop a horizontal FL framework and modular dashboard to enable collaborative training among different parties. The module is available for key performance monitoring operational view on both server and clients in three aspects; computer-related indicators, machine learning-related indicators, and manufacturing related indicators. Using the proposed framework, it can provide insight to the user regarding FL results.
 Keywords
 Modular Dashboard
 Federated Learning
 Privacy Preserving Mechanism",integration of artificial intelligence  ai  in a work environment is the key factor of the industry     revolution  vertical and horizontal integration among different parties become relevant but privacy could be the issues  federated learning  fl  has been widely used as a decentralized mechanism to cope with privacy preserving problems  however  the initial setup for fl in the real world application is difficult and requires a lot of human involvement in daily operation  in addition  project key performance indicator which is important to assess enterprise collaboration accomplishment among partners has been rarely addressed  in this work  we develop a horizontal fl framework and modular dashboard to enable collaborative training among different parties  the module is available for key performance monitoring operational view on both server and clients in three aspects  computer related indicators  machine learning related indicators  and manufacturing related indicators  using the proposed framework  it can provide insight to the user regarding fl results   keywords  modular dashboard  federated learning  privacy preserving mechanism,6.0245748,7.83415,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Kubeflow and Kubeflow Pipelines,"Machine learning is often and rightly viewed as the use of mathematical algorithms to teach the computer to learn tasks that are computationally infeasible to program as a set of specified instructions. However, it turns out that these algorithms constitute only a small fraction of the overall learning pipeline from an engineering perspective. Building high-performant and dynamic learning models includes a number of other critical components. These components actually dominate the space of concerns for delivering an end-to-end machine learning product.",machine learning is often and rightly viewed as the use of mathematical algorithms to teach the computer to learn tasks that are computationally infeasible to program as a set of specified instructions  however  it turns out that these algorithms constitute only a small fraction of the overall learning pipeline from an engineering perspective  building high performant and dynamic learning models includes a number of other critical components  these components actually dominate the space of concerns for delivering an end to end machine learning product ,3.1740112,7.9402194,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
A set optimization approach to zero-sum matrix games with multi-dimensional payoffs,"A new solution concept for two-player zero-sum matrix games with multi-dimensional payoffs is introduced. It is based on extensions of the vector order in \mathbb {R}^d to order relations in the power set of \mathbb {R}^d, so-called set relations, and strictly motivated by the interpretation of the payoff as multi-dimensional loss for one and gain for the other player. The new concept provides coherent worst case estimates for games with multi-dimensional payoffs. It is shown thatâ€“in contrast to games with one-dimensional payoffsâ€“the corresponding strategies are different from equilibrium strategies for games with multi-dimensional payoffs. The two concepts are combined into new equilibrium notions for which existence theorems are given. Relationships of the new concepts to existing ones such as Shapley and vector equilibria, vector minimax and maximin solutions as well as Pareto optimal security strategies are clarified.",a new solution concept for two player zero sum matrix games with multi dimensional payoffs is introduced  it is based on extensions of the vector order in  mathbb  r  d to order relations in the power set of  mathbb  r  d  so called set relations  and strictly motivated by the interpretation of the payoff as multi dimensional loss for one and gain for the other player  the new concept provides coherent worst case estimates for games with multi dimensional payoffs  it is shown that   in contrast to games with one dimensional payoffs   the corresponding strategies are different from equilibrium strategies for games with multi dimensional payoffs  the two concepts are combined into new equilibrium notions for which existence theorems are given  relationships of the new concepts to existing ones such as shapley and vector equilibria  vector minimax and maximin solutions as well as pareto optimal security strategies are clarified ,2.9407194,8.2212515,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Real-Time Detection of Atrial Fibrillation from Short Time Single Lead ECG Traces Using Recurrent Neural Networks,"Atrial fibrillation (AF) is the predominant type of cardiac arrhythmia affecting more than 45 Million individuals globally. It is one of the leading contributors of strokes and hence detecting them in real-time is of paramount importance for early intervention. Traditional methods require long ECG traces and tedious preprocessing for accurate diagnosis. In this paper, we explore and employ deep learning methods such as RNN, LSTM and GRU to detect the Atrial Fibrillation (AF) faster in the given electrocardiogram traces. For this study, we used one of the well-known publicly available MIT-BIH Physionet dataset. To the best of our knowledge this is the first time Deep learning has been employed to detect the Atrial Fibrillation in real-time. Based on our experiments RNN, LSTM and GRU offer the accuracy of 0.950, 1.000 and 1.000 respectively. Our methodology does not require any de-noising, other filtering and preprocessing methods. Results are encouraging enough to begin clinical trials for the real-time detection of AF that will be highly beneficial in the scenarios of ambulatory, intensive care units and for real-time detection of AF for life saving implantable defibrillators.
 Keywords
 Recurrent Neural Networks (RNN)
 Long Short-term Memory (LSTM)
 Gated Recurrent Unit (GRU)
 LSTM Network
 Recurrent Hidden Layer
 These keywords were added by machine and not by the authors. This process is experimental and the keywords may be updated as the learning algorithm improves.",atrial fibrillation  af  is the predominant type of cardiac arrhythmia affecting more than    million individuals globally  it is one of the leading contributors of strokes and hence detecting them in real time is of paramount importance for early intervention  traditional methods require long ecg traces and tedious preprocessing for accurate diagnosis  in this paper  we explore and employ deep learning methods such as rnn  lstm and gru to detect the atrial fibrillation  af  faster in the given electrocardiogram traces  for this study  we used one of the well known publicly available mit bih physionet dataset  to the best of our knowledge this is the first time deep learning has been employed to detect the atrial fibrillation in real time  based on our experiments rnn  lstm and gru offer the accuracy of              and       respectively  our methodology does not require any de noising  other filtering and preprocessing methods  results are encouraging enough to begin clinical trials for the real time detection of af that will be highly beneficial in the scenarios of ambulatory  intensive care units and for real time detection of af for life saving implantable defibrillators   keywords  recurrent neural networks  rnn   long short term memory  lstm   gated recurrent unit  gru   lstm network  recurrent hidden layer  these keywords were added by machine and not by the authors  this process is experimental and the keywords may be updated as the learning algorithm improves ,3.5244179,5.5683,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Bilevel Optimization Using Bacteria Foraging Optimization Algorithm,"Bilevel programming problems involve two optimization problems where the constraint region of the first level problem is implicitly determined by another optimization problem. There are number of different algorithms developed based on classical deterministic optimization methods for Bilevel Optimizations Problems (BLOP), but these are very much problem specific, non-robust and computation intensive when number of decision variables increase, while not applicable for multi-modal problems. Evolutionary Algorithms are inherently parallel, capable of local as well as global search, random, and robust techniques and can used to solve these BLOPs. In this paper, Bilevel Bacteria Foraging Optimization Algorithm (BiBFOA) is proposed for solving BLOP based on the foraging technique of common bacteria. Experimental results demonstrate the validity of the BFOA-based algorithm for solution of BLOPs.
 Keywords
 Bilevel optimization problem (BLOP)
 Bacteria foraging optimization algorithm (BFOA)
 Bibfoa
 Chemotaxis
 Elimination -dispersion",bilevel programming problems involve two optimization problems where the constraint region of the first level problem is implicitly determined by another optimization problem  there are number of different algorithms developed based on classical deterministic optimization methods for bilevel optimizations problems  blop   but these are very much problem specific  non robust and computation intensive when number of decision variables increase  while not applicable for multi modal problems  evolutionary algorithms are inherently parallel  capable of local as well as global search  random  and robust techniques and can used to solve these blops  in this paper  bilevel bacteria foraging optimization algorithm  bibfoa  is proposed for solving blop based on the foraging technique of common bacteria  experimental results demonstrate the validity of the bfoa based algorithm for solution of blops   keywords  bilevel optimization problem  blop   bacteria foraging optimization algorithm  bfoa   bibfoa  chemotaxis  elimination  dispersion,2.883936,8.181521,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Evaluating Load-Carrying Capacity of Short Composite Beam Using Strain-Hardening HPFRC,"The main goal of this study was to develop the short composite beams using strain-hardening fiber-reinforced concrete (S_HPFRC) and conventional concrete (CC) together. Firstly, the sensitivity of the hybrid fiber system to the enhancement of mechanical properties of plain high performance concrete (P_mortar) was experimentally studied. The ranking of the mechanical properties in terms of sensitive coefficient was observed as follows: direct tensile > splitting tensile > compressive. Next, the responses of short composite beams with various thicknesses of S_HPFRC were investigated under a three-point bending test (3PBT). Six beams with no reinforcement (type A) and six beams with reinforcement were tested (type B) with their identical dimensions of 150 Ã— 150 Ã— 300 mm (depth Ã— width Ã— span length). The compressive strength of S_HPFRC and CC were about 80.65 MPa and 21.12 MPa, respectively. Most of the composite beams were observed to fail in shear mode. And, there was a favorable effect on enhancing the load-carrying capacity of a beam as S_HPFRC was placed at a critical tensile zone. Finally, based on the test data, the analytical equations were proposed for the purpose of predicting shear resistance of the S_HPFRC â€” CC beam.",the main goal of this study was to develop the short composite beams using strain hardening fiber reinforced concrete  s hpfrc  and conventional concrete  cc  together  firstly  the sensitivity of the hybrid fiber system to the enhancement of mechanical properties of plain high performance concrete  p mortar  was experimentally studied  the ranking of the mechanical properties in terms of sensitive coefficient was observed as follows  direct tensile   splitting tensile   compressive  next  the responses of short composite beams with various thicknesses of s hpfrc were investigated under a three point bending test   pbt   six beams with no reinforcement  type a  and six beams with reinforcement were tested  type b  with their identical dimensions of                   mm  depth    width    span length   the compressive strength of s hpfrc and cc were about       mpa and       mpa  respectively  most of the composite beams were observed to fail in shear mode  and  there was a favorable effect on enhancing the load carrying capacity of a beam as s hpfrc was placed at a critical tensile zone  finally  based on the test data  the analytical equations were proposed for the purpose of predicting shear resistance of the s hpfrc     cc beam ,4.301671,3.2584982,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
"A reproducible method for biochemical, histological and functional assessment of the effects of ischaemiaâ€“reperfusion syndrome in the lower limbs","Current methodology described to mimic lower limb ischaemiaâ€“reperfusion injury (LL-IRI) does not accurately define the procedures and pressures exerted to induce and maintain ischaemia. In this piece of work, we propose a well-defined and detailed rat model that simulates the conditions established in clinical practice guidelines for tourniquet application and allows us to test treatments that aim to prevent/reduce LL-IRI. Eighty-six male WAG/RijHsd rats were subjected to hind limb IRI (LL-IRI), using a mechanical system applying a 1 kg tension to induce and maintain ischemia for 2 or 3 h, and assessed the damage caused by reperfusion at biochemical and muscular levels at different time points. At the biochemical level, both 2 and 3 h of ischemia induced changes (except for electrolyte levels); 3 h of ischemia induced greater changes in specific markers of muscular damage: creatine kinase (CK) and lactate dehydrogenase (LDH). At the histopathological level, 3 h of ischemia and 24 h of reperfusion was associated with an increase in hind limb girth, cross-sectional area, and weight and presence of neutrophils, as well as histological damage in more than 60% of muscle fibres. Our model allows to reliably reproduce the damage associated with the use of a pneumatic tourniquet. CK and LDH, as well as measures of tissue damage, allow to define and characterize the response to LL-IRI-related damage. A period of 3 h of ischemia followed by 3 h of reperfusion caused only local damage but showed greater sensitivity to detect differences in future studies on prophylactic treatments against LL-IRI.",current methodology described to mimic lower limb ischaemia   reperfusion injury  ll iri  does not accurately define the procedures and pressures exerted to induce and maintain ischaemia  in this piece of work  we propose a well defined and detailed rat model that simulates the conditions established in clinical practice guidelines for tourniquet application and allows us to test treatments that aim to prevent reduce ll iri  eighty six male wag rijhsd rats were subjected to hind limb iri  ll iri   using a mechanical system applying a   kg tension to induce and maintain ischemia for   or   h  and assessed the damage caused by reperfusion at biochemical and muscular levels at different time points  at the biochemical level  both   and   h of ischemia induced changes  except for electrolyte levels     h of ischemia induced greater changes in specific markers of muscular damage  creatine kinase  ck  and lactate dehydrogenase  ldh   at the histopathological level    h of ischemia and    h of reperfusion was associated with an increase in hind limb girth  cross sectional area  and weight and presence of neutrophils  as well as histological damage in more than     of muscle fibres  our model allows to reliably reproduce the damage associated with the use of a pneumatic tourniquet  ck and ldh  as well as measures of tissue damage  allow to define and characterize the response to ll iri related damage  a period of   h of ischemia followed by   h of reperfusion caused only local damage but showed greater sensitivity to detect differences in future studies on prophylactic treatments against ll iri ,4.537649,2.9776077,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
ROS and Oxidative Stress: Origin and Implication,"Molecular oxygen (O2) is the primary cellular electron acceptor in aerobic respiration that serves fundamental roles in membrane-linked ATP formation and other fundamental cellular and metabolic functions. But, as an untoward but inescapable consequence of different metabolic events in oxygen-saturated cellular environment, reactive oxygen species (ROS) are incessantly generated by partial or incomplete reduction of molecular oxygen. In plants, ROS are continuously generated as oxidation â€“ reduction cascades of different metabolism located in different cellular compartments and as by-product of various metabolic events. The most important ROS include superoxide (O2.âˆ’), perhydroxy radical (HO2.), hydrogen peroxide (H2O2), hydroxy radical (OH.), and singlet oxygen (âˆ£O2). The other secondary oxidative products like alkoxy radical (RO.), peroxy radical (ROO.), organic hydroperoxide (ROOH), excited carbonyl (RO.), etc. are also produced in plant cells. Though ROS is generated under natural conditions, their productions are augmented under the exposure of unfavorable environmental cues and natural course of senescence. Major sources of ROS in plant cell encompass spilling of electrons during photosynthetic and respiratory electron transport, decompartmentalization of transition metal ions, and also various biological redox reactions. In fact, the redox cascades of chloroplast, peroxisome, and mitochondria of green cells not only determine the driving forces for metabolism but also recognized as the prime source of ROS. Lipid peroxidation, which is known to produce ROS like alkoxy, peroxy radicals as well as singlet oxygen, is also considered as bona fide source of ROS in plant cells. In plants, apoplastic enzyme respiratory burst oxidase homologs (RBOHs) or NADPH oxidases play a major role in originating ROS wave through the other network of ROS production as well. The ROS wave, which is a consequence of perception of unfavorable environmental cues should be integrated with additional metabolic/signaling pathways to enable rapid systemic acclimation of plants. However, an elaborate and efficient antioxidative defense system, comprising a variety of antioxidant molecules, quenchers, and enzymes, determines the ROS turnover and hence the steady-state level of ROS and the redox status of the cell. Plants are equipped with those defense systems not only to combat enhanced level of ROS but also to tightly regulate the endogenous concentration necessary for controlling various events of Plant Biology. However, the decontrolled level of ROS generation, if remaining unabated may cause a solemn threat to or cause oxidative deterioration and in extreme cases the death of plant cells. The present chapter describes the physicochemical basis of the production of ROS, under normal and unfavorable environmental conditions, and senescence, with an added effort to understand their implication associated with those situations.
 Keywords
 Oxyfree radicals
 Oxidative stress
 Antioxidative defense
 Environmental stress
 ROS wave
 Environmental stress",molecular oxygen  o   is the primary cellular electron acceptor in aerobic respiration that serves fundamental roles in membrane linked atp formation and other fundamental cellular and metabolic functions  but  as an untoward but inescapable consequence of different metabolic events in oxygen saturated cellular environment  reactive oxygen species  ros  are incessantly generated by partial or incomplete reduction of molecular oxygen  in plants  ros are continuously generated as oxidation     reduction cascades of different metabolism located in different cellular compartments and as by product of various metabolic events  the most important ros include superoxide  o        perhydroxy radical  ho     hydrogen peroxide  h o    hydroxy radical  oh    and singlet oxygen     o    the other secondary oxidative products like alkoxy radical  ro    peroxy radical  roo    organic hydroperoxide  rooh   excited carbonyl  ro    etc  are also produced in plant cells  though ros is generated under natural conditions  their productions are augmented under the exposure of unfavorable environmental cues and natural course of senescence  major sources of ros in plant cell encompass spilling of electrons during photosynthetic and respiratory electron transport  decompartmentalization of transition metal ions  and also various biological redox reactions  in fact  the redox cascades of chloroplast  peroxisome  and mitochondria of green cells not only determine the driving forces for metabolism but also recognized as the prime source of ros  lipid peroxidation  which is known to produce ros like alkoxy  peroxy radicals as well as singlet oxygen  is also considered as bona fide source of ros in plant cells  in plants  apoplastic enzyme respiratory burst oxidase homologs  rbohs  or nadph oxidases play a major role in originating ros wave through the other network of ros production as well  the ros wave  which is a consequence of perception of unfavorable environmental cues should be integrated with additional metabolic signaling pathways to enable rapid systemic acclimation of plants  however  an elaborate and efficient antioxidative defense system  comprising a variety of antioxidant molecules  quenchers  and enzymes  determines the ros turnover and hence the steady state level of ros and the redox status of the cell  plants are equipped with those defense systems not only to combat enhanced level of ros but also to tightly regulate the endogenous concentration necessary for controlling various events of plant biology  however  the decontrolled level of ros generation  if remaining unabated may cause a solemn threat to or cause oxidative deterioration and in extreme cases the death of plant cells  the present chapter describes the physicochemical basis of the production of ros  under normal and unfavorable environmental conditions  and senescence  with an added effort to understand their implication associated with those situations   keywords  oxyfree radicals  oxidative stress  antioxidative defense  environmental stress  ros wave  environmental stress,3.5811627,2.164263,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
RLOP: A Framework Design for Offset Prefetching Combined with Reinforcement Learning,"Previous prefetching schemes have been found to be very effective at enhancing the performance of computers. However, speculative prefetching requests can have negative effects on computers, such as increased memory bandwidth consumption and cache pollution. To address the deficiencies of previous prefetching schemes, we propose the Reinforcement Learning Based Offset Prefetching Scheme (RLOP), an offset prefetching scheme based on reinforcement learning. As with previous offset prefetching schemes, RLOP evaluates multiple offsets and enables offsets that qualify to issue prefetching requests. RLOP, however, selects appropriate prefetch offsets through reinforcement learning, and the reinforcement learning reward scheme determines the goal of the prefetcher; we divide the rewards into four different rewardsâ€”accurate and timely prefetch, accurate but delayed prefetch, inaccurate prefetch, and no prefetch operationâ€”and by increasing or decreasing the reward value, we facilitate or inhibit RLOP from future environments to collect such rewards, which enables or inhibits RLOP from collecting such rewards, which enables We evaluated and contrasted RLOP with various advanced data prefetchers and demonstrated that our scheme resulted in a 25.26% increase in system performance over systems without data prefetchers and a 3.8% increase over the previous best performing data prefetcher.
 Keywords
 Cache optimization
 Data prefetching
 Offset prefetching
 Machine learning
 Reinforcement learning",previous prefetching schemes have been found to be very effective at enhancing the performance of computers  however  speculative prefetching requests can have negative effects on computers  such as increased memory bandwidth consumption and cache pollution  to address the deficiencies of previous prefetching schemes  we propose the reinforcement learning based offset prefetching scheme  rlop   an offset prefetching scheme based on reinforcement learning  as with previous offset prefetching schemes  rlop evaluates multiple offsets and enables offsets that qualify to issue prefetching requests  rlop  however  selects appropriate prefetch offsets through reinforcement learning  and the reinforcement learning reward scheme determines the goal of the prefetcher  we divide the rewards into four different rewards   accurate and timely prefetch  accurate but delayed prefetch  inaccurate prefetch  and no prefetch operation   and by increasing or decreasing the reward value  we facilitate or inhibit rlop from future environments to collect such rewards  which enables or inhibits rlop from collecting such rewards  which enables we evaluated and contrasted rlop with various advanced data prefetchers and demonstrated that our scheme resulted in a        increase in system performance over systems without data prefetchers and a      increase over the previous best performing data prefetcher   keywords  cache optimization  data prefetching  offset prefetching  machine learning  reinforcement learning,4.688206,8.278168,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Multi-dimensional multi-directional mask maximum edge pattern for bio-medical image retrieval,"Authors have proposed novel multi-dimensional multi-directional mask maximum edge patterns for the bio-medical image retrieval. Standard local binary patterns encode relationship of neighbor pixels with center pixel. Local mesh patterns encode the relationship between adjacent pixels surrounding the center pixel. Proposed approach encodes relationship of neighbour pixels in adjacent planes of a multi-dimensional image, in three stages. In the first stage, five sub images are formed by traversing in five different directions on three planes of a multi-dimensional image. In the second stage, directional masks are applied on each sub image to find directional edges. In stage three, maximum edge patterns are found based on the directions of the directional edges. To examine performance analysis of the proposed algorithm, we tested proposed algorithm on three benchmark databases, which gives retrieval accuracy 56.93\% for top 5 images, 93.36 and 62.49\% for top 10 images on MESSIDOR (Retinal images), VIA/I-ELCAP (CT images) and OASIS-MRI databases respectively in terms of average retrieval precision. The comparison reflects, there is considerable improvement in the performance.",authors have proposed novel multi dimensional multi directional mask maximum edge patterns for the bio medical image retrieval  standard local binary patterns encode relationship of neighbor pixels with center pixel  local mesh patterns encode the relationship between adjacent pixels surrounding the center pixel  proposed approach encodes relationship of neighbour pixels in adjacent planes of a multi dimensional image  in three stages  in the first stage  five sub images are formed by traversing in five different directions on three planes of a multi dimensional image  in the second stage  directional masks are applied on each sub image to find directional edges  in stage three  maximum edge patterns are found based on the directions of the directional edges  to examine performance analysis of the proposed algorithm  we tested proposed algorithm on three benchmark databases  which gives retrieval accuracy         for top   images        and         for top    images on messidor  retinal images   via i elcap  ct images  and oasis mri databases respectively in terms of average retrieval precision  the comparison reflects  there is considerable improvement in the performance ,4.1664944,6.082732,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
"Allied Ophthalmic Personnel: Workforce, Education, and Training","Globally, approximately 43 million people are blind and 295 million people are moderate to severe visually impaired. Therefore, the prevention of blindness is a high-priority global agenda. The â€œVISION 2020: The Right to Sightâ€ global initiative was launched with the aim of eliminating avoidable blindness by the year 2020. This ambitious goal can only be achieved through strengthening of health systems with improved provision of eye care delivery at all levels. This, in turn, depends on the availability of appropriately trained eye care professionals (Fig. 19.1).",globally  approximately    million people are blind and     million people are moderate to severe visually impaired  therefore  the prevention of blindness is a high priority global agenda  the    vision       the right to sight    global initiative was launched with the aim of eliminating avoidable blindness by the year       this ambitious goal can only be achieved through strengthening of health systems with improved provision of eye care delivery at all levels  this  in turn  depends on the availability of appropriately trained eye care professionals  fig        ,6.8823895,3.7208695,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
"S2B, a Temperate Bacteriophage That Infects Caulobacter Crescentus Strain CB15","The Caulobacter crescentus strain CB15 has been the basis of numerous studies designed to characterize the biphasic life cycle of this bacterium. Here we describe a newly isolated podovirus, designated S2B, which is capable of integrating into the CB15 chromosome by recombining with the 3â€™-end of a particular tRNAâˆ’ser gene. In addition, we show that S2B is a representative of a family of closely related prophages that are present in the genomes of characterized strains from several Alphaproteobacteria genera. In contrast, only distantly related bacteriophage genomes are present in the GenBank database. The 42,846 bp S2B genome includes 262 bp terminal repeats, and it contains 62 genes of which 45 code for proteins of unknown function. Proteins with predicted functions include a T7 DNA polymerase, a T3/T7 RNA polymerase, and a T7 helicase/primase suggesting that S2B is part of the Studiervirinae subfamily of the Autographiviridae family.",the caulobacter crescentus strain cb   has been the basis of numerous studies designed to characterize the biphasic life cycle of this bacterium  here we describe a newly isolated podovirus  designated s b  which is capable of integrating into the cb   chromosome by recombining with the      end of a particular trna   ser gene  in addition  we show that s b is a representative of a family of closely related prophages that are present in the genomes of characterized strains from several alphaproteobacteria genera  in contrast  only distantly related bacteriophage genomes are present in the genbank database  the        bp s b genome includes     bp terminal repeats  and it contains    genes of which    code for proteins of unknown function  proteins with predicted functions include a t  dna polymerase  a t  t  rna polymerase  and a t  helicase primase suggesting that s b is part of the studiervirinae subfamily of the autographiviridae family ,3.6647503,2.4669623,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
The qualities of patients interested in using a game-based digital mental health intervention for depression: a sequential mixed methods study,"Background
 Digital interventions are typically evaluated by their effectiveness and engagement, while the characteristics of patients who perceive them to be attractive have remained poorly understood. This challenges user-centered intervention development but also presents an avenue to improve intervention efficacy and engagement. Our objective was to characterize people to whom game-based interventions appeal to with a focus on their mental health backgrounds and prior digital game experiences.
 Methods
 We performed a sequential mixed methods study with adults suffering from major depressive disorder (MDD) who participated in a randomized controlled clinical trial studying the effectiveness of a game-based digital intervention for depression. First, randomly chosen participants were interviewed (Nâ€‰=â€‰22), and the transcribed data were analyzed inductively. Then, focusing on the themes established through the interview data, we triangulated the findings using complementary questionnaire data (Nâ€‰=â€‰445).
 Results
 The interview data yielded four themes that we illuminated with quantified questionnaire data. (T1) The participants had enduring and diverse psychiatric symptomology: 73% had been diagnosed with a comorbid disorder in addition to depression. (T2) Participants had received at least some treatments that had not led to full remission of depression. 92% currently received therapeutic support, psychiatric medication, or both. (T3) Many participants had close relationships with digital gaming and played actively: on average, for 13 h a week on various gaming platforms and in various genres. (T4) Some participants used gaming to manage their psychiatric symptoms, and 76% found that playing helped them feel better.
 Conclusions
 Identifying and characterizing people attracted to game-based therapeutic interventions can catalyze intervention development and improve their efficacy. We found that game-based interventions have appealing potential across diverse psychiatric symptoms and for people with prior or existing treatments. Game-based interventions may appeal particularly to active players and offer a promising alternative to the self-treatment usage of entertainment games.",background  digital interventions are typically evaluated by their effectiveness and engagement  while the characteristics of patients who perceive them to be attractive have remained poorly understood  this challenges user centered intervention development but also presents an avenue to improve intervention efficacy and engagement  our objective was to characterize people to whom game based interventions appeal to with a focus on their mental health backgrounds and prior digital game experiences   methods  we performed a sequential mixed methods study with adults suffering from major depressive disorder  mdd  who participated in a randomized controlled clinical trial studying the effectiveness of a game based digital intervention for depression  first  randomly chosen participants were interviewed  n            and the transcribed data were analyzed inductively  then  focusing on the themes established through the interview data  we triangulated the findings using complementary questionnaire data  n              results  the interview data yielded four themes that we illuminated with quantified questionnaire data   t   the participants had enduring and diverse psychiatric symptomology      had been diagnosed with a comorbid disorder in addition to depression   t   participants had received at least some treatments that had not led to full remission of depression      currently received therapeutic support  psychiatric medication  or both   t   many participants had close relationships with digital gaming and played actively  on average  for    h a week on various gaming platforms and in various genres   t   some participants used gaming to manage their psychiatric symptoms  and     found that playing helped them feel better   conclusions  identifying and characterizing people attracted to game based therapeutic interventions can catalyze intervention development and improve their efficacy  we found that game based interventions have appealing potential across diverse psychiatric symptoms and for people with prior or existing treatments  game based interventions may appeal particularly to active players and offer a promising alternative to the self treatment usage of entertainment games ,4.7963066,2.7864935,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Synchronous effect of increasing oxygen and inhibiting phosphorus release from heavily polluted sediment by applying a novel oxygen micro-nano-bubble material,"Purpose
 This study developed a modified oxygen nano-bubble lanthanum-aluminum attapulgite (OLA) for increasing oxygen and inhibiting phosphorus (P) release from heavily polluted sediment.
 Materials and methods
 The OLA material was prepared. The vertical sediment columns were divided into three groups for incubation experiment, namely, OLA capping, LA capping group, and uncapping group. The feasibility of OLA applied as a capping material to regulate redox condition at the sedimentâ€’water interface (SWI) and to reduce the sediment P release was assessed by comprehensively analyzing the oxygen penetration depth and time. The changes of dissolved and labile P and Fe in pore water and sediment were measured using DGTs and HR-Peepers. Variations of inorganic and organic P (IP and OP) and the microbial diversity in sediment were investigated during the incubation period.
 Results and discussion
 OLA can rapidly increase the dissolved oxygen (DO), which significantly alleviate the anoxic environment of SWI. The largest DO penetration depth reached 22.5 mm and maintained a high concentration for 48h. The presence of oxygen changed the abundance of microorganisms on the sediment surface, with a decrease in the relative abundance of Proteobacteria and Cyanobacteria and an increase of Chloroflexi. This resulted in the acceleration of the conversion of organic P (OP) to dissolved P. Also, a part of OP and mobile P oxidized into non-labile OP. It is worth noting that Fe(II) and S(-II) showed positive correlation at the depth of 0â€“40 mm. This may be due to the reduction of sulfate generating FeS, which decouples Fe and P.
 Conclusions
 OLA capping is a promising method for controlling the internal P release from sediments and has the potential for emergency P remediation management from black odorous rivers.",purpose  this study developed a modified oxygen nano bubble lanthanum aluminum attapulgite  ola  for increasing oxygen and inhibiting phosphorus  p  release from heavily polluted sediment   materials and methods  the ola material was prepared  the vertical sediment columns were divided into three groups for incubation experiment  namely  ola capping  la capping group  and uncapping group  the feasibility of ola applied as a capping material to regulate redox condition at the sediment   water interface  swi  and to reduce the sediment p release was assessed by comprehensively analyzing the oxygen penetration depth and time  the changes of dissolved and labile p and fe in pore water and sediment were measured using dgts and hr peepers  variations of inorganic and organic p  ip and op  and the microbial diversity in sediment were investigated during the incubation period   results and discussion  ola can rapidly increase the dissolved oxygen  do   which significantly alleviate the anoxic environment of swi  the largest do penetration depth reached      mm and maintained a high concentration for   h  the presence of oxygen changed the abundance of microorganisms on the sediment surface  with a decrease in the relative abundance of proteobacteria and cyanobacteria and an increase of chloroflexi  this resulted in the acceleration of the conversion of organic p  op  to dissolved p  also  a part of op and mobile p oxidized into non labile op  it is worth noting that fe ii  and s  ii  showed positive correlation at the depth of        mm  this may be due to the reduction of sulfate generating fes  which decouples fe and p   conclusions  ola capping is a promising method for controlling the internal p release from sediments and has the potential for emergency p remediation management from black odorous rivers ,3.8525226,2.0651617,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Industrialising Data,Fourth-generation banking data infrastructure is undergoing a major shift as financial services firms are facing challenges to deliver digital experience in real time by processing very high data volumes.,fourth generation banking data infrastructure is undergoing a major shift as financial services firms are facing challenges to deliver digital experience in real time by processing very high data volumes ,10.14162,7.568246,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Software Architectures for Edge Analytics: A Survey,"Traditionally, industrial and IoT data analytics applications run in the cloud, leveraging its power regarding big data processing capabilities. With edge computing, opportunities for moving data processing from the cloud to the edge has emerged, i.e., compute nodes become close to where data is generated and to where the processed results are consumed. When running analytics on the edge, lag time is minimal, such that real-time data can be considered and insights can be delivered faster, which leads to improving both the effectiveness and efficiency in online decision-making.
 From a software architecture perspective, it is still a challenge to design systems for edge analytics as it raises many architecture-related questions. However, this architectural perspective on edge analytics has not been consolidated in literature so far. Therefore, in this paper, we first give an overview of the edge analytics topic from the perspective of our own experience from industrial projects, before we survey a subset of existing approaches for edge analytics and review them from a software architecture point of view. We investigate the differences among the surveyed architectures in order to shed some light on the covered architectural aspects of edge analytics architectures, which will be useful for future academic and industrial projects incorporating edge analytics.
 Keywords
 Edge computing
 Data analytics
 Software architecture",traditionally  industrial and iot data analytics applications run in the cloud  leveraging its power regarding big data processing capabilities  with edge computing  opportunities for moving data processing from the cloud to the edge has emerged  i e   compute nodes become close to where data is generated and to where the processed results are consumed  when running analytics on the edge  lag time is minimal  such that real time data can be considered and insights can be delivered faster  which leads to improving both the effectiveness and efficiency in online decision making   from a software architecture perspective  it is still a challenge to design systems for edge analytics as it raises many architecture related questions  however  this architectural perspective on edge analytics has not been consolidated in literature so far  therefore  in this paper  we first give an overview of the edge analytics topic from the perspective of our own experience from industrial projects  before we survey a subset of existing approaches for edge analytics and review them from a software architecture point of view  we investigate the differences among the surveyed architectures in order to shed some light on the covered architectural aspects of edge analytics architectures  which will be useful for future academic and industrial projects incorporating edge analytics   keywords  edge computing  data analytics  software architecture,7.3119035,6.384537,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Combining Semantic Web and Machine Learning for Auditable Legal Key Element Extraction,"Based on a real world use case, we developed and evaluated a hybrid AI system that aims to extract key elements from legal permits by combining methods from the Semantic Web and Machine Learning. Specifically, we modelled the available background knowledge in a custom Knowledge Graph, which we exploited together with the usage of different language- and text-embedding-models in order to extract different information from official Austrian permits, including the Issuing Authority, the Operator of the facility in question, the Reference Number, and the Issuing Date. Additionally, we implemented mechanisms to capture automatically auditable traces of the system to ensure the transparency of the processes. Our quantitative evaluation showed overall promising results, while the in-depth qualitative analysis revealed concrete error types, providing guidance on how to improve the current prototype.
 Keywords
 legal permits
 information extraction
 semantic web
 machine learning
 auditability",based on a real world use case  we developed and evaluated a hybrid ai system that aims to extract key elements from legal permits by combining methods from the semantic web and machine learning  specifically  we modelled the available background knowledge in a custom knowledge graph  which we exploited together with the usage of different language  and text embedding models in order to extract different information from official austrian permits  including the issuing authority  the operator of the facility in question  the reference number  and the issuing date  additionally  we implemented mechanisms to capture automatically auditable traces of the system to ensure the transparency of the processes  our quantitative evaluation showed overall promising results  while the in depth qualitative analysis revealed concrete error types  providing guidance on how to improve the current prototype   keywords  legal permits  information extraction  semantic web  machine learning  auditability,10.47963,6.7363725,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
An overview of key trustworthiness attributes and KPIs for trusted ML-based systems engineering,"When deployed, machine-learning (ML) adoption depends on its ability to actually deliver the expected service safely, and to meet user expectations in terms of quality and continuity of service. For instance, the users expect that the technology will not do something it is not supposed to do, e.g., performing actions without informing users. Thus, the use of Artificial Intelligence (AI) in safety-critical systems such as in avionics, mobility, defense, and healthcare requires proving their trustworthiness through out its overall lifecycle (from design to deployment). Based on surveys on quality measures, characteristics and sub-characteristics of AI systems, the Confiance.ai program (www.confiance.ai) aims to identify the relevant trustworthiness attributes and their associated key performance indicators (KPI) or their associated methods for assessing the induced level of trust.",when deployed  machine learning  ml  adoption depends on its ability to actually deliver the expected service safely  and to meet user expectations in terms of quality and continuity of service  for instance  the users expect that the technology will not do something it is not supposed to do  e g   performing actions without informing users  thus  the use of artificial intelligence  ai  in safety critical systems such as in avionics  mobility  defense  and healthcare requires proving their trustworthiness through out its overall lifecycle  from design to deployment   based on surveys on quality measures  characteristics and sub characteristics of ai systems  the confiance ai program  www confiance ai  aims to identify the relevant trustworthiness attributes and their associated key performance indicators  kpi  or their associated methods for assessing the induced level of trust ,12.123983,6.067135,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Sustainability Effects of Robust and Resilient Artificial Intelligence,"It is commonly understood that the resilience of critical information technology (IT) systems based on artificial intelligence (AI) must be ensured. In this regard, we consider resilience both in terms of IT security threats, such as cyberattacks, as well as the ability to robustly persist under uncertain and changing environmental conditions, such as climate change or economic crises. This paper explores the relationship between resilience and sustainability with regard to AI systems, develops fields of action for resilient AI, and elaborates direct and indirect influences on the achievement of the United Nations Sustainable Development Goals. Indirect in this case means that a sustainability effect is reached by taking resilience measures when applying AI in a sustainability-relevant application area, for example precision agriculture or smart health.
 Keywords
 artificial intelligence
 machine learning
 resilience
 security
 sustainability",it is commonly understood that the resilience of critical information technology  it  systems based on artificial intelligence  ai  must be ensured  in this regard  we consider resilience both in terms of it security threats  such as cyberattacks  as well as the ability to robustly persist under uncertain and changing environmental conditions  such as climate change or economic crises  this paper explores the relationship between resilience and sustainability with regard to ai systems  develops fields of action for resilient ai  and elaborates direct and indirect influences on the achievement of the united nations sustainable development goals  indirect in this case means that a sustainability effect is reached by taking resilience measures when applying ai in a sustainability relevant application area  for example precision agriculture or smart health   keywords  artificial intelligence  machine learning  resilience  security  sustainability,11.681488,6.0555487,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
From DevOps to DevDataOps: Data Management in DevOps Processes,"DevOps is a quite effective approach for managing software development and operation, as confirmed by plenty of success stories in real applications and case studies. DevOps is now becoming the main-stream solution adopted by the software industry in development, able to reduce the time to market and costs while improving quality and ensuring evolvability and adaptability of the resulting software architecture. Among the aspects to take into account in a DevOps process, data is assuming strategic importance, since it allows to gain insights from the operation directly into the development, the main objective of a DevOps approach. Data can be therefore considered as the fuel of the DevOps process, requiring proper solutions for its management. Based on the amount of data generated, its variety, velocity, variability, value and other relevant features, DevOps data management can be mainly framed into the BigData category. This allows exploiting BigData solutions for the management of DevOps data generated throughout the process, including artefacts, code, documentation, logs and so on. This paper aims at investigating data management in DevOps processes, identifying related issues, challenges and potential solutions taken from the BigData world as well as from new trends adopting and adapting DevOps approaches in data management, i.e. DataOps.",devops is a quite effective approach for managing software development and operation  as confirmed by plenty of success stories in real applications and case studies  devops is now becoming the main stream solution adopted by the software industry in development  able to reduce the time to market and costs while improving quality and ensuring evolvability and adaptability of the resulting software architecture  among the aspects to take into account in a devops process  data is assuming strategic importance  since it allows to gain insights from the operation directly into the development  the main objective of a devops approach  data can be therefore considered as the fuel of the devops process  requiring proper solutions for its management  based on the amount of data generated  its variety  velocity  variability  value and other relevant features  devops data management can be mainly framed into the bigdata category  this allows exploiting bigdata solutions for the management of devops data generated throughout the process  including artefacts  code  documentation  logs and so on  this paper aims at investigating data management in devops processes  identifying related issues  challenges and potential solutions taken from the bigdata world as well as from new trends adopting and adapting devops approaches in data management  i e  dataops ,10.59508,5.481499,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
A Dark Art: The Machine Learning Labour Process,"This chapter sketches a picture of the labour process that goes into producing machine learning systems. This labour process is schematized with three main stages: data processing, model building and deployment. Drawing on interviews conducted with people working in the AI industry, Steinhoff argues that the machine learning labour process is structured by the exigencies of capitalist production. This is elaborated in four discussions: the commodity form of AI, empirical control of the labour process, AI as an automation technology and the automation of AI work. The chapter concludes with a discussion of the technology of automated machine learning (AutoML) and shows that AutoML is being applied in all stages of the machine learning labour process. Steinhoff argues that machine learning and AutoML could represent a new type of â€œsyntheticâ€ automation, which dispenses with the need to capture skills and knowledge from workers.",this chapter sketches a picture of the labour process that goes into producing machine learning systems  this labour process is schematized with three main stages  data processing  model building and deployment  drawing on interviews conducted with people working in the ai industry  steinhoff argues that the machine learning labour process is structured by the exigencies of capitalist production  this is elaborated in four discussions  the commodity form of ai  empirical control of the labour process  ai as an automation technology and the automation of ai work  the chapter concludes with a discussion of the technology of automated machine learning  automl  and shows that automl is being applied in all stages of the machine learning labour process  steinhoff argues that machine learning and automl could represent a new type of    synthetic    automation  which dispenses with the need to capture skills and knowledge from workers ,10.264932,3.704189,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
The Need of Standardised Metadata to Encode Causal Relationships: Towards Safer Data-Driven Machine Learning Biological Solutions,"In this paper, we discuss the importance of considering causal relations in the development of machine learning solutions to prevent factors hampering the robustness and generalisation capacity of the models, such as induced biases. This issue often arises when the algorithm decision is affected by confounding factors. In this work, we argue that the integration of research assumptions as causal relationships can help identify potential confounders. Together with metadata information, it can enable meta-comparison of data acquisition pipelines. We call for standardised meta-information practices as a crucial step for proper machine learning solutions development, validation, and data sharing. Such practices include detailing the data acquisition process, aiming for automatic integration of causal relationships and actionable metadata.
 Keywords
 Confounders
 Causality
 Metadata
 Machine learning
 Systems biology",in this paper  we discuss the importance of considering causal relations in the development of machine learning solutions to prevent factors hampering the robustness and generalisation capacity of the models  such as induced biases  this issue often arises when the algorithm decision is affected by confounding factors  in this work  we argue that the integration of research assumptions as causal relationships can help identify potential confounders  together with metadata information  it can enable meta comparison of data acquisition pipelines  we call for standardised meta information practices as a crucial step for proper machine learning solutions development  validation  and data sharing  such practices include detailing the data acquisition process  aiming for automatic integration of causal relationships and actionable metadata   keywords  confounders  causality  metadata  machine learning  systems biology,10.644931,6.045509,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Translational Challenges of Biomedical Machine Learning Solutions in Clinical and Laboratory Settings,"The ever increasing use of artificial intelligence (AI) methods in biomedical sciences calls for closer inter-disciplinary collaborations that transfer the domain knowledge from life scientists to computer science researchers and vice-versa. We highlight two general areas where the use of AI-based solutions designed for clinical and laboratory settings has proven problematic. These are used to demonstrate common sources of translational challenges that often stem from the differences in data interpretation between the clinical and research view, and the unmatched expectations and requirements on the result quality metrics. We outline how explicit interpretable inference reporting might be used as a guide to overcome such translational challenges. We conclude with several recommendations for safer translation of machine learning solutions into real-world settings.
 Keywords
 Machine learning
 Biomedicine",the ever increasing use of artificial intelligence  ai  methods in biomedical sciences calls for closer inter disciplinary collaborations that transfer the domain knowledge from life scientists to computer science researchers and vice versa  we highlight two general areas where the use of ai based solutions designed for clinical and laboratory settings has proven problematic  these are used to demonstrate common sources of translational challenges that often stem from the differences in data interpretation between the clinical and research view  and the unmatched expectations and requirements on the result quality metrics  we outline how explicit interpretable inference reporting might be used as a guide to overcome such translational challenges  we conclude with several recommendations for safer translation of machine learning solutions into real world settings   keywords  machine learning  biomedicine,6.582146,3.8891027,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Natural Language Processing and Artificial Intelligence Overview,"In recent years, we have heard a lot about artificial intelligence, machine learning, deep learning, and natural language processing. What are they? Are they all the same? How do we differentiate between them?",in recent years  we have heard a lot about artificial intelligence  machine learning  deep learning  and natural language processing  what are they  are they all the same  how do we differentiate between them ,9.454962,7.103206,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
"From Smart Devices to Smarter Systems: The Evolution of Artificial Intelligence of Things (AIoT) with Characteristics, Architecture, Use Cases and Challenges","An opportunity to continuously collect data about all aspects of a businessâ€™s operations is provided by the Internet of Things (IoT). Companies globally are quickly leveraging IoT to create novel products and services that are creating new business opportunities and generating new revenue streams. This shift is ushering in a new era of how companies operate and interact with customers. There is a huge potential for businesses that are able to transform the raw IoT data into powerful market perceptions and efficient data analysis is the key to achieving this goal. Organizations must now delve deeper into their data to find innovative procedures to improve efficiency and competitiveness. With recent advancements in science and technology, particularly Artificial Intelligence (AI), organizations are adopting larger, more comprehensive analysis methods. To fully realize the benefits of IoT, companies must integrate it with the rapidly evolving AI technologies, enabling â€œsmart machinesâ€ to mimic intelligent behavior and make well-informed decisions with minimal human intervention. This paper is an effort to examine the growth of IoT and explore how the best way to integrate with AI can benefit the business in the future. This paper also discusses the evolution, underlying architecture, applications, and challenges of implementing IoT with the integration of AI.
 Keywords
 IoT
 AI
 Smart machines
 Data analysis
 AIoT
 Data science
 Integration
 Cyber-physical system",an opportunity to continuously collect data about all aspects of a business   s operations is provided by the internet of things  iot   companies globally are quickly leveraging iot to create novel products and services that are creating new business opportunities and generating new revenue streams  this shift is ushering in a new era of how companies operate and interact with customers  there is a huge potential for businesses that are able to transform the raw iot data into powerful market perceptions and efficient data analysis is the key to achieving this goal  organizations must now delve deeper into their data to find innovative procedures to improve efficiency and competitiveness  with recent advancements in science and technology  particularly artificial intelligence  ai   organizations are adopting larger  more comprehensive analysis methods  to fully realize the benefits of iot  companies must integrate it with the rapidly evolving ai technologies  enabling    smart machines    to mimic intelligent behavior and make well informed decisions with minimal human intervention  this paper is an effort to examine the growth of iot and explore how the best way to integrate with ai can benefit the business in the future  this paper also discusses the evolution  underlying architecture  applications  and challenges of implementing iot with the integration of ai   keywords  iot  ai  smart machines  data analysis  aiot  data science  integration  cyber physical system,10.527075,7.8937597,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
No More Strided Convolutions or Pooling: A New CNN Building Block for Low-Resolution Images and Small Objects,"Convolutional neural networks (CNNs) have made resounding success in many computer vision tasks such as image classification and object detection. However, their performance degrades rapidly on tougher tasks where images are of low resolution or objects are small. In this paper, we point out that this roots in a defective yet common design in existing CNN architectures, namely the use of strided convolution and/or pooling layers, which results in a loss of fine-grained information and learning of less effective feature representations. To this end, we propose a new CNN building block called SPD-Conv in place of each strided convolution layer and each pooling layer (thus eliminates them altogether). SPD-Conv is comprised of a space-to-depth (SPD) layer followed by a non-strided convolution (Conv) layer, and can be applied in most if not all CNN architectures. We explain this new design under two most representative computer vision tasks: object detection and image classification. We then create new CNN architectures by applying SPD-Conv to YOLOv5 and ResNet, and empirically show that our approach significantly outperforms state-of-the-art deep learning models, especially on tougher tasks with low-resolution images and small objects. We have open-sourced our code at https://github.com/LabSAINT/SPD-Conv.",convolutional neural networks  cnns  have made resounding success in many computer vision tasks such as image classification and object detection  however  their performance degrades rapidly on tougher tasks where images are of low resolution or objects are small  in this paper  we point out that this roots in a defective yet common design in existing cnn architectures  namely the use of strided convolution and or pooling layers  which results in a loss of fine grained information and learning of less effective feature representations  to this end  we propose a new cnn building block called spd conv in place of each strided convolution layer and each pooling layer  thus eliminates them altogether   spd conv is comprised of a space to depth  spd  layer followed by a non strided convolution  conv  layer  and can be applied in most if not all cnn architectures  we explain this new design under two most representative computer vision tasks  object detection and image classification  we then create new cnn architectures by applying spd conv to yolov  and resnet  and empirically show that our approach significantly outperforms state of the art deep learning models  especially on tougher tasks with low resolution images and small objects  we have open sourced our code at https   github com labsaint spd conv ,3.8944552,7.122961,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
From a Data Science Driven Process to a Continuous Delivery Process for Machine Learning Systems,"Development of machine learning (ML) enabled applications in real-world settings is challenging and requires the consideration of sound software engineering (SE) principles and practices. A large body of knowledge exists on the use of modern approaches to developing traditional software components, but not ML components. Using exploratory case study approach, this study investigates the adoption and use of existing software development approaches, specifically continuous delivery (CD), to development of ML components. Research data was collected using a multivocal literature review (MLR) and focus group technique with ten practitioners involved in developing ML-enabled systems at a large telecommunication company. The results of our MLR show that companies do not outright apply CD to the development of ML components rather as a result of improving their development practices and infrastructure over time. A process improvement conceptual model, that includes the description of CD application to ML components is developed and initially validated in the study.
 Keywords
 Machine learning system
 Software process
 Continuous delivery",development of machine learning  ml  enabled applications in real world settings is challenging and requires the consideration of sound software engineering  se  principles and practices  a large body of knowledge exists on the use of modern approaches to developing traditional software components  but not ml components  using exploratory case study approach  this study investigates the adoption and use of existing software development approaches  specifically continuous delivery  cd   to development of ml components  research data was collected using a multivocal literature review  mlr  and focus group technique with ten practitioners involved in developing ml enabled systems at a large telecommunication company  the results of our mlr show that companies do not outright apply cd to the development of ml components rather as a result of improving their development practices and infrastructure over time  a process improvement conceptual model  that includes the description of cd application to ml components is developed and initially validated in the study   keywords  machine learning system  software process  continuous delivery,8.516054,4.902154,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Applying Digital Technologies to Financial Product Marketing,"This article listed some of the current challenges that are faced in the area of applying digital technologies in marketing of financial products. Possible solutions to these challenges are suggested as well as the results. The vision of the future of this area is also discussed at the end of this article.
 Keywords
 Component
 Marketing strategies
 Data modeling
 Big data
 Financial products
 Digital technologies",this article listed some of the current challenges that are faced in the area of applying digital technologies in marketing of financial products  possible solutions to these challenges are suggested as well as the results  the vision of the future of this area is also discussed at the end of this article   keywords  component  marketing strategies  data modeling  big data  financial products  digital technologies,9.508592,7.525941,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
A Framework for Building pro-bono Data for Good Projects,"Initiatives relying on data science for social good - non-commercial projects that deliver socially beneficial outcomes - have been on the rise in the last years. The area of Data for Good has several specific challenges, one of which is the definition of a formal framework for the design, conception, prioritization, development and impact measurement of such applications. All over the world, volunteers are organized in local/regional initiatives that provide voluntary support to social good organizations in the development of Data for Good projects. Each of these initiatives follows specific internal frameworks that are not standardized within the community, with information-sharing efforts just starting to appear. Sharing these frameworks could lead to an increase in the amount of successful data for good projects, delivering concrete value in the daily operations of social good institutions. In this paper, the framework that was created and is being followed with success at Data Science for Social Good Portugal (DSSG PT), an open community of data enthusiasts working pro-bono in Data for Good projects, is shared. This includes all processes regarding structural organization and management, communication between stakeholders, project scoping and project development that are being followed. It also presents a methodology for social impact measurement of projects and ensuring of ethical standards, such as data privacy and fairness.
 Keywords
 Data science
 Project framework
 Data for Good
 Sustainability
 Social impact",initiatives relying on data science for social good   non commercial projects that deliver socially beneficial outcomes   have been on the rise in the last years  the area of data for good has several specific challenges  one of which is the definition of a formal framework for the design  conception  prioritization  development and impact measurement of such applications  all over the world  volunteers are organized in local regional initiatives that provide voluntary support to social good organizations in the development of data for good projects  each of these initiatives follows specific internal frameworks that are not standardized within the community  with information sharing efforts just starting to appear  sharing these frameworks could lead to an increase in the amount of successful data for good projects  delivering concrete value in the daily operations of social good institutions  in this paper  the framework that was created and is being followed with success at data science for social good portugal  dssg pt   an open community of data enthusiasts working pro bono in data for good projects  is shared  this includes all processes regarding structural organization and management  communication between stakeholders  project scoping and project development that are being followed  it also presents a methodology for social impact measurement of projects and ensuring of ethical standards  such as data privacy and fairness   keywords  data science  project framework  data for good  sustainability  social impact,11.809718,5.600246,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Governing Artificial Intelligence in Post-Pandemic Society,"Pandemic escalated the need of adopting technology for human security and public service. Technological integration and digital transformation are of focus in the strategy to recover and reconstruct civic society post-pandemic across the globe, especially in the domains of healthcare, education, surveillance, and governance. Artificial intelligence (AI) is seen to benefit society through building and assisting critical socio-technical systems.
 Automated decision-making through algorithms is debated widely for its limitations in tackling biases and inability to discourage unintended. Moreover, AI learns patterns from the data, which by nature is biased due to existing socio-economic complexities. The pervasive application of AI when implemented and integrated with social systems is observed to pose socio-ethical challenges such as institutionalization of discrimination, biased decision-making, intrusiveness, low accountability, and mistrust. Various threats and vulnerabilities imposed to human community-like natural disasters, health pandemics, and economic uncertainties necessitate inevitable adoption of AI applications that can mitigate socio-ethical challenges and adhere to human security principles. Current data protection laws seem to be insufficient to protect human rights in the given scenarios.
 Literature advocates for transparency, explainability, and auditability of AI models. However, it may not necessarily lead to accountability and fairness. Embedding these socio-technical systems in the broader institutional frameworks of regulation and governance can balance the risks without compromising on the benefits of technological innovations. The socio-economic context in which AI model is deployed necessitates the responses to be local and context specific. This also necessitates AI governance framework to be comprehensive, prevention-oriented, while protecting and empowering human value and dignity.
 This chapter provides commentary on the social, ethical, and technical issues that AI can impose along with various aspects that need to be considered while governing AI. Finally, an AI governance framework is proposed based on socio-administrative principles to extend their credibility in mitigating, managing and governing the human threats and uphold human security.
 Keywords
 Artificial intelligence
 Automated decision
 Ethics
 Governance
 Participation
 Institutions
 Human security",pandemic escalated the need of adopting technology for human security and public service  technological integration and digital transformation are of focus in the strategy to recover and reconstruct civic society post pandemic across the globe  especially in the domains of healthcare  education  surveillance  and governance  artificial intelligence  ai  is seen to benefit society through building and assisting critical socio technical systems   automated decision making through algorithms is debated widely for its limitations in tackling biases and inability to discourage unintended  moreover  ai learns patterns from the data  which by nature is biased due to existing socio economic complexities  the pervasive application of ai when implemented and integrated with social systems is observed to pose socio ethical challenges such as institutionalization of discrimination  biased decision making  intrusiveness  low accountability  and mistrust  various threats and vulnerabilities imposed to human community like natural disasters  health pandemics  and economic uncertainties necessitate inevitable adoption of ai applications that can mitigate socio ethical challenges and adhere to human security principles  current data protection laws seem to be insufficient to protect human rights in the given scenarios   literature advocates for transparency  explainability  and auditability of ai models  however  it may not necessarily lead to accountability and fairness  embedding these socio technical systems in the broader institutional frameworks of regulation and governance can balance the risks without compromising on the benefits of technological innovations  the socio economic context in which ai model is deployed necessitates the responses to be local and context specific  this also necessitates ai governance framework to be comprehensive  prevention oriented  while protecting and empowering human value and dignity   this chapter provides commentary on the social  ethical  and technical issues that ai can impose along with various aspects that need to be considered while governing ai  finally  an ai governance framework is proposed based on socio administrative principles to extend their credibility in mitigating  managing and governing the human threats and uphold human security   keywords  artificial intelligence  automated decision  ethics  governance  participation  institutions  human security,11.950326,5.601168,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Requirements and software engineering for automotive perception systems: an interview study,"Driving automation systems, including autonomous driving and advanced driver assistance, are an important safety-critical domain. Such systems often incorporate perception systems that use machine learning to analyze the vehicle environment. We explore new or differing topics and challenges experienced by practitioners in this domain, which relate to requirements engineering (RE), quality, and systems and software engineering. We have conducted a semi-structured interview study with 19 participants across five companies and performed thematic analysis of the transcriptions. Practitioners have difficulty specifying upfront requirements and often rely on scenarios and operational design domains (ODDs) as RE artifacts. RE challenges relate to ODD detection and ODD exit detection, realistic scenarios, edge case specification, breaking down requirements, traceability, creating specifications for data and annotations, and quantifying quality requirements. Practitioners consider performance, reliability, robustness, user comfort, andâ€”most importantlyâ€”safety as important quality attributes. Quality is assessed using statistical analysis of key metrics, and quality assurance is complicated by the addition of ML, simulation realism, and evolving standards. Systems are developed using a mix of methods, but these methods may not be sufficient for the needs of ML. Data quality methods must be a part of development methods. ML also requires a data-intensive verification and validation process, introducing data, analysis, and simulation challenges. Our findings contribute to understanding RE, safety engineering, and development methodologies for perception systems. This understanding and the collected challenges can drive future research for driving automation and other ML systems.",driving automation systems  including autonomous driving and advanced driver assistance  are an important safety critical domain  such systems often incorporate perception systems that use machine learning to analyze the vehicle environment  we explore new or differing topics and challenges experienced by practitioners in this domain  which relate to requirements engineering  re   quality  and systems and software engineering  we have conducted a semi structured interview study with    participants across five companies and performed thematic analysis of the transcriptions  practitioners have difficulty specifying upfront requirements and often rely on scenarios and operational design domains  odds  as re artifacts  re challenges relate to odd detection and odd exit detection  realistic scenarios  edge case specification  breaking down requirements  traceability  creating specifications for data and annotations  and quantifying quality requirements  practitioners consider performance  reliability  robustness  user comfort  and   most importantly   safety as important quality attributes  quality is assessed using statistical analysis of key metrics  and quality assurance is complicated by the addition of ml  simulation realism  and evolving standards  systems are developed using a mix of methods  but these methods may not be sufficient for the needs of ml  data quality methods must be a part of development methods  ml also requires a data intensive verification and validation process  introducing data  analysis  and simulation challenges  our findings contribute to understanding re  safety engineering  and development methodologies for perception systems  this understanding and the collected challenges can drive future research for driving automation and other ml systems ,11.493302,6.0862803,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
FLRA: A Reference Architecture for Federated Learning Systems,"Federated learning is an emerging machine learning paradigm that enables multiple devices to train models locally and formulate a global model, without sharing the clientsâ€™ local data. A federated learning system can be viewed as a large-scale distributed system, involving different components and stakeholders with diverse requirements and constraints. Hence, developing a federated learning system requires both software system design thinking and machine learning knowledge. Although much effort has been put into federated learning from the machine learning perspectives, our previous systematic literature review on the area shows that there is a distinct lack of considerations for software architecture design for federated learning. In this paper, we propose FLRA, a reference architecture for federated learning systems, which provides a template design for federated learning-based solutions. The proposed FLRA reference architecture is based on an extensive review of existing patterns of federated learning systems found in the literature and existing industrial implementation. The FLRA reference architecture consists of a pool of architectural patterns that could address the frequently recurring design problems in federated learning architectures. The FLRA reference architecture can serve as a design guideline to assist architects and developers with practical solutions for their problems, which can be further customised.
 Keywords
 Software architecture
 Reference architecture
 Federated learning
 Pattern
 Software engineering
 Machine learning
 Artificial intelligence",federated learning is an emerging machine learning paradigm that enables multiple devices to train models locally and formulate a global model  without sharing the clients    local data  a federated learning system can be viewed as a large scale distributed system  involving different components and stakeholders with diverse requirements and constraints  hence  developing a federated learning system requires both software system design thinking and machine learning knowledge  although much effort has been put into federated learning from the machine learning perspectives  our previous systematic literature review on the area shows that there is a distinct lack of considerations for software architecture design for federated learning  in this paper  we propose flra  a reference architecture for federated learning systems  which provides a template design for federated learning based solutions  the proposed flra reference architecture is based on an extensive review of existing patterns of federated learning systems found in the literature and existing industrial implementation  the flra reference architecture consists of a pool of architectural patterns that could address the frequently recurring design problems in federated learning architectures  the flra reference architecture can serve as a design guideline to assist architects and developers with practical solutions for their problems  which can be further customised   keywords  software architecture  reference architecture  federated learning  pattern  software engineering  machine learning  artificial intelligence,11.16933,5.34943,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Recognition and Visualization of Facial Expression and Emotion in Healthcare,"To make the SenseCare KM-EP system more useful and smart, we integrated emotion recognition from facial expression. People with dementia have capricious feelings; the target of this paper is measuring and predicting these facial expressions. Analysis of data from emotional monitoring of dementia patients at home or during medical treatment will help healthcare professionals to judge the behavior of people with dementia in an improved and more informed way. In relation to the research project, SenseCare, this paper describes methods of video analysis focusing on facial expression and visualization of emotions, in order to implement an â€œEmotional Monitoringâ€ web tool, which facilitates recognition and visualization of facial expression, in order to raise the quality of therapy. In this study, we detail the conceptual design of each process of the proposed system, and we describe our methods chosen for the implementation of the prototype using face-api.js and tensorflow.js for detection and recognition of facial expression and the PAD space model for 3D visualization of emotions.
 Keywords
 Emotion recognition
 Facial expression analysis
 Emotion visualization
 Emotion monitoring
 Convolutional Neural Networks (CNNs)
 Affective computing",to make the sensecare km ep system more useful and smart  we integrated emotion recognition from facial expression  people with dementia have capricious feelings  the target of this paper is measuring and predicting these facial expressions  analysis of data from emotional monitoring of dementia patients at home or during medical treatment will help healthcare professionals to judge the behavior of people with dementia in an improved and more informed way  in relation to the research project  sensecare  this paper describes methods of video analysis focusing on facial expression and visualization of emotions  in order to implement an    emotional monitoring    web tool  which facilitates recognition and visualization of facial expression  in order to raise the quality of therapy  in this study  we detail the conceptual design of each process of the proposed system  and we describe our methods chosen for the implementation of the prototype using face api js and tensorflow js for detection and recognition of facial expression and the pad space model for  d visualization of emotions   keywords  emotion recognition  facial expression analysis  emotion visualization  emotion monitoring  convolutional neural networks  cnns   affective computing,5.933056,4.793493,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
"Opacity, Machine Learning and Explainable AI","Artificial Intelligence is being applied in a multitude of scenarios that are sensitive to the human user, i.e., medical diagnosis, granting loans, human resources management, among many others. Behind most of these Artificial Intelligence tools is a pattern recognition model generated by Machine Learning. To do this, it is necessary to start from a dataset that characterizes the problem under study, and â€œtrainâ€ this model to represent the former information through different mathematical approximations. Thus, when sensitive applications and mathematical models are placed in the same equation, mistrust arises about the correct functioning of Artificial Intelligence systems. This is the main reason behind which the model makes one decision and not another. The answer lies in the interpretability or transparency of the model itself, i.e., that its components are directly understandable by the human user. When this is not possible, a posteriori explainability mechanisms are used to facilitate knowledge of which variables or characteristics the model has considered. Throughout this chapter, we will introduce the current trends to achieve trustworthy Artificial Intelligence. We will expose the components that allow a model to be transparent, as well as the existing techniques to explain more complex models such as those based on Deep Learning. Finally, we will expose some prospects that can be considered to keep improving the explanations and to allow a wider use of Machine Learning solutions in all fields of application.",artificial intelligence is being applied in a multitude of scenarios that are sensitive to the human user  i e   medical diagnosis  granting loans  human resources management  among many others  behind most of these artificial intelligence tools is a pattern recognition model generated by machine learning  to do this  it is necessary to start from a dataset that characterizes the problem under study  and    train    this model to represent the former information through different mathematical approximations  thus  when sensitive applications and mathematical models are placed in the same equation  mistrust arises about the correct functioning of artificial intelligence systems  this is the main reason behind which the model makes one decision and not another  the answer lies in the interpretability or transparency of the model itself  i e   that its components are directly understandable by the human user  when this is not possible  a posteriori explainability mechanisms are used to facilitate knowledge of which variables or characteristics the model has considered  throughout this chapter  we will introduce the current trends to achieve trustworthy artificial intelligence  we will expose the components that allow a model to be transparent  as well as the existing techniques to explain more complex models such as those based on deep learning  finally  we will expose some prospects that can be considered to keep improving the explanations and to allow a wider use of machine learning solutions in all fields of application ,6.0406394,5.6993256,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
"Advances, challenges and opportunities in creating data for trustworthy AI","As artificial intelligence (AI) transitions from research to deployment, creating the appropriate datasets and data pipelines to develop and evaluate AI models is increasingly the biggest challenge. Automated AI model builders that are publicly available can now achieve top performance in many applications. In contrast, the design and sculpting of the data used to develop AI often rely on bespoke manual work, and they critically affect the trustworthiness of the model. This Perspective discusses key considerations for each stage of the data-for-AI pipelineâ€”starting from data design to data sculpting (for example, cleaning, valuation and annotation) and data evaluationâ€”to make AI more reliable. We highlight technical advances that help to make the data-for-AI pipeline more scalable and rigorous. Furthermore, we discuss how recent data regulations and policies can impact AI.",as artificial intelligence  ai  transitions from research to deployment  creating the appropriate datasets and data pipelines to develop and evaluate ai models is increasingly the biggest challenge  automated ai model builders that are publicly available can now achieve top performance in many applications  in contrast  the design and sculpting of the data used to develop ai often rely on bespoke manual work  and they critically affect the trustworthiness of the model  this perspective discusses key considerations for each stage of the data for ai pipeline   starting from data design to data sculpting  for example  cleaning  valuation and annotation  and data evaluation   to make ai more reliable  we highlight technical advances that help to make the data for ai pipeline more scalable and rigorous  furthermore  we discuss how recent data regulations and policies can impact ai ,10.191743,5.6516514,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Quality Characteristics of a Software Platform for Human-AI Teaming in Smart Manufacturing,"As AI-enabled software systems become more prevalent in smart manufacturing, their role shifts from a reactive to a proactive one that provides context-specific support to machine operators. In the context of an international research project, we develop an AI-based software platform that shall facilitate the collaboration between human operators and manufacturing machines.
 We conducted 14 structured interviews with stakeholders of the prospective software platform in order to determine the individual relevance of selected quality characteristics for human-AI teaming in smart manufacturing. These characteristics include the ISO 25010:2011 standard for software quality and AI-specific quality characteristics such as trustworthiness, explicability, and auditability. The interviewees rated trustworthiness, functional suitability, reliability, and security as the most important quality characteristics for this context, and portability, compatibility, and maintainability as the least important. Also, we observed agreement regarding the relevance of the quality characteristics among interviewees having the same role. On the other hand, the relevance of each quality characteristics varied depending on the concrete use case of the prospective software platform.
 The interviewees also were asked about the key success factors related to human-AI teaming in smart manufacturing. They identified improving the production cycle, increasing operator efficiency, reducing scrap, and reducing ergonomic risks as key success criteria. In this paper, we also discuss metrics for measuring the fulfillment of these quality characteristics, which we intend to operationalize and monitor during operation of the prospective software platform.
 Keywords
 Quality characteristics
 Human-AI teaming
 Smart manufacturing
 Trustworthiness
 Explicability
 Auditability",as ai enabled software systems become more prevalent in smart manufacturing  their role shifts from a reactive to a proactive one that provides context specific support to machine operators  in the context of an international research project  we develop an ai based software platform that shall facilitate the collaboration between human operators and manufacturing machines   we conducted    structured interviews with stakeholders of the prospective software platform in order to determine the individual relevance of selected quality characteristics for human ai teaming in smart manufacturing  these characteristics include the iso            standard for software quality and ai specific quality characteristics such as trustworthiness  explicability  and auditability  the interviewees rated trustworthiness  functional suitability  reliability  and security as the most important quality characteristics for this context  and portability  compatibility  and maintainability as the least important  also  we observed agreement regarding the relevance of the quality characteristics among interviewees having the same role  on the other hand  the relevance of each quality characteristics varied depending on the concrete use case of the prospective software platform   the interviewees also were asked about the key success factors related to human ai teaming in smart manufacturing  they identified improving the production cycle  increasing operator efficiency  reducing scrap  and reducing ergonomic risks as key success criteria  in this paper  we also discuss metrics for measuring the fulfillment of these quality characteristics  which we intend to operationalize and monitor during operation of the prospective software platform   keywords  quality characteristics  human ai teaming  smart manufacturing  trustworthiness  explicability  auditability,11.4186325,5.0573325,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
AI2VIS4BigData: Qualitative Evaluation of an AI-Based Big Data Analysis and Visualization Reference Model,"AI2VIS4BigData is a reference model for Artificial Intelligence (AI) - based Big Data Analysis and Visualization that provides uniform terminology and logical entity-relationships to scientists and professionals working in this application domain. It thereby enables re-utilization of concepts and software, prevents reinventing the wheel and facilitates collaboration scenarios. AI2VIS4BigData was systematically derived from two foundation reference models utilizing reasoned assumptions. These assumptions required subjective decisions which were not evaluated right away. This publication targets to change that through presenting two qualitative evaluation approaches that were conducted in the course of an official satellite workshop of an international conference. Selected scientific and industrial experts participated thereby in an expert round table workshop and a survey. The validation results confirm the reference modelâ€™s practical applicability and legitimate the substantial majority of subjective decisions that were taken in the course of the reference model derivation. This publication concludes with outlining five research fields for future work that comprise the non-validated subjective decisions.
 Keywords
 AI2VIS4BigData
 Evaluation
 Reference model
 AI
 Big data analysis
 Visualization",ai vis bigdata is a reference model for artificial intelligence  ai    based big data analysis and visualization that provides uniform terminology and logical entity relationships to scientists and professionals working in this application domain  it thereby enables re utilization of concepts and software  prevents reinventing the wheel and facilitates collaboration scenarios  ai vis bigdata was systematically derived from two foundation reference models utilizing reasoned assumptions  these assumptions required subjective decisions which were not evaluated right away  this publication targets to change that through presenting two qualitative evaluation approaches that were conducted in the course of an official satellite workshop of an international conference  selected scientific and industrial experts participated thereby in an expert round table workshop and a survey  the validation results confirm the reference model   s practical applicability and legitimate the substantial majority of subjective decisions that were taken in the course of the reference model derivation  this publication concludes with outlining five research fields for future work that comprise the non validated subjective decisions   keywords  ai vis bigdata  evaluation  reference model  ai  big data analysis  visualization,9.118728,5.211088,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Cloud Computing,"This chapter provides an overview of the current Cloud computing state of developments. First, it presents basic definitions and an analysis of underlying technologies, such as virtualisation and containerisation. Next, it advances a detailed overview of the existing services in public cloud providers, addressing IaaS and PaaS and including advanced service offerings as an example in the fields of Serverless, IoT Artificial intelligence. Finally, the chapter focuses on Hybrid and Multi-Cloud public cloud and open source products.",this chapter provides an overview of the current cloud computing state of developments  first  it presents basic definitions and an analysis of underlying technologies  such as virtualisation and containerisation  next  it advances a detailed overview of the existing services in public cloud providers  addressing iaas and paas and including advanced service offerings as an example in the fields of serverless  iot artificial intelligence  finally  the chapter focuses on hybrid and multi cloud public cloud and open source products ,9.711217,7.7629533,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Case Studies and Examples,"Case studies are a valuable tool for learning about how other companies have implemented AI solutions. They can provide insights into the challenges and benefits of AI, as well as best practices for implementation. By studying case studies, businesses can make informed decisions about whether to adopt AI, and how to do so successfully.",case studies are a valuable tool for learning about how other companies have implemented ai solutions  they can provide insights into the challenges and benefits of ai  as well as best practices for implementation  by studying case studies  businesses can make informed decisions about whether to adopt ai  and how to do so successfully ,11.345708,6.277038,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Digital Transformation of Software Development: Implications for the Future of Work,"In this work we explore digital transformation in software development. A set of interviews were conducted among industry experts to identify and elucidate the drivers and trajectories of digital transformation within the software industry. Using the Gioia method for qualitative analysis and synthesis, two major trajectories were found: (1) automation increasingly impacts several key activities related to software development; and (2) the importance of software and digital products is increasing in sectors where the core product or service has not traditionally been software-intensive. The findings have implications for the future of work in the context of software business. First, software developers and operators are increasingly needed, and more heavily involved across industry sectors. Second, as the level of automation becomes higher, the roles of automated testing and governance are highlighted, meaning a significant portion of development time will be spent in creating and validating automated tests. Third and finally, the importance of digital skills will increase also in non-IT roles as digital elements infuse into traditionally physical goods and services.
 Keywords
 Digital transformation
 Artificial Intelligence
 Software business
 Software development
 Automation
 Future of work",in this work we explore digital transformation in software development  a set of interviews were conducted among industry experts to identify and elucidate the drivers and trajectories of digital transformation within the software industry  using the gioia method for qualitative analysis and synthesis  two major trajectories were found      automation increasingly impacts several key activities related to software development  and     the importance of software and digital products is increasing in sectors where the core product or service has not traditionally been software intensive  the findings have implications for the future of work in the context of software business  first  software developers and operators are increasingly needed  and more heavily involved across industry sectors  second  as the level of automation becomes higher  the roles of automated testing and governance are highlighted  meaning a significant portion of development time will be spent in creating and validating automated tests  third and finally  the importance of digital skills will increase also in non it roles as digital elements infuse into traditionally physical goods and services   keywords  digital transformation  artificial intelligence  software business  software development  automation  future of work,9.729611,4.518381,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Review: Progress with Functional Materials Based on Loess Particles,"Loess is a large-scale deposit which is easy to mine and widely distributed on the epipedon. The clay fraction of loess, also known as â€˜loessial clayâ€™, is a very important component of loess which affects its properties and performance. From a â€˜materialsâ€™ perspective, the clay fraction of loess has been ignored. Recently, loess particles have attracted interest because of their potential applications. The focus in the current review is on the methods of modifying loess particles and their application as functional materials. The major components of loess particles are clays, calcite, and quartz, with the clays including kaolinite, illite, montmorillonite, and chlorite. Loess has a range of particle sizes, types, and dispersibilities. The particles agglomerate readily, mainly because cementation occurs readily in the clay fraction. Loess particles can be modified and their properties can be improved by compaction, separation, purification, acidification, calcination, surfactant modification, geopolymerization, and polymer modification. Loess-based functional materials have been used as sorbents, eco-friendly superabsorbents, soil and water conservation materials, humidity-regulating materials, and building materials. Separated and purified loess particles can adsorb metal ions and harmful elements directly. Surfactant-modified loess particles can remove organic compounds effectively. After modification with polymers, loess particles exhibit greater capacity for the removal of environmental pollutants such as harmful metal ions and dyes. As a superabsorbent, modified loess shows excellent thermal stability and swelling behavior. Calcined loess could be utilized as an energy-saving building material with good humidity-regulating performance, and geological polymerization has further expanded the scope of applications of loess in architecture. In summary, loess-based functional materials, which are inexpensive and ecologically friendly, deserve more attention and further development.",loess is a large scale deposit which is easy to mine and widely distributed on the epipedon  the clay fraction of loess  also known as    loessial clay     is a very important component of loess which affects its properties and performance  from a    materials    perspective  the clay fraction of loess has been ignored  recently  loess particles have attracted interest because of their potential applications  the focus in the current review is on the methods of modifying loess particles and their application as functional materials  the major components of loess particles are clays  calcite  and quartz  with the clays including kaolinite  illite  montmorillonite  and chlorite  loess has a range of particle sizes  types  and dispersibilities  the particles agglomerate readily  mainly because cementation occurs readily in the clay fraction  loess particles can be modified and their properties can be improved by compaction  separation  purification  acidification  calcination  surfactant modification  geopolymerization  and polymer modification  loess based functional materials have been used as sorbents  eco friendly superabsorbents  soil and water conservation materials  humidity regulating materials  and building materials  separated and purified loess particles can adsorb metal ions and harmful elements directly  surfactant modified loess particles can remove organic compounds effectively  after modification with polymers  loess particles exhibit greater capacity for the removal of environmental pollutants such as harmful metal ions and dyes  as a superabsorbent  modified loess shows excellent thermal stability and swelling behavior  calcined loess could be utilized as an energy saving building material with good humidity regulating performance  and geological polymerization has further expanded the scope of applications of loess in architecture  in summary  loess based functional materials  which are inexpensive and ecologically friendly  deserve more attention and further development ,3.62528,2.1987083,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Deep learning-enabled segmentation of ambiguous bioimages with deepflash2,"Bioimages frequently exhibit low signal-to-noise ratios due to experimental conditions, specimen characteristics, and imaging trade-offs. Reliable segmentation of such ambiguous images is difficult and laborious. Here we introduce deepflash2, a deep learning-enabled segmentation tool for bioimage analysis. The tool addresses typical challenges that may arise during the training, evaluation, and application of deep learning models on ambiguous data. The toolâ€™s training and evaluation pipeline uses multiple expert annotations and deep model ensembles to achieve accurate results. The application pipeline supports various use-cases for expert annotations and includes a quality assurance mechanism in the form of uncertainty measures. Benchmarked against other tools, deepflash2 offers both high predictive accuracy and efficient computational resource usage. The tool is built upon established deep learning libraries and enables sharing of trained model ensembles with the research community. deepflash2 aims to simplify the integration of deep learning into bioimage analysis projects while improving accuracy and reliability.",bioimages frequently exhibit low signal to noise ratios due to experimental conditions  specimen characteristics  and imaging trade offs  reliable segmentation of such ambiguous images is difficult and laborious  here we introduce deepflash   a deep learning enabled segmentation tool for bioimage analysis  the tool addresses typical challenges that may arise during the training  evaluation  and application of deep learning models on ambiguous data  the tool   s training and evaluation pipeline uses multiple expert annotations and deep model ensembles to achieve accurate results  the application pipeline supports various use cases for expert annotations and includes a quality assurance mechanism in the form of uncertainty measures  benchmarked against other tools  deepflash  offers both high predictive accuracy and efficient computational resource usage  the tool is built upon established deep learning libraries and enables sharing of trained model ensembles with the research community  deepflash  aims to simplify the integration of deep learning into bioimage analysis projects while improving accuracy and reliability ,6.0171885,5.9690976,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
AI lifecycle models need to be revised An exploratory study in Fintech,"Tech-leading organizations are embracing the forthcoming artificial intelligence revolution. Intelligent systems are replacing and cooperating with traditional software components. Thus, the same development processes and standards in software engineering ought to be complied in artificial intelligence systems. This study aims to understand the processes by which artificial intelligence-based systems are developed and how state-of-the-art lifecycle models fit the current needs of the industry. We conducted an exploratory case study at ING, a global bank with a strong European base. We interviewed 17 people with different roles and from different departments within the organization. We have found that the following stages have been overlooked by previous lifecycle models: data collection, feasibility study, documentation, model monitoring, and model risk assessment. Our work shows that the real challenges of applying Machine Learning go much beyond sophisticated learning algorithms â€“ more focus is needed on the entire lifecycle. In particular, regardless of the existing development tools for Machine Learning, we observe that they are still not meeting the particularities of this field.",tech leading organizations are embracing the forthcoming artificial intelligence revolution  intelligent systems are replacing and cooperating with traditional software components  thus  the same development processes and standards in software engineering ought to be complied in artificial intelligence systems  this study aims to understand the processes by which artificial intelligence based systems are developed and how state of the art lifecycle models fit the current needs of the industry  we conducted an exploratory case study at ing  a global bank with a strong european base  we interviewed    people with different roles and from different departments within the organization  we have found that the following stages have been overlooked by previous lifecycle models  data collection  feasibility study  documentation  model monitoring  and model risk assessment  our work shows that the real challenges of applying machine learning go much beyond sophisticated learning algorithms     more focus is needed on the entire lifecycle  in particular  regardless of the existing development tools for machine learning  we observe that they are still not meeting the particularities of this field ,9.092227,5.796429,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Dynamic Resource Management for Machine Learning Pipeline Workloads,"The recent success of deep learning applications is driven by the computing power of GPUs. However, as the workflow of deep learning becomes increasingly complicated and resource-intensive, how to manage the expensive GPU resources for Machine Learning (ML) workload becomes a critical problem. Existing resource managers mostly only focus on a single specific type of workload, like batch processing or web services, and lacks runtime optimization and application performance awareness. Therefore, we aim to develop a set of runtime dynamic management techniques (including auto-scaling, job preemption, workload-aware scheduling, and elastic GPU sharing) to handle a mixture of ML workloads consisting of modeling, training, and inference jobs. In our previous work, we have implemented these techniques as a set of extended operators on Kubernetes. In this paper, we further extend our approach by introducing a topology-aware scheduling algorithm based on the hypergraph partition problem to minimize the communication cost of distributed training for maximizing the system throughput and minimizing the job completion time. Our evaluations on AWS GPU clusters prove our approach can out-perform the native Kubernetes by 60% system throughput improvement, 70% training time reduction without causing any SLA violations on inference services. Compared to the start-of-the-art topology-aware scheduling algorithm, we shorten the average job completion time by 24â€“44%.",the recent success of deep learning applications is driven by the computing power of gpus  however  as the workflow of deep learning becomes increasingly complicated and resource intensive  how to manage the expensive gpu resources for machine learning  ml  workload becomes a critical problem  existing resource managers mostly only focus on a single specific type of workload  like batch processing or web services  and lacks runtime optimization and application performance awareness  therefore  we aim to develop a set of runtime dynamic management techniques  including auto scaling  job preemption  workload aware scheduling  and elastic gpu sharing  to handle a mixture of ml workloads consisting of modeling  training  and inference jobs  in our previous work  we have implemented these techniques as a set of extended operators on kubernetes  in this paper  we further extend our approach by introducing a topology aware scheduling algorithm based on the hypergraph partition problem to minimize the communication cost of distributed training for maximizing the system throughput and minimizing the job completion time  our evaluations on aws gpu clusters prove our approach can out perform the native kubernetes by     system throughput improvement      training time reduction without causing any sla violations on inference services  compared to the start of the art topology aware scheduling algorithm  we shorten the average job completion time by          ,6.600813,6.7827277,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Data Fabric Within an Enterprise Architecture,"Any data architecture, and therefore also our Data Fabric architecture, needs to be looked at in conjunction with the implemented application architecture in an existing enterprise landscape. Many organizations are in the process to modernize and digitalize their application and data landscape. Applications have different requirements with respect to data characteristics, which may recommend a particular data architecture implementation over another, for example, characterized by data access based on data virtualization or data replication and transformation.",any data architecture  and therefore also our data fabric architecture  needs to be looked at in conjunction with the implemented application architecture in an existing enterprise landscape  many organizations are in the process to modernize and digitalize their application and data landscape  applications have different requirements with respect to data characteristics  which may recommend a particular data architecture implementation over another  for example  characterized by data access based on data virtualization or data replication and transformation ,9.45154,3.7061818,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Modern Data Warehouses,"In the last decade, numerous technology updates have happened in the area of data warehousing. In addition, customer expectations increase with each passing year.",in the last decade  numerous technology updates have happened in the area of data warehousing  in addition  customer expectations increase with each passing year ,6.5937214,6.9982276,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Data Science and Revenue Management,â€œBeing data-drivenâ€ has been touted by management consultants and the business press as a cure-all for business challenges for several years now. But what exactly does it mean? Any modern manager has access to a plethora of reports and dashboards that they happily use to point out their performance or the improvement needs of others.,   being data driven    has been touted by management consultants and the business press as a cure all for business challenges for several years now  but what exactly does it mean  any modern manager has access to a plethora of reports and dashboards that they happily use to point out their performance or the improvement needs of others ,10.775352,7.7198696,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Challenges of Python Debugging in Cloud Computing,"In this chapter, you will start surveying the challenges of debugging in cloud computing, AI, and machine learning. You will start with cloud computing first, the backbone of modern AI/ML.",in this chapter  you will start surveying the challenges of debugging in cloud computing  ai  and machine learning  you will start with cloud computing first  the backbone of modern ai ml ,11.130996,6.1087513,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Human-Centered AI Developer Experience Design,"In the previous chapter, we learned how to build a human-centered AI experience design oriented toward the end user. In this chapter, we will learn how to design AI developer experience (DX), a methodology aimed at making the development process of AI-powered applications more straightforward and intuitive for developers. By focusing on the needs and preferences of developers, this approach can help streamline the creation of AI-based products and services. In addition, by providing a framework for incorporating AI into applications, AI developer experience design can help reduce the risk of errors and glitches during development. In building a developer experience for AI products, design thinking is essential to create an intuitive and user-friendly experience that contributes to the AI product's robustness and trustworthiness. By empathizing with the needs and preferences of developers and using design thinking methodologies to guide the development process, teams can create an experience tailored to their target audience's needs. This allows for a more efficient and effective development process and an end product more likely to succeed. In this chapter, we will explore the role of design thinking in creating a successful developer experience for AI products and provide two case studies that illustrate its application in practice.",in the previous chapter  we learned how to build a human centered ai experience design oriented toward the end user  in this chapter  we will learn how to design ai developer experience  dx   a methodology aimed at making the development process of ai powered applications more straightforward and intuitive for developers  by focusing on the needs and preferences of developers  this approach can help streamline the creation of ai based products and services  in addition  by providing a framework for incorporating ai into applications  ai developer experience design can help reduce the risk of errors and glitches during development  in building a developer experience for ai products  design thinking is essential to create an intuitive and user friendly experience that contributes to the ai product s robustness and trustworthiness  by empathizing with the needs and preferences of developers and using design thinking methodologies to guide the development process  teams can create an experience tailored to their target audience s needs  this allows for a more efficient and effective development process and an end product more likely to succeed  in this chapter  we will explore the role of design thinking in creating a successful developer experience for ai products and provide two case studies that illustrate its application in practice ,11.349815,7.0951033,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Citation Recommendation Chatbot for Professional Communities,"In recent years, the proliferation of academic literature has made it increasingly challenging for researchers and professionals to discover relevant citations for their work. To address this issue, this paper presents CitBot, a novel Citation Recommendation Chatbot designed specifically for professional communities. We describe the design, development, and evaluation of CitBot focusing on its performance and usefulness. CitBot combines the citation context with document-level embeddings utilizing SPECTER to generate personalized citation recommendations based on the communityâ€™s research interests. The system is designed to seamlessly integrate with online professional platforms, providing users with citation suggestions in response to their queries. A user study was conducted to assess the chatbotâ€™s performance, comparing it to other citation recommendation tools. The findings of the study, along with a discussion of CitBotâ€™s benefits and limitations, are presented. By enhancing the citation discovery process, CitBot has the potential to improve the productivity of professional communities and transform the way researchers and practitioners access and engage with scientific knowledge.
 Keywords
 Citation Recommendation
 Chatbots
 Community of Practice
 Recommender Systems",in recent years  the proliferation of academic literature has made it increasingly challenging for researchers and professionals to discover relevant citations for their work  to address this issue  this paper presents citbot  a novel citation recommendation chatbot designed specifically for professional communities  we describe the design  development  and evaluation of citbot focusing on its performance and usefulness  citbot combines the citation context with document level embeddings utilizing specter to generate personalized citation recommendations based on the community   s research interests  the system is designed to seamlessly integrate with online professional platforms  providing users with citation suggestions in response to their queries  a user study was conducted to assess the chatbot   s performance  comparing it to other citation recommendation tools  the findings of the study  along with a discussion of citbot   s benefits and limitations  are presented  by enhancing the citation discovery process  citbot has the potential to improve the productivity of professional communities and transform the way researchers and practitioners access and engage with scientific knowledge   keywords  citation recommendation  chatbots  community of practice  recommender systems,5.70199,4.3568435,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
"Overview of ChatGPT, Web3, and New Business Landscape","This chapter explores generative artificial intelligence (GenAI), its killer app ChatGPT, and the emerging Web3 paradigm. It elucidates how these technologies are revolutionizing the business landscape, driven by key players and facilitated by significant advancements in computational power and data availability. It discusses why GenAI is increasingly crucial in the current era of personalization and how it fits into the broader digital transformation. The chapter also navigates through the various applications and challenges of GenAI, painting a picture of its potential and the hurdles to overcome. It concludes with a futuristic outlook, underlining the significance of Web3 and the integration of GenAI within this new framework. This chapter serves as a way to understand the complex interplay of GenAI, ChatGPT, and Web3, and their collective impact on the future of business and technology.
 Keywords
 Generative artificial intelligence (GenAI)
 ChatGPT
 Web3
 Business transformation
 Personalization
 Key players in AI
 Transformer architecture
 Future trends in AI
 Business landscape
 Large Language Models (LLM)",this chapter explores generative artificial intelligence  genai   its killer app chatgpt  and the emerging web  paradigm  it elucidates how these technologies are revolutionizing the business landscape  driven by key players and facilitated by significant advancements in computational power and data availability  it discusses why genai is increasingly crucial in the current era of personalization and how it fits into the broader digital transformation  the chapter also navigates through the various applications and challenges of genai  painting a picture of its potential and the hurdles to overcome  it concludes with a futuristic outlook  underlining the significance of web  and the integration of genai within this new framework  this chapter serves as a way to understand the complex interplay of genai  chatgpt  and web   and their collective impact on the future of business and technology   keywords  generative artificial intelligence  genai   chatgpt  web   business transformation  personalization  key players in ai  transformer architecture  future trends in ai  business landscape  large language models  llm ,10.358348,7.73377,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
EIMDC: A New Model for Designing Digital Twin Applications,"With the development of communications and big data, digital twin as a novel paradigm has been received insentive attentions. However, there are some huge challenges in designing digital twins due to the complexity of digital twin applications. Firstly, most existing approaches merely focus on customized development, they are not general enough to tailor multiple applicaiton domains. Secondly, it lacks down-to-earth methodology for leading the designing process. Thirdly, it is tricky for developers to develop high valuable applications in real scenarios. To conquer these challenges, in this paper, we propose an EIMDC model for designing digital twin applications. It is comprised of entity, infrastructure, model, data and context. The entity is used to depict the physical entities mentioned in applications. The infrastructure exhibits the supporting infrastructure for enabling the digitalization of the physical entities. The model specifies the behavior of digital twin including geometric physical modeling, data-driven model and mechanism model. The data illustrates the data in cyberspace sensing from physical entites. The context represents the application context for digital twins. Finally we use a SMT production line case to show the effectiveness of the proposed model.
 Keywords
 Digital twin
 Design methodology
 Application design",with the development of communications and big data  digital twin as a novel paradigm has been received insentive attentions  however  there are some huge challenges in designing digital twins due to the complexity of digital twin applications  firstly  most existing approaches merely focus on customized development  they are not general enough to tailor multiple applicaiton domains  secondly  it lacks down to earth methodology for leading the designing process  thirdly  it is tricky for developers to develop high valuable applications in real scenarios  to conquer these challenges  in this paper  we propose an eimdc model for designing digital twin applications  it is comprised of entity  infrastructure  model  data and context  the entity is used to depict the physical entities mentioned in applications  the infrastructure exhibits the supporting infrastructure for enabling the digitalization of the physical entities  the model specifies the behavior of digital twin including geometric physical modeling  data driven model and mechanism model  the data illustrates the data in cyberspace sensing from physical entites  the context represents the application context for digital twins  finally we use a smt production line case to show the effectiveness of the proposed model   keywords  digital twin  design methodology  application design,9.06315,4.5911093,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Towards Safe Machine Learning Lifecycles with ESG Model Cards,"Machine Learning (ML) models have played a key role in many decisions that can affect society. However, the inductive and experimental nature of ML exposes it to specific risks. If the latter are not controlled, ML has the potential to wreak havoc by impacting people and the environment. In that context, Environmental, Social and Corporate Governance (ESG) is an approach used to measure a companyâ€™s sustainable behavior along those three dimensions. To develop responsible behavior, an organization should employ an ESG framework within its structure. In this paper, we propose a risk-based approach which aims to produce safe ML lifecycles. Its objective is to smoothly implement the ESG strategy throughout the ML process by identifying and mitigating risks. Based on that analysis, we present the ESG model card, a concrete tool to report the ESG impacts of the ML lifecycle, along with the actions used to reach that outcome.
 Keywords
 Model card
 Safe Machine Learning
 Risk-based approach
 ESG impacts",machine learning  ml  models have played a key role in many decisions that can affect society  however  the inductive and experimental nature of ml exposes it to specific risks  if the latter are not controlled  ml has the potential to wreak havoc by impacting people and the environment  in that context  environmental  social and corporate governance  esg  is an approach used to measure a company   s sustainable behavior along those three dimensions  to develop responsible behavior  an organization should employ an esg framework within its structure  in this paper  we propose a risk based approach which aims to produce safe ml lifecycles  its objective is to smoothly implement the esg strategy throughout the ml process by identifying and mitigating risks  based on that analysis  we present the esg model card  a concrete tool to report the esg impacts of the ml lifecycle  along with the actions used to reach that outcome   keywords  model card  safe machine learning  risk based approach  esg impacts,11.619141,5.7359715,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Organizational Capabilities for AI Implementationâ€”Coping with Inscrutability and Data Dependency in AI,"Artificial Intelligence (AI) implementation incorporates challenges that are unique to the context of AI, such as dealing with probabilistic outputs. To address these challenges, recent research suggests that organizations should develop specific capabilities for AI implementation. Currently, we lack a thorough understanding of how certain capabilities facilitate AI implementation. It remains unclear how they help organizations to cope with AIâ€™s unique characteristics. To address this research gap, we employ a qualitative research approach and conduct 25 explorative interviews with experts on AI implementation. We derive four organizational capabilities for AI implementation: AI Project Planning and Co-Development help to cope with the inscrutability in AI, which complicates the planning of AI projects and communication between different stakeholders. Data Management and AI Model Lifecycle Management help to cope with the data dependency in AI, which challenges organizations to provide the proper data foundation and continuously adjust AI systems as the data evolves. We contribute to our understanding of the sociotechnical implications of AIâ€™s characteristics and further develop the concept of organizational capabilities as an important success factor for AI implementation. For practice, we provide actionable recommendations to develop organizational capabilities for AI implementation.",artificial intelligence  ai  implementation incorporates challenges that are unique to the context of ai  such as dealing with probabilistic outputs  to address these challenges  recent research suggests that organizations should develop specific capabilities for ai implementation  currently  we lack a thorough understanding of how certain capabilities facilitate ai implementation  it remains unclear how they help organizations to cope with ai   s unique characteristics  to address this research gap  we employ a qualitative research approach and conduct    explorative interviews with experts on ai implementation  we derive four organizational capabilities for ai implementation  ai project planning and co development help to cope with the inscrutability in ai  which complicates the planning of ai projects and communication between different stakeholders  data management and ai model lifecycle management help to cope with the data dependency in ai  which challenges organizations to provide the proper data foundation and continuously adjust ai systems as the data evolves  we contribute to our understanding of the sociotechnical implications of ai   s characteristics and further develop the concept of organizational capabilities as an important success factor for ai implementation  for practice  we provide actionable recommendations to develop organizational capabilities for ai implementation ,11.842954,5.575431,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
"Data Democratization, Governance, and Security","Modern data democratization, governance, and security in the modern data warehouse environment is not conceptual anymoreâ€”it is essential. Data needs are growing in volume, velocity, veracity, and complexity, so governance and security are becoming more and more challenging. Data democratization and security are at opposite ends of the spectrum, but governance is essential to balance both. There are a plethora of tools and techniques available for the same, but concepts, activities, and possible pitfalls are found in the same services available in the cloud.",modern data democratization  governance  and security in the modern data warehouse environment is not conceptual anymore   it is essential  data needs are growing in volume  velocity  veracity  and complexity  so governance and security are becoming more and more challenging  data democratization and security are at opposite ends of the spectrum  but governance is essential to balance both  there are a plethora of tools and techniques available for the same  but concepts  activities  and possible pitfalls are found in the same services available in the cloud ,9.928543,7.61519,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Ethical AI for Social Good,"The concept of AI for Social Good(AI4SG) is gaining momentum in both information societies and the AI community. Through all the advancement of AI-based solutions, it can solve societal issues effectively. To date, however, there is only a rudimentary grasp of what constitutes AI socially beneficial in principle, what constitutes AI4SG in reality, and what are the policies and regulations needed to ensure it. This paper fills the vacuum by addressing the ethical aspects that are critical for future AI4SG efforts. Some of these characteristics are new to AI, while others have greater importance due to its usage.
 Keywords
 Ai for social good
 Artificial intelligence
 Ethics
 Fairness
 Equitable
 Responsible AI
 Human centered AI",the concept of ai for social good ai sg  is gaining momentum in both information societies and the ai community  through all the advancement of ai based solutions  it can solve societal issues effectively  to date  however  there is only a rudimentary grasp of what constitutes ai socially beneficial in principle  what constitutes ai sg in reality  and what are the policies and regulations needed to ensure it  this paper fills the vacuum by addressing the ethical aspects that are critical for future ai sg efforts  some of these characteristics are new to ai  while others have greater importance due to its usage   keywords  ai for social good  artificial intelligence  ethics  fairness  equitable  responsible ai  human centered ai,11.948791,5.6744504,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Supporting Deep Learning-Based Named Entity Recognition Using Cloud Resource Management,"This paper presents a system for managing Cloud Resources such as memory and CPU/GPU that is used to develop, train, and customize Deep Learning-based Named Entity Recognition (NER) models in domains like heath care. The increasing digitization of healthcare services has led to the emergence of electronic health records (EHRs) as a significant component of healthcare data management. NER is a machine learning technique that can be applied to EHRs to extract information such as drug and treatment information, helping to support clinical decision making. The paper is addressing the difficulty domain experts face in using Cloud technologies to perform NER tasks, since they often require technical expertise and technical management overhead. The paper presents a system for the configuration of cloud resources for NER training using the spaCy framework and AWS compute services. The research is structured using Nunamakerâ€™s methodology, which provides a structured approach to software development through four phases: observation, theory building, systems development, and experimentation. The paper identifies problem statements and research questions to guide the research and maps them to the objectives of the methodology. The objectives of the methodology include researching the state-of-the-art of NER and cloud technologies, analyzing the architecture of motivating research projects, defining user requirements and the system architecture, and implementing the system. The system is designed using User Centered Systems Design and is based on previously identified user requirements. Two main user groups are considered for the application: NER Experts and Medical Domain Experts. The system is implemented using the Model-View-Controller architecture pattern. It allows for the training of Transformer models, selection of compute resources, and adjusting training configuration and hyperparameters. The system is designed for scalability of compute and storage resources. The paper also discusses the evaluation of the system through experiments and analysis of the results to gain insights. It provides information about the technical implementation and details about the user interface. It is evaluated using cognitive walkthrough and experiments with Transformer-based models.
 Keywords
 Cloud Resource Management
 Deep Learning
 Named Entity Recognition
 Transformer
 Cloud Computing
 Micro Service Architecture",this paper presents a system for managing cloud resources such as memory and cpu gpu that is used to develop  train  and customize deep learning based named entity recognition  ner  models in domains like heath care  the increasing digitization of healthcare services has led to the emergence of electronic health records  ehrs  as a significant component of healthcare data management  ner is a machine learning technique that can be applied to ehrs to extract information such as drug and treatment information  helping to support clinical decision making  the paper is addressing the difficulty domain experts face in using cloud technologies to perform ner tasks  since they often require technical expertise and technical management overhead  the paper presents a system for the configuration of cloud resources for ner training using the spacy framework and aws compute services  the research is structured using nunamaker   s methodology  which provides a structured approach to software development through four phases  observation  theory building  systems development  and experimentation  the paper identifies problem statements and research questions to guide the research and maps them to the objectives of the methodology  the objectives of the methodology include researching the state of the art of ner and cloud technologies  analyzing the architecture of motivating research projects  defining user requirements and the system architecture  and implementing the system  the system is designed using user centered systems design and is based on previously identified user requirements  two main user groups are considered for the application  ner experts and medical domain experts  the system is implemented using the model view controller architecture pattern  it allows for the training of transformer models  selection of compute resources  and adjusting training configuration and hyperparameters  the system is designed for scalability of compute and storage resources  the paper also discusses the evaluation of the system through experiments and analysis of the results to gain insights  it provides information about the technical implementation and details about the user interface  it is evaluated using cognitive walkthrough and experiments with transformer based models   keywords  cloud resource management  deep learning  named entity recognition  transformer  cloud computing  micro service architecture,8.210064,4.090459,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Automated Tools,"Gone are the days where, as a data scientist, you had to put in your sweat to develop an optimized machine learning model. The tools that are available at the hands of a data scientist today have eased out the entire data science process. Right from designing the best-performing data pipeline to creating an ensemble of high-performing algorithms, these tools take care of everything. Some tools even try out both GOFAI and ANN approaches to design a well-performing ML model on your dataset. In this chapter, I will introduce you to this AutoML technology through the two popular open-source projects and then later on give you the various options that are available for your use. As a data scientist, this will help you in quickly developing ML models on any dataset, be it small or big.",gone are the days where  as a data scientist  you had to put in your sweat to develop an optimized machine learning model  the tools that are available at the hands of a data scientist today have eased out the entire data science process  right from designing the best performing data pipeline to creating an ensemble of high performing algorithms  these tools take care of everything  some tools even try out both gofai and ann approaches to design a well performing ml model on your dataset  in this chapter  i will introduce you to this automl technology through the two popular open source projects and then later on give you the various options that are available for your use  as a data scientist  this will help you in quickly developing ml models on any dataset  be it small or big ,9.502217,6.5413275,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Setting the Stage: AI Potential and Challenges,"Human history has been closely intertwined with technology, which has been at the heart of a few epochal moments that have transformed the course of civilization. The discovery of fire, the invention of the wheel, the birth of agriculture, the industrial revolution â€“ each of these milestones marked a fundamental shift in the way humans interacted with the world around them. Today, we live through another such revolution â€“ a moment that promises to reshape our lives and redefine our future: the advent of artificial intelligence (AI). This section will provide an overview of AIâ€™s transformative power, its growing importance in the modern world, and the key challenges faced by organizations when implementing AI solutions. I will also introduce the â€œFirst Principlesâ€ methodology, to successfully implement AI.",human history has been closely intertwined with technology  which has been at the heart of a few epochal moments that have transformed the course of civilization  the discovery of fire  the invention of the wheel  the birth of agriculture  the industrial revolution     each of these milestones marked a fundamental shift in the way humans interacted with the world around them  today  we live through another such revolution     a moment that promises to reshape our lives and redefine our future  the advent of artificial intelligence  ai   this section will provide an overview of ai   s transformative power  its growing importance in the modern world  and the key challenges faced by organizations when implementing ai solutions  i will also introduce the    first principles    methodology  to successfully implement ai ,11.068011,5.963211,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
What Is Productive and Efficient Data Science?,The goal of this chapter is to introduce you to the benefits of performing data science tasks efficiently and productively. I also illustrate some potential pitfalls in the everyday work of a regular data scientist to drive home the point of efficient data science.,the goal of this chapter is to introduce you to the benefits of performing data science tasks efficiently and productively  i also illustrate some potential pitfalls in the everyday work of a regular data scientist to drive home the point of efficient data science ,9.484809,6.7489533,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
On the Analyses of Medical Images Using Traditional Machine Learning Techniques and Convolutional Neural Networks,"Convolutional neural network (CNN) has shown dissuasive accomplishment on different areas especially Object Detection, Segmentation, Reconstruction (2D and 3D), Information Retrieval, Medical Image Registration, Multi-lingual translation, Local language Processing, Anomaly Detection on video and Speech Recognition. CNN is a special type of Neural Network, which has compelling and effective learning ability to learn features at several steps during augmentation of the data. Recently, different interesting and inspiring ideas of Deep Learning (DL) such as different activation functions, hyperparameter optimization, regularization, momentum and loss functions has improved the performance, operation and execution of CNN Different internal architecture innovation of CNN and different representational style of CNN has significantly improved the performance. This survey focuses on internal taxonomy of deep learning, different models of vonvolutional neural network, especially depth and width of models and in addition CNN components, applications and current challenges of deep learning.",convolutional neural network  cnn  has shown dissuasive accomplishment on different areas especially object detection  segmentation  reconstruction   d and  d   information retrieval  medical image registration  multi lingual translation  local language processing  anomaly detection on video and speech recognition  cnn is a special type of neural network  which has compelling and effective learning ability to learn features at several steps during augmentation of the data  recently  different interesting and inspiring ideas of deep learning  dl  such as different activation functions  hyperparameter optimization  regularization  momentum and loss functions has improved the performance  operation and execution of cnn different internal architecture innovation of cnn and different representational style of cnn has significantly improved the performance  this survey focuses on internal taxonomy of deep learning  different models of vonvolutional neural network  especially depth and width of models and in addition cnn components  applications and current challenges of deep learning ,4.567361,5.698608,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Mapping the Landscape of Care Providersâ€™ Quality Assurance Approaches for AI in Diagnostic Imaging,"The discussion on artificial intelligence (AI) solutions in diagnostic imaging has matured in recent years. The potential value of AI adoption is well established, as are the potential risks associated. Much focus has, rightfully, been on regulatory certification of AI products, with the strong incentive of being an enabling step for the commercial actors. It is, however, becoming evident that regulatory approval is not enough to ensure safe and effective AI usage in the local setting. In other words, care providers need to develop and implement quality assurance (QA) approaches for AI solutions in diagnostic imaging. The domain of AI-specific QA is still in an early development phase. We contribute to this development by describing the current landscape of QA-for-AI approaches in medical imaging, with focus on radiology and pathology. We map the potential quality threats and review the existing QA approaches in relation to those threats. We propose a practical categorization of QA approaches, based on key characteristics corresponding to means, situation, and purpose. The review highlights the heterogeneity of methods and practices relevant for this domain and points to targets for future research efforts.",the discussion on artificial intelligence  ai  solutions in diagnostic imaging has matured in recent years  the potential value of ai adoption is well established  as are the potential risks associated  much focus has  rightfully  been on regulatory certification of ai products  with the strong incentive of being an enabling step for the commercial actors  it is  however  becoming evident that regulatory approval is not enough to ensure safe and effective ai usage in the local setting  in other words  care providers need to develop and implement quality assurance  qa  approaches for ai solutions in diagnostic imaging  the domain of ai specific qa is still in an early development phase  we contribute to this development by describing the current landscape of qa for ai approaches in medical imaging  with focus on radiology and pathology  we map the potential quality threats and review the existing qa approaches in relation to those threats  we propose a practical categorization of qa approaches  based on key characteristics corresponding to means  situation  and purpose  the review highlights the heterogeneity of methods and practices relevant for this domain and points to targets for future research efforts ,11.774395,6.1621327,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
KI5GRob: Fusing Cloud Computing and AI for Scalable Robotic System in Production and Logistics,"Robotics and AI are essential components in current and future production scenarios. For example, in object handling, breakthroughs in AI have achieved revolutionary progress. As systems scale and the complexity of tasks increase, the use of deep learning in industrial robotics applications leads to specific challenges in terms of scalability, reliability, and safety. Some of these challenges can be overcome by utilizing cutting-edge technologies in cloud computing such as on-demand computing, massive parallelization, microservices, and the DevOps pipeline. With KI5GRob, we propose a novel approach to facilitate the development of robotic applications fusing cloud computing and AI. As example application for the proposed cloud approach, KI5GRob investigates machine learning methods for multi-modal sensor data processing and transfer learning to solve industrial robotic manipulation tasks. The goal of the project is to develop a microservice based software architecture that enables on-demand deployment of such learning-based methods as well as cloud-based motion planning and robot control. This paper gives a high-level overview of the goals and the ongoing research activities in KI5GRob. The first results about the overall hardware and software architecture are also presented.
 Keywords
 Robotic manipulation
 Machine learning
 Multi-modal sensor fusion
 Transfer learning
 Cloud robotics
 Microservice
 Motion planning
 Robot control",robotics and ai are essential components in current and future production scenarios  for example  in object handling  breakthroughs in ai have achieved revolutionary progress  as systems scale and the complexity of tasks increase  the use of deep learning in industrial robotics applications leads to specific challenges in terms of scalability  reliability  and safety  some of these challenges can be overcome by utilizing cutting edge technologies in cloud computing such as on demand computing  massive parallelization  microservices  and the devops pipeline  with ki grob  we propose a novel approach to facilitate the development of robotic applications fusing cloud computing and ai  as example application for the proposed cloud approach  ki grob investigates machine learning methods for multi modal sensor data processing and transfer learning to solve industrial robotic manipulation tasks  the goal of the project is to develop a microservice based software architecture that enables on demand deployment of such learning based methods as well as cloud based motion planning and robot control  this paper gives a high level overview of the goals and the ongoing research activities in ki grob  the first results about the overall hardware and software architecture are also presented   keywords  robotic manipulation  machine learning  multi modal sensor fusion  transfer learning  cloud robotics  microservice  motion planning  robot control,7.6742496,6.8869777,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
An Investigation of Challenges Encountered When Specifying Training Data and Runtime Monitors for Safety Critical ML Applications,"[Context and motivation] The development and operation of critical software that contains machine learning (ML) models requires diligence and established processes. Especially the training data used during the development of ML models have major influences on the later behaviour of the system. Runtime monitors are used to provide guarantees for that behaviour. [Question/problem] We see major uncertainty in how to specify training data and runtime monitoring for critical ML models and by this specifying the final functionality of the system. In this interview-based study we investigate the underlying challenges for these difficulties. [Principal ideas/results] Based on ten interviews with practitioners who develop ML models for critical applications in the automotive and telecommunication sector, we identified 17 underlying challenges in 6 challenge groups that relate to the challenge of specifying training data and runtime monitoring. [Contribution] The article provides a list of the identified underlying challenges related to the difficulties practitioners experience when specifying training data and runtime monitoring for ML models. Furthermore, interconnection between the challenges were found and based on these connections recommendation proposed to overcome the root causes for the challenges.
 Keywords
 Artificial intelligence
 Context
 Data requirements
 Machine learning
 Requirements engineering
 Runtime monitoring", context and motivation  the development and operation of critical software that contains machine learning  ml  models requires diligence and established processes  especially the training data used during the development of ml models have major influences on the later behaviour of the system  runtime monitors are used to provide guarantees for that behaviour   question problem  we see major uncertainty in how to specify training data and runtime monitoring for critical ml models and by this specifying the final functionality of the system  in this interview based study we investigate the underlying challenges for these difficulties   principal ideas results  based on ten interviews with practitioners who develop ml models for critical applications in the automotive and telecommunication sector  we identified    underlying challenges in   challenge groups that relate to the challenge of specifying training data and runtime monitoring   contribution  the article provides a list of the identified underlying challenges related to the difficulties practitioners experience when specifying training data and runtime monitoring for ml models  furthermore  interconnection between the challenges were found and based on these connections recommendation proposed to overcome the root causes for the challenges   keywords  artificial intelligence  context  data requirements  machine learning  requirements engineering  runtime monitoring,9.801295,5.0123143,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Towards a change taxonomy for machine learning pipelines Empirical study of ML pipelines and forks related to academic publications,"Machine Learning (ML) academic publications commonly provide open-source implementations on GitHub, allowing their audience to replicate, validate, or even extend the ML algorithms, data sets and metadata. However, thus far little is known about the degree of collaboration activity happening on such ML research repositories, in particular regarding (1) the degree to which such repositories receive contributions from forks, (2) the nature of such contributions (i.e., the types of changes), and (3) the nature of changes that are not contributed back to forks, which might represent missed opportunities. In this paper, we empirically study contributions to 1,346 ML research repositories and their 67,369 forks, both quantitatively and qualitatively, by building on Hindle et al.â€™s seminal taxonomy of code changes. We found that while ML research repositories are heavily forked, only 9% of the forks made modifications to the forked repository. 42% of the latter sent changes to the parent repositories, half of which (52%) were accepted by the parent repositories. Our qualitative analysis on 539 contributed and 378 local (fork-only) changes extends Hindle et al.â€™s taxonomy with two new top-level change categories related to ML (Data and Dependency Management), and 16 new sub-categories, including nine ML-specific ones (input data, parameter tuning, pre-processing, training infrastructure, model structure, pipeline performance, sharing, validation infrastructure, and output data). While the changes that are not contributed back by the forks mostly concern domain-specific features and local experimentation (e.g., parameter tuning), the origin repositories do miss out on a non-trivial 15.4% of Documentation changes, 13.6% of Feature changes and 11.4% of Bug fix changes.",machine learning  ml  academic publications commonly provide open source implementations on github  allowing their audience to replicate  validate  or even extend the ml algorithms  data sets and metadata  however  thus far little is known about the degree of collaboration activity happening on such ml research repositories  in particular regarding     the degree to which such repositories receive contributions from forks      the nature of such contributions  i e   the types of changes   and     the nature of changes that are not contributed back to forks  which might represent missed opportunities  in this paper  we empirically study contributions to       ml research repositories and their        forks  both quantitatively and qualitatively  by building on hindle et al    s seminal taxonomy of code changes  we found that while ml research repositories are heavily forked  only    of the forks made modifications to the forked repository      of the latter sent changes to the parent repositories  half of which       were accepted by the parent repositories  our qualitative analysis on     contributed and     local  fork only  changes extends hindle et al    s taxonomy with two new top level change categories related to ml  data and dependency management   and    new sub categories  including nine ml specific ones  input data  parameter tuning  pre processing  training infrastructure  model structure  pipeline performance  sharing  validation infrastructure  and output data   while the changes that are not contributed back by the forks mostly concern domain specific features and local experimentation  e g   parameter tuning   the origin repositories do miss out on a non trivial       of documentation changes        of feature changes and       of bug fix changes ,6.4911575,5.9683795,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Effect of Small Dataset Quality on Deep Neural Network Performance for Lyme Disease Classification,"The problem of application of deep neural networks (DNNs) for extremely small dataset is considered to find the effect of dataset size and quality on performance metrics. Classification task is considered for the set of problems where images of Lyme disease symptoms were collected and structured in the open-access dataset with the different subsets of the whole dataset: clean images only (C), dirty images only (D), and clean and dirty images in the equal proportions (C_D) (https://www.kaggle.com/yoctoman/lyme-clean-and-dirty) . Two different data preprocessing techniques were applied: normalization without data augmentation (NODA) and normalization with data augmentation (DA). The two versions of the modern NASNet DNN architectures of different sizes were used, namely NASNetLarge and NASNetMobile, with the weights obtained after training on ImageNet dataset. These DNNs were trained in two experiments, namely with frozen layers, aka transfer learning (TL), and with unfrozen layers when all weights were updated (NOTL). After fivefold cross-validated training the best results for mean validation metrics were demonstrated by the models trained in C_NOTL_NODA, C_NOTL_DA, and C_TL_NODA experiments for NASNetLarge, and in C_TL_NODA by NASNetMobile. But the testing on the new unknown subset of Lyme disease images with the equal proportion of clean and dirty images gave quite different results. The models trained in the before-mentioned experiments demonstrated poor performance in comparison with the models trained in C_NOTL_DA, D_NOTL_DA experiments, and, especially in D_C_NOTL_DA ones. The successful training strategy should include tuning ImageNet-trained weights without their freezing (NOTL) and intensive data augmentation (DA), but it would not be enough if some diverse relevant background will not be added. That is why the additional methods of â€œcontext-relevant data augmentationâ€ (CRDA) mimicked by inclusion of D_C data configuration should be considered. These findings can be used for the more effective selection of training experiments of DNNs in the healthcare context in the view of the small number of available medical data in practice.
 Keywords
 Neural networks
 Deep learning
 Small dataset problem
 Data augmentation
 Transfer learning
 Health care
 Lyme disease",the problem of application of deep neural networks  dnns  for extremely small dataset is considered to find the effect of dataset size and quality on performance metrics  classification task is considered for the set of problems where images of lyme disease symptoms were collected and structured in the open access dataset with the different subsets of the whole dataset  clean images only  c   dirty images only  d   and clean and dirty images in the equal proportions  c d   https   www kaggle com yoctoman lyme clean and dirty    two different data preprocessing techniques were applied  normalization without data augmentation  noda  and normalization with data augmentation  da   the two versions of the modern nasnet dnn architectures of different sizes were used  namely nasnetlarge and nasnetmobile  with the weights obtained after training on imagenet dataset  these dnns were trained in two experiments  namely with frozen layers  aka transfer learning  tl   and with unfrozen layers when all weights were updated  notl   after fivefold cross validated training the best results for mean validation metrics were demonstrated by the models trained in c notl noda  c notl da  and c tl noda experiments for nasnetlarge  and in c tl noda by nasnetmobile  but the testing on the new unknown subset of lyme disease images with the equal proportion of clean and dirty images gave quite different results  the models trained in the before mentioned experiments demonstrated poor performance in comparison with the models trained in c notl da  d notl da experiments  and  especially in d c notl da ones  the successful training strategy should include tuning imagenet trained weights without their freezing  notl  and intensive data augmentation  da   but it would not be enough if some diverse relevant background will not be added  that is why the additional methods of    context relevant data augmentation     crda  mimicked by inclusion of d c data configuration should be considered  these findings can be used for the more effective selection of training experiments of dnns in the healthcare context in the view of the small number of available medical data in practice   keywords  neural networks  deep learning  small dataset problem  data augmentation  transfer learning  health care  lyme disease,3.4268193,5.6377945,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Transformer-Based Automated Content-Standards Alignment: A Pilot Study,"The passage of the No Child Left Behind Act has increased an emphasis on developing K-12 curricula around existing and emergent state and national standards. The ever-growing volume of readily available K-12 digital content has increased the need for aligning learning and assessment content to relevant educational standards at scale. However, manual alignment is labor-intensive and time-consuming. Inspired by prior works on automated content alignment systems that leveraged recent advances in deep learning and NLP, this study explores a scalable solution for automatically aligning assessment items to multiple state and national standards. Results indicate the Transformer encoder-decoder model trained from scratch shows decent performance, reaching 34.3 BLEU score and 0.4 averaged ROUGE score on a holdout set. To investigate the limitation of the conventional evaluation metrics and gain deeper insights into the many-to-many relationships observed in the data, a series of metrics are utilized to evaluate the matches between the source and target sequences. In-depth error analysis identifies major error categories and explains the discrepancies in performances observed between the training and test set. Finally, this study discusses the potential for a production-level system and the future direction in extending the current approach to facilitate the development of a general skill taxonomy as a â€œcrosswalkâ€ for mapping educational content to standards.
 Keywords
 Educational standards
 Assessment items
 Transformer encoder-decoder model
 Evaluation metrics
 Error analysis",the passage of the no child left behind act has increased an emphasis on developing k    curricula around existing and emergent state and national standards  the ever growing volume of readily available k    digital content has increased the need for aligning learning and assessment content to relevant educational standards at scale  however  manual alignment is labor intensive and time consuming  inspired by prior works on automated content alignment systems that leveraged recent advances in deep learning and nlp  this study explores a scalable solution for automatically aligning assessment items to multiple state and national standards  results indicate the transformer encoder decoder model trained from scratch shows decent performance  reaching      bleu score and     averaged rouge score on a holdout set  to investigate the limitation of the conventional evaluation metrics and gain deeper insights into the many to many relationships observed in the data  a series of metrics are utilized to evaluate the matches between the source and target sequences  in depth error analysis identifies major error categories and explains the discrepancies in performances observed between the training and test set  finally  this study discusses the potential for a production level system and the future direction in extending the current approach to facilitate the development of a general skill taxonomy as a    crosswalk    for mapping educational content to standards   keywords  educational standards  assessment items  transformer encoder decoder model  evaluation metrics  error analysis,4.874338,3.3233302,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
DevOps Best Practices in Highly Regulated Industry,"DevOps has an important role in supporting critical decisions in software and systems development in highly regulated industry. To determine best practice, I have reviewed industry papers, standards, and comments of implementers. A systematic review of key reports on DevOps was conducted. Surveys conducted by a number of organizations with over 277,000 respondents are considered here. Key questions posed are how is DevOps perceived by industry, what are the key benefits from an industrial perspective, and what practices contribute to success. Results of this analysis show that while commonly accepted commercial reports make interesting reading; they are not sufficient to base critical decision in highly regulated industry. Furthermore, standards are required to establish confidence in process and product. This paper provides insights and guidance for software and systems development with DevOps practices in a highly regulated environment. I present the need for consistent quality to be encapsulated through industry standards.
 Keywords
 DevOps
 Best practice
 Regulations
 Standards
 Highly regulated industry
 Meta-study
 Industry perspective
 Risk appetite",devops has an important role in supporting critical decisions in software and systems development in highly regulated industry  to determine best practice  i have reviewed industry papers  standards  and comments of implementers  a systematic review of key reports on devops was conducted  surveys conducted by a number of organizations with over         respondents are considered here  key questions posed are how is devops perceived by industry  what are the key benefits from an industrial perspective  and what practices contribute to success  results of this analysis show that while commonly accepted commercial reports make interesting reading  they are not sufficient to base critical decision in highly regulated industry  furthermore  standards are required to establish confidence in process and product  this paper provides insights and guidance for software and systems development with devops practices in a highly regulated environment  i present the need for consistent quality to be encapsulated through industry standards   keywords  devops  best practice  regulations  standards  highly regulated industry  meta study  industry perspective  risk appetite,9.974757,5.9011407,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Data Monetization with AI,"In todayâ€™s digital era, businesses accumulate vast quantities of data, the â€œnew oilâ€ of the economy. This data is a goldmine for generating business growth and revenue. Leveraging artificial intelligence (AI) for data monetization â€“ converting data into actionable insights or products that create business value â€“ is our primary focus. This chapter equips business executives with essential knowledge on data monetization, enabling the effective utilization of data assets.",in today   s digital era  businesses accumulate vast quantities of data  the    new oil    of the economy  this data is a goldmine for generating business growth and revenue  leveraging artificial intelligence  ai  for data monetization     converting data into actionable insights or products that create business value     is our primary focus  this chapter equips business executives with essential knowledge on data monetization  enabling the effective utilization of data assets ,10.476017,7.6706443,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
What Drives Success in Data Science Projects: A Taxonomy of Antecedents,"Organizations have been trying to reshape their business processes and transform them into a smart environment to attain sustainable competitive advantage in their markets. Data science enables organizations to define interconnected and self-controlled business processes by analyzing the massive amount of unstandardized and unstructured high-speed data produced by heterogeneous Internet of Things devices. However, according to the latest research, the success rate of data science projects is lower than other software projects, and the literature review conducted reveals a fundamental need for determining success drivers for data science projects. To address these research gaps, this study investigates the determinants of success and the taxonomy of antecedents of success in data science projects. We reviewed the literature systematically and conducted an expert panel by following a Delphi method to explore the main success drivers of data science projects. The main contributions of the study are twofold: (1) establishing a common base for determinants of success in data science projects (2) guiding organizations to increase the success of their data science projects.
 Keywords
 Data science
 Project management
 Project success
 Critical success factors",organizations have been trying to reshape their business processes and transform them into a smart environment to attain sustainable competitive advantage in their markets  data science enables organizations to define interconnected and self controlled business processes by analyzing the massive amount of unstandardized and unstructured high speed data produced by heterogeneous internet of things devices  however  according to the latest research  the success rate of data science projects is lower than other software projects  and the literature review conducted reveals a fundamental need for determining success drivers for data science projects  to address these research gaps  this study investigates the determinants of success and the taxonomy of antecedents of success in data science projects  we reviewed the literature systematically and conducted an expert panel by following a delphi method to explore the main success drivers of data science projects  the main contributions of the study are twofold      establishing a common base for determinants of success in data science projects     guiding organizations to increase the success of their data science projects   keywords  data science  project management  project success  critical success factors,10.959986,5.624637,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Gaia-AgStream: An Explainable AI Platform for Mining Complex Data Streams in Agriculture,"We present a position paper about our concept for an artificial intelligence (AI) and data streaming platform for the agricultural sector. The goal of our project is to support agroecology in terms of carbon farming and biodiversity protection by providing an AI and data streaming platform called Gaia-AgStream that accelerates the adoption of AI in agriculture and is directly usable by farmers as well as agricultural companies in general. The technical innovations we propose focus on smart sensor networks, unified uncertainty management, explainable AI, root cause analysis and hybrid AI approaches. Our AI and data streaming platform concept contributes to the European open data infrastructure project Gaia-X in terms of interoperability for data and AI models as well as data sovereignty and AI infrastructure.
 Our envisioned platform and the developed AI components for carbon farming and biodiversity will enable farmers to adopt sustainable and resilient production methods while establishing new and diverse revenue streams by monetizing carbon sequestration and AI ready data streams. The open and federated platform concept allows to bring together research, industry, agricultural start-ups and farmers in order to form sustainable innovation networks. We describe core concepts and architecture of our proposed approach in these contexts, outline practical use cases for our platform and finally outline challenges and future prospects.
 Keywords
 Explainable AI
 Sensor networks
 Distributed systems
 Uncertainty management
 Complex networks
 Machine learning
 Anomaly detection
 Root cause analysis
 Knowledge graph
 Data quality
 Agroecology
 Carbon farming
 Biodiversity
 Data fusion",we present a position paper about our concept for an artificial intelligence  ai  and data streaming platform for the agricultural sector  the goal of our project is to support agroecology in terms of carbon farming and biodiversity protection by providing an ai and data streaming platform called gaia agstream that accelerates the adoption of ai in agriculture and is directly usable by farmers as well as agricultural companies in general  the technical innovations we propose focus on smart sensor networks  unified uncertainty management  explainable ai  root cause analysis and hybrid ai approaches  our ai and data streaming platform concept contributes to the european open data infrastructure project gaia x in terms of interoperability for data and ai models as well as data sovereignty and ai infrastructure   our envisioned platform and the developed ai components for carbon farming and biodiversity will enable farmers to adopt sustainable and resilient production methods while establishing new and diverse revenue streams by monetizing carbon sequestration and ai ready data streams  the open and federated platform concept allows to bring together research  industry  agricultural start ups and farmers in order to form sustainable innovation networks  we describe core concepts and architecture of our proposed approach in these contexts  outline practical use cases for our platform and finally outline challenges and future prospects   keywords  explainable ai  sensor networks  distributed systems  uncertainty management  complex networks  machine learning  anomaly detection  root cause analysis  knowledge graph  data quality  agroecology  carbon farming  biodiversity  data fusion,10.408734,6.486791,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Artificial intelligence applications in histopathology,"Histopathology is a vital diagnostic discipline in medicine, fundamental to our understanding, detection, assessment and treatment of conditions such as cancer, dementia and heart disease. Traditionally, the standard workflow in histopathology has primarily relied on the visual interpretation of tissue samples carried out by human experts under a light microscope. Since the 2000s, thanks to advances in scanning technologies such as whole-slide imaging, histopathology is undergoing a digital transformation. The rapid increase in digital data is fuelling the development and application of artificial intelligence (AI) methods. In this Review, we delve into the latest progress in AI methods for histopathology, which promise to yield accurate, scalable, useful and affordable support tools for clinical decision. We examine the challenges and opportunities in this domain, exploring historically important approaches and problems that have shaped the field, while also highlighting recent technological breakthroughs that are poised to redefine its future. Furthermore, we offer an overview of publicly available datasets that have been instrumental in propelling the development of AI methods in histopathology.",histopathology is a vital diagnostic discipline in medicine  fundamental to our understanding  detection  assessment and treatment of conditions such as cancer  dementia and heart disease  traditionally  the standard workflow in histopathology has primarily relied on the visual interpretation of tissue samples carried out by human experts under a light microscope  since the     s  thanks to advances in scanning technologies such as whole slide imaging  histopathology is undergoing a digital transformation  the rapid increase in digital data is fuelling the development and application of artificial intelligence  ai  methods  in this review  we delve into the latest progress in ai methods for histopathology  which promise to yield accurate  scalable  useful and affordable support tools for clinical decision  we examine the challenges and opportunities in this domain  exploring historically important approaches and problems that have shaped the field  while also highlighting recent technological breakthroughs that are poised to redefine its future  furthermore  we offer an overview of publicly available datasets that have been instrumental in propelling the development of ai methods in histopathology ,6.299291,3.6357515,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
DevOps Challenges and Risk Mitigation Strategies by DevOps Professionals Teams,"DevOps is a team culture and organizational practice that eliminates inefficiencies and bottlenecks in the DevOps infrastructure. While many companies are adopting DevOps practices, it can still be risky. We conducted 26 interviews with DevOps professionals around the globe and found four major risks associated with DevOps practices: Organizational risks (Intra-organizational collaboration and communication, strategic planning), Social and cultural risks (Team Dynamics, Cultural shift), Technical risks (Integration, Build and test automation), Ethics and security breaches in DevOps environment (Ethical risks, Data collection ethics, Ethical decision making). Our research also identified several risk mitigation strategies namely continuous testing, using infrastructure as code, security audit and monitoring, disaster recovery planning, cross-functional training, proper documentation, continuous learning, continuous improvement etc. that companies can adopt for better performance and efficiency.
 Keywords
 DevOps
 DevOps practice
 DevOps risks
 DevOps risk mitigation strategies
 Qualitative research",devops is a team culture and organizational practice that eliminates inefficiencies and bottlenecks in the devops infrastructure  while many companies are adopting devops practices  it can still be risky  we conducted    interviews with devops professionals around the globe and found four major risks associated with devops practices  organizational risks  intra organizational collaboration and communication  strategic planning   social and cultural risks  team dynamics  cultural shift   technical risks  integration  build and test automation   ethics and security breaches in devops environment  ethical risks  data collection ethics  ethical decision making   our research also identified several risk mitigation strategies namely continuous testing  using infrastructure as code  security audit and monitoring  disaster recovery planning  cross functional training  proper documentation  continuous learning  continuous improvement etc  that companies can adopt for better performance and efficiency   keywords  devops  devops practice  devops risks  devops risk mitigation strategies  qualitative research,10.144352,5.4190807,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Developing and Operating Artificial Intelligence Models in Trustworthy Autonomous Systems,"Companies dealing with Artificial Intelligence (AI) models in Autonomous Systems (AS) face several problems, such as usersâ€™ lack of trust in adverse or unknown conditions, gaps between software engineering and AI model development, and operation in a continuously changing operational environment. This work-in-progress paper aims to close the gap between the development and operation of trustworthy AI-based AS by defining an approach that coordinates both activities. We synthesize the main challenges of AI-based AS in industrial settings. We reflect on the research efforts required to overcome these challenges and propose a novel, holistic DevOps approach to put it into practice. We elaborate on four research directions: (a) increased usersâ€™ trust by monitoring operational AI-based AS and identifying self-adaptation needs in critical situations; (b) integrated agile process for the development and evolution of AI models and AS; (c) continuous deployment of different context-specific instances of AI models in a distributed setting of AS; and (d) holistic DevOps-based lifecycle for AI-based AS.
 Keywords
 DevOps
 Autonomous Systems
 AI
 Trustworthiness",companies dealing with artificial intelligence  ai  models in autonomous systems  as  face several problems  such as users    lack of trust in adverse or unknown conditions  gaps between software engineering and ai model development  and operation in a continuously changing operational environment  this work in progress paper aims to close the gap between the development and operation of trustworthy ai based as by defining an approach that coordinates both activities  we synthesize the main challenges of ai based as in industrial settings  we reflect on the research efforts required to overcome these challenges and propose a novel  holistic devops approach to put it into practice  we elaborate on four research directions   a  increased users    trust by monitoring operational ai based as and identifying self adaptation needs in critical situations   b  integrated agile process for the development and evolution of ai models and as   c  continuous deployment of different context specific instances of ai models in a distributed setting of as  and  d  holistic devops based lifecycle for ai based as   keywords  devops  autonomous systems  ai  trustworthiness,11.761062,5.5002685,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Other Useful Skills to Master,"As you progress towards the end of the grand journey of productive and efficient data science that you took in this book, I would like to dedicate one complete chapter to the set of various disparate useful skills that a data scientist should strive to master to enhance their productivity. Unlike the previous chapters, where you examined similarly grouped skills (e.g., memory profilers or distributed computing tools), the tools and skills youâ€™ll explore in this chapter may look somewhat disjointed from each other. It is true that they do not fall under one unifying class but taken as a whole, they truly aid any data scientist in performing their tasks with higher productivity. Unlike previous chapters, this chapter is not focused on one (or a small number of) Python tools/libraries. While I may be discussing a few useful Python libraries in some sections, elsewhere I may be discussing general technology features without any reference to a specific Python tool. In those sections, I may have general suggestions for what topics to learn and how to go about that.",as you progress towards the end of the grand journey of productive and efficient data science that you took in this book  i would like to dedicate one complete chapter to the set of various disparate useful skills that a data scientist should strive to master to enhance their productivity  unlike the previous chapters  where you examined similarly grouped skills  e g   memory profilers or distributed computing tools   the tools and skills you   ll explore in this chapter may look somewhat disjointed from each other  it is true that they do not fall under one unifying class but taken as a whole  they truly aid any data scientist in performing their tasks with higher productivity  unlike previous chapters  this chapter is not focused on one  or a small number of  python tools libraries  while i may be discussing a few useful python libraries in some sections  elsewhere i may be discussing general technology features without any reference to a specific python tool  in those sections  i may have general suggestions for what topics to learn and how to go about that ,9.631975,6.6853366,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Proceedings of the first world conference on AI in fertility,Recordings of the AI Fertility oral presentations will be made available through the AI Fertility Society at https://aifertility.org/.,recordings of the ai fertility oral presentations will be made available through the ai fertility society at https   aifertility org  ,11.249251,6.1583524,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Data-driven decarbonisation pathways for reducing life cycle GHG emissions from food waste in the hospitality and food service sectors,"The Hospitality and Food Service (HaFS) sectors are notoriously known for their contribution to the food waste problem. Hence, there is an urgent need to devise strategies to reduce food waste in the HaFS sectors and to decarbonise their operation to help fight hunger, achieve food security, improve nutrition and mitigate climate change. This study proposes three streams to decarbonise the staff cafeteria operation in an integrated resort in Macau. These include upstream optimisation to reduce unserved food waste, midstream education to raise awareness amongst staff about the impact of food choices on the climate and health, and finally downstream recognition to reduce edible plate waste using a state-of-the-art computer vision system. Technology can be an effective medium to facilitate desired behavioural change through nudging, much like how speed cameras can cause people to slow down and help save lives. The holistic and data-driven approach taken revealed great potential for organisations or institutions that offer catering services to reduce their food waste and associated carbon footprint whilst educating individuals about the intricate link between food, climate and well-being.",the hospitality and food service  hafs  sectors are notoriously known for their contribution to the food waste problem  hence  there is an urgent need to devise strategies to reduce food waste in the hafs sectors and to decarbonise their operation to help fight hunger  achieve food security  improve nutrition and mitigate climate change  this study proposes three streams to decarbonise the staff cafeteria operation in an integrated resort in macau  these include upstream optimisation to reduce unserved food waste  midstream education to raise awareness amongst staff about the impact of food choices on the climate and health  and finally downstream recognition to reduce edible plate waste using a state of the art computer vision system  technology can be an effective medium to facilitate desired behavioural change through nudging  much like how speed cameras can cause people to slow down and help save lives  the holistic and data driven approach taken revealed great potential for organisations or institutions that offer catering services to reduce their food waste and associated carbon footprint whilst educating individuals about the intricate link between food  climate and well being ,11.076144,5.546317,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Implementation and Evaluation of a MLaaS for Document Classification with Continuous Deep Learning Models,"This paper indicates an approach of a continuous training pipeline to enhance deep learning models and assessing their feasibility based on an evaluation. The purpose of this research is to analyze the quality effect of a continuously learning neural network algorithm for document classification by taking user feedback into account. The hypothesis implies that user feedback through active learning increases the precision and thus makes the process of document classification more efficient. For this purpose, based on a utility analysis, the available technologies are identified, and necessary ones are selected for designing a software concept. TensorFlow as a deep learning framework, Tesseract as an OCR engine, and Apache Airflow for the life cycle management and for orchestrating the elements for the continuous training pipeline are used. This implementation of a machine learning as a service prototype allows for exploration into the synergistic effect between the use of active learning, in the form of user feedback, and the quality of document classification achieved by deep learning. In an experiment, the implemented service is used to analyze the models behavior based on three different states. This includes synthetic data and active learning in the form of user feedback through data from data augmentation and simulated realistic data. The result shows that active learning enhanced models indicate a higher accuracy than artificially generated models. The evaluation experiment confirms the hypothesis that user feedback with continuously learning models perform better in terms of generalizing within the document classification. In conclusion, the paper demonstrates the technical requirements for implementing a machine learning as a service and affirms that the use of active learning can be integrated into existing industrial systems.
 Keywords
 Active learning
 Document classification
 TensorFlow serving
 Lifecycle management
 Continuous integration
 Deep learning
 Continuous training pipeline
 Machine learning as a service
 MLOps
 TFX",this paper indicates an approach of a continuous training pipeline to enhance deep learning models and assessing their feasibility based on an evaluation  the purpose of this research is to analyze the quality effect of a continuously learning neural network algorithm for document classification by taking user feedback into account  the hypothesis implies that user feedback through active learning increases the precision and thus makes the process of document classification more efficient  for this purpose  based on a utility analysis  the available technologies are identified  and necessary ones are selected for designing a software concept  tensorflow as a deep learning framework  tesseract as an ocr engine  and apache airflow for the life cycle management and for orchestrating the elements for the continuous training pipeline are used  this implementation of a machine learning as a service prototype allows for exploration into the synergistic effect between the use of active learning  in the form of user feedback  and the quality of document classification achieved by deep learning  in an experiment  the implemented service is used to analyze the models behavior based on three different states  this includes synthetic data and active learning in the form of user feedback through data from data augmentation and simulated realistic data  the result shows that active learning enhanced models indicate a higher accuracy than artificially generated models  the evaluation experiment confirms the hypothesis that user feedback with continuously learning models perform better in terms of generalizing within the document classification  in conclusion  the paper demonstrates the technical requirements for implementing a machine learning as a service and affirms that the use of active learning can be integrated into existing industrial systems   keywords  active learning  document classification  tensorflow serving  lifecycle management  continuous integration  deep learning  continuous training pipeline  machine learning as a service  mlops  tfx,7.33442,4.8322625,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Crowdsourcing Through TinyML as a Way to Engage End-Users in IoT Solutions,"Tiny machine learning (TinyML) is a new field aimed at miniaturizing machine learning algorithms to the point that app developers can integrate them into IoT devices. Since TinyML delivers AI capabilities to embedded devices, it is also known as edge AI or embedded AI.
 TinyML allows bringing AI to devices like smartphones, tablets et al., too. Since these mobile devices have currently surpassed desktop computers as the primary computing device for most users, it allows the possibility to engage even more end-users in crowdsourcing data for the IoT world.
 In this chapter, we will review the current status of TinyML by illustrating its underlying technologies and methodologies and showing some relevant examples where this new area is being used to provide novel applications, thanks to crowdsourcing as a way to engage the final user.
 Keywords
 Tiny machine learning
 Crowdsourcing
 IoT",tiny machine learning  tinyml  is a new field aimed at miniaturizing machine learning algorithms to the point that app developers can integrate them into iot devices  since tinyml delivers ai capabilities to embedded devices  it is also known as edge ai or embedded ai   tinyml allows bringing ai to devices like smartphones  tablets et al   too  since these mobile devices have currently surpassed desktop computers as the primary computing device for most users  it allows the possibility to engage even more end users in crowdsourcing data for the iot world   in this chapter  we will review the current status of tinyml by illustrating its underlying technologies and methodologies and showing some relevant examples where this new area is being used to provide novel applications  thanks to crowdsourcing as a way to engage the final user   keywords  tiny machine learning  crowdsourcing  iot,10.914992,5.238856,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Fuzzy energy management strategy for parallel HEV based on pigeon-inspired optimization algorithm,"Improvements in fuel consumption and emissions of hybrid electric vehicle (HEV) heavily depend upon an efficient energy management strategy (EMS). This paper presents an optimizing fuzzy control strategy of parallel hybrid electric vehicle employing a quantum chaotic pigeon-inspired optimization (QCPIO) algorithm. In this approach, the torque of the engine and the motor is assigned by a fuzzy torque distribution controller which is based on the battery state of charge (SoC) and the required torque of the hybrid powertrain. The rules and membership functions of the fuzzy torque distribution controller are optimized simultaneously through the use of QCPIO algorithm. The simulation ground on ADVISOR demonstrates that this EMS improves fuel economy more effectually than original fuzzy and PSO_Fuzzy EMS.",improvements in fuel consumption and emissions of hybrid electric vehicle  hev  heavily depend upon an efficient energy management strategy  ems   this paper presents an optimizing fuzzy control strategy of parallel hybrid electric vehicle employing a quantum chaotic pigeon inspired optimization  qcpio  algorithm  in this approach  the torque of the engine and the motor is assigned by a fuzzy torque distribution controller which is based on the battery state of charge  soc  and the required torque of the hybrid powertrain  the rules and membership functions of the fuzzy torque distribution controller are optimized simultaneously through the use of qcpio algorithm  the simulation ground on advisor demonstrates that this ems improves fuel economy more effectually than original fuzzy and pso fuzzy ems ,3.726391,7.48133,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
"Development of an End-to-End Web Application for Visualization, Evaluation, and Post-processing of Result Data from Neural Network Predictions for the Melanoma Use Case","Image acquisition technology advances in various fields, yet current image analysis tools limit the effective application of image analysis due to their cumbersome operation process and the requirement of professional knowledge and skills. In this paper, we develop a semi-automated web application for image segmentation and classification tasks with the support of neural networks (relieving the above-mentioned current research dilemma) using melanoma detection as a use case. The web application enables scientists to participate and improve the decision-making process of the neural network through the concept of â€œhuman-in-the-loopâ€, while saving expensive labor costs due to its automation in image annotation and classification. In addition, our web application achieves high usability in the general user community by testing seven aspects of usability: the first impression, distinguishability and clarity of the tools, intuitive characteristics, learnability, feedback and reaction, implementation of expected functionality, and the fulfillment of usability.",image acquisition technology advances in various fields  yet current image analysis tools limit the effective application of image analysis due to their cumbersome operation process and the requirement of professional knowledge and skills  in this paper  we develop a semi automated web application for image segmentation and classification tasks with the support of neural networks  relieving the above mentioned current research dilemma  using melanoma detection as a use case  the web application enables scientists to participate and improve the decision making process of the neural network through the concept of    human in the loop     while saving expensive labor costs due to its automation in image annotation and classification  in addition  our web application achieves high usability in the general user community by testing seven aspects of usability  the first impression  distinguishability and clarity of the tools  intuitive characteristics  learnability  feedback and reaction  implementation of expected functionality  and the fulfillment of usability ,6.7877455,5.232697,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Neural Networks and Deep Learning,"At the heart of most of todayâ€™s â€œflagshipâ€ or â€œhyped-upâ€ applications of Artificial Intelligence is Deep Learning, and, specifically the use and predictive power of Artificial Neural Networks, or ANNs.",at the heart of most of today   s    flagship    or    hyped up    applications of artificial intelligence is deep learning  and  specifically the use and predictive power of artificial neural networks  or anns ,7.7262387,3.5331829,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
GoNDEF: an exact method to generate all non-dominated points of multi-objective mixed-integer linear programs,"Most real-world problems involve multiple conflicting criteria. These problems are called multi-criteria/multi-objective optimization problems (MOOP). The main task in solving MOOPs is to find the non-dominated (ND) points in the objective space or efficient solutions in the decision space. A ND point is a point in the objective space with objective function values that cannot be improved without worsening another objective function. In this paper, we present a new method that generates the set of ND points for a multi-objective mixed-integer linear program (MOMILP). The Generator of ND and Efficient Frontier (GoNDEF) for MOMILPs finds that the ND points represented as points, line segments, and facets consist of every type of ND point. First, the GoNDEF sets integer variables to the values that result in ND points. Fixing integer variables to specific values results in a multi-objective linear program (MOLP). This MOLP has its own set of ND points. A subset of this set establishes a subset of the ND points set of the MOMILP. In this paper, we present an extensive theoretical analysis of the GoNDEF and illustrate its effectiveness on a set of instance problems.",most real world problems involve multiple conflicting criteria  these problems are called multi criteria multi objective optimization problems  moop   the main task in solving moops is to find the non dominated  nd  points in the objective space or efficient solutions in the decision space  a nd point is a point in the objective space with objective function values that cannot be improved without worsening another objective function  in this paper  we present a new method that generates the set of nd points for a multi objective mixed integer linear program  momilp   the generator of nd and efficient frontier  gondef  for momilps finds that the nd points represented as points  line segments  and facets consist of every type of nd point  first  the gondef sets integer variables to the values that result in nd points  fixing integer variables to specific values results in a multi objective linear program  molp   this molp has its own set of nd points  a subset of this set establishes a subset of the nd points set of the momilp  in this paper  we present an extensive theoretical analysis of the gondef and illustrate its effectiveness on a set of instance problems ,2.8900228,8.301081,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
The shaky foundations of large language models and foundation models for electronic health records,"The success of foundation models such as ChatGPT and AlphaFold has spurred significant interest in building similar models for electronic medical records (EMRs) to improve patient care and hospital operations. However, recent hype has obscured critical gaps in our understanding of these modelsâ€™ capabilities. In this narrative review, we examine 84 foundation models trained on non-imaging EMR data (i.e., clinical text and/or structured data) and create a taxonomy delineating their architectures, training data, and potential use cases. We find that most models are trained on small, narrowly-scoped clinical datasets (e.g., MIMIC-III) or broad, public biomedical corpora (e.g., PubMed) and are evaluated on tasks that do not provide meaningful insights on their usefulness to health systems. Considering these findings, we propose an improved evaluation framework for measuring the benefits of clinical foundation models that is more closely grounded to metrics that matter in healthcare.",the success of foundation models such as chatgpt and alphafold has spurred significant interest in building similar models for electronic medical records  emrs  to improve patient care and hospital operations  however  recent hype has obscured critical gaps in our understanding of these models    capabilities  in this narrative review  we examine    foundation models trained on non imaging emr data  i e   clinical text and or structured data  and create a taxonomy delineating their architectures  training data  and potential use cases  we find that most models are trained on small  narrowly scoped clinical datasets  e g   mimic iii  or broad  public biomedical corpora  e g   pubmed  and are evaluated on tasks that do not provide meaningful insights on their usefulness to health systems  considering these findings  we propose an improved evaluation framework for measuring the benefits of clinical foundation models that is more closely grounded to metrics that matter in healthcare ,6.5038905,3.7489345,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Web Based User Interface Testing and Test Automation: Exploring the Current Market Challenges,"User Interface Testing is considered the most challenging part for the software testing industry, due to the presence of dynamic contents and browser dependability, when it especially comes to web application testing. Artificial Intelligence tools have started replacing the traditional method of testing where testing was mainly done manually and was performed only at the end phases of software development life cycle. That was indeed more time consuming and error prone. In this era of Artificial Intelligence, various solutions to manual challenges of testing have been provided by many researchers. Objective of this paper is to study the industrial experiences, best practices, challenges, usage of support tools and several other potential scope for research w.r.t User Interface Testing and Automation. It tries to understand the current state of processes and methodologies in terms of User Interface Testing and also explores future prospects for improvement and enhancements. A methodology of â€˜online surveyâ€™ was carried out with 24 testers/quality assurance engineers and other testing experts of small and medium scale organizations, majority being from India. Results of the survey provided certain key findings about the status of User Interface testing in the market, its challenges and drive to switch towards Artificial Intelligence based testing solutions.
 Keywords
 Use interface testing
 Test automation
 Online survey
 UI testing challenges",user interface testing is considered the most challenging part for the software testing industry  due to the presence of dynamic contents and browser dependability  when it especially comes to web application testing  artificial intelligence tools have started replacing the traditional method of testing where testing was mainly done manually and was performed only at the end phases of software development life cycle  that was indeed more time consuming and error prone  in this era of artificial intelligence  various solutions to manual challenges of testing have been provided by many researchers  objective of this paper is to study the industrial experiences  best practices  challenges  usage of support tools and several other potential scope for research w r t user interface testing and automation  it tries to understand the current state of processes and methodologies in terms of user interface testing and also explores future prospects for improvement and enhancements  a methodology of    online survey    was carried out with    testers quality assurance engineers and other testing experts of small and medium scale organizations  majority being from india  results of the survey provided certain key findings about the status of user interface testing in the market  its challenges and drive to switch towards artificial intelligence based testing solutions   keywords  use interface testing  test automation  online survey  ui testing challenges,9.149867,4.8207197,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Introduction to the Customer Data and Ecosystem-Driven Development Theme,"In many ways, digitalization has confirmed that the success of new technologies and innovations is fully realized only when these are effectively adopted and integrated into the daily practices of a company. During the last decade, we have seen how the speed of technology developments only accelerates, and there are numerous examples of innovations that have fundamentally changed businesses as well as everyday life for the customers they serve. In the manufacturing industry, automation is key for improving efficiency as well as for increasing safety. In the automotive domain, electrification of cars and autonomous drive technologies are replacing mechanical power and human intervention. In the telecom domain, seamless connectivity and digital infrastructures allow systems to adapt and respond within the blink of an eye. In the security and surveillance domain, intelligent technologies provide organizations with the ability to detect, respond, and mitigate potential risks and threats with an accuracy and preciseness we could only dream about a few decades ago. While these are only a few examples, they reflect how digital technologies, and the ever-increasing access to data, are transforming businesses to an extent that we have only seen the beginnings of.",in many ways  digitalization has confirmed that the success of new technologies and innovations is fully realized only when these are effectively adopted and integrated into the daily practices of a company  during the last decade  we have seen how the speed of technology developments only accelerates  and there are numerous examples of innovations that have fundamentally changed businesses as well as everyday life for the customers they serve  in the manufacturing industry  automation is key for improving efficiency as well as for increasing safety  in the automotive domain  electrification of cars and autonomous drive technologies are replacing mechanical power and human intervention  in the telecom domain  seamless connectivity and digital infrastructures allow systems to adapt and respond within the blink of an eye  in the security and surveillance domain  intelligent technologies provide organizations with the ability to detect  respond  and mitigate potential risks and threats with an accuracy and preciseness we could only dream about a few decades ago  while these are only a few examples  they reflect how digital technologies  and the ever increasing access to data  are transforming businesses to an extent that we have only seen the beginnings of ,11.81825,6.452499,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
AI Full Stack: Application Development,"IDC estimate AI currently is a $341 billion market, and if global management consultants are to be believed, could contribute $13 trillion (McKinsey) or $15.7 trillion (PwC) to the global economy by 2030.",idc estimate ai currently is a      billion market  and if global management consultants are to be believed  could contribute     trillion  mckinsey  or       trillion  pwc  to the global economy by      ,11.070173,7.5371895,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
KIcker: An Industrial Drive and Control Foosball System automated with Deep Reinforcement Learning,"The majority of efforts in the field of sim-to-real Deep Reinforcement Learning focus on robot manipulators, which is justified by their importance for modern production plants. However, there are only a few studies for a more extensive use in manufacturing processes. In this paper, we contribute to this by automating a complex manufacturing-like process using simulation-based Deep Reinforcement Learning. The setup and workflow presented here are designed to mimic the characteristics of real manufacturing processes and proves that Deep Reinforcement Learning can be applied to physical systems built from industrial drive and control components by transferring policies learned in simulation to the real machine. Aided by domain randomization, training in a virtual environment is crucial due to the benefit of accelerated training speed and the desire for safe Reinforcement Learning. Our key contribution is to demonstrate the applicability of simulation-based Deep Reinforcement Learning in industrial automation technology. We introduce an industrial drive and control system, based on the classic pub game Foosball, from both an engineering and a simulation perspective, describing the strategies applied to increase transfer robustness. Our approach allowed us to train a self-learning agent to independently learn successful control policies for demanding Foosball tasks based on sparse reward signals. The promising results prove that state-of-the-art Deep Reinforcement Learning algorithms are able to produce models trained in simulation, which can successfully control industrial use cases without using the actual system for training beforehand.",the majority of efforts in the field of sim to real deep reinforcement learning focus on robot manipulators  which is justified by their importance for modern production plants  however  there are only a few studies for a more extensive use in manufacturing processes  in this paper  we contribute to this by automating a complex manufacturing like process using simulation based deep reinforcement learning  the setup and workflow presented here are designed to mimic the characteristics of real manufacturing processes and proves that deep reinforcement learning can be applied to physical systems built from industrial drive and control components by transferring policies learned in simulation to the real machine  aided by domain randomization  training in a virtual environment is crucial due to the benefit of accelerated training speed and the desire for safe reinforcement learning  our key contribution is to demonstrate the applicability of simulation based deep reinforcement learning in industrial automation technology  we introduce an industrial drive and control system  based on the classic pub game foosball  from both an engineering and a simulation perspective  describing the strategies applied to increase transfer robustness  our approach allowed us to train a self learning agent to independently learn successful control policies for demanding foosball tasks based on sparse reward signals  the promising results prove that state of the art deep reinforcement learning algorithms are able to produce models trained in simulation  which can successfully control industrial use cases without using the actual system for training beforehand ,8.365985,4.1034155,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Bringing It All Together,"The past chapters in this book have introduced data analysis methods, feature extraction techniques, and traditional machine learning and deep learning techniques. We have conducted multiple experiments on numeric, textual, and visual data and found how to analyze and tweak the performance.",the past chapters in this book have introduced data analysis methods  feature extraction techniques  and traditional machine learning and deep learning techniques  we have conducted multiple experiments on numeric  textual  and visual data and found how to analyze and tweak the performance ,6.18183,4.648122,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Data collection and quality challenges in deep learning: a data-centric AI perspective,"Data-centric AI is at the center of a fundamental shift in software engineering where machine learning becomes the new software, powered by big data and computing infrastructure. Here, software engineering needs to be re-thought where data become a first-class citizen on par with code. One striking observation is that a significant portion of the machine learning process is spent on data preparation. Without good data, even the best machine learning algorithms cannot perform well. As a result, data-centric AI practices are now becoming mainstream. Unfortunately, many datasets in the real world are small, dirty, biased, and even poisoned. In this survey, we study the research landscape for data collection and data quality primarily for deep learning applications. Data collection is important because there is lesser need for feature engineering for recent deep learning approaches, but instead more need for large amounts of data. For data quality, we study data validation, cleaning, and integration techniques. Even if the data cannot be fully cleaned, we can still cope with imperfect data during model training using robust model training techniques. In addition, while bias and fairness have been less studied in traditional data management research, these issues become essential topics in modern machine learning applications. We thus study fairness measures and unfairness mitigation techniques that can be applied before, during, or after model training. We believe that the data management community is well poised to solve these problems.",data centric ai is at the center of a fundamental shift in software engineering where machine learning becomes the new software  powered by big data and computing infrastructure  here  software engineering needs to be re thought where data become a first class citizen on par with code  one striking observation is that a significant portion of the machine learning process is spent on data preparation  without good data  even the best machine learning algorithms cannot perform well  as a result  data centric ai practices are now becoming mainstream  unfortunately  many datasets in the real world are small  dirty  biased  and even poisoned  in this survey  we study the research landscape for data collection and data quality primarily for deep learning applications  data collection is important because there is lesser need for feature engineering for recent deep learning approaches  but instead more need for large amounts of data  for data quality  we study data validation  cleaning  and integration techniques  even if the data cannot be fully cleaned  we can still cope with imperfect data during model training using robust model training techniques  in addition  while bias and fairness have been less studied in traditional data management research  these issues become essential topics in modern machine learning applications  we thus study fairness measures and unfairness mitigation techniques that can be applied before  during  or after model training  we believe that the data management community is well poised to solve these problems ,10.366796,4.771196,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Value-Sensitive Software Design: Ethical Deliberation in Agile Development Processes,"This chapter discusses the integration of ethical deliberations within agile software development processes. It emphasizes the importance of considering ethical implications during the development of software, not just AI. The chapter proposes modes of reflection and deliberation that include disclosive, weighing, and applicative modes of contemplation. It argues that these three kinds of thinking are guided by different normative values. The chapter suggests that agile development is an excellent starting point for implementing ethical deliberations, as it allows for continuous reflection and learning. It also proposes that development teams can perform this task themselves up to a point with proper guidance. This section further discusses the potential of agile processes to naturally accommodate ethical deliberation. However, it also acknowledges the challenges associated with implementing agile processes, especially in the context of machine learning models.",this chapter discusses the integration of ethical deliberations within agile software development processes  it emphasizes the importance of considering ethical implications during the development of software  not just ai  the chapter proposes modes of reflection and deliberation that include disclosive  weighing  and applicative modes of contemplation  it argues that these three kinds of thinking are guided by different normative values  the chapter suggests that agile development is an excellent starting point for implementing ethical deliberations  as it allows for continuous reflection and learning  it also proposes that development teams can perform this task themselves up to a point with proper guidance  this section further discusses the potential of agile processes to naturally accommodate ethical deliberation  however  it also acknowledges the challenges associated with implementing agile processes  especially in the context of machine learning models ,9.893257,4.9866924,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
The Audience: Developers,The target audience of developers is of course one of the main differentiators of Developer Relations. Identifying the right target for your program and engaging developers throughout their journey is your challenge. Success requires you and your team to be experts in their field as well as having the knowledge and appreciation of developers.,the target audience of developers is of course one of the main differentiators of developer relations  identifying the right target for your program and engaging developers throughout their journey is your challenge  success requires you and your team to be experts in their field as well as having the knowledge and appreciation of developers ,10.065111,6.809559,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Essential Approaches to Dual-Track Agile: Results from a Grey Literature Review,"Context: Nowadays, companies are challenged by increasing market dynamics, rapid changes and disruptive participants entering the market. To survive in such an environment, companies must be able to quickly discover product ideas that meet the needs of both customers and the company and deliver these products to customers. Dual-track agile is a new type of agile development that combines product discovery and delivery activities in parallel, iterative, and cyclical ways. At present, many companies have difficulties in finding and establishing suitable approaches for implementing dual-track agile in their business context. Objective: In order to gain a better understanding of how product discovery and product delivery can interact with each other and how this interaction can be implemented in practice, this paper aims to identify suitable approaches to dual-track agile. Method: We conducted a grey literature review (GLR) according to the guidelines to Garousi et al. Results: Several approaches that support the integration of product discovery with product delivery were identified. This paper presents a selection of these approaches, i.e., the Discovery-Delivery Cycle model, Now-Next-Later Product Roadmaps, Lean Sprints, Product Kata, and Dual-Track Scrum. The approaches differ in their granularity but are similar in their underlying rationales. All approaches aim to ensure that only validated ideas turn into products and thus promise to lead to products that are better received by their users.
 Keywords
 Product management
 Dual-track agile
 UX design
 Product discovery
 Agile development
 Kata
 Software engineering
 Scrum",context  nowadays  companies are challenged by increasing market dynamics  rapid changes and disruptive participants entering the market  to survive in such an environment  companies must be able to quickly discover product ideas that meet the needs of both customers and the company and deliver these products to customers  dual track agile is a new type of agile development that combines product discovery and delivery activities in parallel  iterative  and cyclical ways  at present  many companies have difficulties in finding and establishing suitable approaches for implementing dual track agile in their business context  objective  in order to gain a better understanding of how product discovery and product delivery can interact with each other and how this interaction can be implemented in practice  this paper aims to identify suitable approaches to dual track agile  method  we conducted a grey literature review  glr  according to the guidelines to garousi et al  results  several approaches that support the integration of product discovery with product delivery were identified  this paper presents a selection of these approaches  i e   the discovery delivery cycle model  now next later product roadmaps  lean sprints  product kata  and dual track scrum  the approaches differ in their granularity but are similar in their underlying rationales  all approaches aim to ensure that only validated ideas turn into products and thus promise to lead to products that are better received by their users   keywords  product management  dual track agile  ux design  product discovery  agile development  kata  software engineering  scrum,9.4955015,4.999086,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Scale,"Playtime is over. The developer is now releasing a product of their own into their production environment. Your product was chosen to be part of this release, as the developer is confident that it solves their problem. Prelaunch, their focus is on optimizing, testing, and shipping. Post launch, their gears shift to operations and maintenance of that product. It may look like you are at the end of your journey with them, but your interactions now couldnâ€™t be more crucial to their success and yours.",playtime is over  the developer is now releasing a product of their own into their production environment  your product was chosen to be part of this release  as the developer is confident that it solves their problem  prelaunch  their focus is on optimizing  testing  and shipping  post launch  their gears shift to operations and maintenance of that product  it may look like you are at the end of your journey with them  but your interactions now couldn   t be more crucial to their success and yours ,10.384829,6.772604,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
"Machine Learning, Deep Learning and Neural Networks","This chapter presents the foundational knowledge required for understanding applications of machine learning, deep learning, neural networks and in general artificial intelligence to medicine. It introduces applications of the technologies as well as a levelheaded assessment of the potential for these technologies to benefit practitioners. It puts a medicine focused framework around the different artificial intelligence technologies and explains each in detail before providing insightful examples. The chapter then discusses challenges around deploying machine learning systems to production and using them in real life. Finally, the chapter addresses the risks and opportunities associated with the promise of artificial intelligence.
 Keywords
 Medical AI
 Medical artificial intelligence
 Healthcare AI
 Healthcare artificial intelligence
 AI in medicine
 Artificial intelligence
 Future of medicine
 Digital health",this chapter presents the foundational knowledge required for understanding applications of machine learning  deep learning  neural networks and in general artificial intelligence to medicine  it introduces applications of the technologies as well as a levelheaded assessment of the potential for these technologies to benefit practitioners  it puts a medicine focused framework around the different artificial intelligence technologies and explains each in detail before providing insightful examples  the chapter then discusses challenges around deploying machine learning systems to production and using them in real life  finally  the chapter addresses the risks and opportunities associated with the promise of artificial intelligence   keywords  medical ai  medical artificial intelligence  healthcare ai  healthcare artificial intelligence  ai in medicine  artificial intelligence  future of medicine  digital health,9.130887,5.4442554,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Why generative AI can make creative destruction more creative but less destructive,"The application of machine learning (ML) to operational data is becoming increasingly important with the rapid development of artificial intelligence (AI). We propose a model where incumbents have an initial advantage in ML technology and access to (historical) operational data. We show that the increased application of ML for operational data raises entrepreneurial barriers that make the creative destruction process less destructive (less business stealing) if entrepreneurs have only limited access to the incumbentâ€™s data. However, this situation induces entrepreneurs to take on more risk and to be more creative. Policies making data generally available may therefore be suboptimal. A complementary policy is one that supports entrepreneursâ€™ access to ML, such as open source initiatives, since doing so would stimulate creative entrepreneurship.",the application of machine learning  ml  to operational data is becoming increasingly important with the rapid development of artificial intelligence  ai   we propose a model where incumbents have an initial advantage in ml technology and access to  historical  operational data  we show that the increased application of ml for operational data raises entrepreneurial barriers that make the creative destruction process less destructive  less business stealing  if entrepreneurs have only limited access to the incumbent   s data  however  this situation induces entrepreneurs to take on more risk and to be more creative  policies making data generally available may therefore be suboptimal  a complementary policy is one that supports entrepreneurs    access to ml  such as open source initiatives  since doing so would stimulate creative entrepreneurship ,10.7379875,7.5869384,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
AI and Big Data in Tourism,"Classical definitions of Artificial Intelligence (AI) date back to the 1950s, all including the concept that AI can enable computers to accomplish intelligent tasks and activities, i.e., requiring human-level intelligence. Given the difficulties in defining human intelligence, a more operational definition refers to the abilities and capabilities AI aims to automatize: communication, in all forms and including all types of media (text, picture, audio); perception, which has attracted a considerable amount of attention with recent developments in new input/output devices (sensors, the Internet of Things); knowledge, making it storable, retrievable, and processable for a variety of applications; planning, as a backup for decision-making and responding (robotics, autonomous driving); and reasoning, simulating human thinking and learning processes. As all these are interconnected, so are the corresponding subfields of AI research: problem-solving, intelligent agents, natural language processing (NLP), speech recognition, computer vision, robotics, knowledge representation, and machine learning. Despite its ups and downs, the use of AI technologies and systems has become so widespread that discussions about their applications, performances, and impact are quotidian. As such, this chapter aims to discuss and explore why and how investing in AI and big data can be considerably beneficial for the tourism sector.
 Keywords
 Tourism and big data
 Artificial Intelligence
 Data Science
 Data value
 AI progress
 Machine learning",classical definitions of artificial intelligence  ai  date back to the     s  all including the concept that ai can enable computers to accomplish intelligent tasks and activities  i e   requiring human level intelligence  given the difficulties in defining human intelligence  a more operational definition refers to the abilities and capabilities ai aims to automatize  communication  in all forms and including all types of media  text  picture  audio   perception  which has attracted a considerable amount of attention with recent developments in new input output devices  sensors  the internet of things   knowledge  making it storable  retrievable  and processable for a variety of applications  planning  as a backup for decision making and responding  robotics  autonomous driving   and reasoning  simulating human thinking and learning processes  as all these are interconnected  so are the corresponding subfields of ai research  problem solving  intelligent agents  natural language processing  nlp   speech recognition  computer vision  robotics  knowledge representation  and machine learning  despite its ups and downs  the use of ai technologies and systems has become so widespread that discussions about their applications  performances  and impact are quotidian  as such  this chapter aims to discuss and explore why and how investing in ai and big data can be considerably beneficial for the tourism sector   keywords  tourism and big data  artificial intelligence  data science  data value  ai progress  machine learning,10.318626,7.8092117,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
OMRNet: A lightweight deep learning model for optical mark recognition,"Existing Optical Mark Recognition (OMR) systems tend to be expensive and rigid in their operation, often resulting in erroneous evaluations due to strict correction protocols. This scenario airs the need for a flexible OMR system. Hence, in this work, we propose a lightweight transfer learning based Convolutional Neural Network (CNN) model, dubbed as OMRNet, which can classify answer boxes on any generalized OMR test sheet. Unlike most existing techniques that rely on image processing algorithms to recognize extracted answer boxes in two classes: confirmed and empty, the OMRNet is designed to classify the answer boxes into confirmed, crossed-out, and empty categories. That is, OMRNet is facilitating the crossing out of previously answered questions and thus removing the rigidity of templates in Multiple Choice Question (MCQ) tests. We have built OMRNet on top of a MobileNetV2 backbone connected to four fully connected layers with appropriate dropouts and activation functions in between. We have evaluated OMRNet on the Multiple Choice Answer Boxes dataset available at https://sites.google.com/view/mcq-dataset. We have performed experiments following a 5 fold cross validation scheme, and OMRNet has achieved accuracies of 95.29%, 95.88%, 93.97%, 97.45%, and 97.20%, with an average accuracy of 95.96%. Also, the experimental results confirm that the present model performs better than the compared state-of-the-art methods and standard CNN models in terms of accuracy, execution time, and memory required to store the trained module. Moreover, we have employed a quantization technique to make the trained module more memory efficient and deployed it to a web app using our own Representational State Transfer Application Programming Interface (REST API). It makes OMRNet available via a Hypertext Transfer Protocol (HTTP) endpoint, allowing potential users to connect to it via the Internet. The source code for the work is available at the following link: https://github.com/sa-y-an/OMRNet.",existing optical mark recognition  omr  systems tend to be expensive and rigid in their operation  often resulting in erroneous evaluations due to strict correction protocols  this scenario airs the need for a flexible omr system  hence  in this work  we propose a lightweight transfer learning based convolutional neural network  cnn  model  dubbed as omrnet  which can classify answer boxes on any generalized omr test sheet  unlike most existing techniques that rely on image processing algorithms to recognize extracted answer boxes in two classes  confirmed and empty  the omrnet is designed to classify the answer boxes into confirmed  crossed out  and empty categories  that is  omrnet is facilitating the crossing out of previously answered questions and thus removing the rigidity of templates in multiple choice question  mcq  tests  we have built omrnet on top of a mobilenetv  backbone connected to four fully connected layers with appropriate dropouts and activation functions in between  we have evaluated omrnet on the multiple choice answer boxes dataset available at https   sites google com view mcq dataset  we have performed experiments following a   fold cross validation scheme  and omrnet has achieved accuracies of                                 and         with an average accuracy of         also  the experimental results confirm that the present model performs better than the compared state of the art methods and standard cnn models in terms of accuracy  execution time  and memory required to store the trained module  moreover  we have employed a quantization technique to make the trained module more memory efficient and deployed it to a web app using our own representational state transfer application programming interface  rest api   it makes omrnet available via a hypertext transfer protocol  http  endpoint  allowing potential users to connect to it via the internet  the source code for the work is available at the following link  https   github com sa y an omrnet ,3.9890609,6.6977754,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
A hyper-heuristic with two guidance indicators for bi-objective mixed-shift vehicle routing problem with time windows,"In this paper, a Mixed-Shift Vehicle Routing Problem is proposed based on a real-life container transportation problem. In a long planning horizon of multiple shifts, transport tasks are completed satisfying the time constraints. Due to the different travel distances and time of tasks, there are two types of shifts (long shift and short shift) in this problem. The unit driver cost for long shifts is higher than that of short shifts. A mathematical model of this Mixed-Shift Vehicle Routing Problem with Time Windows (MS-VRPTW) is established in this paper, with two objectives of minimizing the total driver payment and the total travel distance. Due to the large scale and nonlinear constraints, the exact search showed is not suitable to MS-VRPTW. An initial solution construction heuristic (EBIH) and a selective perturbation Hyper-Heuristic (GIHH) are thus developed. In GIHH, five heuristics with different extents of perturbation at the low level are adaptively selected by a high level selection scheme with the Hill Climbing acceptance criterion. Two guidance indicators are devised at the high level to adaptively adjust the selection of the low level heuristics for this bi-objective problem. The two indicators estimate the objective value improvement and the improvement direction over the Pareto Front, respectively. To evaluate the generality of the proposed algorithms, a set of benchmark instances with various features is extracted from real-life historical datasets. The experiment results show that GIHH significantly improves the quality of the final Pareto Solution Set, outperforming the state-of-the-art algorithms for similar problems. Its application on VRPTW also obtains promising results.",in this paper  a mixed shift vehicle routing problem is proposed based on a real life container transportation problem  in a long planning horizon of multiple shifts  transport tasks are completed satisfying the time constraints  due to the different travel distances and time of tasks  there are two types of shifts  long shift and short shift  in this problem  the unit driver cost for long shifts is higher than that of short shifts  a mathematical model of this mixed shift vehicle routing problem with time windows  ms vrptw  is established in this paper  with two objectives of minimizing the total driver payment and the total travel distance  due to the large scale and nonlinear constraints  the exact search showed is not suitable to ms vrptw  an initial solution construction heuristic  ebih  and a selective perturbation hyper heuristic  gihh  are thus developed  in gihh  five heuristics with different extents of perturbation at the low level are adaptively selected by a high level selection scheme with the hill climbing acceptance criterion  two guidance indicators are devised at the high level to adaptively adjust the selection of the low level heuristics for this bi objective problem  the two indicators estimate the objective value improvement and the improvement direction over the pareto front  respectively  to evaluate the generality of the proposed algorithms  a set of benchmark instances with various features is extracted from real life historical datasets  the experiment results show that gihh significantly improves the quality of the final pareto solution set  outperforming the state of the art algorithms for similar problems  its application on vrptw also obtains promising results ,3.1252086,7.9744296,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Cost Reduction of Inventory-Production-System in Multi-echelon Supply Chain Using Game Theory and Fuzzy Demand Forecasting,"Industry commitments include inventory planning and control, aiming to find the most appropriate purchasing and managing inventory policies by examining the conditions and costs. The Economic Order Quantity (EOQ) is a mathematical model for inventory control in manufacturing systems. As a result, they should be developed from several perspectives to effectively utilize classic models' findings. The current study employs an EOQ model that involves creating new demand and on-time and regulated production variables while considering market demand in two-sided markets. The cost of the inventory-production system in the multi-echelon Supply Chain (SC) was reduced Using game theory and fuzzy demand forecasting. The findings revealed that the level of inventory maturity control has a strong relationship with accurate forecasting of fuzzy demand. As a result, precise forecasting of the ambiguous demands related to increasing price elasticity inevitably lowers retailer performance in SC. As price elasticity rises in response to market demand, all retailers should take the required steps to avoid losing sales. This problem boosts retailers' net profits as well as the overall management system's profitability while also lowering inventory control costs.",industry commitments include inventory planning and control  aiming to find the most appropriate purchasing and managing inventory policies by examining the conditions and costs  the economic order quantity  eoq  is a mathematical model for inventory control in manufacturing systems  as a result  they should be developed from several perspectives to effectively utilize classic models  findings  the current study employs an eoq model that involves creating new demand and on time and regulated production variables while considering market demand in two sided markets  the cost of the inventory production system in the multi echelon supply chain  sc  was reduced using game theory and fuzzy demand forecasting  the findings revealed that the level of inventory maturity control has a strong relationship with accurate forecasting of fuzzy demand  as a result  precise forecasting of the ambiguous demands related to increasing price elasticity inevitably lowers retailer performance in sc  as price elasticity rises in response to market demand  all retailers should take the required steps to avoid losing sales  this problem boosts retailers  net profits as well as the overall management system s profitability while also lowering inventory control costs ,4.127814,1.5221795,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Online Product Localization: Challenges and Solutions in Global Online Marketplaces,"Intercultural interaction is riddled with challenges even during in-person encounters. When the physical playing field is removed, communication becomes all that more difficult, relying heavily on text and image. International ecommerce attempts to transcend this barrier, finding opportunity in online marketplaces. Without face-to-face interaction, localization efforts must be made in order to optimize the experience between virtual seller and buyer. With increased insight into the opportunity available for both buyer and seller in online marketplaces, the need to localize product feeds becomes apparent. As many international marketplaces exist today that facilitate the selling and buying of products across a multitude of verticals, studying how localization is currently implemented is useful to find areas of improvement based on theory that can be applied to a broad spectrum of product types and cultures. By detecting issues in looking at three of the largest, most successful online marketplaces, it can be inferred that there is a need for optimization on a larger scale. Determining best use of resources for these optimizations based on effort and impact is essential in answering the question of localization vs. standardization on a product level.
 Keywords
 Localization
 Standardization
 Online marketplaces
 Click-through rate
 High-context culture
 Low-context culture",intercultural interaction is riddled with challenges even during in person encounters  when the physical playing field is removed  communication becomes all that more difficult  relying heavily on text and image  international ecommerce attempts to transcend this barrier  finding opportunity in online marketplaces  without face to face interaction  localization efforts must be made in order to optimize the experience between virtual seller and buyer  with increased insight into the opportunity available for both buyer and seller in online marketplaces  the need to localize product feeds becomes apparent  as many international marketplaces exist today that facilitate the selling and buying of products across a multitude of verticals  studying how localization is currently implemented is useful to find areas of improvement based on theory that can be applied to a broad spectrum of product types and cultures  by detecting issues in looking at three of the largest  most successful online marketplaces  it can be inferred that there is a need for optimization on a larger scale  determining best use of resources for these optimizations based on effort and impact is essential in answering the question of localization vs  standardization on a product level   keywords  localization  standardization  online marketplaces  click through rate  high context culture  low context culture,9.822691,6.9523134,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Hybridising heuristics within an estimation distribution algorithm for examination timetabling,"This paper presents a hybrid hyper-heuristic approach based on estimation distribution algorithms. The main motivation is to raise the level of generality for search methodologies. The objective of the hyper-heuristic is to produce solutions of acceptable quality for a number of optimisation problems. In this work, we demonstrate the generality through experimental results for different variants of exam timetabling problems. The hyper-heuristic represents an automated constructive method that searches for heuristic choices from a given set of low-level heuristics based only on non-domain-specific knowledge. The high-level search methodology is based on a simple estimation distribution algorithm. It is capable of guiding the search to select appropriate heuristics in different problem solving situations. The probability distribution of low-level heuristics at different stages of solution construction can be used to measure their effectiveness and possibly help to facilitate more intelligent hyper-heuristic search methods.",this paper presents a hybrid hyper heuristic approach based on estimation distribution algorithms  the main motivation is to raise the level of generality for search methodologies  the objective of the hyper heuristic is to produce solutions of acceptable quality for a number of optimisation problems  in this work  we demonstrate the generality through experimental results for different variants of exam timetabling problems  the hyper heuristic represents an automated constructive method that searches for heuristic choices from a given set of low level heuristics based only on non domain specific knowledge  the high level search methodology is based on a simple estimation distribution algorithm  it is capable of guiding the search to select appropriate heuristics in different problem solving situations  the probability distribution of low level heuristics at different stages of solution construction can be used to measure their effectiveness and possibly help to facilitate more intelligent hyper heuristic search methods ,3.041923,8.291102,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
A triple-frequency cycle slip detection and correction method based on modified HMW combinations applied on GPS and BDS,"By taking advantage of the additional combined signals introduced by triple-frequency GNSS, we propose a cycle slip detection and correction method based on the traditional extra-wide-lane Hatchâ€“Melbourneâ€“WÃ¼bbena (HMW) combination and also modified HMW combinations. Instead of using the combined code signals directly in the traditional HMW combination, the modified HMW combination adopts the original code signals and one combined phase signal with corrected cycle slips to eliminate the ionospheric bias and reduce the effect of the noise induced by the code measurement. To determine the optimally combined signals and the corresponding coefficients in the modified HMW combination, four constrained conditions are proposed based on the maximum acceptable ionospheric bias and measurement noise of the combination in the process of cycle slip detection. Two optimally combined signals are selected; however, the second best signal cannot maintain a 100% success rate when epoch intervals are increased, due to the effect of the remaining ionospheric bias. To solve this problem, a scale factor is introduced to balance the corrected percentage of the ionospheric bias and the amplification of the measurement noise. These selected signals are further tested with real triple-frequency GPS and BDS observations. Results show that the proposed method can provide a 100% success rate in detecting cycle slips in the observations with large epoch intervals (up to 30 s) from medium earth orbit satellites with elevation angles above 5Â°, as well as inclined geosynchronous orbit and geostationary orbit satellites with elevation angles above 20Â°.",by taking advantage of the additional combined signals introduced by triple frequency gnss  we propose a cycle slip detection and correction method based on the traditional extra wide lane hatch   melbourne   w  bbena  hmw  combination and also modified hmw combinations  instead of using the combined code signals directly in the traditional hmw combination  the modified hmw combination adopts the original code signals and one combined phase signal with corrected cycle slips to eliminate the ionospheric bias and reduce the effect of the noise induced by the code measurement  to determine the optimally combined signals and the corresponding coefficients in the modified hmw combination  four constrained conditions are proposed based on the maximum acceptable ionospheric bias and measurement noise of the combination in the process of cycle slip detection  two optimally combined signals are selected  however  the second best signal cannot maintain a      success rate when epoch intervals are increased  due to the effect of the remaining ionospheric bias  to solve this problem  a scale factor is introduced to balance the corrected percentage of the ionospheric bias and the amplification of the measurement noise  these selected signals are further tested with real triple frequency gps and bds observations  results show that the proposed method can provide a      success rate in detecting cycle slips in the observations with large epoch intervals  up to    s  from medium earth orbit satellites with elevation angles above      as well as inclined geosynchronous orbit and geostationary orbit satellites with elevation angles above      ,3.9410582,2.5195754,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Hsa-mir-548 family expression in human reproductive tissues,"Background
 Hsa-miR-548ba expressed in ovarian granulosa cells targets PTEN and LIFR, which are essential for ovarian follicle activation and growth. The expression pattern of hsa-miR-548ba correlates with its host gene follicle-stimulating hormone receptor (FSHR), and FSH has a positive influence on hsa-miR-548ba expression. However, hsa-miR-548ba is a member of a large hsa-mir-548 family with potentially overlapping targets. The current study aims to investigate the co-expression of hsa-mir-548 family members in FSHR-positive reproductive tissues and to explore the potential co-regulation of pathways.
 Results
 For the above-described analysis, small RNA sequencing data from public data repositories were used. Sequencing results revealed that hsa-miR-548ba was expressed at the highest level in the ovarian granulosa cells and uterine myometrial samples together with another twelve and one hsa-miR-548 family members, respectively. Pathway enrichment analysis of microRNA targets in the ovarian samples revealed the hsa-miR-548ba and hsa-miR-548b-5p co-regulation of RAB geranylgeranylation in mural granulosa cells. Moreover, other hsa-mir-548 family members co-regulate pathways essential for ovarian functions (PIP3 activates AKT signalling and signalling by ERBB4). In addition to hsa-miR-548ba, hsa-miR-548o-3p is expressed in the myometrium, which separately targets the peroxisome proliferator-activated receptor alpha (PPARA) pathway.
 Conclusion
 This study reveals that hsa-mir-548 family members are expressed in variable combinations in the reproductive tract, where they potentially fulfil different regulatory roles. The results provide a reference for further studies of the hsa-mir-548 family role in the reproductive tract.",background  hsa mir    ba expressed in ovarian granulosa cells targets pten and lifr  which are essential for ovarian follicle activation and growth  the expression pattern of hsa mir    ba correlates with its host gene follicle stimulating hormone receptor  fshr   and fsh has a positive influence on hsa mir    ba expression  however  hsa mir    ba is a member of a large hsa mir     family with potentially overlapping targets  the current study aims to investigate the co expression of hsa mir     family members in fshr positive reproductive tissues and to explore the potential co regulation of pathways   results  for the above described analysis  small rna sequencing data from public data repositories were used  sequencing results revealed that hsa mir    ba was expressed at the highest level in the ovarian granulosa cells and uterine myometrial samples together with another twelve and one hsa mir     family members  respectively  pathway enrichment analysis of microrna targets in the ovarian samples revealed the hsa mir    ba and hsa mir    b  p co regulation of rab geranylgeranylation in mural granulosa cells  moreover  other hsa mir     family members co regulate pathways essential for ovarian functions  pip  activates akt signalling and signalling by erbb    in addition to hsa mir    ba  hsa mir    o  p is expressed in the myometrium  which separately targets the peroxisome proliferator activated receptor alpha  ppara  pathway   conclusion  this study reveals that hsa mir     family members are expressed in variable combinations in the reproductive tract  where they potentially fulfil different regulatory roles  the results provide a reference for further studies of the hsa mir     family role in the reproductive tract ,3.6701212,3.0209777,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Software Testing in the DevOps Context: A Systematic Mapping Study,"Abstract
 DevOps is a philosophy and framework that allows software development and operations teams to work in a coordinated manner, with the purpose of developing and releasing software quickly and cheaply. However, the effectiveness and benefits of DevOps depend on several factors, as reported in the literature. In particular, several studies have been published on software test automation, which is a cornerstone for the continuous integration phase in DevOps, which needs to be identified and classified. This study consolidates and classifies the existing literature on automated tests in the DevOps context. For the study, a systematic mapping study was performed to identify and classify papers on automated testing in DevOps based on 8 research questions. In the query of 6 relevant databases, 3,312 were obtained; and then, after the selection process, 299 papers were selected as primary studies. Researchers maintain a continuing and growing interest in software testing in the DevOps context. Most of the research (71.2%) is carried out in the industry and is done on web applications and SOA. The most reported types of tests are unit and integration tests.",abstract  devops is a philosophy and framework that allows software development and operations teams to work in a coordinated manner  with the purpose of developing and releasing software quickly and cheaply  however  the effectiveness and benefits of devops depend on several factors  as reported in the literature  in particular  several studies have been published on software test automation  which is a cornerstone for the continuous integration phase in devops  which needs to be identified and classified  this study consolidates and classifies the existing literature on automated tests in the devops context  for the study  a systematic mapping study was performed to identify and classify papers on automated testing in devops based on   research questions  in the query of   relevant databases        were obtained  and then  after the selection process      papers were selected as primary studies  researchers maintain a continuing and growing interest in software testing in the devops context  most of the research         is carried out in the industry and is done on web applications and soa  the most reported types of tests are unit and integration tests ,9.584179,4.5205135,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Organic Foreign Bodies,"Orbital organic foreign bodies are often seen following trauma which may need emergent attention. Clinical presentation largely depends on severity of impact and type of foreign body. Assessment of general physical condition should be foremost as most of such injuries can be life threatening. Appropriate imaging plays important role in localizing and identifying nature of foreign body. Overall, surgical removal is indicated in all organic foreign bodies.
 Keywords
 Organic
 Foreign bodies
 Vegetative material
 Wood
 Discharging fistula",orbital organic foreign bodies are often seen following trauma which may need emergent attention  clinical presentation largely depends on severity of impact and type of foreign body  assessment of general physical condition should be foremost as most of such injuries can be life threatening  appropriate imaging plays important role in localizing and identifying nature of foreign body  overall  surgical removal is indicated in all organic foreign bodies   keywords  organic  foreign bodies  vegetative material  wood  discharging fistula,4.9265895,2.06372,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Inorganic Foreign Bodies,"Orbital trauma can be the cause of significant morbidity and may vary from trivial trauma at workplace to catastrophic gunshots and explosions. The size, composition and velocity of the object inflicting trauma, the direction and the point of impact affect the severity and type of injury. The effect of retention of inorganic foreign bodies in the orbit appears to be much less dramatic than organic materials, and most metals except copper remain inert for long periods without warranting removal.
 Keywords
 Inorganic
 Foreign body
 Metallic
 Non-metallic
 Copper",orbital trauma can be the cause of significant morbidity and may vary from trivial trauma at workplace to catastrophic gunshots and explosions  the size  composition and velocity of the object inflicting trauma  the direction and the point of impact affect the severity and type of injury  the effect of retention of inorganic foreign bodies in the orbit appears to be much less dramatic than organic materials  and most metals except copper remain inert for long periods without warranting removal   keywords  inorganic  foreign body  metallic  non metallic  copper,4.701625,1.8138471,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Looking Forward,"It is a characteristic of excellent AI line managers and project managers to direct world-class data scientists to build AI solutions that match the companyâ€™s strategic business goals. The challenge is not having ideas on how AI could change the world. The challenge is to build practical, helpful AI solutions delivering concrete benefits and, afterward, running these AI solutions over the years.",it is a characteristic of excellent ai line managers and project managers to direct world class data scientists to build ai solutions that match the company   s strategic business goals  the challenge is not having ideas on how ai could change the world  the challenge is to build practical  helpful ai solutions delivering concrete benefits and  afterward  running these ai solutions over the years ,11.135868,7.0514054,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Management of atherogenic dyslipidemia according to current treatment guidelines: DESPEGA study in real clinical practice,"Background
 Studies in patients with dyslipidemia have revealed that, despite guideline recommendations, treatment remains unchanged even when therapeutic goals are not achieved.
 Objective
 Our objective was to determine the degree to which primary care (PC) and specialty care (SC) physicians adhere to clinical guidelines for the management of atherogenic dyslipidemia (AD).
 Methods
 This was an observational, descriptive, cross-sectional study. Physicians working in the Spanish Health System completed an electronic questionnaire comprising 24 items organized into three blocks: clinical guidelines, adherence to clinical guidelines, and other issues in the management of AD. The questions were formulated with closed polytomous or categorized responses. Adherence to guidelines, in terms of treatment, was assessed according to physiciansâ€™ responses to six patient profiles. Absolute and relative frequencies (qualitative variables), central tendency and dispersion (quantitative variables) were calculated.
 Results
 In total, 980 physicians (88.5% PC) participated in the study; 77.3% used guidelines in their routine clinical practice, with the most used being the Spanish SEMERGEN (73.8%) and the European Society of Cardiology/European Atherosclerosis Society guidelines (41.2%). A total of 83% adhered to guideline recommendations in more than four of the six profiles proposed, 26.2% adhered to the SEMERGEN definition of AD, 66.6% combined all lipoprotein ratios to diagnose AD, andâ€‰>â€‰60% used non-high-density lipoprotein cholesterol (HDL-C) to diagnose patients with AD at high cardiovascular risk. In total, 99.0% prescribed a fibrate to reduce triglyceride levels, 47.4% to increase HDL-C levels and 40.2% to reduce small, dense low-density lipoprotein cholesterol particles.
 Conclusion
 Since adherence to clinical guidelines improves both the quality of care and health outcomes, greater adherence to and satisfaction with clinical guidelines for the management of AD may contribute to improvements in and optimization of the management of patients with AD in the Spanish health system.",background  studies in patients with dyslipidemia have revealed that  despite guideline recommendations  treatment remains unchanged even when therapeutic goals are not achieved   objective  our objective was to determine the degree to which primary care  pc  and specialty care  sc  physicians adhere to clinical guidelines for the management of atherogenic dyslipidemia  ad    methods  this was an observational  descriptive  cross sectional study  physicians working in the spanish health system completed an electronic questionnaire comprising    items organized into three blocks  clinical guidelines  adherence to clinical guidelines  and other issues in the management of ad  the questions were formulated with closed polytomous or categorized responses  adherence to guidelines  in terms of treatment  was assessed according to physicians    responses to six patient profiles  absolute and relative frequencies  qualitative variables   central tendency and dispersion  quantitative variables  were calculated   results  in total      physicians        pc  participated in the study        used guidelines in their routine clinical practice  with the most used being the spanish semergen         and the european society of cardiology european atherosclerosis society guidelines          a total of     adhered to guideline recommendations in more than four of the six profiles proposed        adhered to the semergen definition of ad        combined all lipoprotein ratios to diagnose ad  and           used non high density lipoprotein cholesterol  hdl c  to diagnose patients with ad at high cardiovascular risk  in total        prescribed a fibrate to reduce triglyceride levels        to increase hdl c levels and       to reduce small  dense low density lipoprotein cholesterol particles   conclusion  since adherence to clinical guidelines improves both the quality of care and health outcomes  greater adherence to and satisfaction with clinical guidelines for the management of ad may contribute to improvements in and optimization of the management of patients with ad in the spanish health system ,4.7944636,2.8506217,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Acute Presentation of Vascular Lesions in the Orbit,"Orbital vascular disease can present acutely and, if untreated, may lead to raised orbital pressure, reduced arterial perfusion and consequent loss of visual function. Although haemorrhage is the commonest orbital vascular event, acute presentation of arteriovenous shunts and rarely intraorbital vascular occlusions can also occur. In most cases, the probable aetiology can be deduced from the clinical history and examination, and after appropriate imaging, the patient can safely be monitored for progression. High pressure at the orbital apex can, however, result in ischaemic optic neuropathy, and any evidence for progression or persistence of severe visual impairment should prompt urgent intervention.
 Keywords
 Arteriovenous anomaly
 Haemangioma
 Haemorrhage
 Lymphangioma
 Orbit
 Varix
 Vascular
 Shunt",orbital vascular disease can present acutely and  if untreated  may lead to raised orbital pressure  reduced arterial perfusion and consequent loss of visual function  although haemorrhage is the commonest orbital vascular event  acute presentation of arteriovenous shunts and rarely intraorbital vascular occlusions can also occur  in most cases  the probable aetiology can be deduced from the clinical history and examination  and after appropriate imaging  the patient can safely be monitored for progression  high pressure at the orbital apex can  however  result in ischaemic optic neuropathy  and any evidence for progression or persistence of severe visual impairment should prompt urgent intervention   keywords  arteriovenous anomaly  haemangioma  haemorrhage  lymphangioma  orbit  varix  vascular  shunt,5.1808853,2.0416424,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Mapillary Planet-Scale Depth Dataset,"Learning-based methods produce remarkable results on single image depth tasks when trained on well-established benchmarks, however, there is a large gap from these benchmarks to real-world performance that is usually obscured by the common practice of fine-tuning on the target dataset. We introduce a new depth dataset that is an order of magnitude larger than previous datasets, but more importantly, contains an unprecedented gamut of locations, camera models and scene types while offering metric depth (not just up-to-scale). Additionally, we investigate the problem of training single image depth networks using images captured with many different cameras, validating an existing approach and proposing a simpler alternative. With our contributions we achieve excellent results on challenging benchmarks before fine-tuning, and set the state of the art on the popular KITTI dataset after fine-tuning.
 The dataset is available at mapillary.com/dataset/depth.",learning based methods produce remarkable results on single image depth tasks when trained on well established benchmarks  however  there is a large gap from these benchmarks to real world performance that is usually obscured by the common practice of fine tuning on the target dataset  we introduce a new depth dataset that is an order of magnitude larger than previous datasets  but more importantly  contains an unprecedented gamut of locations  camera models and scene types while offering metric depth  not just up to scale   additionally  we investigate the problem of training single image depth networks using images captured with many different cameras  validating an existing approach and proposing a simpler alternative  with our contributions we achieve excellent results on challenging benchmarks before fine tuning  and set the state of the art on the popular kitti dataset after fine tuning   the dataset is available at mapillary com dataset depth ,4.0152965,7.0055785,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
"Ergo, SMIRK is safe: a safety case for a machine learning component in a pedestrian automatic emergency brake system","Integration of machine learning (ML) components in critical applications introduces novel challenges for software certification and verification. New safety standards and technical guidelines are under development to support the safety of ML-based systems, e.g., ISO 21448 SOTIF for the automotive domain and the Assurance of Machine Learning for use in Autonomous Systems (AMLAS) framework. SOTIF and AMLAS provide high-level guidance but the details must be chiseled out for each specific case. We initiated a research project with the goal to demonstrate a complete safety case for an ML component in an open automotive system. This paper reports results from an industry-academia collaboration on safety assurance of SMIRK, an ML-based pedestrian automatic emergency braking demonstrator running in an industry-grade simulator. We demonstrate an application of AMLAS on SMIRK for a minimalistic operational design domain, i.e., we share a complete safety case for its integrated ML-based component. Finally, we report lessons learned and provide both SMIRK and the safety case under an open-source license for the research community to reuse.",integration of machine learning  ml  components in critical applications introduces novel challenges for software certification and verification  new safety standards and technical guidelines are under development to support the safety of ml based systems  e g   iso       sotif for the automotive domain and the assurance of machine learning for use in autonomous systems  amlas  framework  sotif and amlas provide high level guidance but the details must be chiseled out for each specific case  we initiated a research project with the goal to demonstrate a complete safety case for an ml component in an open automotive system  this paper reports results from an industry academia collaboration on safety assurance of smirk  an ml based pedestrian automatic emergency braking demonstrator running in an industry grade simulator  we demonstrate an application of amlas on smirk for a minimalistic operational design domain  i e   we share a complete safety case for its integrated ml based component  finally  we report lessons learned and provide both smirk and the safety case under an open source license for the research community to reuse ,8.317866,5.635933,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Statistical Techniques and Concepts in Data Science,"The prominent role that data science plays in technology today has created a need for all professions to possess a strong fundamental working knowledge of the math used in statistical techniques. The â€œdata scientistâ€ today may be a transitioning database professionals, data/Big Data engineers, software engineer, IT auditor, fraud investigator, or even a business analyst. Often, a project team would be comprised of all these professionals that have been brought together to solve a business problem, optimize a process, or create predictive models based on data-driven techniques. It is thus imperative that all members of the team have some idea of the statistical techniques and concepts used in data science.",the prominent role that data science plays in technology today has created a need for all professions to possess a strong fundamental working knowledge of the math used in statistical techniques  the    data scientist    today may be a transitioning database professionals  data big data engineers  software engineer  it auditor  fraud investigator  or even a business analyst  often  a project team would be comprised of all these professionals that have been brought together to solve a business problem  optimize a process  or create predictive models based on data driven techniques  it is thus imperative that all members of the team have some idea of the statistical techniques and concepts used in data science ,9.143145,6.059187,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
SoftNER: Mining knowledge graphs from cloud incidents,"The move from boxed products to services and the widespread adoption of cloud computing has had a huge impact on the software development life cycle and DevOps processes. Particularly, incident management has become critical for developing and operating large-scale services. Prior work on incident management has heavily focused on the challenges with incident triaging and de-duplication. In this work, we address the fundamental problem of structured knowledge extraction from service incidents. We have built SoftNER, a framework for mining Knowledge Graphs from incident reports. First, we build a novel multi-task learning based BiLSTM-CRF model which leverages not just the semantic context but also the data-types for extracting factual information in the form of named entities. Next, we present an approach to mine relations between the named entities for automatically constructing knowledge graphs. We have deployed SoftNER at Microsoft, a major cloud service provider and have evaluated it on more than 2 months of cloud incidents. We show that SoftNERâ€™s unsupervised pipeline learns the software entity types from unstructured incident data with high precision of 0.96 (at rank 50) and 0.77 (at rank 100). We also evaluate and show that SoftNERâ€™s unsupervised pipeline accurately labels data with a precision of 0.94. Further, our multi-task learning based deep learning model also outperforms the state-of-the-art NER models with an average F1 of 0.96. Lastly, using the knowledge extracted by SoftNER, we are able to build accurate models for tasks such as incident triaging and recommending entities based on their relevance to incident titles.",the move from boxed products to services and the widespread adoption of cloud computing has had a huge impact on the software development life cycle and devops processes  particularly  incident management has become critical for developing and operating large scale services  prior work on incident management has heavily focused on the challenges with incident triaging and de duplication  in this work  we address the fundamental problem of structured knowledge extraction from service incidents  we have built softner  a framework for mining knowledge graphs from incident reports  first  we build a novel multi task learning based bilstm crf model which leverages not just the semantic context but also the data types for extracting factual information in the form of named entities  next  we present an approach to mine relations between the named entities for automatically constructing knowledge graphs  we have deployed softner at microsoft  a major cloud service provider and have evaluated it on more than   months of cloud incidents  we show that softner   s unsupervised pipeline learns the software entity types from unstructured incident data with high precision of       at rank     and       at rank       we also evaluate and show that softner   s unsupervised pipeline accurately labels data with a precision of       further  our multi task learning based deep learning model also outperforms the state of the art ner models with an average f  of       lastly  using the knowledge extracted by softner  we are able to build accurate models for tasks such as incident triaging and recommending entities based on their relevance to incident titles ,6.491255,7.178209,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
"Apache Spark, Big Data, and Azure Databricks","The exponential pace of innovation in artificial intelligence in recent years can be attributed to advancements in machine learning. In turn, the advancements in machine learning are based on two core developments â€“ availability of data and ubiquitous access to unparalleled compute capabilities.",the exponential pace of innovation in artificial intelligence in recent years can be attributed to advancements in machine learning  in turn  the advancements in machine learning are based on two core developments     availability of data and ubiquitous access to unparalleled compute capabilities ,9.802674,7.813991,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
"Scheduling offshore cargo handling with operational dynamics including cost composites, downtime periods, and cargo attributes","An efficient cargo logistics service for vessels anchored offshore becomes imperative to meet the increasing demand of transporting dry bulk cargoes and overcome insufficient infrastructural resources of ports. Offshore cargo handling service providers propose a fleet of offshore floating terminals (OFTs) performing the cargo handling service directly nearby anchorages at sea. This approach reduces the time and the usage of resources compared with relying on ports. In this paper, we develop a scheduling mathematical model for the fleet of OFTs to improve the operating efficiency in serving cargo vessels and their barges. This study proposes the model with various objective functions that can be used for a service provider depending on its goals and customer satisfaction policies. This study introduces real-world considerations inspired by an offshore service provider in Singapore and addresses complicated combinations of practical requirement owing to cargo/vessel/operation attributes, maintenance periods, and operating cost components in development of an optimization model via mixed-integer linear programming. An efficient genetic algorithm is also developed to solve the model with finding near-optimal effective solutions. Through examining a large set of real data provided by the service provider, the proposed genetic algorithm shows a high effectiveness in terms of solution quality and computational time.",an efficient cargo logistics service for vessels anchored offshore becomes imperative to meet the increasing demand of transporting dry bulk cargoes and overcome insufficient infrastructural resources of ports  offshore cargo handling service providers propose a fleet of offshore floating terminals  ofts  performing the cargo handling service directly nearby anchorages at sea  this approach reduces the time and the usage of resources compared with relying on ports  in this paper  we develop a scheduling mathematical model for the fleet of ofts to improve the operating efficiency in serving cargo vessels and their barges  this study proposes the model with various objective functions that can be used for a service provider depending on its goals and customer satisfaction policies  this study introduces real world considerations inspired by an offshore service provider in singapore and addresses complicated combinations of practical requirement owing to cargo vessel operation attributes  maintenance periods  and operating cost components in development of an optimization model via mixed integer linear programming  an efficient genetic algorithm is also developed to solve the model with finding near optimal effective solutions  through examining a large set of real data provided by the service provider  the proposed genetic algorithm shows a high effectiveness in terms of solution quality and computational time ,6.8730063,7.7271214,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
FLORAS: urban flash-flood prediction using a multivariate model,"Hydrological models allow water levels to be predicted at critical spots when the problem of flooding is being addressed. However, these models fall short in their attempts to provide timely warnings to communities at risk as they often involve complex setup requirements and incur high computation costs. Other approaches have been adopted that make use of water level monitoring sensors for detecting floods. Although accurate in their performance, these approaches often require a high level of maintenance because their predictions rely on critical readings from sensors that have to be immersed in rivers. We recommend a machine learning-based methodology for flood detection to address this issue, called FLORAS. It makes it possible to build models that make predictions solely on the basis of meteorological data from weather stations-water height measurements are only needed to employ ground truth for the purposes of training and validation. We evaluated the methodology with current data readings from SÃ£o Carlos (SP - Brazil) in experimental analyses. Water height measurements from sensors placed at sites along the river were correlated with open weather data from a reputable, local source (Climatempo â€“ Brazilian weather). The results show that the model achieved a higher degree of of accuracy and incurred lower computational costs than SwMM, a hydrological model. These results show that the recommended methodology is suitable for systems that run with resource-scarce devices, such as the IoT systems that are usually deployed in flood detection frameworks.",hydrological models allow water levels to be predicted at critical spots when the problem of flooding is being addressed  however  these models fall short in their attempts to provide timely warnings to communities at risk as they often involve complex setup requirements and incur high computation costs  other approaches have been adopted that make use of water level monitoring sensors for detecting floods  although accurate in their performance  these approaches often require a high level of maintenance because their predictions rely on critical readings from sensors that have to be immersed in rivers  we recommend a machine learning based methodology for flood detection to address this issue  called floras  it makes it possible to build models that make predictions solely on the basis of meteorological data from weather stations water height measurements are only needed to employ ground truth for the purposes of training and validation  we evaluated the methodology with current data readings from s  o carlos  sp   brazil  in experimental analyses  water height measurements from sensors placed at sites along the river were correlated with open weather data from a reputable  local source  climatempo     brazilian weather   the results show that the model achieved a higher degree of of accuracy and incurred lower computational costs than swmm  a hydrological model  these results show that the recommended methodology is suitable for systems that run with resource scarce devices  such as the iot systems that are usually deployed in flood detection frameworks ,4.859249,5.202094,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
Data Science in the Modern Enterprise,"Data science is the hottest trend in IT, and it is not showing signs of cooling down anytime soon. It is often used as a catchall phrase for all latest innovation, such as machine learning (ML), artificial intelligence (AI), and Internet of Things (IoT). This is not an inaccurate representation since data science is after all the foundation for ML, AI, and IoT.",data science is the hottest trend in it  and it is not showing signs of cooling down anytime soon  it is often used as a catchall phrase for all latest innovation  such as machine learning  ml   artificial intelligence  ai   and internet of things  iot   this is not an inaccurate representation since data science is after all the foundation for ml  ai  and iot ,8.837175,6.280711,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Data Preparation and Data Engineering Basics,"There is a common saying that the bulk of the work involved with data science is in data preparation. In fact, data preparation is a crucial part of the process, which, if not done correctly, would yield inaccurate results and may lead to negative consequences. That is why so much time is being spent on data preparation. If we want to make the data science process more efficient, shaving off the amount of time spent on data preparation is one area for us to look at.",there is a common saying that the bulk of the work involved with data science is in data preparation  in fact  data preparation is a crucial part of the process  which  if not done correctly  would yield inaccurate results and may lead to negative consequences  that is why so much time is being spent on data preparation  if we want to make the data science process more efficient  shaving off the amount of time spent on data preparation is one area for us to look at ,9.2041,6.3458705,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Optimized glycemic control of type 2 diabetes with reinforcement learning: a proof-of-concept trial,"The personalized titration and optimization of insulin regimens for treatment of type 2 diabetes (T2D) are resource-demanding healthcare tasks. Here we propose a model-based reinforcement learning (RL) framework (called RL-DITR), which learns the optimal insulin regimen by analyzing glycemic state rewards through patient model interactions. When evaluated during the development phase for managing hospitalized patients with T2D, RL-DITR achieved superior insulin titration optimization (mean absolute error (MAE) of 1.10â€‰Â±â€‰0.03â€‰U) compared to other deep learning models and standard clinical methods. We performed a stepwise clinical validation of the artificial intelligence system from simulation to deployment, demonstrating better performance in glycemic control in inpatients compared to junior and intermediate-level physicians through quantitative (MAE of 1.18â€‰Â±â€‰0.09â€‰U) and qualitative metrics from a blinded review. Additionally, we conducted a single-arm, patient-blinded, proof-of-concept feasibility trial in 16 patients with T2D. The primary outcome was difference in mean daily capillary blood glucose during the trial, which decreased from 11.1 (Â±3.6) to 8.6 (Â±2.4) mmolâ€‰Lâˆ’1 (Pâ€‰<â€‰0.01), meeting the pre-specified endpoint. No episodes of severe hypoglycemia or hyperglycemia with ketosis occurred. These preliminary results warrant further investigation in larger, more diverse clinical studies. ClinicalTrials.gov registration: NCT05409391.",the personalized titration and optimization of insulin regimens for treatment of type   diabetes  t d  are resource demanding healthcare tasks  here we propose a model based reinforcement learning  rl  framework  called rl ditr   which learns the optimal insulin regimen by analyzing glycemic state rewards through patient model interactions  when evaluated during the development phase for managing hospitalized patients with t d  rl ditr achieved superior insulin titration optimization  mean absolute error  mae  of                    u  compared to other deep learning models and standard clinical methods  we performed a stepwise clinical validation of the artificial intelligence system from simulation to deployment  demonstrating better performance in glycemic control in inpatients compared to junior and intermediate level physicians through quantitative  mae of                    u  and qualitative metrics from a blinded review  additionally  we conducted a single arm  patient blinded  proof of concept feasibility trial in    patients with t d  the primary outcome was difference in mean daily capillary blood glucose during the trial  which decreased from              to             mmol   l      p              meeting the pre specified endpoint  no episodes of severe hypoglycemia or hyperglycemia with ketosis occurred  these preliminary results warrant further investigation in larger  more diverse clinical studies  clinicaltrials gov registration  nct         ,4.7968245,2.7586684,4,Machine Learning - Deep Learning - Predictive Analytics - Healthcare - Diagnostics - Data Analysis,Advances in Predictive and Diagnostic Techniques
Deep Reinforcement Learning for the Capacitated Pickup and Delivery Problem with Time Windows,"Abstract
 The vehicle routing problem with pickup and delivery is one of the most important problems in the context of global urban population growth. Although these kinds of small-size problems can be solved using various classical approaches, a fast (or real-time) route optimizer under real-world constraints (such as throughput and time window constraints) for medium- and large-size problems is still a challenge. In this work, we first successfully applied a deep reinforcement learning approach (a modified JAMPR model) to solve the capacitated pickup and delivery problem with time windows (CPDPTW). We obtained a robust model that gives a fast optimal solution for small- to medium-size problems and gives a fast suboptimal solution for large-size (>200) problems.",abstract  the vehicle routing problem with pickup and delivery is one of the most important problems in the context of global urban population growth  although these kinds of small size problems can be solved using various classical approaches  a fast  or real time  route optimizer under real world constraints  such as throughput and time window constraints  for medium  and large size problems is still a challenge  in this work  we first successfully applied a deep reinforcement learning approach  a modified jampr model  to solve the capacitated pickup and delivery problem with time windows  cpdptw   we obtained a robust model that gives a fast optimal solution for small  to medium size problems and gives a fast suboptimal solution for large size        problems ,2.9509811,7.970394,5,MLOps - Model Optimization - Reinforcement Learning - Quantum Algorithms - Neural Networks - Privacy-Preserving Techniques,Advanced Machine Learning Frameworks and Applications
On the performance of SQL scalable systems on Kubernetes: a comparative study,"The popularization of Hadoop as the the-facto standard platform for data analytics in the context of Big Data applications has led to the upsurge of SQL-on-Hadoop systems, which provide scalable query execution engines allowing the use of SQL queries on data stored in HDFS. In this context, Kubernetes appears as the leading choice to simplify the deployment and scaling of containerized applications; however, there is a lack of studies about the performance of SQL-on-Hadoop systems deployed on Kubernetes, and this is the gap we intend to fill in this paper. We present an experimental study involving four representative SQL scalable platforms: Apache Drill, Apache Hive, Apache Spark SQL and Trino. Concretely, we analyze the performance of these systems when they are deployed on a Hadoop cluster with Kubernetes by using the TPC-H benchmark. The results of our study can help practitioners and users about what they can expect in terms of performance if they plan to use the advantages of Kubernetes to deploy applications using the analyzed SQL scalable platforms.",the popularization of hadoop as the the facto standard platform for data analytics in the context of big data applications has led to the upsurge of sql on hadoop systems  which provide scalable query execution engines allowing the use of sql queries on data stored in hdfs  in this context  kubernetes appears as the leading choice to simplify the deployment and scaling of containerized applications  however  there is a lack of studies about the performance of sql on hadoop systems deployed on kubernetes  and this is the gap we intend to fill in this paper  we present an experimental study involving four representative sql scalable platforms  apache drill  apache hive  apache spark sql and trino  concretely  we analyze the performance of these systems when they are deployed on a hadoop cluster with kubernetes by using the tpc h benchmark  the results of our study can help practitioners and users about what they can expect in terms of performance if they plan to use the advantages of kubernetes to deploy applications using the analyzed sql scalable platforms ,8.512602,7.7682834,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Operationalising AI ethics: how are companies bridging the gap between practice and principles? An exploratory study,"Despite the increase in the research field of ethics in artificial intelligence, most efforts have focused on the debate about principles and guidelines for responsible AI, but not enough attention has been given to the â€œhowâ€ of applied ethics. This paper aims to advance the research exploring the gap between practice and principles in AI ethics by identifying how companies are applying those guidelines and principles in practice. Through a qualitative methodology based on 22 semi-structured interviews and two focus groups, the goal of the current study is to understand how companies approach ethical issues related to AI systems. A structured analysis of the transcripts brought out many actual practices and findings, which are presented around the following main research topics: ethics and principles, privacy, explainability, and fairness. The interviewees also raised issues of accountability and governance. Finally, some recommendations are suggested such as developing specific sector regulations, fostering a data-driven organisational culture, considering the algorithmâ€™s complete life cycle, developing and using a specific code of ethics, and providing specific training on ethical issues. Despite some obvious limitations, such as the type and number of companies interviewed, this work identifies real examples and direct priorities to advance the research exploring the gap between practice and principles in AI ethics, with a specific focus on Spanish companies.",despite the increase in the research field of ethics in artificial intelligence  most efforts have focused on the debate about principles and guidelines for responsible ai  but not enough attention has been given to the    how    of applied ethics  this paper aims to advance the research exploring the gap between practice and principles in ai ethics by identifying how companies are applying those guidelines and principles in practice  through a qualitative methodology based on    semi structured interviews and two focus groups  the goal of the current study is to understand how companies approach ethical issues related to ai systems  a structured analysis of the transcripts brought out many actual practices and findings  which are presented around the following main research topics  ethics and principles  privacy  explainability  and fairness  the interviewees also raised issues of accountability and governance  finally  some recommendations are suggested such as developing specific sector regulations  fostering a data driven organisational culture  considering the algorithm   s complete life cycle  developing and using a specific code of ethics  and providing specific training on ethical issues  despite some obvious limitations  such as the type and number of companies interviewed  this work identifies real examples and direct priorities to advance the research exploring the gap between practice and principles in ai ethics  with a specific focus on spanish companies ,10.874109,7.011011,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
"Machine Learning Operations (MLOps): Overview, Definition, and Architecture","The final goal of all industrial machine learning (ML) projects is to develop ML products and rapidly bring them into production. However, it is highly challenging to automate and operationalize ML products and thus many ML endeavors fail to deliver on their expectations. The paradigm of Machine Learning Operations (MLOps) addresses this issue. MLOps includes several aspects, such as best practices, sets of concepts, and development culture. However, MLOps is still a vague term and its consequences for researchers and professionals are ambiguous. To address this gap, we conduct mixed-method research, including a literature review, a tool review, and expert interviews. As a result of these investigations, we contribute to the body of knowledge by providing an aggregated overview of the necessary principles, components, and roles, as well as the associated architecture and workflows. Furthermore, we provide a comprehensive definition of MLOps and highlight open challenges in the field. Finally, this work provides guidance for ML researchers and practitioners who want to automate and operate their ML products with a designated set of technologies.",the final goal of all industrial machine learning  ml  projects is to develop ml products and rapidly bring them into production  however  it is highly challenging to automate and operationalize ml products and thus many ml endeavors fail to deliver on their expectations  the paradigm of machine learning operations  mlops  addresses this issue  mlops includes several aspects  such as best practices  sets of concepts  and development culture  however  mlops is still a vague term and its consequences for researchers and professionals are ambiguous  to address this gap  we conduct mixed method research  including a literature review  a tool review  and expert interviews  as a result of these investigations  we contribute to the body of knowledge by providing an aggregated overview of the necessary principles  components  and roles  as well as the associated architecture and workflows  furthermore  we provide a comprehensive definition of mlops and highlight open challenges in the field  finally  this work provides guidance for ml researchers and practitioners who want to automate and operate their ml products with a designated set of technologies ,8.873193,5.270719,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
From DevOps to MLOps: Overview and Application to Electricity Market Forecasting,"In the Software Development Life Cycle (SDLC), Development and Operations (DevOps) has been proven to deliver reliable, scalable software within a shorter time. Due to the explosion of Machine Learning (ML) applications, the term Machine Learning Operations (MLOps) has gained significant interest among ML practitioners. This paper explains the DevOps and MLOps processes relevant to the implementation of MLOps. The contribution of this paper towards the MLOps framework is threefold: First, we review the state of the art in MLOps by analyzing the related work in MLOps. Second, we present an overview of the leading DevOps principles relevant to MLOps. Third, we derive an MLOps framework from the MLOps theory and apply it to a time-series forecasting application in the hourly day-ahead electricity market. The paper concludes with how MLOps could be generalized and applied to two more use cases with minor changes.",in the software development life cycle  sdlc   development and operations  devops  has been proven to deliver reliable  scalable software within a shorter time  due to the explosion of machine learning  ml  applications  the term machine learning operations  mlops  has gained significant interest among ml practitioners  this paper explains the devops and mlops processes relevant to the implementation of mlops  the contribution of this paper towards the mlops framework is threefold  first  we review the state of the art in mlops by analyzing the related work in mlops  second  we present an overview of the leading devops principles relevant to mlops  third  we derive an mlops framework from the mlops theory and apply it to a time series forecasting application in the hourly day ahead electricity market  the paper concludes with how mlops could be generalized and applied to two more use cases with minor changes ,8.864348,4.8876257,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Role of Regulatory Sandboxes and MLOps for AI-Enabled Public Sector Services,"This paper discusses how innovations in public sector AI-based services must comply with the Artificial Intelligence Act (AI Act) regulatory frameworks while enabling experimentation and participation of diverse stakeholders throughout the Artificial Intelligence (AI) lifecycle. The paper examines the implications of the emerging regulation, AI regulatory sandboxes and Machine Learning Operations (MLOps) as tools that facilitate compliance while enabling co-learning and active participation of multiple stakeholders. We propose a framework that fosters experimentation with automation pipelines and continuous monitoring for the deployment of future public sector AI-based services in a regulatory-compliant and technically innovative manner. AI regulatory sandboxes can be beneficial as a space for contained experimentation that goes beyond regulatory considerations to specific experimentation with the implementation of ML frameworks. While the paper presents a framework based on emerging regulations, tools and practices pertaining to the responsible use of AI, this must be validated through pilot experimentation with public and private stakeholders and regulators in different areas of high-risk AI-based services.",this paper discusses how innovations in public sector ai based services must comply with the artificial intelligence act  ai act  regulatory frameworks while enabling experimentation and participation of diverse stakeholders throughout the artificial intelligence  ai  lifecycle  the paper examines the implications of the emerging regulation  ai regulatory sandboxes and machine learning operations  mlops  as tools that facilitate compliance while enabling co learning and active participation of multiple stakeholders  we propose a framework that fosters experimentation with automation pipelines and continuous monitoring for the deployment of future public sector ai based services in a regulatory compliant and technically innovative manner  ai regulatory sandboxes can be beneficial as a space for contained experimentation that goes beyond regulatory considerations to specific experimentation with the implementation of ml frameworks  while the paper presents a framework based on emerging regulations  tools and practices pertaining to the responsible use of ai  this must be validated through pilot experimentation with public and private stakeholders and regulators in different areas of high risk ai based services ,11.995887,5.570221,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Demystifying MLOps and Presenting a Recipe for the Selection of Open-Source Tools,"Nowadays, machine learning projects have become more and more relevant to various real-world use cases. The success of complex Neural Network models depends upon many factors, as the requirement for structured and machine learning-centric project development management arises. Due to the multitude of tools available for different operational phases, responsibilities and requirements become more and more unclear. In this work, Machine Learning Operations (MLOps) technologies and tools for every part of the overall project pipeline, as well as involved roles, are examined and clearly defined. With the focus on the inter-connectivity of specific tools and comparison by well-selected requirements of MLOps, model performance, input data, and system quality metrics are briefly discussed. By identifying aspects of machine learning, which can be reused from project to project, open-source tools which help in specific parts of the pipeline, and possible combinations, an overview of support in MLOps is given. Deep learning has revolutionized the field of Image processing, and building an automated machine learning workflow for object detection is of great interest for many organizations. For this, a simple MLOps workflow for object detection with images is portrayed.",nowadays  machine learning projects have become more and more relevant to various real world use cases  the success of complex neural network models depends upon many factors  as the requirement for structured and machine learning centric project development management arises  due to the multitude of tools available for different operational phases  responsibilities and requirements become more and more unclear  in this work  machine learning operations  mlops  technologies and tools for every part of the overall project pipeline  as well as involved roles  are examined and clearly defined  with the focus on the inter connectivity of specific tools and comparison by well selected requirements of mlops  model performance  input data  and system quality metrics are briefly discussed  by identifying aspects of machine learning  which can be reused from project to project  open source tools which help in specific parts of the pipeline  and possible combinations  an overview of support in mlops is given  deep learning has revolutionized the field of image processing  and building an automated machine learning workflow for object detection is of great interest for many organizations  for this  a simple mlops workflow for object detection with images is portrayed ,8.623194,5.550023,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
An industry maturity model for implementing Machine Learning operations in manufacturing,"The next evolutionary technological step in the industry presumes the automation of the elements found within a factory, which can be accomplished through the extensive introduction of automatons, computers and Internet of Things (IoT) components. All this seeks to streamline, improve, and increase production at the lowest possible cost and avoid any failure in the creation of the product, following a strategy called ""Zero Defect Manufacturing"". Machine Learning Operations (MLOps) provide a ML-based solution to this challenge, promoting the automation of all product-relevant steps, from development to deployment. When integrating different machine learning models within manufacturing operations, it is necessary to understand what functionality is needed and what is expected. This article presents a maturity model that can help companies identify and map their current level of implementation of machine learning models.",the next evolutionary technological step in the industry presumes the automation of the elements found within a factory  which can be accomplished through the extensive introduction of automatons  computers and internet of things  iot  components  all this seeks to streamline  improve  and increase production at the lowest possible cost and avoid any failure in the creation of the product  following a strategy called  zero defect manufacturing   machine learning operations  mlops  provide a ml based solution to this challenge  promoting the automation of all product relevant steps  from development to deployment  when integrating different machine learning models within manufacturing operations  it is necessary to understand what functionality is needed and what is expected  this article presents a maturity model that can help companies identify and map their current level of implementation of machine learning models ,10.069158,3.7466576,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Democratizing artificial intelligence: How no-code AI can leverage machine learning operations,"Organizations are increasingly seeking to generate value and insights from their data by integrating advances in artificial intelligence (AI) (e.g., machine learning (ML) systems) into their operations. However, there are several managerial challenges associated with ML operations (MLOps). In this article, we outline three key challenges and discuss how an emerging type of AI platform-no-code AI-may help organizations address and overcome them. We outline how no-code AI can leverage MLOps by closing the gap between business and technology experts, enabling faster iterations between problems and solutions, and aiding infrastructure management. After outlining the important remaining challenges associated with no-code AI and MLOps, we propose three managerial recommendations. By doing so, we provide insights into an important emerging phenomenon in AI software and set the stage for further research in the area. (c) 2023 Kelley School of Business, Indiana University. Published by Elsevier Inc. This is an open access article under the CC BY license (http://creativecommons.org/ licenses/by/4.0/).",organizations are increasingly seeking to generate value and insights from their data by integrating advances in artificial intelligence  ai   e g   machine learning  ml  systems  into their operations  however  there are several managerial challenges associated with ml operations  mlops   in this article  we outline three key challenges and discuss how an emerging type of ai platform no code ai may help organizations address and overcome them  we outline how no code ai can leverage mlops by closing the gap between business and technology experts  enabling faster iterations between problems and solutions  and aiding infrastructure management  after outlining the important remaining challenges associated with no code ai and mlops  we propose three managerial recommendations  by doing so  we provide insights into an important emerging phenomenon in ai software and set the stage for further research in the area   c       kelley school of business  indiana university  published by elsevier inc  this is an open access article under the cc by license  http   creativecommons org  licenses by       ,11.389929,6.2364492,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
What drives MLOps adoption? An analysis using the TOE framework,"MLOps is essential to streamline the machine learning (ML) development process, ensure ML models stay operational, and provide users with the desired value. MLOps enhances the auditability, dependability, repeatability, and quality of ML data, models, and systems. MLOps technologies tackle several operational difficulties in an ML process. This research used the TOE framework to identify drivers and challenges to adopting MLOps tool. Data were collected from 277 professionals from various industries and AI/ML-related job roles. The responses were analysed using a three-step approach - Data Profiling, Chi-square tests and Logistic regression (LR) model. The analysis uncovered that ML usage, performance drivers, and security drive MLOps adoption, whereas regulatory environment, organizational preparation, and ML infrastructure moderately influence it. The investigation shows that management/leadership needs to be aware of MLOps technologies' benefits. This study provides insights to AI/ML professionals, academics, researchers, and machine learning model users on MLOps adoption.",mlops is essential to streamline the machine learning  ml  development process  ensure ml models stay operational  and provide users with the desired value  mlops enhances the auditability  dependability  repeatability  and quality of ml data  models  and systems  mlops technologies tackle several operational difficulties in an ml process  this research used the toe framework to identify drivers and challenges to adopting mlops tool  data were collected from     professionals from various industries and ai ml related job roles  the responses were analysed using a three step approach   data profiling  chi square tests and logistic regression  lr  model  the analysis uncovered that ml usage  performance drivers  and security drive mlops adoption  whereas regulatory environment  organizational preparation  and ml infrastructure moderately influence it  the investigation shows that management leadership needs to be aware of mlops technologies  benefits  this study provides insights to ai ml professionals  academics  researchers  and machine learning model users on mlops adoption ,10.238376,4.139044,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
MLOps: A Taxonomy and a Methodology,"Over the past few decades, the substantial growth in enterprise-data availability and the advancements in Artificial Intelligence (AI) have allowed companies to solve real-world problems using Machine Learning (ML). ML Operations (MLOps) represents an effective strategy for bringing ML models from academic resources to useful tools for solving problems in the corporate world. The current literature on MLOps is still mostly disconnected and sporadic. In this work, we review the existing scientific literature and we propose a taxonomy for clustering research papers on MLOps. In addition, we present methodologies and operations aimed at defining an ML pipeline to simplify the release of ML applications in the industry. The pipeline is based on ten steps: business problem understanding, data acquisition, ML methodology, ML training & testing, continuous integration, continuous delivery, continuous training, continuous monitoring, explainability, and sustainability. The scientific and business interest and the impact of MLOps have grown significantly over the past years: the definition of a clear and standardized methodology for conducting MLOps projects is the main contribution of this paper.",over the past few decades  the substantial growth in enterprise data availability and the advancements in artificial intelligence  ai  have allowed companies to solve real world problems using machine learning  ml   ml operations  mlops  represents an effective strategy for bringing ml models from academic resources to useful tools for solving problems in the corporate world  the current literature on mlops is still mostly disconnected and sporadic  in this work  we review the existing scientific literature and we propose a taxonomy for clustering research papers on mlops  in addition  we present methodologies and operations aimed at defining an ml pipeline to simplify the release of ml applications in the industry  the pipeline is based on ten steps  business problem understanding  data acquisition  ml methodology  ml training   testing  continuous integration  continuous delivery  continuous training  continuous monitoring  explainability  and sustainability  the scientific and business interest and the impact of mlops have grown significantly over the past years  the definition of a clear and standardized methodology for conducting mlops projects is the main contribution of this paper ,11.273718,6.6505775,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Riding a bicycle while building its wheels: the process of machine learning-based capability development and IT-business alignment practices,"PurposeRecent advancements in Artificial Intelligence (AI) and, at its core, Machine Learning (ML) offer opportunities for organizations to develop new or enhance existing capabilities. Despite the endless possibilities, organizations face operational challenges in harvesting the value of ML-based capabilities (MLbC), and current research has yet to explicate these challenges and theorize their remedies. To bridge the gap, this study explored the current practices to propose a systematic way of orchestrating MLbC development, which is an extension of ongoing digitalization of organizations.Design/methodology/approachData were collected from Finland's Artificial Intelligence Accelerator (FAIA) and complemented by follow-up interviews with experts outside FAIA in Europe, China and the United States over four years. Data were analyzed through open coding, thematic analysis and cross-comparison to develop a comprehensive understanding of the MLbC development process.FindingsThe analysis identified the main components of MLbC development, its three phases (development, release and operation) and two major MLbC development challenges: Temporal Complexity and Context Sensitivity. The study then introduced Fostering Temporal Congruence and Cultivating Organizational Meta-learning as strategic practices addressing these challenges.Originality/valueThis study offers a better theoretical explanation for the MLbC development process beyond MLOps (Machine Learning Operations) and its hindrances. It also proposes a practical way to align ML-based applications with business needs while accounting for their structural limitations. Beyond the MLbC context, this study offers a strategic framework that can be adapted for different cases of digital transformation that include automation and augmentation of work.",purposerecent advancements in artificial intelligence  ai  and  at its core  machine learning  ml  offer opportunities for organizations to develop new or enhance existing capabilities  despite the endless possibilities  organizations face operational challenges in harvesting the value of ml based capabilities  mlbc   and current research has yet to explicate these challenges and theorize their remedies  to bridge the gap  this study explored the current practices to propose a systematic way of orchestrating mlbc development  which is an extension of ongoing digitalization of organizations design methodology approachdata were collected from finland s artificial intelligence accelerator  faia  and complemented by follow up interviews with experts outside faia in europe  china and the united states over four years  data were analyzed through open coding  thematic analysis and cross comparison to develop a comprehensive understanding of the mlbc development process findingsthe analysis identified the main components of mlbc development  its three phases  development  release and operation  and two major mlbc development challenges  temporal complexity and context sensitivity  the study then introduced fostering temporal congruence and cultivating organizational meta learning as strategic practices addressing these challenges originality valuethis study offers a better theoretical explanation for the mlbc development process beyond mlops  machine learning operations  and its hindrances  it also proposes a practical way to align ml based applications with business needs while accounting for their structural limitations  beyond the mlbc context  this study offers a strategic framework that can be adapted for different cases of digital transformation that include automation and augmentation of work ,9.288856,5.5431943,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
Towards a Risk-Based Continuous Auditing-Based Certification for Machine Learning,"Machine learning systems have gained widespread adoption across various industries. This includes highly regulated ones that need to match certain quality requirements based on a given risk exposure. The MLOps paradigm, following a similar approach to DevOps, promises major improvements in quality and speed, with a focus on deploying ML models at a fast pace with high quality on an automated basis. However, traditional point-in-time certifications with manual audits are inadequate for MLOps setups due to frequent changes to the ML system. To overcome this challenge, we propose Continuous Audit-Based Certification (CABC), which uses automated audits to issue or revoke certificates based on an automated assessment of artifacts from the MLOps lifecycle. Our approach utilizes artifacts from the MLOps lifecycle for quality measurements based on standards such as ISO 25012. We propose a risk-based measurement selection, an audit API for standardized retrieval of data for measurement, a tamper-proof data collection process, and an architecture for separation of duties in the certification process. CABC aims to improve efficiency, enhance trust in the ML system, and support highly regulated industries in achieving their quality goals.",machine learning systems have gained widespread adoption across various industries  this includes highly regulated ones that need to match certain quality requirements based on a given risk exposure  the mlops paradigm  following a similar approach to devops  promises major improvements in quality and speed  with a focus on deploying ml models at a fast pace with high quality on an automated basis  however  traditional point in time certifications with manual audits are inadequate for mlops setups due to frequent changes to the ml system  to overcome this challenge  we propose continuous audit based certification  cabc   which uses automated audits to issue or revoke certificates based on an automated assessment of artifacts from the mlops lifecycle  our approach utilizes artifacts from the mlops lifecycle for quality measurements based on standards such as iso        we propose a risk based measurement selection  an audit api for standardized retrieval of data for measurement  a tamper proof data collection process  and an architecture for separation of duties in the certification process  cabc aims to improve efficiency  enhance trust in the ml system  and support highly regulated industries in achieving their quality goals ,7.8440385,5.1096115,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Structure Learning and Hyperparameter Optimization Using an Automated Machine Learning (AutoML) Pipeline,"In this paper, we built an automated machine learning (AutoML) pipeline for structure-based learning and hyperparameter optimization purposes. The pipeline consists of three main automated stages. The first carries out the collection and preprocessing of the dataset from the Kaggle database through the Kaggle API. The second utilizes the Keras-Bayesian optimization tuning library to perform hyperparameter optimization. The third focuses on the training process of the machine learning (ML) model using the hyperparameter values estimated in the previous stage, and its evaluation is performed on the testing data by implementing the Neptune AI. The main technologies used to develop a stable and reusable machine learning pipeline are the popular Git version control system, the Google cloud virtual machine, the Jenkins server, the Docker containerization technology, and the Ngrok reverse proxy tool. The latter can securely publish the local Jenkins address as public through the internet. As such, some parts of the proposed pipeline are taken from the thematic area of machine learning operations (MLOps), resulting in a hybrid software scheme. The machine learning model was used to evaluate the pipeline, which is a multilayer perceptron (MLP) that combines typical dense, as well as polynomial, layers. The simulation results show that the proposed pipeline exhibits a reliable and accurate performance while managing to boost the network's performance in classification tasks.",in this paper  we built an automated machine learning  automl  pipeline for structure based learning and hyperparameter optimization purposes  the pipeline consists of three main automated stages  the first carries out the collection and preprocessing of the dataset from the kaggle database through the kaggle api  the second utilizes the keras bayesian optimization tuning library to perform hyperparameter optimization  the third focuses on the training process of the machine learning  ml  model using the hyperparameter values estimated in the previous stage  and its evaluation is performed on the testing data by implementing the neptune ai  the main technologies used to develop a stable and reusable machine learning pipeline are the popular git version control system  the google cloud virtual machine  the jenkins server  the docker containerization technology  and the ngrok reverse proxy tool  the latter can securely publish the local jenkins address as public through the internet  as such  some parts of the proposed pipeline are taken from the thematic area of machine learning operations  mlops   resulting in a hybrid software scheme  the machine learning model was used to evaluate the pipeline  which is a multilayer perceptron  mlp  that combines typical dense  as well as polynomial  layers  the simulation results show that the proposed pipeline exhibits a reliable and accurate performance while managing to boost the network s performance in classification tasks ,7.500902,5.908022,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
FedOps: A Platform of Federated Learning Operations With Heterogeneity Management,"Federated learning (FL) is a decentralized machine learning (ML) method that enables model training while preserving privacy. FL is gaining attention because it avoids data transfer to the server, facilitating the decentralized learning of the traditional ML model. Despite its potential, FL project is significantly more challenging to develop than centralized ML methods owing to decentralized local data. We propose FedOps, federated learning operations for constructing systematic FL project by enhancing machine learning operations (MLOps) to be effectively applied to FL while preserving its core process. To address complexity of FL implementation, we developed FedOps platform, which involves FedOps-based projects to manage the whole lifecycle in FL context. We also investigated methods to identify performance degradation factors in FL and suggest an approach for improvement. FedOps Platform provides an analysis tool for client heterogeneity, called chunk-bench. This tool enables researchers and engineers to gain insights into systems heterogeneity by using only small chunk of the clients' data to execute test in the shortest time possible while tracking the systems heterogeneity across the clients. By addressing systems heterogeneity, FedOps Platform achieved 13%-43% improvement in communication cost-to-accuracy and 20%-68% improvement in time-to-accuracy. We believe that FedOps Platform offers an optimal solution for end-to-end development of FL projects, with significantly improving both computational and communication efficiencies.",federated learning  fl  is a decentralized machine learning  ml  method that enables model training while preserving privacy  fl is gaining attention because it avoids data transfer to the server  facilitating the decentralized learning of the traditional ml model  despite its potential  fl project is significantly more challenging to develop than centralized ml methods owing to decentralized local data  we propose fedops  federated learning operations for constructing systematic fl project by enhancing machine learning operations  mlops  to be effectively applied to fl while preserving its core process  to address complexity of fl implementation  we developed fedops platform  which involves fedops based projects to manage the whole lifecycle in fl context  we also investigated methods to identify performance degradation factors in fl and suggest an approach for improvement  fedops platform provides an analysis tool for client heterogeneity  called chunk bench  this tool enables researchers and engineers to gain insights into systems heterogeneity by using only small chunk of the clients  data to execute test in the shortest time possible while tracking the systems heterogeneity across the clients  by addressing systems heterogeneity  fedops platform achieved         improvement in communication cost to accuracy and         improvement in time to accuracy  we believe that fedops platform offers an optimal solution for end to end development of fl projects  with significantly improving both computational and communication efficiencies ,6.0477695,7.7152224,1,MLOps - Scalability - Continuous Deployment - AI Monitoring - Edge Computing - Operationalization,"MLOps for Scalable, Real-Time Production Systems"
Continuous Software Engineering Practices in AI/ML Development Past the Narrow Lens of MLOps: Adoption Challenges,"Background: Continuous software engineering practices are currently considered state of the art in Software Engineering (SE). Recently, this interest in continuous SE has extended to ML system development as well, primarily through MLOps. However, little is known about continuous SE in ML development outside the specific continuous practices present in MLOps. Aim: In this paper, we explored continuous SE in ML development more generally, outside the specific scope of MLOps. We sought to understand what challenges organizations face in adopting all the 13 continuous SE practices identified in existing literature. Method: We conducted a multiple case study of organizations developing ML systems. Data from the cases was collected through thematic interviews. The interview instrument focused on different aspects of continuous SE, as well as the use of relevant tools and methods. Results: We interviewed 8 ML experts from different organizations. Based on the data, we identified various challenges associated with the adoption of continuous SE practices in ML development. Our results are summarized through 7 key findings. Conclusion: The largest challenges we identified seem to stem from communication issues. ML experts seem to continue to work in silos, detached from both the rest of the project and the customers.",background  continuous software engineering practices are currently considered state of the art in software engineering  se   recently  this interest in continuous se has extended to ml system development as well  primarily through mlops  however  little is known about continuous se in ml development outside the specific continuous practices present in mlops  aim  in this paper  we explored continuous se in ml development more generally  outside the specific scope of mlops  we sought to understand what challenges organizations face in adopting all the    continuous se practices identified in existing literature  method  we conducted a multiple case study of organizations developing ml systems  data from the cases was collected through thematic interviews  the interview instrument focused on different aspects of continuous se  as well as the use of relevant tools and methods  results  we interviewed   ml experts from different organizations  based on the data  we identified various challenges associated with the adoption of continuous se practices in ml development  our results are summarized through   key findings  conclusion  the largest challenges we identified seem to stem from communication issues  ml experts seem to continue to work in silos  detached from both the rest of the project and the customers ,10.155895,4.400902,3,MLOps - Industry 4.0 - Machine Learning Operations - Continuous Deployment - AI in Manufacturing - Adoption Challenges,Challenges and Applications of MLOps in Industry
Clinical deployment environments: Five pillars of translational machine learning for health,"Machine Learning for Health (ML4H) has demonstrated efficacy in computer imaging and other self-contained digital workflows, but has failed to substantially impact routine clinical care. This is no longer because of poor adoption of Electronic Health Records Systems (EHRS), but because ML4H needs an infrastructure for development, deployment and evaluation within the healthcare institution. In this paper, we propose a design pattern called a Clinical Deployment Environment (CDE). We sketch the five pillars of the CDE: (1) real world development supported by live data where ML4H teams can iteratively build and test at the bedside (2) an ML-Ops platform that brings the rigour and standards of continuous deployment to ML4H (3) design and supervision by those with expertise in AI safety (4) the methods of implementation science that enable the algorithmic insights to influence the behaviour of clinicians and patients and (5) continuous evaluation that uses randomisation to avoid bias but in an agile manner. The CDE is intended to answer the same requirements that bio-medicine articulated in establishing the translational medicine domain. It envisions a transition from ""real-world"" data to ""real-world"" development.",machine learning for health  ml h  has demonstrated efficacy in computer imaging and other self contained digital workflows  but has failed to substantially impact routine clinical care  this is no longer because of poor adoption of electronic health records systems  ehrs   but because ml h needs an infrastructure for development  deployment and evaluation within the healthcare institution  in this paper  we propose a design pattern called a clinical deployment environment  cde   we sketch the five pillars of the cde      real world development supported by live data where ml h teams can iteratively build and test at the bedside     an ml ops platform that brings the rigour and standards of continuous deployment to ml h     design and supervision by those with expertise in ai safety     the methods of implementation science that enable the algorithmic insights to influence the behaviour of clinicians and patients and     continuous evaluation that uses randomisation to avoid bias but in an agile manner  the cde is intended to answer the same requirements that bio medicine articulated in establishing the translational medicine domain  it envisions a transition from  real world  data to  real world  development ,8.6065035,5.852752,2,MLOps - Ethical AI - Machine Learning Lifecycle - Model Deployment - AI Governance - Data Science Automation - Agile Methodologies,Comprehensive MLOps and Responsible AI Practices
